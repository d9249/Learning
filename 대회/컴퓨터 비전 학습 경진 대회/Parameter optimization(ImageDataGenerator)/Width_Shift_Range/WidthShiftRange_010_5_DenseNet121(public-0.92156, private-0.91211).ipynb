{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WidthShiftRange_010_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4trefoR0PXeWYf2P9llpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/WidthShiftRange_010_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c74489c-afe3-4c81-b918-9ccca75fa89c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 31 08:43:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9650cc3-4100-4476-d2d0-628a2a401846"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504b7c86-7986-431e-bf9c-93028a9f97d2"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95862612-c6a8-4320-9059-b804415d9421"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8ddb68-20ef-49ac-c4b0-387e728f464c"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 39s 269ms/step - loss: 1.7833 - accuracy: 0.3946 - val_loss: 4.5059 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 1.2006 - accuracy: 0.5828 - val_loss: 6.0180 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11330\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.9569 - accuracy: 0.6906 - val_loss: 7.3050 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11330\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.8221 - accuracy: 0.7211 - val_loss: 9.5494 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.7415 - accuracy: 0.7418 - val_loss: 8.3452 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.6159 - accuracy: 0.7942 - val_loss: 5.5234 - val_accuracy: 0.1897\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11330 to 0.18966, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.6243 - accuracy: 0.7875 - val_loss: 5.4937 - val_accuracy: 0.2414\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.18966 to 0.24138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.5376 - accuracy: 0.8246 - val_loss: 3.6566 - val_accuracy: 0.3621\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.24138 to 0.36207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.5469 - accuracy: 0.8149 - val_loss: 2.0629 - val_accuracy: 0.4631\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.36207 to 0.46305, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.4763 - accuracy: 0.8429 - val_loss: 1.1644 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.46305 to 0.67241, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.3954 - accuracy: 0.8642 - val_loss: 0.7640 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.67241 to 0.78818, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.4287 - accuracy: 0.8508 - val_loss: 1.3724 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.78818\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.3991 - accuracy: 0.8636 - val_loss: 2.3586 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.78818\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.3610 - accuracy: 0.8770 - val_loss: 0.9095 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.78818\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.3566 - accuracy: 0.8794 - val_loss: 1.2752 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.78818\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.3063 - accuracy: 0.8916 - val_loss: 0.9338 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.78818\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.2873 - accuracy: 0.8983 - val_loss: 0.5630 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.78818 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.2623 - accuracy: 0.9129 - val_loss: 0.7205 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85222\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2329 - accuracy: 0.9220 - val_loss: 0.7112 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85222\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2591 - accuracy: 0.9099 - val_loss: 0.7331 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85222\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2560 - accuracy: 0.9147 - val_loss: 1.2418 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85222\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2597 - accuracy: 0.9117 - val_loss: 1.0288 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85222\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.2058 - accuracy: 0.9275 - val_loss: 0.4663 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.85222 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.2114 - accuracy: 0.9166 - val_loss: 0.5355 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86946\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.1989 - accuracy: 0.9318 - val_loss: 1.2053 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86946\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2356 - accuracy: 0.9227 - val_loss: 0.6306 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86946\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.2124 - accuracy: 0.9239 - val_loss: 0.5982 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86946\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1698 - accuracy: 0.9428 - val_loss: 0.7571 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86946\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.1467 - accuracy: 0.9519 - val_loss: 0.6695 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86946\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1448 - accuracy: 0.9507 - val_loss: 0.5727 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86946\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1376 - accuracy: 0.9555 - val_loss: 0.7081 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.86946\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.1253 - accuracy: 0.9592 - val_loss: 0.5628 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86946\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1346 - accuracy: 0.9531 - val_loss: 0.5242 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86946\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1352 - accuracy: 0.9543 - val_loss: 0.8880 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86946\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.2257 - accuracy: 0.9184 - val_loss: 2.0446 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86946\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.1362 - accuracy: 0.9513 - val_loss: 0.5666 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86946\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1212 - accuracy: 0.9616 - val_loss: 0.4671 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86946\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1472 - accuracy: 0.9476 - val_loss: 0.8533 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86946\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1196 - accuracy: 0.9586 - val_loss: 0.5896 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86946\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1126 - accuracy: 0.9622 - val_loss: 0.6067 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86946\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1000 - accuracy: 0.9616 - val_loss: 0.5783 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.86946\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1453 - accuracy: 0.9434 - val_loss: 0.8665 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86946\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1451 - accuracy: 0.9549 - val_loss: 0.7017 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86946\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0948 - accuracy: 0.9641 - val_loss: 0.6572 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86946\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0774 - accuracy: 0.9677 - val_loss: 0.6289 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86946\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0943 - accuracy: 0.9702 - val_loss: 1.2844 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.86946\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.1556 - accuracy: 0.9470 - val_loss: 0.7732 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.86946\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.6488 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.86946\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0990 - accuracy: 0.9695 - val_loss: 0.5942 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.86946\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0734 - accuracy: 0.9769 - val_loss: 0.4077 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.86946 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0813 - accuracy: 0.9714 - val_loss: 0.5242 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90394\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1040 - accuracy: 0.9720 - val_loss: 0.5059 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90394\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 0.4484 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90394\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0441 - accuracy: 0.9884 - val_loss: 0.6053 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90394\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.7025 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90394\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0863 - accuracy: 0.9683 - val_loss: 0.6694 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90394\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.1076 - accuracy: 0.9659 - val_loss: 0.5859 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90394\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.4811 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90394\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0636 - accuracy: 0.9805 - val_loss: 0.5421 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90394\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0824 - accuracy: 0.9787 - val_loss: 0.5711 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90394\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0731 - accuracy: 0.9756 - val_loss: 0.4663 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90394\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.4603 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90394\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.5099 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90394\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0381 - accuracy: 0.9860 - val_loss: 0.7038 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90394\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.9856 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90394\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0711 - accuracy: 0.9811 - val_loss: 0.9614 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90394\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.9795 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90394\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0825 - accuracy: 0.9708 - val_loss: 0.5785 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90394\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0728 - accuracy: 0.9781 - val_loss: 0.4458 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90394\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.6806 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90394\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.6362 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90394\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 1.2596 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90394\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0954 - accuracy: 0.9702 - val_loss: 0.7757 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90394\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0925 - accuracy: 0.9689 - val_loss: 0.9567 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90394\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0513 - accuracy: 0.9799 - val_loss: 0.5005 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90394\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.5150 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90394\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.5021 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90394\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.6253 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90394\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4604 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90394\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1018 - accuracy: 0.9635 - val_loss: 0.8713 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90394\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0734 - accuracy: 0.9726 - val_loss: 1.2874 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90394\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0595 - accuracy: 0.9811 - val_loss: 0.5427 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90394\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.7220 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90394\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0818 - accuracy: 0.9720 - val_loss: 0.8615 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90394\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0992 - accuracy: 0.9695 - val_loss: 0.7598 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90394\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.6773 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90394\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 0.5414 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90394\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0920 - accuracy: 0.9653 - val_loss: 0.5855 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90394\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.4226 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90394\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.3917 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00090: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.4771 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.90640 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0542 - accuracy: 0.9817 - val_loss: 0.6113 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90887\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.4810 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90887\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.6450 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90887\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0601 - accuracy: 0.9829 - val_loss: 0.5279 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90887\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.5333 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90887\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0163 - accuracy: 0.9970 - val_loss: 0.4017 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90887\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.4232 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00098: val_accuracy improved from 0.90887 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.5264 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0305 - accuracy: 0.9878 - val_loss: 0.5473 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.6808 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0482 - accuracy: 0.9817 - val_loss: 0.7280 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.6538 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.4299 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00104: val_accuracy improved from 0.91379 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.6388 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91626\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.7151 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91626\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.5681 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91626\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 1.1372 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91626\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0646 - accuracy: 0.9836 - val_loss: 0.6811 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91626\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0740 - accuracy: 0.9750 - val_loss: 0.8380 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91626\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0605 - accuracy: 0.9793 - val_loss: 0.8198 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91626\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0633 - accuracy: 0.9817 - val_loss: 0.9337 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91626\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 0.6159 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91626\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.7507 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91626\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0502 - accuracy: 0.9884 - val_loss: 0.5920 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91626\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0350 - accuracy: 0.9866 - val_loss: 0.7778 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91626\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 1.0259 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91626\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 1.2139 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91626\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.3996 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00119: val_accuracy improved from 0.91626 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.4966 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92118\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.3841 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92118\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.7442 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92118\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.5131 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92118\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.5970 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92118\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0411 - accuracy: 0.9842 - val_loss: 0.4380 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92118\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.4838 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92118\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.5102 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92118\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.3584 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00128: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.3730 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92611\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 1.7718 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92611\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0887 - accuracy: 0.9708 - val_loss: 1.2204 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92611\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.7154 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92611\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0819 - accuracy: 0.9750 - val_loss: 1.1716 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92611\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.8417 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92611\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.8132 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92611\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.4922 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92611\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.3411 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92611\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.5439 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92611\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.5731 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92611\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.7834 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92611\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.5763 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92611\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.5801 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92611\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.4470 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92611\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.3877 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92611\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4007 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92611\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.3472 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92611\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92611\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5409 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92611\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4837 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92611\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.4193 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92611\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.3938 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92611\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92611\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00153: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92857\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5962 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92857\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.8077 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92857\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1201 - accuracy: 0.9659 - val_loss: 2.1941 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92857\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 0.8425 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92857\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0511 - accuracy: 0.9793 - val_loss: 1.0142 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92857\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.6867 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92857\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.6630 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92857\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.4310 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92857\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.5639 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92857\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4785 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92857\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.5405 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92857\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.4684 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92857\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4796 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92857\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4935 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92857\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4313 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92857\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4890 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92857\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92857\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4445 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92857\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4780 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92857\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5376 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92857\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3510 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92857\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3673 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92857\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92857\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.4896 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92857\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0531 - accuracy: 0.9878 - val_loss: 1.0630 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92857\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1952 - accuracy: 0.9452 - val_loss: 2.3600 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92857\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 0.7359 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92857\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0540 - accuracy: 0.9854 - val_loss: 0.4118 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92857\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.5829 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92857\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.5861 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92857\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.4216 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92857\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4915 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92857\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3803 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92857\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5444 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92857\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3659 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92857\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92857\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4388 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92857\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5031 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92857\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4230 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92857\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5251 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92857\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4928 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92857\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6047 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92857\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.5324 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92857\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0216 - accuracy: 0.9909 - val_loss: 0.5533 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92857\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0248 - accuracy: 0.9890 - val_loss: 0.7321 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92857\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0489 - accuracy: 0.9836 - val_loss: 0.8185 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92857\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 1.0700 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92857\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.6419 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92857\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.7956 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92857\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.7615 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92857\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.6882 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92857\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.6085 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92857\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5521 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92857\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.4610 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92857\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5309 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92857\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4714 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.6736 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.7798 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.9968 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.6595 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.8908 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.5673 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0440 - accuracy: 0.9903 - val_loss: 1.3121 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 1.0390 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.9066 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.5264 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.6270 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5718 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.7911 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.7272 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0287 - accuracy: 0.9884 - val_loss: 0.7133 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.6463 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.7152 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.6298 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.8104 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5915 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.7409 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6699 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0077 - accuracy: 0.9957 - val_loss: 0.6513 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5131 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 8.2919e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4718 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 8.1667e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5278 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5320 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5282 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6684 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.7165 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5130 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5556 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5121 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 8.0367e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4616 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 5.0475e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 7.6900e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 9.4151e-04 - accuracy: 0.9994 - val_loss: 0.5336 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 5.8518e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00253: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 5.0721e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93350\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 1.2642e-04 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00255: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 4.0695e-04 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93596\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 6.3110e-04 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93596\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 4.3105e-04 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93596\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 2.1372e-04 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93596\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 7.6633e-04 - accuracy: 0.9994 - val_loss: 0.4553 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93596\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 1.6008 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93596\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.2157 - accuracy: 0.9415 - val_loss: 5.4745 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93596\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.1007 - accuracy: 0.9708 - val_loss: 1.9008 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93596\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0600 - accuracy: 0.9769 - val_loss: 0.6998 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93596\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.4559 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93596\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.4508 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93596\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5069 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93596\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93596\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4295 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93596\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93596\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93596\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4364 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93596\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5037 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93596\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.4740 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93596\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.6009 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93596\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.7260 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93596\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6092 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93596\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5444 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93596\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.9368 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93596\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.7899 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93596\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 0.8924 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93596\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.9352 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93596\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6342 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93596\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.5836 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93596\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.6902 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93596\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.6913 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93596\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.6337 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93596\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.9187 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93596\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.7203 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93596\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.6456 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93596\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93596\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 8.4592e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93596\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 7.0186e-04 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93596\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 4.9936e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93596\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 4.6065e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93596\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.6212 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93596\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.4862 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93596\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0042 - accuracy: 0.9976 - val_loss: 0.6181 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93596\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.5339 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93596\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.7195 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93596\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.8190 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93596\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0109 - accuracy: 0.9945 - val_loss: 0.7449 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93596\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.8369 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93596\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.7912 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93596\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.5717 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93596\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6534 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93596\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6268 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93596\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0647 - accuracy: 0.9817 - val_loss: 0.9168 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93596\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0553 - accuracy: 0.9848 - val_loss: 15.8604 - val_accuracy: 0.2562\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93596\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.1222 - accuracy: 0.9714 - val_loss: 1.9636 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93596\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0190 - accuracy: 0.9915 - val_loss: 1.1321 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93596\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5824 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93596\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.6774 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93596\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.5159 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93596\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.6110 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93596\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.6171 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93596\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.6449 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93596\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93596\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5413 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93596\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4587 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93596\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93596\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4831 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93596\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4424 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93596\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93596\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5124 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93596\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.5642 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93596\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6908 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93596\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93596\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.7535 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93596\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6129 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93596\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.6246 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93596\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5841 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93596\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5925 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93596\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5811 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93596\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5744 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93596\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6375 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93596\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5946 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93596\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5429 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93596\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6103 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93596\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.6078e-04 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93596\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.2661e-04 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93596\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93596\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.6501 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93596\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5852 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93596\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.7453 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93596\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5902 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93596\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93596\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.7073e-04 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93596\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 3.2083e-04 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93596\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 3.6797e-04 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93596\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5088 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93596\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 9.5374e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93596\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 5.3673e-04 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93596\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93596\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.5705e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93596\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 2.0030e-04 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93596\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 4.6505e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93596\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 1.5569 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93596\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.1609 - accuracy: 0.9488 - val_loss: 2.2208 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93596\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.7612 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93596\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.5443 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93596\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.8535 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93596\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.5111 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93596\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5021 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93596\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5305 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93596\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93596\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4474 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93596\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4861 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93596\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.5390 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93596\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4886 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93596\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93596\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93596\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.1299e-04 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93596\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93596\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93596\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4695 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93596\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.0806e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93596\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 3.5339e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93596\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 4.5725e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93596\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.4980e-04 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93596\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 2.7459e-04 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93596\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5943 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93596\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5870 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93596\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.8947 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93596\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 1.0671 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93596\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0620 - accuracy: 0.9805 - val_loss: 1.0190 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93596\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.9264 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93596\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0250 - accuracy: 0.9896 - val_loss: 0.7348 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93596\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.7696 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93596\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6027 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93596\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0118 - accuracy: 0.9945 - val_loss: 0.8225 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93596\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.4709 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93596\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93596\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4899 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93596\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.2116e-04 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93596\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 8.0009e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93596\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.4251e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93596\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.4225e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93596\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4912 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93596\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.9636 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93596\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0258 - accuracy: 0.9903 - val_loss: 2.0520 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93596\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.6557 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93596\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0127 - accuracy: 0.9945 - val_loss: 0.6474 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93596\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.8715 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93596\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.9720 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93596\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.9588 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93596\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 0.5171 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93596\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6377 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93596\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.5376 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93596\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.6398 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93596\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.5700 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93596\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4602 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93596\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5217 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93596\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4754 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93596\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 6.9269e-04 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93596\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93596\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4864 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93596\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.1647e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93596\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 3.7035e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93596\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 8.8031e-04 - accuracy: 0.9994 - val_loss: 0.4813 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93596\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 7.9364e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93596\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 3.1026e-04 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93596\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.8833 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93596\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4782 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93596\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5250 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93596\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.6302 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93596\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.5049 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93596\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.8168 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93596\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.5173 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93596\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.5744 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93596\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5989 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93596\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4943 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93596\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4741 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93596\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93596\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 7.4661e-04 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93596\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4953 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93596\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5251 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93596\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.8222 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93596\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.5093 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93596\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.4484 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93596\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.8859 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93596\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.5857 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93596\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.7932 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93596\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5664 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93596\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 7.5260e-04 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93596\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.9201 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93596\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0779 - accuracy: 0.9744 - val_loss: 3.3255 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93596\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.5605 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93596\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5826 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93596\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4496 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93596\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4449 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93596\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4267 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93596\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5388 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93596\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93596\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.4853 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93596\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4477 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93596\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3840 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93596\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4210 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93596\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4767 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93596\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4155 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93596\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 7.0383e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93596\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 6.6446e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93596\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93596\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 3.5989e-04 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93596\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 5.1112e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93596\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 5.8218e-04 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93596\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4340 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93596\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 5.1580e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93596\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 3.9284e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93596\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 8.2257e-04 - accuracy: 0.9994 - val_loss: 0.4063 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93596\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5049 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93596\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5147 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93596\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5523 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93596\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4498 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93596\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4641 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93596\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5019 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93596\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 12s 223ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.6167 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93596\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4115 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93596\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3494 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93596\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 12s 224ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.4577 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93596\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.6289 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93596\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6588 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93596\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5959 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93596\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 1.2180 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93596\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0268 - accuracy: 0.9939 - val_loss: 0.5906 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93596\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.5809 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93596\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0306 - accuracy: 0.9939 - val_loss: 0.6744 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93596\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6072 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93596\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5823 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93596\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4891 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93596\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4597 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93596\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4461 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93596\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 7.9010e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93596\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 8.4708e-04 - accuracy: 0.9994 - val_loss: 0.4453 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93596\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 6.5007e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93596\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.5943 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93596\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 12s 222ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.6966 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93596\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6685 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93596\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 12s 220ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5088 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93596\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5582 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f28103eb950>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3b4328b0-422a-49a8-9c43-58b80cb94b22"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8ab331-c833-4d38-e9ff-dcdde750d4df"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0446f0-54e5-4145-dade-3752759b14f0"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e6225a60-b00d-48ce-e3b5-1f3bd8e9e416"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d1aacd15-0602-4cd7-d7dc-3db9ba85778a"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_010_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_010_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_da85fc12-3f09-4fa1-b00c-c967ffdd21b9\", \"WidthShiftRange_010_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}