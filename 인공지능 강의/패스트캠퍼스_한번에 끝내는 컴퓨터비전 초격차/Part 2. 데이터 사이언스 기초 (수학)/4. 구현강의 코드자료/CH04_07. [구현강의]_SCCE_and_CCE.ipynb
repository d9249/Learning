{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CH04_07. [구현강의]_SCCE_and_CCE","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMdKfnkjLJdXUp5jUGjJEzu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"p6lRj3WUsaLg"},"source":["#SCCE Calculation"]},{"cell_type":"code","metadata":{"id":"RNBZZiCWsYux"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","batch_size, n_class = 16, 5\n","\n","predictions = tf.random.uniform(shape=(batch size, n_class),\n","                                      minval=0, maxval=l,\n","                                      dtype = tf.float32)\n","\n","pred_sum = tf.reshape(tf.reduce_sum(predictions, axis=1), (-1, 1))\n","predictions = predictions/pred_sum\n","\n","labels = tf.random.uniform(shape=(batch_size, ), \n","                                  minval=0, maxval=n_class,\n","                                  dtype = tf.int32)\n","\n","loss_object © SparseCategoricalCrossentropy()\n","loss = loss_object{labels, predictions)\n","\n","print(loss.numpy())\n","\n","ce = 0\n","for label, prediction in zip(labels, predictions):\n","    ce += -tf.math.log(prediction( label))\n","    Ce /= batch_size\n","print(ce.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"byV8OnVzsbdr"},"source":["#SCCE with Model/Dataset"]},{"cell_type":"code","metadata":{"id":"KUmbXEMMsbry"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","W, n_feature = 100, 2\n","nclass = 5\n","\n","X = tf.zeros(shapes(0, n_feature))\n","Y = tf.zeros(shape=(0, 1),dtype=tf.int32)\n","\n","for class_idx in range(n_classa):\n","  center = tf.random.uniform(minval=-15, maxvale15, shapee(2, ))\n","\n","  x1 = center[0] + tf.random.normal(shape=(N, 1))\n","  x2 = center[1] + tf.random.normal(shape=(N, 1))\n","\n","  x = tf.concat((xl, x2), axisel)\n","  y = class_idx*tf.ones(shape=(N, 1}, dtype=tf.int32)\n","\n","  X = tf.concat((X, x), axis=0)\n","  Y = tf.concat((Y, y), axis=0)\n","\n","dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","dataset = dataset.batch(batch_size)\n","\n","model = Dense(unitsen_claes, activations ‘softmax')\n","loss_object © SparseCategoricalCrossentropy()\n","\n","for x, y in dataset:\n","  predictions = model({x)\n","  loss = loss_object(y, predictions)\n","  print(loss.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPXB5LGAscFQ"},"source":["# CCE Calculation"]},{"cell_type":"code","metadata":{"id":"pFfNK093scRG"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.losses import CategoricalCroseentropy\n","\n","batch_size, n_class = 16, 5\n","\n","predictions = tf.random.uniform(shape=(batch_size, n_class),\n","                                minval = 0, maxval =1,\n","                                dtype = tf.float32)\n","pred_sum = tf.reshape(tf.reduce_sum(predictions, axis=1), (-1, 1))\n","predictions = predictions/pred_sum\n","\n","labels = tf.random.uniform(shape=(batch_size, ),\n","                          minval = 0,maxval=n_class,\n","                          dtype = tf.int32)\n","\n","labels = tf.one_hot(labels, n_class)\n","\n","loss_object = CategoricalCrossentropy()\n","loss = loss_object(labels, predictions)\n","\n","print(\"CCE(Tensorfiow): “, loss.numpy())\n","\n","cce_man = tf.reduce_mean(tf.reduce_sum(labels*tf.math.log(predictions), axis=1))\n","print(\"CCE(Manual): \", cce_man.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZw3CnJssjno"},"source":["# CCE with Model/Dataset"]},{"cell_type":"code","metadata":{"id":"Vtlm1Ut7sj-W"},"source":["import tensorflow as tf\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","N, n_feature = 6, 2\n","n_class «5\n","X = tf.zeros(shape=(0, n_feature)}\n","Y = tf.zeros(shapes(0, ), dtype=tf.int32)\n","for class_idx in range(n_class):\n","  center = tf.random.uniform(minval=-15, maxvale15, shape=(2, ))\n","  \n","  x1 = center{0) + tf.random.normal(shapes(N, 1))\n","  x2 © center{1] ¢ tf.random.normal(shape=(N, 1))\n","\n","  x = tf.concat((xl, x2), axis=1)\n","  y = claes_idx*tf.ones(shapes(N, ), dtype = tf.int32)\n","\n","  X = tf.concat({(X, x), axis=0)\n","  Y = tf.concat((Y, y), axis=0)\n","\n","Y = tf.one_hot(Y, depth=n_class, dtype=tf.int32)\n","\n","dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","dataset = dataset .batch(batch_ size)\n","\n","model = Dense(units=n_class, activation=‘softmax')\n","loss_object = CategoricalCrossentropy()\n","\n","for x, y in dataset:\n","  predictions = model(x)\n","  loss = loss _object(y, predictions)\n","  print(loss.numpy())"],"execution_count":null,"outputs":[]}]}