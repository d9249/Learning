{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "DenseNet161_epoch500_batchsize12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet161_epoch500_batchsize12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CazxOt_4UQwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7241bc53-529b-4b62-eb46-405952a9ad68"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 16 08:41:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7UcyDC5UIu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f355c3d9-4b5e-4485-a95c-4933a73ff3d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUAr_kpxUW1M"
      },
      "source": [
        "!unzip -uq \"/content/drive/MyDrive/DACON_CropsAreSick/sicks.zip\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUdmpZtKTK2Z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGuJ_GzwTK2c"
      },
      "source": [
        "train_total = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSEfcP0fTK2f"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "batch_size = 12\n",
        "class_n = len(train_total['disease_code'].unique())\n",
        "learning_rate = 0.0001\n",
        "epochs = 500\n",
        "save_path = '/content/drive/MyDrive/DACON_CropsAreSick/DenseNet161_model.pt'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3_1FuRYTK2h"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, labels=None, mode='train'):\n",
        "        self.mode = mode\n",
        "        self.files = files\n",
        "        if mode == 'train':\n",
        "            self.labels = labels\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        if self.mode == 'train':\n",
        "            img = cv2.imread('./train_imgs/'+self.files[i])\n",
        "            img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
        "            img = img.astype(np.float32)/255\n",
        "            img = np.transpose(img, (2,0,1))\n",
        "            return {\n",
        "                'img' : torch.tensor(img, dtype=torch.float32),\n",
        "                'label' : torch.tensor(self.labels[i], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            img = cv2.imread('./test_imgs/'+self.files[i])\n",
        "            img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
        "            img = img.astype(np.float32)/255\n",
        "            img = np.transpose(img, (2,0,1))\n",
        "            return {\n",
        "                'img' : torch.tensor(img, dtype=torch.float32),\n",
        "            }"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doD_-1nKTK2i"
      },
      "source": [
        "train = train_total.iloc[:200]\n",
        "val = train_total.iloc[200:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9uRxOklTK2j",
        "outputId": "dff35225-5e5d-4041-ae48-4291c8d47f33"
      },
      "source": [
        "train_dataset = CustomDataset(train['img_path'].str.split('/').str[-1].values, train['disease_code'].values)\n",
        "val_dataset = CustomDataset(val['img_path'].str.split('/').str[-1].values, val['disease_code'].values)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=16, shuffle=False)\n",
        "\n",
        "test_dataset = CustomDataset(test['img_path'].str.split('/').str[-1], labels=None, mode='test')\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=16, shuffle=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "linriOSHTK2k"
      },
      "source": [
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self, class_n, rate=0.1):\n",
        "        super(CNN_Model, self).__init__()\n",
        "        self.model = models.densenet161(pretrained=True)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "        self.output_layer = nn.Linear(in_features=1000, out_features=class_n, bias=True)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output = self.output_layer(self.dropout(self.model(inputs)))\n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-IxRtenTK2l"
      },
      "source": [
        "model = CNN_Model(class_n).to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oShEYCziwzeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf782ca-438e-4cfe-90e2-d8fa63ef617c"
      },
      "source": [
        "model.model.eval()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer25): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer26): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer27): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer28): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer29): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer30): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer31): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer32): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer33): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer34): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer35): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer36): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bAoZ66eTK2l"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zQb1W0KTK2m"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(img)\n",
        "            loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        return loss\n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "            loss = criterion(output, label)\n",
        "            \n",
        "        return loss"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcLa4O3rTK2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec64a2c-209b-44f2-dfa2-e38b9ac60542"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    \n",
        "    if np.min(val_loss_plot) == val_loss_plot[-1]:\n",
        "        torch.save(model, save_path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "17it [00:12,  1.37it/s, Epoch=1, Loss=0.010114, Total Loss=0.016286]\n",
            "5it [00:03,  1.52it/s, Epoch=1, Val Loss=0.009808, Total Val Loss=0.077210]\n",
            "17it [00:12,  1.32it/s, Epoch=2, Loss=0.021133, Total Loss=0.010155]\n",
            "5it [00:03,  1.56it/s, Epoch=2, Val Loss=0.013776, Total Val Loss=0.075214]\n",
            "17it [00:12,  1.34it/s, Epoch=3, Loss=0.009640, Total Loss=0.007041]\n",
            "5it [00:03,  1.54it/s, Epoch=3, Val Loss=0.010841, Total Val Loss=0.072923]\n",
            "17it [00:12,  1.39it/s, Epoch=4, Loss=0.009084, Total Loss=0.007724]\n",
            "5it [00:03,  1.51it/s, Epoch=4, Val Loss=0.004406, Total Val Loss=0.055676]\n",
            "17it [00:12,  1.34it/s, Epoch=5, Loss=0.002091, Total Loss=0.005194]\n",
            "5it [00:03,  1.52it/s, Epoch=5, Val Loss=0.002527, Total Val Loss=0.061406]\n",
            "17it [00:12,  1.32it/s, Epoch=6, Loss=0.174020, Total Loss=0.013372]\n",
            "5it [00:03,  1.53it/s, Epoch=6, Val Loss=0.002797, Total Val Loss=0.076692]\n",
            "17it [00:12,  1.40it/s, Epoch=7, Loss=0.003117, Total Loss=0.004536]\n",
            "5it [00:03,  1.58it/s, Epoch=7, Val Loss=0.000782, Total Val Loss=0.062860]\n",
            "17it [00:12,  1.38it/s, Epoch=8, Loss=0.000865, Total Loss=0.004657]\n",
            "5it [00:03,  1.53it/s, Epoch=8, Val Loss=0.000624, Total Val Loss=0.056400]\n",
            "17it [00:12,  1.41it/s, Epoch=9, Loss=0.067939, Total Loss=0.005904]\n",
            "5it [00:03,  1.55it/s, Epoch=9, Val Loss=0.000840, Total Val Loss=0.054919]\n",
            "17it [00:11,  1.43it/s, Epoch=10, Loss=0.002279, Total Loss=0.002640]\n",
            "5it [00:03,  1.53it/s, Epoch=10, Val Loss=0.001205, Total Val Loss=0.056644]\n",
            "17it [00:12,  1.38it/s, Epoch=11, Loss=0.001891, Total Loss=0.005153]\n",
            "5it [00:03,  1.54it/s, Epoch=11, Val Loss=0.001808, Total Val Loss=0.065559]\n",
            "17it [00:12,  1.39it/s, Epoch=12, Loss=0.002221, Total Loss=0.001147]\n",
            "5it [00:03,  1.56it/s, Epoch=12, Val Loss=0.002887, Total Val Loss=0.068883]\n",
            "17it [00:11,  1.45it/s, Epoch=13, Loss=0.003019, Total Loss=0.001601]\n",
            "5it [00:03,  1.51it/s, Epoch=13, Val Loss=0.001435, Total Val Loss=0.063677]\n",
            "17it [00:12,  1.37it/s, Epoch=14, Loss=0.004551, Total Loss=0.001496]\n",
            "5it [00:03,  1.59it/s, Epoch=14, Val Loss=0.002566, Total Val Loss=0.077537]\n",
            "17it [00:11,  1.42it/s, Epoch=15, Loss=0.000420, Total Loss=0.002284]\n",
            "5it [00:03,  1.55it/s, Epoch=15, Val Loss=0.002592, Total Val Loss=0.092149]\n",
            "17it [00:12,  1.36it/s, Epoch=16, Loss=0.001094, Total Loss=0.010484]\n",
            "5it [00:03,  1.53it/s, Epoch=16, Val Loss=0.005698, Total Val Loss=0.100744]\n",
            "17it [00:12,  1.35it/s, Epoch=17, Loss=0.001409, Total Loss=0.006772]\n",
            "5it [00:03,  1.60it/s, Epoch=17, Val Loss=0.013933, Total Val Loss=0.131845]\n",
            "17it [00:12,  1.38it/s, Epoch=18, Loss=0.000528, Total Loss=0.002327]\n",
            "5it [00:03,  1.62it/s, Epoch=18, Val Loss=0.014150, Total Val Loss=0.146714]\n",
            "17it [00:12,  1.34it/s, Epoch=19, Loss=0.003653, Total Loss=0.022435]\n",
            "5it [00:03,  1.60it/s, Epoch=19, Val Loss=0.024149, Total Val Loss=0.128574]\n",
            "17it [00:11,  1.42it/s, Epoch=20, Loss=0.001500, Total Loss=0.036233]\n",
            "5it [00:03,  1.55it/s, Epoch=20, Val Loss=0.035609, Total Val Loss=0.177789]\n",
            "17it [00:13,  1.27it/s, Epoch=21, Loss=0.004251, Total Loss=0.062121]\n",
            "5it [00:03,  1.54it/s, Epoch=21, Val Loss=0.010735, Total Val Loss=0.288513]\n",
            "17it [00:12,  1.38it/s, Epoch=22, Loss=0.003638, Total Loss=0.053181]\n",
            "5it [00:03,  1.57it/s, Epoch=22, Val Loss=0.045862, Total Val Loss=0.314951]\n",
            "17it [00:12,  1.39it/s, Epoch=23, Loss=0.002023, Total Loss=0.057503]\n",
            "5it [00:03,  1.56it/s, Epoch=23, Val Loss=0.000231, Total Val Loss=0.253310]\n",
            "17it [00:12,  1.41it/s, Epoch=24, Loss=0.000575, Total Loss=0.087411]\n",
            "5it [00:03,  1.55it/s, Epoch=24, Val Loss=0.000732, Total Val Loss=0.239922]\n",
            "17it [00:12,  1.35it/s, Epoch=25, Loss=0.000409, Total Loss=0.031653]\n",
            "5it [00:03,  1.50it/s, Epoch=25, Val Loss=0.003600, Total Val Loss=0.149097]\n",
            "17it [00:11,  1.43it/s, Epoch=26, Loss=0.001712, Total Loss=0.022193]\n",
            "5it [00:03,  1.57it/s, Epoch=26, Val Loss=0.005231, Total Val Loss=0.231539]\n",
            "17it [00:12,  1.40it/s, Epoch=27, Loss=0.139194, Total Loss=0.036712]\n",
            "5it [00:03,  1.56it/s, Epoch=27, Val Loss=0.011136, Total Val Loss=0.179052]\n",
            "17it [00:11,  1.43it/s, Epoch=28, Loss=0.042241, Total Loss=0.102040]\n",
            "5it [00:03,  1.57it/s, Epoch=28, Val Loss=0.012894, Total Val Loss=0.482276]\n",
            "17it [00:12,  1.41it/s, Epoch=29, Loss=0.161456, Total Loss=0.040041]\n",
            "5it [00:03,  1.60it/s, Epoch=29, Val Loss=0.000649, Total Val Loss=0.281689]\n",
            "17it [00:11,  1.44it/s, Epoch=30, Loss=0.018776, Total Loss=0.050855]\n",
            "5it [00:03,  1.54it/s, Epoch=30, Val Loss=0.001495, Total Val Loss=0.156511]\n",
            "17it [00:12,  1.41it/s, Epoch=31, Loss=0.027072, Total Loss=0.046693]\n",
            "5it [00:03,  1.53it/s, Epoch=31, Val Loss=0.007149, Total Val Loss=0.174269]\n",
            "17it [00:11,  1.45it/s, Epoch=32, Loss=0.023835, Total Loss=0.134469]\n",
            "5it [00:03,  1.51it/s, Epoch=32, Val Loss=0.001174, Total Val Loss=0.136793]\n",
            "17it [00:11,  1.43it/s, Epoch=33, Loss=0.002539, Total Loss=0.047436]\n",
            "5it [00:03,  1.56it/s, Epoch=33, Val Loss=0.000259, Total Val Loss=0.196538]\n",
            "17it [00:12,  1.34it/s, Epoch=34, Loss=0.042094, Total Loss=0.051135]\n",
            "5it [00:03,  1.51it/s, Epoch=34, Val Loss=0.018559, Total Val Loss=0.303161]\n",
            "17it [00:12,  1.36it/s, Epoch=35, Loss=0.000626, Total Loss=0.042995]\n",
            "5it [00:03,  1.58it/s, Epoch=35, Val Loss=0.006933, Total Val Loss=0.284699]\n",
            "17it [00:11,  1.43it/s, Epoch=36, Loss=0.000429, Total Loss=0.046644]\n",
            "5it [00:03,  1.60it/s, Epoch=36, Val Loss=0.002773, Total Val Loss=0.236126]\n",
            "17it [00:12,  1.40it/s, Epoch=37, Loss=0.014509, Total Loss=0.003217]\n",
            "5it [00:03,  1.59it/s, Epoch=37, Val Loss=0.001128, Total Val Loss=0.179887]\n",
            "17it [00:11,  1.42it/s, Epoch=38, Loss=0.000862, Total Loss=0.009885]\n",
            "5it [00:02,  1.67it/s, Epoch=38, Val Loss=0.006070, Total Val Loss=0.169077]\n",
            "17it [00:12,  1.38it/s, Epoch=39, Loss=0.000784, Total Loss=0.030230]\n",
            "5it [00:03,  1.63it/s, Epoch=39, Val Loss=0.004915, Total Val Loss=0.214592]\n",
            "17it [00:12,  1.40it/s, Epoch=40, Loss=0.000826, Total Loss=0.007767]\n",
            "5it [00:03,  1.52it/s, Epoch=40, Val Loss=0.003120, Total Val Loss=0.121377]\n",
            "17it [00:12,  1.40it/s, Epoch=41, Loss=0.000104, Total Loss=0.001165]\n",
            "5it [00:03,  1.63it/s, Epoch=41, Val Loss=0.001572, Total Val Loss=0.104417]\n",
            "17it [00:12,  1.40it/s, Epoch=42, Loss=0.000804, Total Loss=0.001893]\n",
            "5it [00:03,  1.56it/s, Epoch=42, Val Loss=0.000261, Total Val Loss=0.187031]\n",
            "17it [00:12,  1.39it/s, Epoch=43, Loss=0.000271, Total Loss=0.003630]\n",
            "5it [00:03,  1.57it/s, Epoch=43, Val Loss=0.000241, Total Val Loss=0.206369]\n",
            "17it [00:11,  1.45it/s, Epoch=44, Loss=0.000242, Total Loss=0.000678]\n",
            "5it [00:03,  1.63it/s, Epoch=44, Val Loss=0.000376, Total Val Loss=0.201463]\n",
            "17it [00:12,  1.41it/s, Epoch=45, Loss=0.001377, Total Loss=0.000969]\n",
            "5it [00:03,  1.61it/s, Epoch=45, Val Loss=0.000554, Total Val Loss=0.196524]\n",
            "17it [00:12,  1.37it/s, Epoch=46, Loss=0.000561, Total Loss=0.001030]\n",
            "5it [00:03,  1.55it/s, Epoch=46, Val Loss=0.000264, Total Val Loss=0.198997]\n",
            "17it [00:12,  1.39it/s, Epoch=47, Loss=0.000203, Total Loss=0.000340]\n",
            "5it [00:03,  1.55it/s, Epoch=47, Val Loss=0.000219, Total Val Loss=0.197109]\n",
            "17it [00:12,  1.40it/s, Epoch=48, Loss=0.000335, Total Loss=0.000669]\n",
            "5it [00:03,  1.64it/s, Epoch=48, Val Loss=0.000330, Total Val Loss=0.194162]\n",
            "17it [00:12,  1.38it/s, Epoch=49, Loss=0.000416, Total Loss=0.000283]\n",
            "5it [00:03,  1.51it/s, Epoch=49, Val Loss=0.000167, Total Val Loss=0.195571]\n",
            "17it [00:11,  1.44it/s, Epoch=50, Loss=0.000087, Total Loss=0.000479]\n",
            "5it [00:02,  1.67it/s, Epoch=50, Val Loss=0.000178, Total Val Loss=0.172853]\n",
            "17it [00:12,  1.35it/s, Epoch=51, Loss=0.008687, Total Loss=0.000906]\n",
            "5it [00:03,  1.56it/s, Epoch=51, Val Loss=0.000264, Total Val Loss=0.201475]\n",
            "17it [00:12,  1.40it/s, Epoch=52, Loss=0.000176, Total Loss=0.001214]\n",
            "5it [00:03,  1.53it/s, Epoch=52, Val Loss=0.000369, Total Val Loss=0.235007]\n",
            "17it [00:12,  1.40it/s, Epoch=53, Loss=0.000087, Total Loss=0.000156]\n",
            "5it [00:03,  1.61it/s, Epoch=53, Val Loss=0.000240, Total Val Loss=0.209992]\n",
            "17it [00:12,  1.38it/s, Epoch=54, Loss=0.169563, Total Loss=0.010220]\n",
            "5it [00:03,  1.57it/s, Epoch=54, Val Loss=0.000224, Total Val Loss=0.196439]\n",
            "17it [00:11,  1.46it/s, Epoch=55, Loss=0.000325, Total Loss=0.024925]\n",
            "5it [00:03,  1.53it/s, Epoch=55, Val Loss=0.000593, Total Val Loss=0.064199]\n",
            "17it [00:11,  1.42it/s, Epoch=56, Loss=0.025627, Total Loss=0.008191]\n",
            "5it [00:03,  1.57it/s, Epoch=56, Val Loss=0.000734, Total Val Loss=0.082790]\n",
            "17it [00:12,  1.37it/s, Epoch=57, Loss=0.000487, Total Loss=0.000518]\n",
            "5it [00:03,  1.50it/s, Epoch=57, Val Loss=0.001307, Total Val Loss=0.059529]\n",
            "17it [00:11,  1.43it/s, Epoch=58, Loss=0.013382, Total Loss=0.001356]\n",
            "5it [00:03,  1.50it/s, Epoch=58, Val Loss=0.001265, Total Val Loss=0.072749]\n",
            "17it [00:12,  1.41it/s, Epoch=59, Loss=0.000259, Total Loss=0.001274]\n",
            "5it [00:03,  1.55it/s, Epoch=59, Val Loss=0.000720, Total Val Loss=0.061465]\n",
            "17it [00:12,  1.36it/s, Epoch=60, Loss=0.000080, Total Loss=0.002060]\n",
            "5it [00:03,  1.53it/s, Epoch=60, Val Loss=0.001185, Total Val Loss=0.052718]\n",
            "17it [00:11,  1.44it/s, Epoch=61, Loss=0.000880, Total Loss=0.000773]\n",
            "5it [00:03,  1.55it/s, Epoch=61, Val Loss=0.001004, Total Val Loss=0.080916]\n",
            "17it [00:24,  1.42s/it, Epoch=62, Loss=0.000085, Total Loss=0.000156]\n",
            "5it [00:02,  1.80it/s, Epoch=62, Val Loss=0.000729, Total Val Loss=0.057977]\n",
            "17it [00:12,  1.41it/s, Epoch=63, Loss=0.000378, Total Loss=0.000086]\n",
            "5it [00:02,  1.82it/s, Epoch=63, Val Loss=0.000823, Total Val Loss=0.073921]\n",
            "17it [00:12,  1.38it/s, Epoch=64, Loss=0.029011, Total Loss=0.001981]\n",
            "5it [00:02,  1.76it/s, Epoch=64, Val Loss=0.000780, Total Val Loss=0.061338]\n",
            "17it [00:11,  1.44it/s, Epoch=65, Loss=0.000124, Total Loss=0.000912]\n",
            "5it [00:02,  1.82it/s, Epoch=65, Val Loss=0.000722, Total Val Loss=0.062383]\n",
            "17it [00:12,  1.40it/s, Epoch=66, Loss=0.001086, Total Loss=0.000260]\n",
            "5it [00:02,  1.92it/s, Epoch=66, Val Loss=0.001241, Total Val Loss=0.041559]\n",
            "17it [00:11,  1.44it/s, Epoch=67, Loss=0.000019, Total Loss=0.000223]\n",
            "5it [00:02,  1.86it/s, Epoch=67, Val Loss=0.001124, Total Val Loss=0.052704]\n",
            "17it [00:11,  1.43it/s, Epoch=68, Loss=0.002590, Total Loss=0.000710]\n",
            "5it [00:02,  1.78it/s, Epoch=68, Val Loss=0.000537, Total Val Loss=0.071455]\n",
            "17it [00:11,  1.48it/s, Epoch=69, Loss=0.000129, Total Loss=0.000126]\n",
            "5it [00:02,  1.81it/s, Epoch=69, Val Loss=0.000442, Total Val Loss=0.067388]\n",
            "17it [00:11,  1.47it/s, Epoch=70, Loss=0.000004, Total Loss=0.000089]\n",
            "5it [00:02,  1.81it/s, Epoch=70, Val Loss=0.000278, Total Val Loss=0.069799]\n",
            "17it [00:10,  1.58it/s, Epoch=71, Loss=0.000020, Total Loss=0.000060]\n",
            "5it [00:02,  1.87it/s, Epoch=71, Val Loss=0.000368, Total Val Loss=0.066955]\n",
            "17it [00:11,  1.45it/s, Epoch=72, Loss=0.003953, Total Loss=0.000422]\n",
            "5it [00:02,  1.79it/s, Epoch=72, Val Loss=0.000307, Total Val Loss=0.056579]\n",
            "17it [00:12,  1.41it/s, Epoch=73, Loss=0.000154, Total Loss=0.000168]\n",
            "5it [00:02,  1.75it/s, Epoch=73, Val Loss=0.000229, Total Val Loss=0.061639]\n",
            "17it [00:12,  1.35it/s, Epoch=74, Loss=0.000227, Total Loss=0.000722]\n",
            "5it [00:02,  1.93it/s, Epoch=74, Val Loss=0.000104, Total Val Loss=0.063744]\n",
            "17it [00:12,  1.38it/s, Epoch=75, Loss=0.000019, Total Loss=0.000117]\n",
            "5it [00:02,  1.91it/s, Epoch=75, Val Loss=0.000232, Total Val Loss=0.057853]\n",
            "17it [00:11,  1.43it/s, Epoch=76, Loss=0.000081, Total Loss=0.000042]\n",
            "5it [00:02,  1.85it/s, Epoch=76, Val Loss=0.000258, Total Val Loss=0.064457]\n",
            "17it [00:11,  1.48it/s, Epoch=77, Loss=0.000016, Total Loss=0.000207]\n",
            "5it [00:02,  1.87it/s, Epoch=77, Val Loss=0.000237, Total Val Loss=0.088074]\n",
            "17it [00:12,  1.38it/s, Epoch=78, Loss=0.000075, Total Loss=0.000113]\n",
            "5it [00:02,  1.78it/s, Epoch=78, Val Loss=0.000099, Total Val Loss=0.072062]\n",
            "17it [00:11,  1.46it/s, Epoch=79, Loss=0.000032, Total Loss=0.000177]\n",
            "5it [00:02,  1.84it/s, Epoch=79, Val Loss=0.000139, Total Val Loss=0.079479]\n",
            "17it [00:11,  1.42it/s, Epoch=80, Loss=0.000474, Total Loss=0.000148]\n",
            "5it [00:02,  1.86it/s, Epoch=80, Val Loss=0.000118, Total Val Loss=0.051634]\n",
            "17it [00:11,  1.53it/s, Epoch=81, Loss=0.000059, Total Loss=0.000129]\n",
            "5it [00:02,  1.82it/s, Epoch=81, Val Loss=0.000300, Total Val Loss=0.068344]\n",
            "17it [00:12,  1.41it/s, Epoch=82, Loss=0.000221, Total Loss=0.000349]\n",
            "5it [00:02,  1.88it/s, Epoch=82, Val Loss=0.000131, Total Val Loss=0.072789]\n",
            "17it [00:11,  1.44it/s, Epoch=83, Loss=0.000038, Total Loss=0.000139]\n",
            "5it [00:02,  1.80it/s, Epoch=83, Val Loss=0.000109, Total Val Loss=0.077480]\n",
            "17it [00:11,  1.44it/s, Epoch=84, Loss=0.000601, Total Loss=0.000083]\n",
            "5it [00:02,  1.79it/s, Epoch=84, Val Loss=0.000112, Total Val Loss=0.080370]\n",
            "17it [00:11,  1.44it/s, Epoch=85, Loss=0.000337, Total Loss=0.000108]\n",
            "5it [00:02,  1.77it/s, Epoch=85, Val Loss=0.000075, Total Val Loss=0.074969]\n",
            "17it [00:11,  1.45it/s, Epoch=86, Loss=0.000162, Total Loss=0.000060]\n",
            "5it [00:02,  1.86it/s, Epoch=86, Val Loss=0.000189, Total Val Loss=0.073438]\n",
            "17it [00:11,  1.52it/s, Epoch=87, Loss=0.002070, Total Loss=0.000161]\n",
            "5it [00:02,  1.92it/s, Epoch=87, Val Loss=0.000212, Total Val Loss=0.048693]\n",
            "17it [00:12,  1.41it/s, Epoch=88, Loss=0.000294, Total Loss=0.000524]\n",
            "5it [00:02,  1.84it/s, Epoch=88, Val Loss=0.000092, Total Val Loss=0.057376]\n",
            "17it [00:11,  1.49it/s, Epoch=89, Loss=0.000010, Total Loss=0.000058]\n",
            "5it [00:02,  1.81it/s, Epoch=89, Val Loss=0.000141, Total Val Loss=0.069717]\n",
            "17it [00:11,  1.45it/s, Epoch=90, Loss=0.000730, Total Loss=0.000102]\n",
            "5it [00:02,  1.99it/s, Epoch=90, Val Loss=0.000133, Total Val Loss=0.073866]\n",
            "17it [00:11,  1.48it/s, Epoch=91, Loss=0.000183, Total Loss=0.000250]\n",
            "5it [00:02,  1.93it/s, Epoch=91, Val Loss=0.000179, Total Val Loss=0.055207]\n",
            "17it [00:11,  1.49it/s, Epoch=92, Loss=0.000193, Total Loss=0.000040]\n",
            "5it [00:02,  1.83it/s, Epoch=92, Val Loss=0.000125, Total Val Loss=0.069069]\n",
            "17it [00:12,  1.40it/s, Epoch=93, Loss=0.000268, Total Loss=0.000081]\n",
            "5it [00:02,  1.83it/s, Epoch=93, Val Loss=0.000109, Total Val Loss=0.071444]\n",
            "17it [00:11,  1.42it/s, Epoch=94, Loss=0.000006, Total Loss=0.001067]\n",
            "5it [00:02,  1.83it/s, Epoch=94, Val Loss=0.000166, Total Val Loss=0.085761]\n",
            "17it [00:11,  1.44it/s, Epoch=95, Loss=0.000003, Total Loss=0.000135]\n",
            "5it [00:02,  1.88it/s, Epoch=95, Val Loss=0.000105, Total Val Loss=0.064443]\n",
            "17it [00:12,  1.41it/s, Epoch=96, Loss=0.000049, Total Loss=0.000825]\n",
            "5it [00:02,  1.72it/s, Epoch=96, Val Loss=0.000049, Total Val Loss=0.068220]\n",
            "17it [00:12,  1.40it/s, Epoch=97, Loss=0.000007, Total Loss=0.000098]\n",
            "5it [00:02,  1.80it/s, Epoch=97, Val Loss=0.000459, Total Val Loss=0.123174]\n",
            "17it [00:11,  1.54it/s, Epoch=98, Loss=0.000008, Total Loss=0.000487]\n",
            "5it [00:02,  1.80it/s, Epoch=98, Val Loss=0.000306, Total Val Loss=0.123680]\n",
            "17it [00:10,  1.57it/s, Epoch=99, Loss=0.000042, Total Loss=0.000120]\n",
            "5it [00:02,  1.75it/s, Epoch=99, Val Loss=0.000277, Total Val Loss=0.119420]\n",
            "17it [00:11,  1.52it/s, Epoch=100, Loss=0.002648, Total Loss=0.000220]\n",
            "5it [00:02,  1.73it/s, Epoch=100, Val Loss=0.000274, Total Val Loss=0.124514]\n",
            "17it [00:12,  1.40it/s, Epoch=101, Loss=0.000097, Total Loss=0.000110]\n",
            "5it [00:02,  1.75it/s, Epoch=101, Val Loss=0.000107, Total Val Loss=0.115528]\n",
            "17it [00:11,  1.44it/s, Epoch=102, Loss=0.000384, Total Loss=0.000068]\n",
            "5it [00:02,  1.88it/s, Epoch=102, Val Loss=0.000175, Total Val Loss=0.114132]\n",
            "17it [00:11,  1.43it/s, Epoch=103, Loss=0.000178, Total Loss=0.000176]\n",
            "5it [00:02,  1.83it/s, Epoch=103, Val Loss=0.000114, Total Val Loss=0.107725]\n",
            "17it [00:11,  1.52it/s, Epoch=104, Loss=0.000034, Total Loss=0.000196]\n",
            "5it [00:03,  1.66it/s, Epoch=104, Val Loss=0.000142, Total Val Loss=0.108344]\n",
            "17it [00:11,  1.44it/s, Epoch=105, Loss=0.000003, Total Loss=0.000047]\n",
            "5it [00:02,  1.82it/s, Epoch=105, Val Loss=0.000270, Total Val Loss=0.127839]\n",
            "17it [00:11,  1.45it/s, Epoch=106, Loss=0.000013, Total Loss=0.000809]\n",
            "5it [00:02,  1.81it/s, Epoch=106, Val Loss=0.000408, Total Val Loss=0.135927]\n",
            "17it [00:11,  1.48it/s, Epoch=107, Loss=0.000004, Total Loss=0.000057]\n",
            "5it [00:02,  1.79it/s, Epoch=107, Val Loss=0.000315, Total Val Loss=0.136427]\n",
            "17it [00:11,  1.45it/s, Epoch=108, Loss=0.000139, Total Loss=0.000144]\n",
            "5it [00:02,  1.81it/s, Epoch=108, Val Loss=0.000594, Total Val Loss=0.134193]\n",
            "17it [00:11,  1.48it/s, Epoch=109, Loss=0.000035, Total Loss=0.000062]\n",
            "5it [00:02,  1.80it/s, Epoch=109, Val Loss=0.000939, Total Val Loss=0.184572]\n",
            "17it [00:12,  1.41it/s, Epoch=110, Loss=0.002793, Total Loss=0.000278]\n",
            "5it [00:02,  1.72it/s, Epoch=110, Val Loss=0.000189, Total Val Loss=0.117209]\n",
            "17it [00:11,  1.43it/s, Epoch=111, Loss=0.000144, Total Loss=0.000140]\n",
            "5it [00:02,  1.82it/s, Epoch=111, Val Loss=0.000126, Total Val Loss=0.135382]\n",
            "17it [00:11,  1.44it/s, Epoch=112, Loss=0.000002, Total Loss=0.000126]\n",
            "5it [00:02,  1.83it/s, Epoch=112, Val Loss=0.000278, Total Val Loss=0.136556]\n",
            "17it [00:12,  1.40it/s, Epoch=113, Loss=0.000138, Total Loss=0.000073]\n",
            "5it [00:02,  1.81it/s, Epoch=113, Val Loss=0.000385, Total Val Loss=0.152105]\n",
            "17it [00:12,  1.40it/s, Epoch=114, Loss=0.000046, Total Loss=0.000033]\n",
            "5it [00:02,  1.79it/s, Epoch=114, Val Loss=0.000156, Total Val Loss=0.124080]\n",
            "17it [00:11,  1.44it/s, Epoch=115, Loss=0.000016, Total Loss=0.000051]\n",
            "5it [00:02,  1.85it/s, Epoch=115, Val Loss=0.000173, Total Val Loss=0.121741]\n",
            "17it [00:11,  1.45it/s, Epoch=116, Loss=0.000009, Total Loss=0.000035]\n",
            "5it [00:02,  1.82it/s, Epoch=116, Val Loss=0.000139, Total Val Loss=0.108012]\n",
            "17it [00:12,  1.40it/s, Epoch=117, Loss=0.000007, Total Loss=0.000028]\n",
            "5it [00:02,  1.83it/s, Epoch=117, Val Loss=0.000230, Total Val Loss=0.128278]\n",
            "17it [00:11,  1.49it/s, Epoch=118, Loss=0.000489, Total Loss=0.000064]\n",
            "5it [00:02,  1.81it/s, Epoch=118, Val Loss=0.000137, Total Val Loss=0.116738]\n",
            "17it [00:11,  1.45it/s, Epoch=119, Loss=0.000068, Total Loss=0.000052]\n",
            "5it [00:02,  1.77it/s, Epoch=119, Val Loss=0.000287, Total Val Loss=0.130896]\n",
            "17it [00:11,  1.44it/s, Epoch=120, Loss=0.000012, Total Loss=0.002276]\n",
            "5it [00:02,  1.91it/s, Epoch=120, Val Loss=0.000144, Total Val Loss=0.106583]\n",
            "17it [00:12,  1.41it/s, Epoch=121, Loss=0.001871, Total Loss=0.000326]\n",
            "5it [00:02,  1.76it/s, Epoch=121, Val Loss=0.000497, Total Val Loss=0.162050]\n",
            "17it [00:12,  1.42it/s, Epoch=122, Loss=0.000097, Total Loss=0.000149]\n",
            "5it [00:02,  1.77it/s, Epoch=122, Val Loss=0.000479, Total Val Loss=0.140718]\n",
            "17it [00:11,  1.47it/s, Epoch=123, Loss=0.000050, Total Loss=0.000673]\n",
            "5it [00:02,  1.86it/s, Epoch=123, Val Loss=0.000198, Total Val Loss=0.118016]\n",
            "17it [00:11,  1.46it/s, Epoch=124, Loss=0.000020, Total Loss=0.000190]\n",
            "5it [00:02,  1.79it/s, Epoch=124, Val Loss=0.000158, Total Val Loss=0.128650]\n",
            "17it [00:11,  1.43it/s, Epoch=125, Loss=0.000060, Total Loss=0.000064]\n",
            "5it [00:02,  1.79it/s, Epoch=125, Val Loss=0.000095, Total Val Loss=0.112783]\n",
            "17it [00:11,  1.49it/s, Epoch=126, Loss=0.000002, Total Loss=0.000138]\n",
            "5it [00:02,  1.78it/s, Epoch=126, Val Loss=0.000211, Total Val Loss=0.123683]\n",
            "17it [00:11,  1.48it/s, Epoch=127, Loss=0.000024, Total Loss=0.000041]\n",
            "5it [00:02,  1.77it/s, Epoch=127, Val Loss=0.000152, Total Val Loss=0.132720]\n",
            "17it [00:11,  1.49it/s, Epoch=128, Loss=0.000010, Total Loss=0.000286]\n",
            "5it [00:02,  1.84it/s, Epoch=128, Val Loss=0.000172, Total Val Loss=0.125508]\n",
            "17it [00:11,  1.42it/s, Epoch=129, Loss=0.000021, Total Loss=0.000218]\n",
            "5it [00:02,  1.74it/s, Epoch=129, Val Loss=0.000263, Total Val Loss=0.145909]\n",
            "17it [00:11,  1.43it/s, Epoch=130, Loss=0.000062, Total Loss=0.000055]\n",
            "5it [00:02,  1.78it/s, Epoch=130, Val Loss=0.000384, Total Val Loss=0.136950]\n",
            "17it [00:12,  1.41it/s, Epoch=131, Loss=0.000030, Total Loss=0.000043]\n",
            "5it [00:02,  1.80it/s, Epoch=131, Val Loss=0.000186, Total Val Loss=0.151253]\n",
            "17it [00:11,  1.42it/s, Epoch=132, Loss=0.000000, Total Loss=0.000025]\n",
            "5it [00:02,  1.84it/s, Epoch=132, Val Loss=0.000150, Total Val Loss=0.127043]\n",
            "17it [00:12,  1.41it/s, Epoch=133, Loss=0.000518, Total Loss=0.000062]\n",
            "5it [00:02,  1.83it/s, Epoch=133, Val Loss=0.000332, Total Val Loss=0.148413]\n",
            "17it [00:12,  1.40it/s, Epoch=134, Loss=0.000024, Total Loss=0.000039]\n",
            "5it [00:02,  1.82it/s, Epoch=134, Val Loss=0.000273, Total Val Loss=0.151813]\n",
            "17it [00:11,  1.43it/s, Epoch=135, Loss=0.000674, Total Loss=0.000075]\n",
            "5it [00:02,  1.91it/s, Epoch=135, Val Loss=0.000273, Total Val Loss=0.166007]\n",
            "17it [00:11,  1.43it/s, Epoch=136, Loss=0.000021, Total Loss=0.000143]\n",
            "5it [00:02,  1.86it/s, Epoch=136, Val Loss=0.000191, Total Val Loss=0.142416]\n",
            "17it [00:11,  1.44it/s, Epoch=137, Loss=0.000012, Total Loss=0.000026]\n",
            "5it [00:02,  1.79it/s, Epoch=137, Val Loss=0.000135, Total Val Loss=0.149160]\n",
            "17it [00:12,  1.41it/s, Epoch=138, Loss=0.001845, Total Loss=0.000175]\n",
            "5it [00:02,  1.74it/s, Epoch=138, Val Loss=0.000125, Total Val Loss=0.127718]\n",
            "17it [00:11,  1.45it/s, Epoch=139, Loss=0.000110, Total Loss=0.000192]\n",
            "5it [00:02,  1.74it/s, Epoch=139, Val Loss=0.000096, Total Val Loss=0.151547]\n",
            "17it [00:11,  1.42it/s, Epoch=140, Loss=0.000066, Total Loss=0.000469]\n",
            "5it [00:02,  1.80it/s, Epoch=140, Val Loss=0.000085, Total Val Loss=0.127490]\n",
            "17it [00:11,  1.43it/s, Epoch=141, Loss=0.086865, Total Loss=0.005234]\n",
            "5it [00:02,  1.90it/s, Epoch=141, Val Loss=0.000110, Total Val Loss=0.126331]\n",
            "17it [00:11,  1.52it/s, Epoch=142, Loss=0.096202, Total Loss=0.055274]\n",
            "5it [00:02,  1.83it/s, Epoch=142, Val Loss=0.000345, Total Val Loss=0.545677]\n",
            "17it [00:12,  1.39it/s, Epoch=143, Loss=0.005460, Total Loss=0.340305]\n",
            "5it [00:02,  1.76it/s, Epoch=143, Val Loss=0.000133, Total Val Loss=1.684693]\n",
            "17it [00:12,  1.41it/s, Epoch=144, Loss=0.001939, Total Loss=0.238260]\n",
            "5it [00:02,  1.86it/s, Epoch=144, Val Loss=0.000000, Total Val Loss=1.751107]\n",
            "17it [00:12,  1.39it/s, Epoch=145, Loss=1.484149, Total Loss=0.236148]\n",
            "5it [00:02,  1.73it/s, Epoch=145, Val Loss=0.111754, Total Val Loss=0.734893]\n",
            "17it [00:11,  1.42it/s, Epoch=146, Loss=0.573862, Total Loss=0.375941]\n",
            "5it [00:02,  1.70it/s, Epoch=146, Val Loss=5.741859, Total Val Loss=3.556642]\n",
            "17it [00:11,  1.53it/s, Epoch=147, Loss=0.098921, Total Loss=0.303753]\n",
            "5it [00:02,  1.79it/s, Epoch=147, Val Loss=0.069763, Total Val Loss=0.611624]\n",
            "17it [00:10,  1.57it/s, Epoch=148, Loss=0.046161, Total Loss=0.262370]\n",
            "5it [00:02,  1.77it/s, Epoch=148, Val Loss=0.000258, Total Val Loss=0.903307]\n",
            "17it [00:12,  1.42it/s, Epoch=149, Loss=0.000352, Total Loss=0.160911]\n",
            "5it [00:02,  1.77it/s, Epoch=149, Val Loss=0.540923, Total Val Loss=0.886222]\n",
            "17it [00:11,  1.43it/s, Epoch=150, Loss=0.000327, Total Loss=0.160592]\n",
            "5it [00:02,  1.86it/s, Epoch=150, Val Loss=0.000141, Total Val Loss=0.621245]\n",
            "17it [00:12,  1.32it/s, Epoch=151, Loss=0.024446, Total Loss=0.110971]\n",
            "5it [00:02,  1.76it/s, Epoch=151, Val Loss=0.016461, Total Val Loss=0.174782]\n",
            "17it [00:12,  1.40it/s, Epoch=152, Loss=0.001671, Total Loss=0.082298]\n",
            "5it [00:02,  1.78it/s, Epoch=152, Val Loss=0.000000, Total Val Loss=0.375355]\n",
            "17it [00:12,  1.38it/s, Epoch=153, Loss=0.075515, Total Loss=0.057188]\n",
            "5it [00:02,  1.79it/s, Epoch=153, Val Loss=0.000002, Total Val Loss=0.163283]\n",
            "17it [00:12,  1.38it/s, Epoch=154, Loss=0.000946, Total Loss=0.015400]\n",
            "5it [00:02,  1.76it/s, Epoch=154, Val Loss=0.000045, Total Val Loss=0.248229]\n",
            "17it [00:12,  1.39it/s, Epoch=155, Loss=0.001741, Total Loss=0.012014]\n",
            "5it [00:02,  1.77it/s, Epoch=155, Val Loss=0.038872, Total Val Loss=0.525791]\n",
            "17it [00:11,  1.49it/s, Epoch=156, Loss=0.001162, Total Loss=0.011357]\n",
            "5it [00:02,  1.81it/s, Epoch=156, Val Loss=0.033328, Total Val Loss=0.522610]\n",
            "17it [00:11,  1.45it/s, Epoch=157, Loss=0.000183, Total Loss=0.017174]\n",
            "5it [00:02,  1.86it/s, Epoch=157, Val Loss=0.000011, Total Val Loss=0.217989]\n",
            "17it [00:11,  1.48it/s, Epoch=158, Loss=0.000480, Total Loss=0.003760]\n",
            "5it [00:02,  1.81it/s, Epoch=158, Val Loss=0.000009, Total Val Loss=0.231484]\n",
            "17it [00:11,  1.45it/s, Epoch=159, Loss=0.000605, Total Loss=0.002119]\n",
            "5it [00:02,  1.79it/s, Epoch=159, Val Loss=0.000018, Total Val Loss=0.250431]\n",
            "17it [00:11,  1.51it/s, Epoch=160, Loss=0.000259, Total Loss=0.001061]\n",
            "5it [00:02,  1.81it/s, Epoch=160, Val Loss=0.000022, Total Val Loss=0.262017]\n",
            "17it [00:11,  1.44it/s, Epoch=161, Loss=0.067863, Total Loss=0.006142]\n",
            "5it [00:02,  1.78it/s, Epoch=161, Val Loss=0.000004, Total Val Loss=0.204754]\n",
            "17it [00:11,  1.44it/s, Epoch=162, Loss=0.001212, Total Loss=0.000594]\n",
            "5it [00:02,  1.78it/s, Epoch=162, Val Loss=0.000008, Total Val Loss=0.236617]\n",
            "17it [00:11,  1.48it/s, Epoch=163, Loss=0.000032, Total Loss=0.001430]\n",
            "5it [00:02,  1.76it/s, Epoch=163, Val Loss=0.000014, Total Val Loss=0.219788]\n",
            "17it [00:11,  1.48it/s, Epoch=164, Loss=0.000559, Total Loss=0.002968]\n",
            "5it [00:02,  1.77it/s, Epoch=164, Val Loss=0.000010, Total Val Loss=0.261544]\n",
            "17it [00:11,  1.43it/s, Epoch=165, Loss=0.000291, Total Loss=0.000675]\n",
            "5it [00:02,  1.72it/s, Epoch=165, Val Loss=0.000009, Total Val Loss=0.269268]\n",
            "17it [00:12,  1.40it/s, Epoch=166, Loss=0.000322, Total Loss=0.003023]\n",
            "5it [00:02,  1.81it/s, Epoch=166, Val Loss=0.000007, Total Val Loss=0.247389]\n",
            "17it [00:11,  1.43it/s, Epoch=167, Loss=0.002015, Total Loss=0.001172]\n",
            "5it [00:02,  1.76it/s, Epoch=167, Val Loss=0.000001, Total Val Loss=0.215041]\n",
            "17it [00:12,  1.41it/s, Epoch=168, Loss=0.000726, Total Loss=0.000273]\n",
            "5it [00:02,  1.80it/s, Epoch=168, Val Loss=0.000005, Total Val Loss=0.219685]\n",
            "17it [00:11,  1.46it/s, Epoch=169, Loss=0.000061, Total Loss=0.000467]\n",
            "5it [00:02,  1.75it/s, Epoch=169, Val Loss=0.000006, Total Val Loss=0.233652]\n",
            "17it [00:11,  1.44it/s, Epoch=170, Loss=0.000033, Total Loss=0.000899]\n",
            "5it [00:02,  1.84it/s, Epoch=170, Val Loss=0.000007, Total Val Loss=0.244324]\n",
            "17it [00:11,  1.47it/s, Epoch=171, Loss=0.000005, Total Loss=0.000162]\n",
            "5it [00:02,  1.70it/s, Epoch=171, Val Loss=0.000008, Total Val Loss=0.238434]\n",
            "17it [00:11,  1.47it/s, Epoch=172, Loss=0.000002, Total Loss=0.000196]\n",
            "5it [00:02,  1.83it/s, Epoch=172, Val Loss=0.000015, Total Val Loss=0.308195]\n",
            "17it [00:11,  1.44it/s, Epoch=173, Loss=0.944702, Total Loss=0.055768]\n",
            "5it [00:02,  1.82it/s, Epoch=173, Val Loss=0.000012, Total Val Loss=0.235311]\n",
            "17it [00:11,  1.43it/s, Epoch=174, Loss=0.000156, Total Loss=0.006819]\n",
            "5it [00:02,  1.73it/s, Epoch=174, Val Loss=0.000054, Total Val Loss=0.373243]\n",
            "17it [00:12,  1.41it/s, Epoch=175, Loss=0.000004, Total Loss=0.041309]\n",
            "5it [00:02,  1.79it/s, Epoch=175, Val Loss=0.000021, Total Val Loss=0.487226]\n",
            "17it [00:12,  1.41it/s, Epoch=176, Loss=0.012902, Total Loss=0.001706]\n",
            "5it [00:02,  1.78it/s, Epoch=176, Val Loss=0.000024, Total Val Loss=0.369930]\n",
            "17it [00:11,  1.44it/s, Epoch=177, Loss=0.001682, Total Loss=0.002254]\n",
            "5it [00:02,  1.75it/s, Epoch=177, Val Loss=0.000014, Total Val Loss=0.405043]\n",
            "17it [00:12,  1.38it/s, Epoch=178, Loss=0.000283, Total Loss=0.001130]\n",
            "5it [00:02,  1.72it/s, Epoch=178, Val Loss=0.000012, Total Val Loss=0.360039]\n",
            "17it [00:11,  1.43it/s, Epoch=179, Loss=0.004562, Total Loss=0.007557]\n",
            "5it [00:02,  1.80it/s, Epoch=179, Val Loss=0.000016, Total Val Loss=0.360068]\n",
            "17it [00:12,  1.39it/s, Epoch=180, Loss=0.000038, Total Loss=0.001082]\n",
            "5it [00:02,  1.76it/s, Epoch=180, Val Loss=0.000008, Total Val Loss=0.296878]\n",
            "17it [00:12,  1.40it/s, Epoch=181, Loss=0.006198, Total Loss=0.002574]\n",
            "5it [00:02,  1.78it/s, Epoch=181, Val Loss=0.000008, Total Val Loss=0.314318]\n",
            "17it [00:11,  1.46it/s, Epoch=182, Loss=0.000080, Total Loss=0.000463]\n",
            "5it [00:02,  1.72it/s, Epoch=182, Val Loss=0.000001, Total Val Loss=0.327690]\n",
            "17it [00:11,  1.43it/s, Epoch=183, Loss=0.000220, Total Loss=0.000174]\n",
            "5it [00:02,  1.76it/s, Epoch=183, Val Loss=0.000000, Total Val Loss=0.314878]\n",
            "17it [00:12,  1.35it/s, Epoch=184, Loss=0.027637, Total Loss=0.001841]\n",
            "5it [00:02,  1.74it/s, Epoch=184, Val Loss=0.000001, Total Val Loss=0.297906]\n",
            "17it [00:11,  1.45it/s, Epoch=185, Loss=0.000025, Total Loss=0.000176]\n",
            "5it [00:02,  1.80it/s, Epoch=185, Val Loss=0.000001, Total Val Loss=0.208996]\n",
            "17it [00:11,  1.42it/s, Epoch=186, Loss=0.000003, Total Loss=0.000492]\n",
            "5it [00:02,  1.86it/s, Epoch=186, Val Loss=0.000002, Total Val Loss=0.191400]\n",
            "17it [00:12,  1.41it/s, Epoch=187, Loss=0.000429, Total Loss=0.000498]\n",
            "5it [00:02,  1.82it/s, Epoch=187, Val Loss=0.000003, Total Val Loss=0.230053]\n",
            "17it [00:12,  1.38it/s, Epoch=188, Loss=0.001606, Total Loss=0.002267]\n",
            "5it [00:02,  1.80it/s, Epoch=188, Val Loss=0.000001, Total Val Loss=0.217997]\n",
            "17it [00:12,  1.41it/s, Epoch=189, Loss=0.000010, Total Loss=0.000269]\n",
            "5it [00:02,  1.74it/s, Epoch=189, Val Loss=0.000000, Total Val Loss=0.222336]\n",
            "17it [00:11,  1.49it/s, Epoch=190, Loss=0.000107, Total Loss=0.000221]\n",
            "5it [00:02,  1.74it/s, Epoch=190, Val Loss=0.000002, Total Val Loss=0.252483]\n",
            "17it [00:11,  1.42it/s, Epoch=191, Loss=0.000003, Total Loss=0.000104]\n",
            "5it [00:02,  1.77it/s, Epoch=191, Val Loss=0.000003, Total Val Loss=0.269145]\n",
            "17it [00:12,  1.38it/s, Epoch=192, Loss=0.000013, Total Loss=0.000691]\n",
            "5it [00:02,  1.77it/s, Epoch=192, Val Loss=0.000002, Total Val Loss=0.269360]\n",
            "17it [00:12,  1.39it/s, Epoch=193, Loss=0.000096, Total Loss=0.000332]\n",
            "5it [00:02,  1.71it/s, Epoch=193, Val Loss=0.000001, Total Val Loss=0.234920]\n",
            "17it [00:11,  1.44it/s, Epoch=194, Loss=0.000154, Total Loss=0.000333]\n",
            "5it [00:02,  1.76it/s, Epoch=194, Val Loss=0.000002, Total Val Loss=0.305527]\n",
            "17it [00:12,  1.39it/s, Epoch=195, Loss=0.001072, Total Loss=0.000192]\n",
            "5it [00:02,  1.75it/s, Epoch=195, Val Loss=0.000003, Total Val Loss=0.283247]\n",
            "17it [00:11,  1.47it/s, Epoch=196, Loss=0.001385, Total Loss=0.000458]\n",
            "5it [00:02,  1.74it/s, Epoch=196, Val Loss=0.000007, Total Val Loss=0.284403]\n",
            "17it [00:12,  1.39it/s, Epoch=197, Loss=0.000623, Total Loss=0.000860]\n",
            "5it [00:02,  1.77it/s, Epoch=197, Val Loss=0.000001, Total Val Loss=0.186912]\n",
            "17it [00:11,  1.42it/s, Epoch=198, Loss=0.001309, Total Loss=0.000683]\n",
            "5it [00:02,  1.85it/s, Epoch=198, Val Loss=0.000001, Total Val Loss=0.153222]\n",
            "17it [00:11,  1.45it/s, Epoch=199, Loss=0.000365, Total Loss=0.000211]\n",
            "5it [00:02,  1.76it/s, Epoch=199, Val Loss=0.000001, Total Val Loss=0.185834]\n",
            "17it [00:11,  1.43it/s, Epoch=200, Loss=0.007829, Total Loss=0.000524]\n",
            "5it [00:02,  1.80it/s, Epoch=200, Val Loss=0.000000, Total Val Loss=0.186970]\n",
            "17it [00:12,  1.42it/s, Epoch=201, Loss=0.000051, Total Loss=0.000705]\n",
            "5it [00:02,  1.79it/s, Epoch=201, Val Loss=0.000001, Total Val Loss=0.170387]\n",
            "17it [00:11,  1.45it/s, Epoch=202, Loss=0.000002, Total Loss=0.000083]\n",
            "5it [00:02,  1.71it/s, Epoch=202, Val Loss=0.000001, Total Val Loss=0.156728]\n",
            "17it [00:12,  1.39it/s, Epoch=203, Loss=0.000001, Total Loss=0.000033]\n",
            "5it [00:02,  1.79it/s, Epoch=203, Val Loss=0.000001, Total Val Loss=0.182842]\n",
            "17it [00:11,  1.46it/s, Epoch=204, Loss=0.000041, Total Loss=0.000381]\n",
            "5it [00:02,  1.67it/s, Epoch=204, Val Loss=0.000006, Total Val Loss=0.200853]\n",
            "17it [00:11,  1.46it/s, Epoch=205, Loss=0.003123, Total Loss=0.000749]\n",
            "5it [00:02,  1.73it/s, Epoch=205, Val Loss=0.000000, Total Val Loss=0.198976]\n",
            "17it [00:12,  1.40it/s, Epoch=206, Loss=0.000008, Total Loss=0.000537]\n",
            "5it [00:02,  1.81it/s, Epoch=206, Val Loss=0.000001, Total Val Loss=0.164392]\n",
            "17it [00:11,  1.42it/s, Epoch=207, Loss=0.010496, Total Loss=0.000642]\n",
            "5it [00:02,  1.70it/s, Epoch=207, Val Loss=0.000000, Total Val Loss=0.166944]\n",
            "17it [00:11,  1.43it/s, Epoch=208, Loss=0.000000, Total Loss=0.000045]\n",
            "5it [00:02,  1.82it/s, Epoch=208, Val Loss=0.000002, Total Val Loss=0.153614]\n",
            "17it [00:12,  1.35it/s, Epoch=209, Loss=0.000009, Total Loss=0.000050]\n",
            "5it [00:02,  1.71it/s, Epoch=209, Val Loss=0.000002, Total Val Loss=0.169581]\n",
            "17it [00:11,  1.47it/s, Epoch=210, Loss=0.000047, Total Loss=0.000090]\n",
            "5it [00:02,  1.79it/s, Epoch=210, Val Loss=0.000005, Total Val Loss=0.190918]\n",
            "17it [00:11,  1.46it/s, Epoch=211, Loss=0.000327, Total Loss=0.001819]\n",
            "5it [00:02,  1.75it/s, Epoch=211, Val Loss=0.000008, Total Val Loss=0.228058]\n",
            "17it [00:12,  1.41it/s, Epoch=212, Loss=0.000074, Total Loss=0.000144]\n",
            "5it [00:02,  1.76it/s, Epoch=212, Val Loss=0.000006, Total Val Loss=0.198102]\n",
            "17it [00:12,  1.39it/s, Epoch=213, Loss=0.000033, Total Loss=0.000135]\n",
            "5it [00:02,  1.81it/s, Epoch=213, Val Loss=0.000002, Total Val Loss=0.189634]\n",
            "17it [00:11,  1.47it/s, Epoch=214, Loss=0.000002, Total Loss=0.000368]\n",
            "5it [00:02,  1.80it/s, Epoch=214, Val Loss=0.000005, Total Val Loss=0.220897]\n",
            "17it [00:11,  1.45it/s, Epoch=215, Loss=0.000078, Total Loss=0.000037]\n",
            "5it [00:02,  1.68it/s, Epoch=215, Val Loss=0.000004, Total Val Loss=0.200251]\n",
            "17it [00:12,  1.39it/s, Epoch=216, Loss=0.000013, Total Loss=0.000404]\n",
            "5it [00:02,  1.75it/s, Epoch=216, Val Loss=0.000005, Total Val Loss=0.235946]\n",
            "17it [00:12,  1.39it/s, Epoch=217, Loss=0.000000, Total Loss=0.000335]\n",
            "5it [00:02,  1.75it/s, Epoch=217, Val Loss=0.000003, Total Val Loss=0.294616]\n",
            "17it [00:11,  1.50it/s, Epoch=218, Loss=0.001884, Total Loss=0.000365]\n",
            "5it [00:02,  1.67it/s, Epoch=218, Val Loss=0.000002, Total Val Loss=0.294220]\n",
            "17it [00:11,  1.42it/s, Epoch=219, Loss=0.000214, Total Loss=0.000102]\n",
            "5it [00:02,  1.74it/s, Epoch=219, Val Loss=0.000002, Total Val Loss=0.268803]\n",
            "17it [00:11,  1.43it/s, Epoch=220, Loss=0.000002, Total Loss=0.007620]\n",
            "5it [00:02,  1.76it/s, Epoch=220, Val Loss=0.000003, Total Val Loss=0.254456]\n",
            "17it [00:12,  1.41it/s, Epoch=221, Loss=0.012855, Total Loss=0.000775]\n",
            "5it [00:02,  1.70it/s, Epoch=221, Val Loss=0.000007, Total Val Loss=0.392503]\n",
            "17it [00:11,  1.45it/s, Epoch=222, Loss=0.012761, Total Loss=0.000795]\n",
            "5it [00:02,  1.86it/s, Epoch=222, Val Loss=0.000007, Total Val Loss=0.405374]\n",
            "17it [00:11,  1.42it/s, Epoch=223, Loss=0.000001, Total Loss=0.002562]\n",
            "5it [00:02,  1.71it/s, Epoch=223, Val Loss=0.000006, Total Val Loss=0.278621]\n",
            "17it [00:11,  1.43it/s, Epoch=224, Loss=0.000156, Total Loss=0.000306]\n",
            "5it [00:02,  1.71it/s, Epoch=224, Val Loss=0.000019, Total Val Loss=0.319198]\n",
            "17it [00:11,  1.43it/s, Epoch=225, Loss=0.000013, Total Loss=0.000086]\n",
            "5it [00:03,  1.66it/s, Epoch=225, Val Loss=0.000008, Total Val Loss=0.252472]\n",
            "17it [00:11,  1.43it/s, Epoch=226, Loss=0.000018, Total Loss=0.000973]\n",
            "5it [00:02,  1.77it/s, Epoch=226, Val Loss=0.000001, Total Val Loss=0.304871]\n",
            "17it [00:11,  1.51it/s, Epoch=227, Loss=0.000041, Total Loss=0.000078]\n",
            "5it [00:02,  1.68it/s, Epoch=227, Val Loss=0.000001, Total Val Loss=0.341055]\n",
            "17it [00:12,  1.38it/s, Epoch=228, Loss=0.000101, Total Loss=0.000086]\n",
            "5it [00:02,  1.71it/s, Epoch=228, Val Loss=0.000002, Total Val Loss=0.336704]\n",
            "17it [00:11,  1.49it/s, Epoch=229, Loss=0.416738, Total Loss=0.024741]\n",
            "5it [00:02,  1.70it/s, Epoch=229, Val Loss=0.000001, Total Val Loss=0.396041]\n",
            "17it [00:12,  1.41it/s, Epoch=230, Loss=0.001332, Total Loss=0.003908]\n",
            "5it [00:02,  1.70it/s, Epoch=230, Val Loss=0.000024, Total Val Loss=0.260427]\n",
            "17it [00:11,  1.44it/s, Epoch=231, Loss=0.000683, Total Loss=0.067576]\n",
            "5it [00:02,  1.85it/s, Epoch=231, Val Loss=0.019397, Total Val Loss=0.385750]\n",
            "17it [00:11,  1.51it/s, Epoch=232, Loss=0.030949, Total Loss=0.054132]\n",
            "5it [00:02,  1.74it/s, Epoch=232, Val Loss=0.012282, Total Val Loss=0.446968]\n",
            "17it [00:12,  1.40it/s, Epoch=233, Loss=0.000034, Total Loss=0.036363]\n",
            "5it [00:02,  1.77it/s, Epoch=233, Val Loss=0.001100, Total Val Loss=0.223383]\n",
            "17it [00:12,  1.41it/s, Epoch=234, Loss=0.000110, Total Loss=0.055301]\n",
            "5it [00:02,  1.71it/s, Epoch=234, Val Loss=0.000013, Total Val Loss=0.230147]\n",
            "17it [00:12,  1.41it/s, Epoch=235, Loss=0.000097, Total Loss=0.075130]\n",
            "5it [00:02,  1.73it/s, Epoch=235, Val Loss=0.000000, Total Val Loss=0.822693]\n",
            "17it [00:11,  1.47it/s, Epoch=236, Loss=0.007682, Total Loss=0.235389]\n",
            "5it [00:02,  1.69it/s, Epoch=236, Val Loss=0.000000, Total Val Loss=1.271895]\n",
            "17it [00:12,  1.40it/s, Epoch=237, Loss=0.000271, Total Loss=0.080620]\n",
            "5it [00:02,  1.69it/s, Epoch=237, Val Loss=0.007093, Total Val Loss=0.711845]\n",
            "17it [00:11,  1.47it/s, Epoch=238, Loss=0.006788, Total Loss=0.029268]\n",
            "5it [00:02,  1.70it/s, Epoch=238, Val Loss=0.014419, Total Val Loss=0.389229]\n",
            "17it [00:12,  1.41it/s, Epoch=239, Loss=0.003103, Total Loss=0.022124]\n",
            "5it [00:02,  1.71it/s, Epoch=239, Val Loss=0.025113, Total Val Loss=0.422309]\n",
            "17it [00:12,  1.40it/s, Epoch=240, Loss=0.150628, Total Loss=0.022666]\n",
            "5it [00:02,  1.71it/s, Epoch=240, Val Loss=1.408486, Total Val Loss=0.996815]\n",
            "17it [00:12,  1.37it/s, Epoch=241, Loss=0.000201, Total Loss=0.031383]\n",
            "5it [00:02,  1.73it/s, Epoch=241, Val Loss=0.706785, Total Val Loss=0.739154]\n",
            "17it [00:12,  1.41it/s, Epoch=242, Loss=0.000054, Total Loss=0.020985]\n",
            "5it [00:03,  1.63it/s, Epoch=242, Val Loss=0.007720, Total Val Loss=0.329968]\n",
            "17it [00:12,  1.37it/s, Epoch=243, Loss=0.000014, Total Loss=0.000798]\n",
            "5it [00:02,  1.67it/s, Epoch=243, Val Loss=0.000945, Total Val Loss=0.260804]\n",
            "17it [00:11,  1.48it/s, Epoch=244, Loss=0.011881, Total Loss=0.002076]\n",
            "5it [00:02,  1.69it/s, Epoch=244, Val Loss=0.000492, Total Val Loss=0.274739]\n",
            "17it [00:12,  1.38it/s, Epoch=245, Loss=0.005379, Total Loss=0.000481]\n",
            "5it [00:02,  1.68it/s, Epoch=245, Val Loss=0.003625, Total Val Loss=0.294234]\n",
            "17it [00:12,  1.41it/s, Epoch=246, Loss=0.001372, Total Loss=0.000246]\n",
            "5it [00:02,  1.73it/s, Epoch=246, Val Loss=0.001649, Total Val Loss=0.251726]\n",
            "17it [00:11,  1.43it/s, Epoch=247, Loss=0.000844, Total Loss=0.001057]\n",
            "5it [00:02,  1.72it/s, Epoch=247, Val Loss=0.000158, Total Val Loss=0.188719]\n",
            "17it [00:12,  1.39it/s, Epoch=248, Loss=0.027393, Total Loss=0.001684]\n",
            "5it [00:02,  1.70it/s, Epoch=248, Val Loss=0.000248, Total Val Loss=0.202703]\n",
            "17it [00:12,  1.40it/s, Epoch=249, Loss=0.052584, Total Loss=0.003726]\n",
            "5it [00:02,  1.77it/s, Epoch=249, Val Loss=0.000523, Total Val Loss=0.269313]\n",
            "17it [00:12,  1.40it/s, Epoch=250, Loss=0.000234, Total Loss=0.000274]\n",
            "5it [00:02,  1.69it/s, Epoch=250, Val Loss=0.000045, Total Val Loss=0.371090]\n",
            "17it [00:12,  1.38it/s, Epoch=251, Loss=0.004279, Total Loss=0.002028]\n",
            "5it [00:02,  1.68it/s, Epoch=251, Val Loss=0.000020, Total Val Loss=0.318632]\n",
            "17it [00:12,  1.39it/s, Epoch=252, Loss=0.212916, Total Loss=0.012805]\n",
            "5it [00:02,  1.70it/s, Epoch=252, Val Loss=0.000117, Total Val Loss=0.543387]\n",
            "17it [00:12,  1.36it/s, Epoch=253, Loss=0.016938, Total Loss=0.006242]\n",
            "5it [00:02,  1.70it/s, Epoch=253, Val Loss=0.281044, Total Val Loss=1.733062]\n",
            "17it [00:12,  1.41it/s, Epoch=254, Loss=0.021710, Total Loss=0.007174]\n",
            "5it [00:02,  1.74it/s, Epoch=254, Val Loss=0.008971, Total Val Loss=1.241902]\n",
            "17it [00:12,  1.39it/s, Epoch=255, Loss=0.078636, Total Loss=0.005710]\n",
            "5it [00:02,  1.74it/s, Epoch=255, Val Loss=0.025467, Total Val Loss=0.968537]\n",
            "17it [00:12,  1.39it/s, Epoch=256, Loss=0.000028, Total Loss=0.003788]\n",
            "5it [00:02,  1.73it/s, Epoch=256, Val Loss=0.009935, Total Val Loss=0.739246]\n",
            "17it [00:11,  1.45it/s, Epoch=257, Loss=0.000004, Total Loss=0.003823]\n",
            "5it [00:03,  1.66it/s, Epoch=257, Val Loss=0.009601, Total Val Loss=0.850054]\n",
            "17it [00:12,  1.40it/s, Epoch=258, Loss=0.000022, Total Loss=0.001537]\n",
            "5it [00:03,  1.61it/s, Epoch=258, Val Loss=0.014723, Total Val Loss=0.853130]\n",
            "17it [00:12,  1.41it/s, Epoch=259, Loss=0.000024, Total Loss=0.002244]\n",
            "5it [00:02,  1.68it/s, Epoch=259, Val Loss=0.000414, Total Val Loss=0.719805]\n",
            "17it [00:11,  1.44it/s, Epoch=260, Loss=0.000040, Total Loss=0.000170]\n",
            "5it [00:02,  1.67it/s, Epoch=260, Val Loss=0.000457, Total Val Loss=0.704912]\n",
            "17it [00:11,  1.46it/s, Epoch=261, Loss=0.000001, Total Loss=0.001918]\n",
            "5it [00:02,  1.75it/s, Epoch=261, Val Loss=0.000450, Total Val Loss=0.748909]\n",
            "17it [00:11,  1.43it/s, Epoch=262, Loss=0.000183, Total Loss=0.000194]\n",
            "5it [00:02,  1.78it/s, Epoch=262, Val Loss=0.000143, Total Val Loss=0.677815]\n",
            "17it [00:11,  1.42it/s, Epoch=263, Loss=0.029443, Total Loss=0.002001]\n",
            "5it [00:02,  1.72it/s, Epoch=263, Val Loss=0.000134, Total Val Loss=0.682559]\n",
            "17it [00:11,  1.44it/s, Epoch=264, Loss=0.000012, Total Loss=0.000088]\n",
            "5it [00:02,  1.70it/s, Epoch=264, Val Loss=0.000244, Total Val Loss=0.703231]\n",
            "17it [00:12,  1.42it/s, Epoch=265, Loss=0.001153, Total Loss=0.000761]\n",
            "5it [00:02,  1.68it/s, Epoch=265, Val Loss=0.000048, Total Val Loss=0.673440]\n",
            "17it [00:12,  1.40it/s, Epoch=266, Loss=0.000006, Total Loss=0.000351]\n",
            "5it [00:03,  1.67it/s, Epoch=266, Val Loss=0.000098, Total Val Loss=0.621586]\n",
            "17it [00:11,  1.47it/s, Epoch=267, Loss=0.000030, Total Loss=0.000962]\n",
            "5it [00:02,  1.76it/s, Epoch=267, Val Loss=0.000540, Total Val Loss=0.596212]\n",
            "17it [00:12,  1.37it/s, Epoch=268, Loss=0.000012, Total Loss=0.000495]\n",
            "5it [00:02,  1.68it/s, Epoch=268, Val Loss=0.000303, Total Val Loss=0.667271]\n",
            "17it [00:12,  1.40it/s, Epoch=269, Loss=0.988265, Total Loss=0.058470]\n",
            "5it [00:02,  1.73it/s, Epoch=269, Val Loss=0.000583, Total Val Loss=0.769180]\n",
            "17it [00:12,  1.38it/s, Epoch=270, Loss=0.001344, Total Loss=0.082954]\n",
            "5it [00:02,  1.69it/s, Epoch=270, Val Loss=0.000510, Total Val Loss=0.730755]\n",
            "17it [00:12,  1.37it/s, Epoch=271, Loss=0.004795, Total Loss=0.123124]\n",
            "5it [00:03,  1.62it/s, Epoch=271, Val Loss=0.000021, Total Val Loss=0.984471]\n",
            "17it [00:12,  1.40it/s, Epoch=272, Loss=0.048849, Total Loss=0.012920]\n",
            "5it [00:02,  1.68it/s, Epoch=272, Val Loss=0.000078, Total Val Loss=0.808730]\n",
            "17it [00:11,  1.45it/s, Epoch=273, Loss=0.000096, Total Loss=0.015191]\n",
            "5it [00:03,  1.65it/s, Epoch=273, Val Loss=0.000318, Total Val Loss=0.760084]\n",
            "17it [00:11,  1.44it/s, Epoch=274, Loss=0.000321, Total Loss=0.000921]\n",
            "5it [00:03,  1.64it/s, Epoch=274, Val Loss=0.000721, Total Val Loss=0.694314]\n",
            "17it [00:11,  1.44it/s, Epoch=275, Loss=0.000517, Total Loss=0.010604]\n",
            "5it [00:02,  1.69it/s, Epoch=275, Val Loss=0.001184, Total Val Loss=0.648016]\n",
            "17it [00:12,  1.39it/s, Epoch=276, Loss=0.000282, Total Loss=0.005852]\n",
            "5it [00:02,  1.72it/s, Epoch=276, Val Loss=0.000241, Total Val Loss=0.531884]\n",
            "17it [00:11,  1.46it/s, Epoch=277, Loss=0.000075, Total Loss=0.013006]\n",
            "5it [00:02,  1.75it/s, Epoch=277, Val Loss=0.001159, Total Val Loss=0.684372]\n",
            "17it [00:12,  1.37it/s, Epoch=278, Loss=0.001436, Total Loss=0.002983]\n",
            "5it [00:02,  1.69it/s, Epoch=278, Val Loss=0.001927, Total Val Loss=0.786321]\n",
            "17it [00:12,  1.39it/s, Epoch=279, Loss=0.000030, Total Loss=0.001734]\n",
            "5it [00:03,  1.61it/s, Epoch=279, Val Loss=0.000632, Total Val Loss=0.803484]\n",
            "17it [00:11,  1.48it/s, Epoch=280, Loss=0.010368, Total Loss=0.000975]\n",
            "5it [00:02,  1.68it/s, Epoch=280, Val Loss=0.000094, Total Val Loss=0.717677]\n",
            "17it [00:12,  1.40it/s, Epoch=281, Loss=0.000060, Total Loss=0.000448]\n",
            "5it [00:02,  1.71it/s, Epoch=281, Val Loss=0.000107, Total Val Loss=0.788430]\n",
            "17it [00:11,  1.46it/s, Epoch=282, Loss=0.000031, Total Loss=0.001429]\n",
            "5it [00:02,  1.67it/s, Epoch=282, Val Loss=0.000054, Total Val Loss=0.752879]\n",
            "17it [00:11,  1.45it/s, Epoch=283, Loss=0.000024, Total Loss=0.000155]\n",
            "5it [00:02,  1.73it/s, Epoch=283, Val Loss=0.000082, Total Val Loss=0.740693]\n",
            "17it [00:11,  1.47it/s, Epoch=284, Loss=0.000011, Total Loss=0.000297]\n",
            "5it [00:03,  1.65it/s, Epoch=284, Val Loss=0.000338, Total Val Loss=0.767059]\n",
            "17it [00:12,  1.41it/s, Epoch=285, Loss=0.007805, Total Loss=0.000944]\n",
            "5it [00:03,  1.66it/s, Epoch=285, Val Loss=0.000028, Total Val Loss=0.731413]\n",
            "17it [00:12,  1.39it/s, Epoch=286, Loss=0.000008, Total Loss=0.000111]\n",
            "5it [00:02,  1.74it/s, Epoch=286, Val Loss=0.000146, Total Val Loss=0.721660]\n",
            "17it [00:12,  1.41it/s, Epoch=287, Loss=0.000199, Total Loss=0.000078]\n",
            "5it [00:02,  1.69it/s, Epoch=287, Val Loss=0.000098, Total Val Loss=0.688054]\n",
            "17it [00:11,  1.47it/s, Epoch=288, Loss=0.000710, Total Loss=0.000743]\n",
            "5it [00:03,  1.63it/s, Epoch=288, Val Loss=0.000138, Total Val Loss=0.753879]\n",
            "17it [00:11,  1.42it/s, Epoch=289, Loss=0.000001, Total Loss=0.000083]\n",
            "5it [00:02,  1.73it/s, Epoch=289, Val Loss=0.000066, Total Val Loss=0.767802]\n",
            "17it [00:12,  1.42it/s, Epoch=290, Loss=0.001551, Total Loss=0.004480]\n",
            "5it [00:02,  1.70it/s, Epoch=290, Val Loss=0.000001, Total Val Loss=0.664439]\n",
            "17it [00:12,  1.39it/s, Epoch=291, Loss=0.000026, Total Loss=0.005113]\n",
            "5it [00:02,  1.67it/s, Epoch=291, Val Loss=0.000142, Total Val Loss=0.440184]\n",
            "17it [00:11,  1.42it/s, Epoch=292, Loss=0.000209, Total Loss=0.000372]\n",
            "5it [00:03,  1.66it/s, Epoch=292, Val Loss=0.011602, Total Val Loss=0.488468]\n",
            "17it [00:12,  1.38it/s, Epoch=293, Loss=0.090142, Total Loss=0.005839]\n",
            "5it [00:03,  1.66it/s, Epoch=293, Val Loss=0.002375, Total Val Loss=0.515271]\n",
            "17it [00:12,  1.39it/s, Epoch=294, Loss=0.005529, Total Loss=0.001417]\n",
            "5it [00:02,  1.73it/s, Epoch=294, Val Loss=0.014200, Total Val Loss=0.487227]\n",
            "17it [00:12,  1.38it/s, Epoch=295, Loss=0.000002, Total Loss=0.026493]\n",
            "5it [00:02,  1.70it/s, Epoch=295, Val Loss=0.004758, Total Val Loss=0.644494]\n",
            "17it [00:12,  1.41it/s, Epoch=296, Loss=0.000001, Total Loss=0.000428]\n",
            "5it [00:03,  1.61it/s, Epoch=296, Val Loss=0.011637, Total Val Loss=0.821112]\n",
            "17it [00:12,  1.37it/s, Epoch=297, Loss=0.281419, Total Loss=0.017672]\n",
            "5it [00:03,  1.66it/s, Epoch=297, Val Loss=0.003451, Total Val Loss=0.740015]\n",
            "17it [00:11,  1.42it/s, Epoch=298, Loss=0.000377, Total Loss=0.011826]\n",
            "5it [00:02,  1.70it/s, Epoch=298, Val Loss=0.000000, Total Val Loss=0.600865]\n",
            "17it [00:11,  1.44it/s, Epoch=299, Loss=0.000083, Total Loss=0.028894]\n",
            "5it [00:02,  1.72it/s, Epoch=299, Val Loss=0.000009, Total Val Loss=0.345803]\n",
            "17it [00:11,  1.50it/s, Epoch=300, Loss=0.000004, Total Loss=0.003163]\n",
            "5it [00:03,  1.61it/s, Epoch=300, Val Loss=0.000053, Total Val Loss=0.412415]\n",
            "17it [00:11,  1.42it/s, Epoch=301, Loss=0.000005, Total Loss=0.000775]\n",
            "5it [00:02,  1.69it/s, Epoch=301, Val Loss=0.000039, Total Val Loss=0.460356]\n",
            "17it [00:12,  1.41it/s, Epoch=302, Loss=0.000015, Total Loss=0.000419]\n",
            "5it [00:02,  1.75it/s, Epoch=302, Val Loss=0.000021, Total Val Loss=0.422959]\n",
            "17it [00:12,  1.38it/s, Epoch=303, Loss=0.000024, Total Loss=0.000096]\n",
            "5it [00:02,  1.75it/s, Epoch=303, Val Loss=0.000080, Total Val Loss=0.462226]\n",
            "17it [00:11,  1.47it/s, Epoch=304, Loss=0.001335, Total Loss=0.006759]\n",
            "5it [00:02,  1.69it/s, Epoch=304, Val Loss=0.000145, Total Val Loss=0.340450]\n",
            "17it [00:12,  1.40it/s, Epoch=305, Loss=0.000012, Total Loss=0.000205]\n",
            "5it [00:03,  1.65it/s, Epoch=305, Val Loss=0.000240, Total Val Loss=0.305652]\n",
            "17it [00:11,  1.43it/s, Epoch=306, Loss=0.000518, Total Loss=0.000416]\n",
            "5it [00:02,  1.69it/s, Epoch=306, Val Loss=0.002102, Total Val Loss=0.558310]\n",
            "17it [00:12,  1.40it/s, Epoch=307, Loss=0.015760, Total Loss=0.001034]\n",
            "5it [00:03,  1.65it/s, Epoch=307, Val Loss=0.000724, Total Val Loss=0.582784]\n",
            "17it [00:11,  1.46it/s, Epoch=308, Loss=0.000001, Total Loss=0.001087]\n",
            "5it [00:02,  1.68it/s, Epoch=308, Val Loss=0.000711, Total Val Loss=0.650992]\n",
            "17it [00:11,  1.44it/s, Epoch=309, Loss=0.006749, Total Loss=0.000526]\n",
            "5it [00:02,  1.71it/s, Epoch=309, Val Loss=0.000559, Total Val Loss=0.698498]\n",
            "17it [00:12,  1.39it/s, Epoch=310, Loss=0.000001, Total Loss=0.000205]\n",
            "5it [00:02,  1.67it/s, Epoch=310, Val Loss=0.000121, Total Val Loss=0.588733]\n",
            "17it [00:11,  1.42it/s, Epoch=311, Loss=0.000285, Total Loss=0.000070]\n",
            "5it [00:03,  1.59it/s, Epoch=311, Val Loss=0.000240, Total Val Loss=0.576728]\n",
            "17it [00:11,  1.46it/s, Epoch=312, Loss=0.000007, Total Loss=0.014141]\n",
            "5it [00:02,  1.74it/s, Epoch=312, Val Loss=0.000002, Total Val Loss=0.820110]\n",
            "17it [00:12,  1.39it/s, Epoch=313, Loss=0.000279, Total Loss=0.011443]\n",
            "5it [00:02,  1.71it/s, Epoch=313, Val Loss=0.000002, Total Val Loss=0.638323]\n",
            "17it [00:11,  1.47it/s, Epoch=314, Loss=0.000124, Total Loss=0.005165]\n",
            "5it [00:02,  1.69it/s, Epoch=314, Val Loss=0.000000, Total Val Loss=0.481086]\n",
            "17it [00:12,  1.39it/s, Epoch=315, Loss=0.000349, Total Loss=0.029538]\n",
            "5it [00:03,  1.65it/s, Epoch=315, Val Loss=0.000000, Total Val Loss=0.309729]\n",
            "17it [00:12,  1.39it/s, Epoch=316, Loss=0.000015, Total Loss=0.033225]\n",
            "5it [00:02,  1.70it/s, Epoch=316, Val Loss=0.000000, Total Val Loss=0.433533]\n",
            "17it [00:12,  1.38it/s, Epoch=317, Loss=1.758423, Total Loss=0.105377]\n",
            "5it [00:03,  1.66it/s, Epoch=317, Val Loss=0.000015, Total Val Loss=0.402833]\n",
            "17it [00:12,  1.35it/s, Epoch=318, Loss=0.000209, Total Loss=0.023829]\n",
            "5it [00:02,  1.73it/s, Epoch=318, Val Loss=0.000086, Total Val Loss=0.688123]\n",
            "17it [00:11,  1.42it/s, Epoch=319, Loss=0.000005, Total Loss=0.012115]\n",
            "5it [00:03,  1.64it/s, Epoch=319, Val Loss=0.000688, Total Val Loss=0.849532]\n",
            "17it [00:12,  1.39it/s, Epoch=320, Loss=0.000621, Total Loss=0.094775]\n",
            "5it [00:02,  1.68it/s, Epoch=320, Val Loss=0.000022, Total Val Loss=0.267397]\n",
            "17it [00:12,  1.41it/s, Epoch=321, Loss=0.001342, Total Loss=0.050652]\n",
            "5it [00:03,  1.65it/s, Epoch=321, Val Loss=0.130984, Total Val Loss=0.901759]\n",
            "17it [00:12,  1.36it/s, Epoch=322, Loss=0.000012, Total Loss=0.117913]\n",
            "5it [00:02,  1.76it/s, Epoch=322, Val Loss=0.000064, Total Val Loss=0.780118]\n",
            "17it [00:12,  1.33it/s, Epoch=323, Loss=0.822323, Total Loss=0.097363]\n",
            "5it [00:02,  1.74it/s, Epoch=323, Val Loss=0.000060, Total Val Loss=1.356654]\n",
            "17it [00:12,  1.34it/s, Epoch=324, Loss=0.071159, Total Loss=0.010794]\n",
            "5it [00:02,  1.68it/s, Epoch=324, Val Loss=0.000054, Total Val Loss=0.987803]\n",
            "17it [00:12,  1.37it/s, Epoch=325, Loss=0.853564, Total Loss=0.120626]\n",
            "5it [00:02,  1.69it/s, Epoch=325, Val Loss=0.648689, Total Val Loss=0.669454]\n",
            "17it [00:12,  1.37it/s, Epoch=326, Loss=0.000148, Total Loss=0.002201]\n",
            "5it [00:03,  1.63it/s, Epoch=326, Val Loss=0.506487, Total Val Loss=0.971468]\n",
            "17it [00:12,  1.38it/s, Epoch=327, Loss=0.000049, Total Loss=0.010453]\n",
            "5it [00:03,  1.62it/s, Epoch=327, Val Loss=0.195779, Total Val Loss=0.709140]\n",
            "17it [00:11,  1.45it/s, Epoch=328, Loss=0.000017, Total Loss=0.030365]\n",
            "5it [00:02,  1.68it/s, Epoch=328, Val Loss=0.009223, Total Val Loss=0.678267]\n",
            "17it [00:12,  1.40it/s, Epoch=329, Loss=0.000003, Total Loss=0.058947]\n",
            "5it [00:03,  1.62it/s, Epoch=329, Val Loss=0.000003, Total Val Loss=1.002779]\n",
            "17it [00:11,  1.42it/s, Epoch=330, Loss=0.000006, Total Loss=0.017231]\n",
            "5it [00:02,  1.68it/s, Epoch=330, Val Loss=0.000011, Total Val Loss=0.771789]\n",
            "17it [00:12,  1.38it/s, Epoch=331, Loss=0.000059, Total Loss=0.000422]\n",
            "5it [00:02,  1.68it/s, Epoch=331, Val Loss=0.000005, Total Val Loss=0.696265]\n",
            "17it [00:11,  1.46it/s, Epoch=332, Loss=0.815998, Total Loss=0.048827]\n",
            "5it [00:03,  1.65it/s, Epoch=332, Val Loss=0.000016, Total Val Loss=0.700499]\n",
            "17it [00:11,  1.49it/s, Epoch=333, Loss=0.004152, Total Loss=0.005960]\n",
            "5it [00:02,  1.67it/s, Epoch=333, Val Loss=0.001054, Total Val Loss=0.629635]\n",
            "17it [00:12,  1.34it/s, Epoch=334, Loss=0.012483, Total Loss=0.013557]\n",
            "5it [00:03,  1.63it/s, Epoch=334, Val Loss=0.000586, Total Val Loss=0.558161]\n",
            "17it [00:12,  1.39it/s, Epoch=335, Loss=0.000150, Total Loss=0.003385]\n",
            "5it [00:03,  1.65it/s, Epoch=335, Val Loss=0.001080, Total Val Loss=0.499946]\n",
            "17it [00:12,  1.38it/s, Epoch=336, Loss=0.032137, Total Loss=0.011937]\n",
            "5it [00:02,  1.71it/s, Epoch=336, Val Loss=0.000796, Total Val Loss=0.481129]\n",
            "17it [00:12,  1.38it/s, Epoch=337, Loss=0.001304, Total Loss=0.001337]\n",
            "5it [00:02,  1.68it/s, Epoch=337, Val Loss=0.000277, Total Val Loss=0.441430]\n",
            "17it [00:12,  1.41it/s, Epoch=338, Loss=0.000018, Total Loss=0.010350]\n",
            "5it [00:02,  1.73it/s, Epoch=338, Val Loss=0.000029, Total Val Loss=0.418530]\n",
            "17it [00:11,  1.42it/s, Epoch=339, Loss=0.000125, Total Loss=0.000907]\n",
            "5it [00:02,  1.68it/s, Epoch=339, Val Loss=0.000023, Total Val Loss=0.398447]\n",
            "17it [00:12,  1.38it/s, Epoch=340, Loss=0.000156, Total Loss=0.005789]\n",
            "5it [00:03,  1.62it/s, Epoch=340, Val Loss=0.001094, Total Val Loss=0.481061]\n",
            "17it [00:12,  1.42it/s, Epoch=341, Loss=0.000008, Total Loss=0.007685]\n",
            "5it [00:03,  1.64it/s, Epoch=341, Val Loss=0.000015, Total Val Loss=0.519071]\n",
            "17it [00:12,  1.40it/s, Epoch=342, Loss=0.000001, Total Loss=0.000420]\n",
            "5it [00:02,  1.72it/s, Epoch=342, Val Loss=0.000012, Total Val Loss=0.506231]\n",
            "17it [00:12,  1.40it/s, Epoch=343, Loss=0.000001, Total Loss=0.001838]\n",
            "5it [00:03,  1.65it/s, Epoch=343, Val Loss=0.000002, Total Val Loss=0.530986]\n",
            "17it [00:11,  1.53it/s, Epoch=344, Loss=0.000174, Total Loss=0.000076]\n",
            "5it [00:03,  1.64it/s, Epoch=344, Val Loss=0.000009, Total Val Loss=0.524444]\n",
            "17it [00:12,  1.39it/s, Epoch=345, Loss=0.000656, Total Loss=0.000136]\n",
            "5it [00:02,  1.69it/s, Epoch=345, Val Loss=0.000060, Total Val Loss=0.539878]\n",
            "17it [00:12,  1.40it/s, Epoch=346, Loss=0.006861, Total Loss=0.001158]\n",
            "5it [00:03,  1.63it/s, Epoch=346, Val Loss=0.000016, Total Val Loss=0.507779]\n",
            "17it [00:12,  1.41it/s, Epoch=347, Loss=0.000004, Total Loss=0.000314]\n",
            "5it [00:03,  1.61it/s, Epoch=347, Val Loss=0.000014, Total Val Loss=0.543806]\n",
            "17it [00:11,  1.42it/s, Epoch=348, Loss=0.006249, Total Loss=0.000404]\n",
            "5it [00:02,  1.72it/s, Epoch=348, Val Loss=0.000014, Total Val Loss=0.516604]\n",
            "17it [00:12,  1.40it/s, Epoch=349, Loss=0.000022, Total Loss=0.000094]\n",
            "5it [00:03,  1.66it/s, Epoch=349, Val Loss=0.000006, Total Val Loss=0.500559]\n",
            "17it [00:12,  1.40it/s, Epoch=350, Loss=0.000001, Total Loss=0.000174]\n",
            "5it [00:03,  1.66it/s, Epoch=350, Val Loss=0.000034, Total Val Loss=0.574871]\n",
            "17it [00:12,  1.40it/s, Epoch=351, Loss=0.000014, Total Loss=0.000089]\n",
            "5it [00:03,  1.59it/s, Epoch=351, Val Loss=0.000024, Total Val Loss=0.576731]\n",
            "17it [00:11,  1.48it/s, Epoch=352, Loss=0.000033, Total Loss=0.000201]\n",
            "5it [00:03,  1.63it/s, Epoch=352, Val Loss=0.000007, Total Val Loss=0.573672]\n",
            "17it [00:12,  1.38it/s, Epoch=353, Loss=0.017321, Total Loss=0.002006]\n",
            "5it [00:02,  1.71it/s, Epoch=353, Val Loss=0.000026, Total Val Loss=0.601625]\n",
            "17it [00:12,  1.41it/s, Epoch=354, Loss=0.051467, Total Loss=0.003079]\n",
            "5it [00:02,  1.70it/s, Epoch=354, Val Loss=0.000025, Total Val Loss=0.559249]\n",
            "17it [00:12,  1.35it/s, Epoch=355, Loss=0.008116, Total Loss=0.000612]\n",
            "5it [00:02,  1.69it/s, Epoch=355, Val Loss=0.001316, Total Val Loss=0.894339]\n",
            "17it [00:12,  1.37it/s, Epoch=356, Loss=0.000298, Total Loss=0.000910]\n",
            "5it [00:03,  1.62it/s, Epoch=356, Val Loss=0.000643, Total Val Loss=0.984396]\n",
            "17it [00:12,  1.41it/s, Epoch=357, Loss=0.092655, Total Loss=0.005531]\n",
            "5it [00:03,  1.66it/s, Epoch=357, Val Loss=0.000481, Total Val Loss=0.898301]\n",
            "17it [00:12,  1.37it/s, Epoch=358, Loss=0.000003, Total Loss=0.000153]\n",
            "5it [00:02,  1.71it/s, Epoch=358, Val Loss=0.000032, Total Val Loss=0.643478]\n",
            "17it [00:11,  1.43it/s, Epoch=359, Loss=0.000001, Total Loss=0.000467]\n",
            "5it [00:03,  1.62it/s, Epoch=359, Val Loss=0.000008, Total Val Loss=0.660567]\n",
            "17it [00:11,  1.44it/s, Epoch=360, Loss=0.000374, Total Loss=0.001247]\n",
            "5it [00:03,  1.66it/s, Epoch=360, Val Loss=0.000007, Total Val Loss=0.701315]\n",
            "17it [00:11,  1.44it/s, Epoch=361, Loss=0.000021, Total Loss=0.000091]\n",
            "5it [00:02,  1.74it/s, Epoch=361, Val Loss=0.000012, Total Val Loss=0.640530]\n",
            "17it [00:11,  1.42it/s, Epoch=362, Loss=0.000006, Total Loss=0.000031]\n",
            "5it [00:03,  1.60it/s, Epoch=362, Val Loss=0.000023, Total Val Loss=0.638612]\n",
            "17it [00:11,  1.43it/s, Epoch=363, Loss=0.000200, Total Loss=0.000145]\n",
            "5it [00:03,  1.59it/s, Epoch=363, Val Loss=0.000037, Total Val Loss=0.653177]\n",
            "17it [00:11,  1.42it/s, Epoch=364, Loss=0.000008, Total Loss=0.000020]\n",
            "5it [00:03,  1.57it/s, Epoch=364, Val Loss=0.000046, Total Val Loss=0.606406]\n",
            "17it [00:12,  1.41it/s, Epoch=365, Loss=0.000020, Total Loss=0.000060]\n",
            "5it [00:03,  1.65it/s, Epoch=365, Val Loss=0.000017, Total Val Loss=0.646377]\n",
            "17it [00:12,  1.40it/s, Epoch=366, Loss=0.000006, Total Loss=0.000766]\n",
            "5it [00:03,  1.64it/s, Epoch=366, Val Loss=0.000004, Total Val Loss=0.670700]\n",
            "17it [00:12,  1.36it/s, Epoch=367, Loss=0.000036, Total Loss=0.000102]\n",
            "5it [00:02,  1.69it/s, Epoch=367, Val Loss=0.000011, Total Val Loss=0.634472]\n",
            "17it [00:11,  1.44it/s, Epoch=368, Loss=0.005665, Total Loss=0.000369]\n",
            "5it [00:03,  1.59it/s, Epoch=368, Val Loss=0.000006, Total Val Loss=0.677091]\n",
            "17it [00:11,  1.42it/s, Epoch=369, Loss=0.000000, Total Loss=0.000076]\n",
            "5it [00:03,  1.58it/s, Epoch=369, Val Loss=0.000008, Total Val Loss=0.614854]\n",
            "17it [00:12,  1.39it/s, Epoch=370, Loss=0.000007, Total Loss=0.000103]\n",
            "5it [00:02,  1.78it/s, Epoch=370, Val Loss=0.000020, Total Val Loss=0.590047]\n",
            "17it [00:12,  1.40it/s, Epoch=371, Loss=0.000144, Total Loss=0.000109]\n",
            "5it [00:03,  1.64it/s, Epoch=371, Val Loss=0.000010, Total Val Loss=0.616998]\n",
            "17it [00:12,  1.40it/s, Epoch=372, Loss=0.000002, Total Loss=0.000074]\n",
            "5it [00:03,  1.65it/s, Epoch=372, Val Loss=0.000013, Total Val Loss=0.606140]\n",
            "17it [00:12,  1.35it/s, Epoch=373, Loss=0.000002, Total Loss=0.000008]\n",
            "5it [00:03,  1.61it/s, Epoch=373, Val Loss=0.000015, Total Val Loss=0.627727]\n",
            "17it [00:12,  1.39it/s, Epoch=374, Loss=0.000021, Total Loss=0.000018]\n",
            "5it [00:03,  1.60it/s, Epoch=374, Val Loss=0.000018, Total Val Loss=0.605605]\n",
            "17it [00:11,  1.50it/s, Epoch=375, Loss=0.000063, Total Loss=0.000036]\n",
            "5it [00:03,  1.64it/s, Epoch=375, Val Loss=0.000011, Total Val Loss=0.641689]\n",
            "17it [00:12,  1.40it/s, Epoch=376, Loss=0.000008, Total Loss=0.000007]\n",
            "5it [00:03,  1.61it/s, Epoch=376, Val Loss=0.000016, Total Val Loss=0.613430]\n",
            "17it [00:11,  1.45it/s, Epoch=377, Loss=0.000055, Total Loss=0.000031]\n",
            "5it [00:03,  1.59it/s, Epoch=377, Val Loss=0.000007, Total Val Loss=0.641842]\n",
            "17it [00:12,  1.37it/s, Epoch=378, Loss=0.000000, Total Loss=0.000087]\n",
            "5it [00:03,  1.64it/s, Epoch=378, Val Loss=0.000006, Total Val Loss=0.649403]\n",
            "17it [00:12,  1.39it/s, Epoch=379, Loss=0.000000, Total Loss=0.000056]\n",
            "5it [00:03,  1.60it/s, Epoch=379, Val Loss=0.000018, Total Val Loss=0.607786]\n",
            "17it [00:11,  1.46it/s, Epoch=380, Loss=0.000001, Total Loss=0.000217]\n",
            "5it [00:03,  1.60it/s, Epoch=380, Val Loss=0.000007, Total Val Loss=0.601209]\n",
            "17it [00:12,  1.39it/s, Epoch=381, Loss=0.001386, Total Loss=0.000112]\n",
            "5it [00:03,  1.62it/s, Epoch=381, Val Loss=0.000009, Total Val Loss=0.623274]\n",
            "17it [00:12,  1.38it/s, Epoch=382, Loss=0.000015, Total Loss=0.000028]\n",
            "5it [00:02,  1.69it/s, Epoch=382, Val Loss=0.000052, Total Val Loss=0.575336]\n",
            "17it [00:12,  1.39it/s, Epoch=383, Loss=0.000032, Total Loss=0.000012]\n",
            "5it [00:03,  1.58it/s, Epoch=383, Val Loss=0.000022, Total Val Loss=0.586440]\n",
            "17it [00:11,  1.43it/s, Epoch=384, Loss=0.000001, Total Loss=0.000061]\n",
            "5it [00:03,  1.62it/s, Epoch=384, Val Loss=0.000026, Total Val Loss=0.614754]\n",
            "17it [00:12,  1.36it/s, Epoch=385, Loss=0.000215, Total Loss=0.000294]\n",
            "5it [00:03,  1.56it/s, Epoch=385, Val Loss=0.000006, Total Val Loss=0.631363]\n",
            "17it [00:12,  1.37it/s, Epoch=386, Loss=0.000016, Total Loss=0.000035]\n",
            "5it [00:03,  1.63it/s, Epoch=386, Val Loss=0.000004, Total Val Loss=0.616814]\n",
            "17it [00:11,  1.44it/s, Epoch=387, Loss=0.000018, Total Loss=0.000026]\n",
            "5it [00:02,  1.69it/s, Epoch=387, Val Loss=0.000020, Total Val Loss=0.594348]\n",
            "17it [00:12,  1.37it/s, Epoch=388, Loss=0.000000, Total Loss=0.000008]\n",
            "5it [00:03,  1.63it/s, Epoch=388, Val Loss=0.000004, Total Val Loss=0.610507]\n",
            "17it [00:12,  1.33it/s, Epoch=389, Loss=0.000002, Total Loss=0.000023]\n",
            "5it [00:03,  1.64it/s, Epoch=389, Val Loss=0.000022, Total Val Loss=0.595692]\n",
            "17it [00:12,  1.40it/s, Epoch=390, Loss=0.000005, Total Loss=0.000039]\n",
            "5it [00:03,  1.57it/s, Epoch=390, Val Loss=0.000013, Total Val Loss=0.617397]\n",
            "17it [00:12,  1.33it/s, Epoch=391, Loss=0.000362, Total Loss=0.000041]\n",
            "5it [00:03,  1.60it/s, Epoch=391, Val Loss=0.000022, Total Val Loss=0.590238]\n",
            "17it [00:12,  1.38it/s, Epoch=392, Loss=0.000004, Total Loss=0.000011]\n",
            "5it [00:03,  1.55it/s, Epoch=392, Val Loss=0.000027, Total Val Loss=0.598869]\n",
            "17it [00:12,  1.39it/s, Epoch=393, Loss=0.000004, Total Loss=0.000054]\n",
            "5it [00:03,  1.56it/s, Epoch=393, Val Loss=0.000008, Total Val Loss=0.571343]\n",
            "17it [00:12,  1.35it/s, Epoch=394, Loss=0.000111, Total Loss=0.000038]\n",
            "5it [00:03,  1.61it/s, Epoch=394, Val Loss=0.000023, Total Val Loss=0.569643]\n",
            "17it [00:12,  1.35it/s, Epoch=395, Loss=0.000000, Total Loss=0.000048]\n",
            "5it [00:03,  1.61it/s, Epoch=395, Val Loss=0.000012, Total Val Loss=0.598688]\n",
            "17it [00:12,  1.36it/s, Epoch=396, Loss=0.000023, Total Loss=0.000074]\n",
            "5it [00:03,  1.60it/s, Epoch=396, Val Loss=0.000045, Total Val Loss=0.621208]\n",
            "17it [00:11,  1.47it/s, Epoch=397, Loss=0.000002, Total Loss=0.000015]\n",
            "5it [00:03,  1.57it/s, Epoch=397, Val Loss=0.000012, Total Val Loss=0.621230]\n",
            "17it [00:11,  1.42it/s, Epoch=398, Loss=0.000010, Total Loss=0.000020]\n",
            "5it [00:03,  1.63it/s, Epoch=398, Val Loss=0.000005, Total Val Loss=0.610318]\n",
            "17it [00:12,  1.35it/s, Epoch=399, Loss=0.000009, Total Loss=0.000035]\n",
            "5it [00:03,  1.54it/s, Epoch=399, Val Loss=0.000026, Total Val Loss=0.586000]\n",
            "17it [00:12,  1.40it/s, Epoch=400, Loss=0.000004, Total Loss=0.000019]\n",
            "5it [00:03,  1.58it/s, Epoch=400, Val Loss=0.000020, Total Val Loss=0.634014]\n",
            "17it [00:12,  1.40it/s, Epoch=401, Loss=0.000039, Total Loss=0.000053]\n",
            "5it [00:03,  1.62it/s, Epoch=401, Val Loss=0.000004, Total Val Loss=0.609314]\n",
            "17it [00:12,  1.37it/s, Epoch=402, Loss=0.000041, Total Loss=0.000024]\n",
            "5it [00:02,  1.70it/s, Epoch=402, Val Loss=0.000012, Total Val Loss=0.591555]\n",
            "17it [00:11,  1.45it/s, Epoch=403, Loss=0.000004, Total Loss=0.000016]\n",
            "5it [00:03,  1.59it/s, Epoch=403, Val Loss=0.000010, Total Val Loss=0.593318]\n",
            "17it [00:12,  1.38it/s, Epoch=404, Loss=0.000302, Total Loss=0.000036]\n",
            "5it [00:03,  1.62it/s, Epoch=404, Val Loss=0.000002, Total Val Loss=0.652004]\n",
            "17it [00:12,  1.39it/s, Epoch=405, Loss=0.010063, Total Loss=0.000654]\n",
            "5it [00:03,  1.55it/s, Epoch=405, Val Loss=0.000008, Total Val Loss=0.623024]\n",
            "17it [00:12,  1.40it/s, Epoch=406, Loss=0.000014, Total Loss=0.000009]\n",
            "5it [00:03,  1.64it/s, Epoch=406, Val Loss=0.000021, Total Val Loss=0.645813]\n",
            "17it [00:12,  1.39it/s, Epoch=407, Loss=0.000003, Total Loss=0.000028]\n",
            "5it [00:03,  1.54it/s, Epoch=407, Val Loss=0.000009, Total Val Loss=0.609430]\n",
            "17it [00:12,  1.38it/s, Epoch=408, Loss=0.000004, Total Loss=0.000081]\n",
            "5it [00:03,  1.58it/s, Epoch=408, Val Loss=0.000010, Total Val Loss=0.632946]\n",
            "17it [00:12,  1.32it/s, Epoch=409, Loss=0.000001, Total Loss=0.000027]\n",
            "5it [00:03,  1.57it/s, Epoch=409, Val Loss=0.000012, Total Val Loss=0.610034]\n",
            "17it [00:12,  1.41it/s, Epoch=410, Loss=0.000012, Total Loss=0.000047]\n",
            "5it [00:03,  1.57it/s, Epoch=410, Val Loss=0.000019, Total Val Loss=0.617593]\n",
            "17it [00:12,  1.37it/s, Epoch=411, Loss=0.000004, Total Loss=0.000028]\n",
            "5it [00:03,  1.65it/s, Epoch=411, Val Loss=0.000013, Total Val Loss=0.619040]\n",
            "17it [00:12,  1.40it/s, Epoch=412, Loss=0.000090, Total Loss=0.000042]\n",
            "5it [00:03,  1.62it/s, Epoch=412, Val Loss=0.000014, Total Val Loss=0.616226]\n",
            "17it [00:11,  1.45it/s, Epoch=413, Loss=0.000972, Total Loss=0.000085]\n",
            "5it [00:03,  1.65it/s, Epoch=413, Val Loss=0.000006, Total Val Loss=0.654610]\n",
            "17it [00:11,  1.44it/s, Epoch=414, Loss=0.000001, Total Loss=0.000095]\n",
            "5it [00:03,  1.62it/s, Epoch=414, Val Loss=0.000006, Total Val Loss=0.677711]\n",
            "17it [00:11,  1.45it/s, Epoch=415, Loss=0.000060, Total Loss=0.000060]\n",
            "5it [00:03,  1.58it/s, Epoch=415, Val Loss=0.000005, Total Val Loss=0.643736]\n",
            "17it [00:11,  1.42it/s, Epoch=416, Loss=0.001183, Total Loss=0.000101]\n",
            "5it [00:03,  1.56it/s, Epoch=416, Val Loss=0.000038, Total Val Loss=0.619800]\n",
            "17it [00:11,  1.46it/s, Epoch=417, Loss=0.000000, Total Loss=0.000016]\n",
            "5it [00:03,  1.60it/s, Epoch=417, Val Loss=0.000007, Total Val Loss=0.647947]\n",
            "17it [00:11,  1.48it/s, Epoch=418, Loss=0.000003, Total Loss=0.000008]\n",
            "5it [00:03,  1.59it/s, Epoch=418, Val Loss=0.000012, Total Val Loss=0.660115]\n",
            "17it [00:11,  1.43it/s, Epoch=419, Loss=0.000157, Total Loss=0.000034]\n",
            "5it [00:03,  1.62it/s, Epoch=419, Val Loss=0.000012, Total Val Loss=0.638758]\n",
            "17it [00:12,  1.36it/s, Epoch=420, Loss=0.000001, Total Loss=0.000023]\n",
            "5it [00:03,  1.61it/s, Epoch=420, Val Loss=0.000023, Total Val Loss=0.593597]\n",
            "17it [00:12,  1.39it/s, Epoch=421, Loss=0.000000, Total Loss=0.000043]\n",
            "5it [00:03,  1.63it/s, Epoch=421, Val Loss=0.000009, Total Val Loss=0.638775]\n",
            "17it [00:11,  1.42it/s, Epoch=422, Loss=0.000020, Total Loss=0.000006]\n",
            "5it [00:03,  1.61it/s, Epoch=422, Val Loss=0.000021, Total Val Loss=0.607203]\n",
            "17it [00:12,  1.40it/s, Epoch=423, Loss=0.000013, Total Loss=0.002131]\n",
            "5it [00:03,  1.56it/s, Epoch=423, Val Loss=0.000012, Total Val Loss=0.611106]\n",
            "17it [00:12,  1.37it/s, Epoch=424, Loss=0.000002, Total Loss=0.000017]\n",
            "5it [00:03,  1.59it/s, Epoch=424, Val Loss=0.000027, Total Val Loss=0.691205]\n",
            "17it [00:12,  1.36it/s, Epoch=425, Loss=0.008418, Total Loss=0.000505]\n",
            "5it [00:03,  1.56it/s, Epoch=425, Val Loss=0.000025, Total Val Loss=0.725532]\n",
            "17it [00:11,  1.42it/s, Epoch=426, Loss=0.000028, Total Loss=0.000079]\n",
            "5it [00:03,  1.56it/s, Epoch=426, Val Loss=0.000016, Total Val Loss=0.702911]\n",
            "17it [00:12,  1.38it/s, Epoch=427, Loss=0.002567, Total Loss=0.000204]\n",
            "5it [00:03,  1.64it/s, Epoch=427, Val Loss=0.000038, Total Val Loss=0.657745]\n",
            "17it [00:11,  1.43it/s, Epoch=428, Loss=0.000026, Total Loss=0.000073]\n",
            "5it [00:03,  1.65it/s, Epoch=428, Val Loss=0.000019, Total Val Loss=0.700293]\n",
            "17it [00:12,  1.39it/s, Epoch=429, Loss=0.000592, Total Loss=0.000111]\n",
            "5it [00:03,  1.55it/s, Epoch=429, Val Loss=0.000014, Total Val Loss=0.651622]\n",
            "17it [00:12,  1.37it/s, Epoch=430, Loss=0.000061, Total Loss=0.000028]\n",
            "5it [00:03,  1.62it/s, Epoch=430, Val Loss=0.000058, Total Val Loss=0.627065]\n",
            "17it [00:11,  1.46it/s, Epoch=431, Loss=0.000028, Total Loss=0.000062]\n",
            "5it [00:03,  1.57it/s, Epoch=431, Val Loss=0.000033, Total Val Loss=0.672401]\n",
            "17it [00:12,  1.41it/s, Epoch=432, Loss=0.000234, Total Loss=0.000240]\n",
            "5it [00:03,  1.61it/s, Epoch=432, Val Loss=0.000019, Total Val Loss=0.680425]\n",
            "17it [00:12,  1.39it/s, Epoch=433, Loss=0.000000, Total Loss=0.000034]\n",
            "5it [00:03,  1.57it/s, Epoch=433, Val Loss=0.000019, Total Val Loss=0.658170]\n",
            "17it [00:12,  1.35it/s, Epoch=434, Loss=0.000005, Total Loss=0.001961]\n",
            "5it [00:03,  1.64it/s, Epoch=434, Val Loss=0.000086, Total Val Loss=0.730899]\n",
            "17it [00:12,  1.40it/s, Epoch=435, Loss=0.000000, Total Loss=0.000034]\n",
            "5it [00:03,  1.61it/s, Epoch=435, Val Loss=0.000134, Total Val Loss=0.711572]\n",
            "17it [00:12,  1.37it/s, Epoch=436, Loss=0.000640, Total Loss=0.000058]\n",
            "5it [00:03,  1.52it/s, Epoch=436, Val Loss=0.000116, Total Val Loss=0.658042]\n",
            "17it [00:12,  1.39it/s, Epoch=437, Loss=0.000008, Total Loss=0.000021]\n",
            "5it [00:03,  1.60it/s, Epoch=437, Val Loss=0.000032, Total Val Loss=0.619534]\n",
            "17it [00:12,  1.38it/s, Epoch=438, Loss=0.000102, Total Loss=0.000104]\n",
            "5it [00:03,  1.55it/s, Epoch=438, Val Loss=0.000164, Total Val Loss=0.612972]\n",
            "17it [00:12,  1.41it/s, Epoch=439, Loss=0.000037, Total Loss=0.000074]\n",
            "5it [00:03,  1.59it/s, Epoch=439, Val Loss=0.000166, Total Val Loss=0.645729]\n",
            "17it [00:12,  1.41it/s, Epoch=440, Loss=0.000095, Total Loss=0.006211]\n",
            "5it [00:03,  1.62it/s, Epoch=440, Val Loss=0.000019, Total Val Loss=0.638339]\n",
            "17it [00:12,  1.37it/s, Epoch=441, Loss=0.011920, Total Loss=0.009824]\n",
            "5it [00:03,  1.51it/s, Epoch=441, Val Loss=0.000011, Total Val Loss=0.480959]\n",
            "17it [00:12,  1.34it/s, Epoch=442, Loss=0.000051, Total Loss=0.037003]\n",
            "5it [00:03,  1.58it/s, Epoch=442, Val Loss=0.000466, Total Val Loss=0.388416]\n",
            "17it [00:12,  1.41it/s, Epoch=443, Loss=0.000727, Total Loss=0.007806]\n",
            "5it [00:03,  1.63it/s, Epoch=443, Val Loss=0.002261, Total Val Loss=0.516975]\n",
            "17it [00:12,  1.41it/s, Epoch=444, Loss=0.003108, Total Loss=0.004113]\n",
            "5it [00:03,  1.52it/s, Epoch=444, Val Loss=0.000108, Total Val Loss=0.557905]\n",
            "17it [00:12,  1.37it/s, Epoch=445, Loss=0.000248, Total Loss=0.039824]\n",
            "5it [00:03,  1.51it/s, Epoch=445, Val Loss=0.000002, Total Val Loss=0.132425]\n",
            "17it [00:12,  1.37it/s, Epoch=446, Loss=0.000163, Total Loss=0.006452]\n",
            "5it [00:03,  1.56it/s, Epoch=446, Val Loss=0.000037, Total Val Loss=0.198541]\n",
            "17it [00:11,  1.42it/s, Epoch=447, Loss=0.000012, Total Loss=0.007362]\n",
            "5it [00:03,  1.55it/s, Epoch=447, Val Loss=0.000089, Total Val Loss=0.145131]\n",
            "17it [00:12,  1.35it/s, Epoch=448, Loss=0.142162, Total Loss=0.034634]\n",
            "5it [00:03,  1.65it/s, Epoch=448, Val Loss=0.000915, Total Val Loss=0.170242]\n",
            "17it [00:12,  1.33it/s, Epoch=449, Loss=0.000395, Total Loss=0.026947]\n",
            "5it [00:03,  1.57it/s, Epoch=449, Val Loss=0.001876, Total Val Loss=0.466708]\n",
            "17it [00:12,  1.35it/s, Epoch=450, Loss=0.000039, Total Loss=0.140629]\n",
            "5it [00:03,  1.60it/s, Epoch=450, Val Loss=0.006161, Total Val Loss=1.060130]\n",
            "17it [00:12,  1.33it/s, Epoch=451, Loss=0.124339, Total Loss=0.221229]\n",
            "5it [00:03,  1.59it/s, Epoch=451, Val Loss=0.000008, Total Val Loss=0.739548]\n",
            "17it [00:12,  1.34it/s, Epoch=452, Loss=0.000044, Total Loss=0.087657]\n",
            "5it [00:03,  1.55it/s, Epoch=452, Val Loss=0.000003, Total Val Loss=0.447452]\n",
            "17it [00:12,  1.31it/s, Epoch=453, Loss=0.001197, Total Loss=0.049036]\n",
            "5it [00:03,  1.54it/s, Epoch=453, Val Loss=0.000008, Total Val Loss=0.320521]\n",
            "17it [00:11,  1.43it/s, Epoch=454, Loss=0.007578, Total Loss=0.019051]\n",
            "5it [00:03,  1.59it/s, Epoch=454, Val Loss=0.004765, Total Val Loss=0.090642]\n",
            "17it [00:12,  1.36it/s, Epoch=455, Loss=0.000186, Total Loss=0.034147]\n",
            "5it [00:03,  1.55it/s, Epoch=455, Val Loss=0.005611, Total Val Loss=0.588350]\n",
            "17it [00:12,  1.38it/s, Epoch=456, Loss=0.000003, Total Loss=0.026900]\n",
            "5it [00:02,  1.68it/s, Epoch=456, Val Loss=0.029719, Total Val Loss=0.307856]\n",
            "17it [00:12,  1.41it/s, Epoch=457, Loss=0.000165, Total Loss=0.000999]\n",
            "5it [00:03,  1.64it/s, Epoch=457, Val Loss=0.059200, Total Val Loss=0.341510]\n",
            "17it [00:12,  1.39it/s, Epoch=458, Loss=0.000006, Total Loss=0.001065]\n",
            "5it [00:03,  1.53it/s, Epoch=458, Val Loss=0.002838, Total Val Loss=0.230210]\n",
            "17it [00:12,  1.37it/s, Epoch=459, Loss=0.000087, Total Loss=0.019550]\n",
            "5it [00:03,  1.58it/s, Epoch=459, Val Loss=0.000001, Total Val Loss=0.658468]\n",
            "17it [00:12,  1.35it/s, Epoch=460, Loss=0.002379, Total Loss=0.020710]\n",
            "5it [00:03,  1.61it/s, Epoch=460, Val Loss=0.000004, Total Val Loss=0.734878]\n",
            "17it [00:11,  1.50it/s, Epoch=461, Loss=0.000001, Total Loss=0.072824]\n",
            "5it [00:03,  1.59it/s, Epoch=461, Val Loss=0.000310, Total Val Loss=0.692309]\n",
            "17it [00:12,  1.34it/s, Epoch=462, Loss=0.000617, Total Loss=0.016131]\n",
            "5it [00:03,  1.61it/s, Epoch=462, Val Loss=0.001094, Total Val Loss=0.625396]\n",
            "17it [00:12,  1.35it/s, Epoch=463, Loss=0.000018, Total Loss=0.001611]\n",
            "5it [00:03,  1.55it/s, Epoch=463, Val Loss=0.021913, Total Val Loss=0.640278]\n",
            "17it [00:12,  1.41it/s, Epoch=464, Loss=0.108959, Total Loss=0.039495]\n",
            "5it [00:03,  1.54it/s, Epoch=464, Val Loss=0.012473, Total Val Loss=0.906500]\n",
            "17it [00:12,  1.37it/s, Epoch=465, Loss=0.000460, Total Loss=0.013396]\n",
            "5it [00:03,  1.55it/s, Epoch=465, Val Loss=0.014056, Total Val Loss=0.953930]\n",
            "17it [00:12,  1.39it/s, Epoch=466, Loss=0.000004, Total Loss=0.049678]\n",
            "5it [00:03,  1.59it/s, Epoch=466, Val Loss=0.000404, Total Val Loss=0.537301]\n",
            "17it [00:11,  1.43it/s, Epoch=467, Loss=0.000016, Total Loss=0.023128]\n",
            "5it [00:03,  1.62it/s, Epoch=467, Val Loss=0.000035, Total Val Loss=0.361262]\n",
            "17it [00:12,  1.36it/s, Epoch=468, Loss=0.000142, Total Loss=0.020698]\n",
            "5it [00:02,  1.72it/s, Epoch=468, Val Loss=0.002810, Total Val Loss=0.592174]\n",
            "17it [00:12,  1.38it/s, Epoch=469, Loss=0.011950, Total Loss=0.091525]\n",
            "5it [00:03,  1.57it/s, Epoch=469, Val Loss=0.016178, Total Val Loss=0.514323]\n",
            "17it [00:12,  1.38it/s, Epoch=470, Loss=0.000396, Total Loss=0.195650]\n",
            "5it [00:03,  1.60it/s, Epoch=470, Val Loss=0.009134, Total Val Loss=0.354132]\n",
            "17it [00:12,  1.36it/s, Epoch=471, Loss=0.568872, Total Loss=0.113061]\n",
            "5it [00:03,  1.65it/s, Epoch=471, Val Loss=0.076107, Total Val Loss=0.481386]\n",
            "17it [00:12,  1.39it/s, Epoch=472, Loss=0.000062, Total Loss=0.012256]\n",
            "5it [00:02,  1.73it/s, Epoch=472, Val Loss=0.000225, Total Val Loss=0.640098]\n",
            "17it [00:11,  1.46it/s, Epoch=473, Loss=0.029933, Total Loss=0.011242]\n",
            "5it [00:03,  1.58it/s, Epoch=473, Val Loss=0.000031, Total Val Loss=0.751547]\n",
            "17it [00:12,  1.35it/s, Epoch=474, Loss=1.538219, Total Loss=0.092554]\n",
            "5it [00:03,  1.58it/s, Epoch=474, Val Loss=0.000012, Total Val Loss=0.713150]\n",
            "17it [00:11,  1.45it/s, Epoch=475, Loss=0.000015, Total Loss=0.030263]\n",
            "5it [00:03,  1.65it/s, Epoch=475, Val Loss=11.287900, Total Val Loss=3.416367]\n",
            "17it [00:12,  1.36it/s, Epoch=476, Loss=0.018263, Total Loss=0.036309]\n",
            "5it [00:03,  1.60it/s, Epoch=476, Val Loss=0.088404, Total Val Loss=0.993160]\n",
            "17it [00:12,  1.41it/s, Epoch=477, Loss=0.005137, Total Loss=0.005405]\n",
            "5it [00:03,  1.62it/s, Epoch=477, Val Loss=0.004108, Total Val Loss=1.074464]\n",
            "17it [00:11,  1.48it/s, Epoch=478, Loss=0.000028, Total Loss=0.001317]\n",
            "5it [00:03,  1.56it/s, Epoch=478, Val Loss=0.000768, Total Val Loss=1.039104]\n",
            "17it [00:11,  1.42it/s, Epoch=479, Loss=0.000015, Total Loss=0.000772]\n",
            "5it [00:03,  1.59it/s, Epoch=479, Val Loss=0.000661, Total Val Loss=0.968094]\n",
            "17it [00:12,  1.39it/s, Epoch=480, Loss=0.015084, Total Loss=0.001816]\n",
            "5it [00:03,  1.57it/s, Epoch=480, Val Loss=0.000515, Total Val Loss=0.920979]\n",
            "17it [00:11,  1.43it/s, Epoch=481, Loss=0.026053, Total Loss=0.002421]\n",
            "5it [00:03,  1.60it/s, Epoch=481, Val Loss=0.000624, Total Val Loss=0.896342]\n",
            "17it [00:12,  1.32it/s, Epoch=482, Loss=0.000005, Total Loss=0.000237]\n",
            "5it [00:03,  1.61it/s, Epoch=482, Val Loss=0.000524, Total Val Loss=0.758305]\n",
            "17it [00:12,  1.36it/s, Epoch=483, Loss=0.004635, Total Loss=0.000396]\n",
            "5it [00:03,  1.57it/s, Epoch=483, Val Loss=0.000452, Total Val Loss=0.796615]\n",
            "17it [00:12,  1.41it/s, Epoch=484, Loss=0.000000, Total Loss=0.006620]\n",
            "5it [00:03,  1.54it/s, Epoch=484, Val Loss=0.002266, Total Val Loss=0.823232]\n",
            "17it [00:12,  1.34it/s, Epoch=485, Loss=0.000002, Total Loss=0.000416]\n",
            "5it [00:03,  1.51it/s, Epoch=485, Val Loss=0.003225, Total Val Loss=0.791082]\n",
            "17it [00:12,  1.35it/s, Epoch=486, Loss=0.000046, Total Loss=0.000565]\n",
            "5it [00:03,  1.56it/s, Epoch=486, Val Loss=0.006366, Total Val Loss=0.862379]\n",
            "17it [00:11,  1.49it/s, Epoch=487, Loss=0.000031, Total Loss=0.000228]\n",
            "5it [00:03,  1.58it/s, Epoch=487, Val Loss=0.010586, Total Val Loss=0.893958]\n",
            "17it [00:11,  1.44it/s, Epoch=488, Loss=0.000057, Total Loss=0.000226]\n",
            "5it [00:03,  1.55it/s, Epoch=488, Val Loss=0.011957, Total Val Loss=0.821302]\n",
            "17it [00:11,  1.46it/s, Epoch=489, Loss=0.000002, Total Loss=0.000129]\n",
            "5it [00:03,  1.49it/s, Epoch=489, Val Loss=0.005540, Total Val Loss=0.851565]\n",
            "17it [00:12,  1.41it/s, Epoch=490, Loss=0.000005, Total Loss=0.000017]\n",
            "5it [00:03,  1.55it/s, Epoch=490, Val Loss=0.010032, Total Val Loss=0.901763]\n",
            "17it [00:12,  1.36it/s, Epoch=491, Loss=0.000165, Total Loss=0.000037]\n",
            "5it [00:03,  1.55it/s, Epoch=491, Val Loss=0.011379, Total Val Loss=0.864064]\n",
            "17it [00:11,  1.43it/s, Epoch=492, Loss=0.000001, Total Loss=0.000023]\n",
            "5it [00:03,  1.52it/s, Epoch=492, Val Loss=0.010518, Total Val Loss=0.895777]\n",
            "17it [00:12,  1.39it/s, Epoch=493, Loss=0.000305, Total Loss=0.000060]\n",
            "5it [00:03,  1.58it/s, Epoch=493, Val Loss=0.006981, Total Val Loss=0.854530]\n",
            "17it [00:12,  1.38it/s, Epoch=494, Loss=0.000023, Total Loss=0.000051]\n",
            "5it [00:03,  1.56it/s, Epoch=494, Val Loss=0.012705, Total Val Loss=0.847097]\n",
            "17it [00:12,  1.38it/s, Epoch=495, Loss=1.030061, Total Loss=0.060709]\n",
            "5it [00:03,  1.63it/s, Epoch=495, Val Loss=0.008803, Total Val Loss=0.930975]\n",
            "17it [00:12,  1.35it/s, Epoch=496, Loss=0.003615, Total Loss=0.005596]\n",
            "5it [00:03,  1.54it/s, Epoch=496, Val Loss=0.012300, Total Val Loss=0.504352]\n",
            "17it [00:11,  1.44it/s, Epoch=497, Loss=0.000002, Total Loss=0.037452]\n",
            "5it [00:03,  1.59it/s, Epoch=497, Val Loss=0.012646, Total Val Loss=0.513443]\n",
            "17it [00:12,  1.35it/s, Epoch=498, Loss=0.000066, Total Loss=0.001158]\n",
            "5it [00:03,  1.59it/s, Epoch=498, Val Loss=0.002167, Total Val Loss=0.477210]\n",
            "17it [00:12,  1.38it/s, Epoch=499, Loss=0.004610, Total Loss=0.019362]\n",
            "5it [00:03,  1.56it/s, Epoch=499, Val Loss=0.009185, Total Val Loss=0.429436]\n",
            "17it [00:12,  1.40it/s, Epoch=500, Loss=0.000032, Total Loss=0.002614]\n",
            "5it [00:03,  1.62it/s, Epoch=500, Val Loss=0.093055, Total Val Loss=0.358416]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlzTw2lBTK2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f0bbabd5-c1d0-4a24-d402-962caa048927"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsbanrbhTK2o"
      },
      "source": [
        "def predict(dataset):\n",
        "    model.eval()\n",
        "    tqdm_dataset = tqdm(enumerate(dataset))\n",
        "    training = False\n",
        "    results = []\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        img = batch_item['img'].to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "        output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n",
        "        results.extend(output)\n",
        "    return results"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pa0FOmFTK2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe6089a-4522-4f4c-b0ce-a7f2dd4f3fb0"
      },
      "source": [
        "preds = predict(test_dataloader)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "396it [02:29,  2.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXnct79rTK2p"
      },
      "source": [
        "submission = pd.read_csv('./sample_submission.csv')\n",
        "submission.iloc[:,1] = preds\n",
        "submission.to_csv('DenseNet161_epoch500_batchsize12.csv', index=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oTiIj6Zg2Co5",
        "outputId": "40d9c7d2-4263-4f47-c915-0bbc713e3734"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DenseNet161_epoch500_batchsize12.csv')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_58dfa3d8-d54a-49a8-8aa1-5ada03fcd593\", \"DenseNet161_epoch500_batchsize12.csv\", 38017)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}