{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DenseNet201_3_(public-, private-).ipynb","provenance":[{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632997323955,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"b111e9fe-9b5d-410e-bc79-2687da5ecbf6"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 30 10:22:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632997345232,"user_tz":-540,"elapsed":21281,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"1734c845-2f8a-4293-fd7b-dd10d44f1ba4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632997349784,"user_tz":-540,"elapsed":4563,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632997350800,"user_tz":-540,"elapsed":1024,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632997353182,"user_tz":-540,"elapsed":2386,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632997369833,"user_tz":-540,"elapsed":16654,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632997369837,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["model_save = 'DenseNet201_3'\n","Target_model = 'DenseNet201_model'\n","Target_predict = 'DenseNet201_predict'\n","Target_acc = 'DenseNet201_acc'\n","Target_val = 'DenseNet201_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632997377793,"user_tz":-540,"elapsed":7970,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.DenseNet201(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632997377794,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632997378331,"user_tz":-540,"elapsed":555,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"8d540d44-5152-43b2-9628-0dd1287f141c"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632997378334,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633011748379,"user_tz":-540,"elapsed":14370057,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"6eb29d25-11ae-4af8-da3c-9141bf9c802c"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 65s 133ms/step - loss: 1.8502 - accuracy: 0.3553 - val_loss: 4.9796 - val_accuracy: 0.1351\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.13514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 2/500\n","238/238 [==============================] - 28s 119ms/step - loss: 1.2587 - accuracy: 0.5805 - val_loss: 2.4117 - val_accuracy: 0.3446\n","\n","Epoch 00002: val_accuracy improved from 0.13514 to 0.34459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 3/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.0041 - accuracy: 0.6800 - val_loss: 1.0527 - val_accuracy: 0.6554\n","\n","Epoch 00003: val_accuracy improved from 0.34459 to 0.65541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 4/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.8784 - accuracy: 0.7053 - val_loss: 0.7898 - val_accuracy: 0.7297\n","\n","Epoch 00004: val_accuracy improved from 0.65541 to 0.72973, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 5/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.7095 - accuracy: 0.7616 - val_loss: 1.0446 - val_accuracy: 0.7365\n","\n","Epoch 00005: val_accuracy improved from 0.72973 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 6/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.6960 - accuracy: 0.7695 - val_loss: 1.0844 - val_accuracy: 0.6622\n","\n","Epoch 00006: val_accuracy did not improve from 0.73649\n","Epoch 7/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.6277 - accuracy: 0.7816 - val_loss: 0.8152 - val_accuracy: 0.7432\n","\n","Epoch 00007: val_accuracy improved from 0.73649 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 8/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.5730 - accuracy: 0.8158 - val_loss: 0.9103 - val_accuracy: 0.6959\n","\n","Epoch 00008: val_accuracy did not improve from 0.74324\n","Epoch 9/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.5477 - accuracy: 0.8116 - val_loss: 0.8736 - val_accuracy: 0.6892\n","\n","Epoch 00009: val_accuracy did not improve from 0.74324\n","Epoch 10/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.5310 - accuracy: 0.8232 - val_loss: 0.8396 - val_accuracy: 0.7635\n","\n","Epoch 00010: val_accuracy improved from 0.74324 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 11/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.4865 - accuracy: 0.8400 - val_loss: 0.5537 - val_accuracy: 0.8581\n","\n","Epoch 00011: val_accuracy improved from 0.76351 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 12/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.4493 - accuracy: 0.8421 - val_loss: 0.5924 - val_accuracy: 0.8311\n","\n","Epoch 00012: val_accuracy did not improve from 0.85811\n","Epoch 13/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.4598 - accuracy: 0.8537 - val_loss: 0.7299 - val_accuracy: 0.7095\n","\n","Epoch 00013: val_accuracy did not improve from 0.85811\n","Epoch 14/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.4185 - accuracy: 0.8658 - val_loss: 0.4763 - val_accuracy: 0.8378\n","\n","Epoch 00014: val_accuracy did not improve from 0.85811\n","Epoch 15/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.3844 - accuracy: 0.8737 - val_loss: 0.4324 - val_accuracy: 0.8851\n","\n","Epoch 00015: val_accuracy improved from 0.85811 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 16/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.3882 - accuracy: 0.8711 - val_loss: 0.3557 - val_accuracy: 0.8919\n","\n","Epoch 00016: val_accuracy improved from 0.88514 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 17/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.3520 - accuracy: 0.8758 - val_loss: 0.3643 - val_accuracy: 0.8986\n","\n","Epoch 00017: val_accuracy improved from 0.89189 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 18/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.3494 - accuracy: 0.8911 - val_loss: 0.3441 - val_accuracy: 0.8919\n","\n","Epoch 00018: val_accuracy did not improve from 0.89865\n","Epoch 19/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.3225 - accuracy: 0.8932 - val_loss: 0.5208 - val_accuracy: 0.8649\n","\n","Epoch 00019: val_accuracy did not improve from 0.89865\n","Epoch 20/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.3025 - accuracy: 0.9053 - val_loss: 0.3301 - val_accuracy: 0.8784\n","\n","Epoch 00020: val_accuracy did not improve from 0.89865\n","Epoch 21/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3096 - accuracy: 0.8995 - val_loss: 0.3951 - val_accuracy: 0.8514\n","\n","Epoch 00021: val_accuracy did not improve from 0.89865\n","Epoch 22/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2799 - accuracy: 0.9100 - val_loss: 0.4217 - val_accuracy: 0.8581\n","\n","Epoch 00022: val_accuracy did not improve from 0.89865\n","Epoch 23/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2667 - accuracy: 0.9132 - val_loss: 0.4451 - val_accuracy: 0.8716\n","\n","Epoch 00023: val_accuracy did not improve from 0.89865\n","Epoch 24/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2609 - accuracy: 0.9158 - val_loss: 0.4664 - val_accuracy: 0.8581\n","\n","Epoch 00024: val_accuracy did not improve from 0.89865\n","Epoch 25/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.2131 - accuracy: 0.9305 - val_loss: 0.3045 - val_accuracy: 0.8986\n","\n","Epoch 00025: val_accuracy did not improve from 0.89865\n","Epoch 26/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2158 - accuracy: 0.9268 - val_loss: 0.4097 - val_accuracy: 0.8378\n","\n","Epoch 00026: val_accuracy did not improve from 0.89865\n","Epoch 27/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.2311 - accuracy: 0.9295 - val_loss: 0.3916 - val_accuracy: 0.8986\n","\n","Epoch 00027: val_accuracy did not improve from 0.89865\n","Epoch 28/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.2285 - accuracy: 0.9216 - val_loss: 0.5253 - val_accuracy: 0.8108\n","\n","Epoch 00028: val_accuracy did not improve from 0.89865\n","Epoch 29/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2079 - accuracy: 0.9295 - val_loss: 0.4054 - val_accuracy: 0.8784\n","\n","Epoch 00029: val_accuracy did not improve from 0.89865\n","Epoch 30/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.2590 - accuracy: 0.9116 - val_loss: 0.3750 - val_accuracy: 0.8649\n","\n","Epoch 00030: val_accuracy did not improve from 0.89865\n","Epoch 31/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1850 - accuracy: 0.9389 - val_loss: 0.3101 - val_accuracy: 0.9257\n","\n","Epoch 00031: val_accuracy improved from 0.89865 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 32/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1948 - accuracy: 0.9363 - val_loss: 0.4023 - val_accuracy: 0.8784\n","\n","Epoch 00032: val_accuracy did not improve from 0.92568\n","Epoch 33/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1615 - accuracy: 0.9442 - val_loss: 0.5038 - val_accuracy: 0.8649\n","\n","Epoch 00033: val_accuracy did not improve from 0.92568\n","Epoch 34/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1689 - accuracy: 0.9405 - val_loss: 0.4071 - val_accuracy: 0.8581\n","\n","Epoch 00034: val_accuracy did not improve from 0.92568\n","Epoch 35/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1968 - accuracy: 0.9295 - val_loss: 0.5500 - val_accuracy: 0.8446\n","\n","Epoch 00035: val_accuracy did not improve from 0.92568\n","Epoch 36/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1772 - accuracy: 0.9479 - val_loss: 0.6965 - val_accuracy: 0.8649\n","\n","Epoch 00036: val_accuracy did not improve from 0.92568\n","Epoch 37/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1272 - accuracy: 0.9574 - val_loss: 0.4465 - val_accuracy: 0.8716\n","\n","Epoch 00037: val_accuracy did not improve from 0.92568\n","Epoch 38/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1372 - accuracy: 0.9547 - val_loss: 0.4538 - val_accuracy: 0.8649\n","\n","Epoch 00038: val_accuracy did not improve from 0.92568\n","Epoch 39/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1937 - accuracy: 0.9395 - val_loss: 0.3261 - val_accuracy: 0.8919\n","\n","Epoch 00039: val_accuracy did not improve from 0.92568\n","Epoch 40/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1621 - accuracy: 0.9400 - val_loss: 0.3553 - val_accuracy: 0.9122\n","\n","Epoch 00040: val_accuracy did not improve from 0.92568\n","Epoch 41/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1329 - accuracy: 0.9547 - val_loss: 0.4186 - val_accuracy: 0.8986\n","\n","Epoch 00041: val_accuracy did not improve from 0.92568\n","Epoch 42/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1072 - accuracy: 0.9689 - val_loss: 0.2956 - val_accuracy: 0.9122\n","\n","Epoch 00042: val_accuracy did not improve from 0.92568\n","Epoch 43/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0754 - accuracy: 0.9721 - val_loss: 0.5050 - val_accuracy: 0.8784\n","\n","Epoch 00043: val_accuracy did not improve from 0.92568\n","Epoch 44/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1366 - accuracy: 0.9516 - val_loss: 0.5652 - val_accuracy: 0.8851\n","\n","Epoch 00044: val_accuracy did not improve from 0.92568\n","Epoch 45/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1564 - accuracy: 0.9453 - val_loss: 0.3046 - val_accuracy: 0.9122\n","\n","Epoch 00045: val_accuracy did not improve from 0.92568\n","Epoch 46/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0943 - accuracy: 0.9668 - val_loss: 0.3980 - val_accuracy: 0.8851\n","\n","Epoch 00046: val_accuracy did not improve from 0.92568\n","Epoch 47/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.3163 - val_accuracy: 0.9054\n","\n","Epoch 00047: val_accuracy did not improve from 0.92568\n","Epoch 48/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0880 - accuracy: 0.9726 - val_loss: 0.5425 - val_accuracy: 0.8784\n","\n","Epoch 00048: val_accuracy did not improve from 0.92568\n","Epoch 49/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1502 - accuracy: 0.9563 - val_loss: 0.5248 - val_accuracy: 0.8649\n","\n","Epoch 00049: val_accuracy did not improve from 0.92568\n","Epoch 50/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1128 - accuracy: 0.9589 - val_loss: 0.5086 - val_accuracy: 0.8851\n","\n","Epoch 00050: val_accuracy did not improve from 0.92568\n","Epoch 51/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1189 - accuracy: 0.9616 - val_loss: 0.4665 - val_accuracy: 0.8716\n","\n","Epoch 00051: val_accuracy did not improve from 0.92568\n","Epoch 52/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0753 - accuracy: 0.9726 - val_loss: 0.4469 - val_accuracy: 0.9054\n","\n","Epoch 00052: val_accuracy did not improve from 0.92568\n","Epoch 53/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1191 - accuracy: 0.9605 - val_loss: 0.3921 - val_accuracy: 0.8986\n","\n","Epoch 00053: val_accuracy did not improve from 0.92568\n","Epoch 54/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1202 - accuracy: 0.9584 - val_loss: 0.5342 - val_accuracy: 0.8581\n","\n","Epoch 00054: val_accuracy did not improve from 0.92568\n","Epoch 55/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0618 - accuracy: 0.9826 - val_loss: 0.2838 - val_accuracy: 0.9257\n","\n","Epoch 00055: val_accuracy did not improve from 0.92568\n","Epoch 56/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.3711 - val_accuracy: 0.8919\n","\n","Epoch 00056: val_accuracy did not improve from 0.92568\n","Epoch 57/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0893 - accuracy: 0.9711 - val_loss: 0.3377 - val_accuracy: 0.9054\n","\n","Epoch 00057: val_accuracy did not improve from 0.92568\n","Epoch 58/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.3650 - val_accuracy: 0.8784\n","\n","Epoch 00058: val_accuracy did not improve from 0.92568\n","Epoch 59/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 0.6213 - val_accuracy: 0.8649\n","\n","Epoch 00059: val_accuracy did not improve from 0.92568\n","Epoch 60/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0943 - accuracy: 0.9711 - val_loss: 0.3735 - val_accuracy: 0.9122\n","\n","Epoch 00060: val_accuracy did not improve from 0.92568\n","Epoch 61/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0861 - accuracy: 0.9695 - val_loss: 0.3078 - val_accuracy: 0.9324\n","\n","Epoch 00061: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 62/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0772 - accuracy: 0.9789 - val_loss: 0.4767 - val_accuracy: 0.8851\n","\n","Epoch 00062: val_accuracy did not improve from 0.93243\n","Epoch 63/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1098 - accuracy: 0.9663 - val_loss: 0.5942 - val_accuracy: 0.8716\n","\n","Epoch 00063: val_accuracy did not improve from 0.93243\n","Epoch 64/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.3521 - val_accuracy: 0.9189\n","\n","Epoch 00064: val_accuracy did not improve from 0.93243\n","Epoch 65/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.1060 - accuracy: 0.9637 - val_loss: 0.5287 - val_accuracy: 0.8784\n","\n","Epoch 00065: val_accuracy did not improve from 0.93243\n","Epoch 66/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0851 - accuracy: 0.9747 - val_loss: 0.3143 - val_accuracy: 0.8919\n","\n","Epoch 00066: val_accuracy did not improve from 0.93243\n","Epoch 67/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1185 - accuracy: 0.9632 - val_loss: 0.4299 - val_accuracy: 0.8784\n","\n","Epoch 00067: val_accuracy did not improve from 0.93243\n","Epoch 68/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0888 - accuracy: 0.9700 - val_loss: 0.4613 - val_accuracy: 0.8581\n","\n","Epoch 00068: val_accuracy did not improve from 0.93243\n","Epoch 69/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.5360 - val_accuracy: 0.8716\n","\n","Epoch 00069: val_accuracy did not improve from 0.93243\n","Epoch 70/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0446 - accuracy: 0.9842 - val_loss: 0.4488 - val_accuracy: 0.9054\n","\n","Epoch 00070: val_accuracy did not improve from 0.93243\n","Epoch 71/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0759 - accuracy: 0.9758 - val_loss: 0.5841 - val_accuracy: 0.8851\n","\n","Epoch 00071: val_accuracy did not improve from 0.93243\n","Epoch 72/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.4108 - val_accuracy: 0.8919\n","\n","Epoch 00072: val_accuracy did not improve from 0.93243\n","Epoch 73/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0593 - accuracy: 0.9784 - val_loss: 0.4739 - val_accuracy: 0.8716\n","\n","Epoch 00073: val_accuracy did not improve from 0.93243\n","Epoch 74/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0782 - accuracy: 0.9768 - val_loss: 0.5062 - val_accuracy: 0.8581\n","\n","Epoch 00074: val_accuracy did not improve from 0.93243\n","Epoch 75/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.3473 - val_accuracy: 0.9257\n","\n","Epoch 00075: val_accuracy did not improve from 0.93243\n","Epoch 76/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0574 - accuracy: 0.9779 - val_loss: 0.3059 - val_accuracy: 0.9257\n","\n","Epoch 00076: val_accuracy did not improve from 0.93243\n","Epoch 77/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 0.4186 - val_accuracy: 0.8784\n","\n","Epoch 00077: val_accuracy did not improve from 0.93243\n","Epoch 78/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.5225 - val_accuracy: 0.8919\n","\n","Epoch 00078: val_accuracy did not improve from 0.93243\n","Epoch 79/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.5527 - val_accuracy: 0.8649\n","\n","Epoch 00079: val_accuracy did not improve from 0.93243\n","Epoch 80/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.6221 - val_accuracy: 0.8514\n","\n","Epoch 00080: val_accuracy did not improve from 0.93243\n","Epoch 81/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0982 - accuracy: 0.9695 - val_loss: 0.7706 - val_accuracy: 0.8649\n","\n","Epoch 00081: val_accuracy did not improve from 0.93243\n","Epoch 82/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.3697 - val_accuracy: 0.9054\n","\n","Epoch 00082: val_accuracy did not improve from 0.93243\n","Epoch 83/500\n","238/238 [==============================] - 28s 116ms/step - loss: 0.0551 - accuracy: 0.9821 - val_loss: 0.3784 - val_accuracy: 0.8851\n","\n","Epoch 00083: val_accuracy did not improve from 0.93243\n","Epoch 84/500\n","238/238 [==============================] - 28s 116ms/step - loss: 0.0520 - accuracy: 0.9800 - val_loss: 0.3654 - val_accuracy: 0.8986\n","\n","Epoch 00084: val_accuracy did not improve from 0.93243\n","Epoch 85/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.4082 - val_accuracy: 0.8986\n","\n","Epoch 00085: val_accuracy did not improve from 0.93243\n","Epoch 86/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.3733 - val_accuracy: 0.8919\n","\n","Epoch 00086: val_accuracy did not improve from 0.93243\n","Epoch 87/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0416 - accuracy: 0.9868 - val_loss: 0.4249 - val_accuracy: 0.8986\n","\n","Epoch 00087: val_accuracy did not improve from 0.93243\n","Epoch 88/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.4195 - val_accuracy: 0.8919\n","\n","Epoch 00088: val_accuracy did not improve from 0.93243\n","Epoch 89/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.2673 - val_accuracy: 0.9324\n","\n","Epoch 00089: val_accuracy did not improve from 0.93243\n","Epoch 90/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 1.1113 - val_accuracy: 0.7703\n","\n","Epoch 00090: val_accuracy did not improve from 0.93243\n","Epoch 91/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 0.3270 - val_accuracy: 0.9189\n","\n","Epoch 00091: val_accuracy did not improve from 0.93243\n","Epoch 92/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.3419 - val_accuracy: 0.9257\n","\n","Epoch 00092: val_accuracy did not improve from 0.93243\n","Epoch 93/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0397 - accuracy: 0.9863 - val_loss: 0.5399 - val_accuracy: 0.8919\n","\n","Epoch 00093: val_accuracy did not improve from 0.93243\n","Epoch 94/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.3528 - val_accuracy: 0.9122\n","\n","Epoch 00094: val_accuracy did not improve from 0.93243\n","Epoch 95/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.3827 - val_accuracy: 0.9459\n","\n","Epoch 00095: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 96/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0592 - accuracy: 0.9821 - val_loss: 0.4094 - val_accuracy: 0.8986\n","\n","Epoch 00096: val_accuracy did not improve from 0.94595\n","Epoch 97/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.4841 - val_accuracy: 0.8919\n","\n","Epoch 00097: val_accuracy did not improve from 0.94595\n","Epoch 98/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.6440 - val_accuracy: 0.8784\n","\n","Epoch 00098: val_accuracy did not improve from 0.94595\n","Epoch 99/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.4256 - val_accuracy: 0.9122\n","\n","Epoch 00099: val_accuracy did not improve from 0.94595\n","Epoch 100/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.4807 - val_accuracy: 0.8919\n","\n","Epoch 00100: val_accuracy did not improve from 0.94595\n","Epoch 101/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 0.6203 - val_accuracy: 0.8581\n","\n","Epoch 00101: val_accuracy did not improve from 0.94595\n","Epoch 102/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.6093 - val_accuracy: 0.8784\n","\n","Epoch 00102: val_accuracy did not improve from 0.94595\n","Epoch 103/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0636 - accuracy: 0.9811 - val_loss: 0.6278 - val_accuracy: 0.8649\n","\n","Epoch 00103: val_accuracy did not improve from 0.94595\n","Epoch 104/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0431 - accuracy: 0.9853 - val_loss: 0.5389 - val_accuracy: 0.8851\n","\n","Epoch 00104: val_accuracy did not improve from 0.94595\n","Epoch 105/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.5157 - val_accuracy: 0.8851\n","\n","Epoch 00105: val_accuracy did not improve from 0.94595\n","Epoch 106/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 0.5088 - val_accuracy: 0.9189\n","\n","Epoch 00106: val_accuracy did not improve from 0.94595\n","Epoch 107/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.5730 - val_accuracy: 0.8784\n","\n","Epoch 00107: val_accuracy did not improve from 0.94595\n","Epoch 108/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0638 - accuracy: 0.9816 - val_loss: 0.6958 - val_accuracy: 0.8378\n","\n","Epoch 00108: val_accuracy did not improve from 0.94595\n","Epoch 109/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 0.4367 - val_accuracy: 0.8716\n","\n","Epoch 00109: val_accuracy did not improve from 0.94595\n","Epoch 110/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0623 - accuracy: 0.9874 - val_loss: 0.7184 - val_accuracy: 0.8446\n","\n","Epoch 00110: val_accuracy did not improve from 0.94595\n","Epoch 111/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.5279 - val_accuracy: 0.8649\n","\n","Epoch 00111: val_accuracy did not improve from 0.94595\n","Epoch 112/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.2668 - val_accuracy: 0.9324\n","\n","Epoch 00112: val_accuracy did not improve from 0.94595\n","Epoch 113/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0317 - accuracy: 0.9879 - val_loss: 0.4642 - val_accuracy: 0.9122\n","\n","Epoch 00113: val_accuracy did not improve from 0.94595\n","Epoch 114/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 0.2886 - val_accuracy: 0.9324\n","\n","Epoch 00114: val_accuracy did not improve from 0.94595\n","Epoch 115/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.4484 - val_accuracy: 0.9122\n","\n","Epoch 00115: val_accuracy did not improve from 0.94595\n","Epoch 116/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.3194 - val_accuracy: 0.9392\n","\n","Epoch 00116: val_accuracy did not improve from 0.94595\n","Epoch 117/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.4769 - val_accuracy: 0.8716\n","\n","Epoch 00117: val_accuracy did not improve from 0.94595\n","Epoch 118/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.6946 - val_accuracy: 0.8851\n","\n","Epoch 00118: val_accuracy did not improve from 0.94595\n","Epoch 119/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.2937 - val_accuracy: 0.9189\n","\n","Epoch 00119: val_accuracy did not improve from 0.94595\n","Epoch 120/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.5803 - val_accuracy: 0.8851\n","\n","Epoch 00120: val_accuracy did not improve from 0.94595\n","Epoch 121/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 0.4536 - val_accuracy: 0.9257\n","\n","Epoch 00121: val_accuracy did not improve from 0.94595\n","Epoch 122/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.6400 - val_accuracy: 0.8716\n","\n","Epoch 00122: val_accuracy did not improve from 0.94595\n","Epoch 123/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.4683 - val_accuracy: 0.8986\n","\n","Epoch 00123: val_accuracy did not improve from 0.94595\n","Epoch 124/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.5188 - val_accuracy: 0.8649\n","\n","Epoch 00124: val_accuracy did not improve from 0.94595\n","Epoch 125/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.3889 - val_accuracy: 0.9054\n","\n","Epoch 00125: val_accuracy did not improve from 0.94595\n","Epoch 126/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.3396 - val_accuracy: 0.9324\n","\n","Epoch 00126: val_accuracy did not improve from 0.94595\n","Epoch 127/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0298 - accuracy: 0.9932 - val_loss: 0.5722 - val_accuracy: 0.9054\n","\n","Epoch 00127: val_accuracy did not improve from 0.94595\n","Epoch 128/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0510 - accuracy: 0.9826 - val_loss: 0.5558 - val_accuracy: 0.9054\n","\n","Epoch 00128: val_accuracy did not improve from 0.94595\n","Epoch 129/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.4235 - val_accuracy: 0.8851\n","\n","Epoch 00129: val_accuracy did not improve from 0.94595\n","Epoch 130/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0281 - accuracy: 0.9884 - val_loss: 0.5532 - val_accuracy: 0.8919\n","\n","Epoch 00130: val_accuracy did not improve from 0.94595\n","Epoch 131/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.5353 - val_accuracy: 0.8919\n","\n","Epoch 00131: val_accuracy did not improve from 0.94595\n","Epoch 132/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.4362 - val_accuracy: 0.9189\n","\n","Epoch 00132: val_accuracy did not improve from 0.94595\n","Epoch 133/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4729 - val_accuracy: 0.9122\n","\n","Epoch 00133: val_accuracy did not improve from 0.94595\n","Epoch 134/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.3100 - val_accuracy: 0.9054\n","\n","Epoch 00134: val_accuracy did not improve from 0.94595\n","Epoch 135/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.4053 - val_accuracy: 0.9189\n","\n","Epoch 00135: val_accuracy did not improve from 0.94595\n","Epoch 136/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.3574 - val_accuracy: 0.8851\n","\n","Epoch 00136: val_accuracy did not improve from 0.94595\n","Epoch 137/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.3691 - val_accuracy: 0.9324\n","\n","Epoch 00137: val_accuracy did not improve from 0.94595\n","Epoch 138/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.4328 - val_accuracy: 0.8851\n","\n","Epoch 00138: val_accuracy did not improve from 0.94595\n","Epoch 139/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.3657 - val_accuracy: 0.9054\n","\n","Epoch 00139: val_accuracy did not improve from 0.94595\n","Epoch 140/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.4481 - val_accuracy: 0.8851\n","\n","Epoch 00140: val_accuracy did not improve from 0.94595\n","Epoch 141/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.6781 - val_accuracy: 0.8514\n","\n","Epoch 00141: val_accuracy did not improve from 0.94595\n","Epoch 142/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.2339 - val_accuracy: 0.9459\n","\n","Epoch 00142: val_accuracy did not improve from 0.94595\n","Epoch 143/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.4541 - val_accuracy: 0.9189\n","\n","Epoch 00143: val_accuracy did not improve from 0.94595\n","Epoch 144/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.4316 - val_accuracy: 0.9257\n","\n","Epoch 00144: val_accuracy did not improve from 0.94595\n","Epoch 145/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.3282 - val_accuracy: 0.9392\n","\n","Epoch 00145: val_accuracy did not improve from 0.94595\n","Epoch 146/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.5083 - val_accuracy: 0.8851\n","\n","Epoch 00146: val_accuracy did not improve from 0.94595\n","Epoch 147/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5862 - val_accuracy: 0.8716\n","\n","Epoch 00147: val_accuracy did not improve from 0.94595\n","Epoch 148/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0817 - accuracy: 0.9795 - val_loss: 0.8523 - val_accuracy: 0.8784\n","\n","Epoch 00148: val_accuracy did not improve from 0.94595\n","Epoch 149/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0480 - accuracy: 0.9874 - val_loss: 0.5079 - val_accuracy: 0.9054\n","\n","Epoch 00149: val_accuracy did not improve from 0.94595\n","Epoch 150/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.4191 - val_accuracy: 0.9054\n","\n","Epoch 00150: val_accuracy did not improve from 0.94595\n","Epoch 151/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.3858 - val_accuracy: 0.9122\n","\n","Epoch 00151: val_accuracy did not improve from 0.94595\n","Epoch 152/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5100 - val_accuracy: 0.8919\n","\n","Epoch 00152: val_accuracy did not improve from 0.94595\n","Epoch 153/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0201 - accuracy: 0.9921 - val_loss: 0.3633 - val_accuracy: 0.8919\n","\n","Epoch 00153: val_accuracy did not improve from 0.94595\n","Epoch 154/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.3836 - val_accuracy: 0.9257\n","\n","Epoch 00154: val_accuracy did not improve from 0.94595\n","Epoch 155/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.3443 - val_accuracy: 0.9189\n","\n","Epoch 00155: val_accuracy did not improve from 0.94595\n","Epoch 156/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.3881 - val_accuracy: 0.8919\n","\n","Epoch 00156: val_accuracy did not improve from 0.94595\n","Epoch 157/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.4352 - val_accuracy: 0.9122\n","\n","Epoch 00157: val_accuracy did not improve from 0.94595\n","Epoch 158/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.4718 - val_accuracy: 0.8851\n","\n","Epoch 00158: val_accuracy did not improve from 0.94595\n","Epoch 159/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.7437 - val_accuracy: 0.8716\n","\n","Epoch 00159: val_accuracy did not improve from 0.94595\n","Epoch 160/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.3079 - val_accuracy: 0.8986\n","\n","Epoch 00160: val_accuracy did not improve from 0.94595\n","Epoch 161/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.4153 - val_accuracy: 0.9122\n","\n","Epoch 00161: val_accuracy did not improve from 0.94595\n","Epoch 162/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.4261 - val_accuracy: 0.9122\n","\n","Epoch 00162: val_accuracy did not improve from 0.94595\n","Epoch 163/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.4556 - val_accuracy: 0.8919\n","\n","Epoch 00163: val_accuracy did not improve from 0.94595\n","Epoch 164/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0163 - accuracy: 0.9968 - val_loss: 0.4116 - val_accuracy: 0.9054\n","\n","Epoch 00164: val_accuracy did not improve from 0.94595\n","Epoch 165/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.4904 - val_accuracy: 0.9257\n","\n","Epoch 00165: val_accuracy did not improve from 0.94595\n","Epoch 166/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3369 - val_accuracy: 0.9189\n","\n","Epoch 00166: val_accuracy did not improve from 0.94595\n","Epoch 167/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.5486 - val_accuracy: 0.9122\n","\n","Epoch 00167: val_accuracy did not improve from 0.94595\n","Epoch 168/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.4429 - val_accuracy: 0.9257\n","\n","Epoch 00168: val_accuracy did not improve from 0.94595\n","Epoch 169/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5248 - val_accuracy: 0.8919\n","\n","Epoch 00169: val_accuracy did not improve from 0.94595\n","Epoch 170/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0528 - accuracy: 0.9805 - val_loss: 0.3753 - val_accuracy: 0.9122\n","\n","Epoch 00170: val_accuracy did not improve from 0.94595\n","Epoch 171/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.3073 - val_accuracy: 0.9392\n","\n","Epoch 00171: val_accuracy did not improve from 0.94595\n","Epoch 172/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.7203 - val_accuracy: 0.8784\n","\n","Epoch 00172: val_accuracy did not improve from 0.94595\n","Epoch 173/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.5840 - val_accuracy: 0.8716\n","\n","Epoch 00173: val_accuracy did not improve from 0.94595\n","Epoch 174/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.3880 - val_accuracy: 0.9257\n","\n","Epoch 00174: val_accuracy did not improve from 0.94595\n","Epoch 175/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.5389 - val_accuracy: 0.9054\n","\n","Epoch 00175: val_accuracy did not improve from 0.94595\n","Epoch 176/500\n","238/238 [==============================] - 28s 117ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.4786 - val_accuracy: 0.8986\n","\n","Epoch 00176: val_accuracy did not improve from 0.94595\n","Epoch 177/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.7163 - val_accuracy: 0.8378\n","\n","Epoch 00177: val_accuracy did not improve from 0.94595\n","Epoch 178/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.4951 - val_accuracy: 0.9054\n","\n","Epoch 00178: val_accuracy did not improve from 0.94595\n","Epoch 179/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.3551 - val_accuracy: 0.9122\n","\n","Epoch 00179: val_accuracy did not improve from 0.94595\n","Epoch 180/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.3562 - val_accuracy: 0.9324\n","\n","Epoch 00180: val_accuracy did not improve from 0.94595\n","Epoch 181/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0067 - accuracy: 0.9963 - val_loss: 0.4465 - val_accuracy: 0.9257\n","\n","Epoch 00181: val_accuracy did not improve from 0.94595\n","Epoch 182/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4201 - val_accuracy: 0.9189\n","\n","Epoch 00182: val_accuracy did not improve from 0.94595\n","Epoch 183/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.4613 - val_accuracy: 0.9189\n","\n","Epoch 00183: val_accuracy did not improve from 0.94595\n","Epoch 184/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.9457 - val_accuracy: 0.8446\n","\n","Epoch 00184: val_accuracy did not improve from 0.94595\n","Epoch 185/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.4654 - val_accuracy: 0.9257\n","\n","Epoch 00185: val_accuracy did not improve from 0.94595\n","Epoch 186/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.4346 - val_accuracy: 0.9054\n","\n","Epoch 00186: val_accuracy did not improve from 0.94595\n","Epoch 187/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4954 - val_accuracy: 0.9122\n","\n","Epoch 00187: val_accuracy did not improve from 0.94595\n","Epoch 188/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.4351 - val_accuracy: 0.8919\n","\n","Epoch 00188: val_accuracy did not improve from 0.94595\n","Epoch 189/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.4415 - val_accuracy: 0.8851\n","\n","Epoch 00189: val_accuracy did not improve from 0.94595\n","Epoch 190/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.5113 - val_accuracy: 0.9122\n","\n","Epoch 00190: val_accuracy did not improve from 0.94595\n","Epoch 191/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.3687 - val_accuracy: 0.9122\n","\n","Epoch 00191: val_accuracy did not improve from 0.94595\n","Epoch 192/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5445 - val_accuracy: 0.8986\n","\n","Epoch 00192: val_accuracy did not improve from 0.94595\n","Epoch 193/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.5091 - val_accuracy: 0.9122\n","\n","Epoch 00193: val_accuracy did not improve from 0.94595\n","Epoch 194/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.4695 - val_accuracy: 0.9054\n","\n","Epoch 00194: val_accuracy did not improve from 0.94595\n","Epoch 195/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.6364 - val_accuracy: 0.8851\n","\n","Epoch 00195: val_accuracy did not improve from 0.94595\n","Epoch 196/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.4455 - val_accuracy: 0.9122\n","\n","Epoch 00196: val_accuracy did not improve from 0.94595\n","Epoch 197/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.3450 - val_accuracy: 0.9392\n","\n","Epoch 00197: val_accuracy did not improve from 0.94595\n","Epoch 198/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.4432 - val_accuracy: 0.9122\n","\n","Epoch 00198: val_accuracy did not improve from 0.94595\n","Epoch 199/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4790 - val_accuracy: 0.8986\n","\n","Epoch 00199: val_accuracy did not improve from 0.94595\n","Epoch 200/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0318 - accuracy: 0.9916 - val_loss: 0.4566 - val_accuracy: 0.9189\n","\n","Epoch 00200: val_accuracy did not improve from 0.94595\n","Epoch 201/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.3848 - val_accuracy: 0.8986\n","\n","Epoch 00201: val_accuracy did not improve from 0.94595\n","Epoch 202/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4588 - val_accuracy: 0.9324\n","\n","Epoch 00202: val_accuracy did not improve from 0.94595\n","Epoch 203/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.4134 - val_accuracy: 0.9257\n","\n","Epoch 00203: val_accuracy did not improve from 0.94595\n","Epoch 204/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.5420 - val_accuracy: 0.9122\n","\n","Epoch 00204: val_accuracy did not improve from 0.94595\n","Epoch 205/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.4298 - val_accuracy: 0.8986\n","\n","Epoch 00205: val_accuracy did not improve from 0.94595\n","Epoch 206/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.4343 - val_accuracy: 0.9324\n","\n","Epoch 00206: val_accuracy did not improve from 0.94595\n","Epoch 207/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5913 - val_accuracy: 0.9054\n","\n","Epoch 00207: val_accuracy did not improve from 0.94595\n","Epoch 208/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.3989 - val_accuracy: 0.9054\n","\n","Epoch 00208: val_accuracy did not improve from 0.94595\n","Epoch 209/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.5137 - val_accuracy: 0.8986\n","\n","Epoch 00209: val_accuracy did not improve from 0.94595\n","Epoch 210/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.6083 - val_accuracy: 0.8919\n","\n","Epoch 00210: val_accuracy did not improve from 0.94595\n","Epoch 211/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5962 - val_accuracy: 0.9189\n","\n","Epoch 00211: val_accuracy did not improve from 0.94595\n","Epoch 212/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.6022 - val_accuracy: 0.8986\n","\n","Epoch 00212: val_accuracy did not improve from 0.94595\n","Epoch 213/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0415 - accuracy: 0.9895 - val_loss: 0.3601 - val_accuracy: 0.8919\n","\n","Epoch 00213: val_accuracy did not improve from 0.94595\n","Epoch 214/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.5252 - val_accuracy: 0.8784\n","\n","Epoch 00214: val_accuracy did not improve from 0.94595\n","Epoch 215/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.4358 - val_accuracy: 0.8851\n","\n","Epoch 00215: val_accuracy did not improve from 0.94595\n","Epoch 216/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.5461 - val_accuracy: 0.9189\n","\n","Epoch 00216: val_accuracy did not improve from 0.94595\n","Epoch 217/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.4418 - val_accuracy: 0.9257\n","\n","Epoch 00217: val_accuracy did not improve from 0.94595\n","Epoch 218/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.5242 - val_accuracy: 0.9257\n","\n","Epoch 00218: val_accuracy did not improve from 0.94595\n","Epoch 219/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3609 - val_accuracy: 0.8919\n","\n","Epoch 00219: val_accuracy did not improve from 0.94595\n","Epoch 220/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5225 - val_accuracy: 0.8986\n","\n","Epoch 00220: val_accuracy did not improve from 0.94595\n","Epoch 221/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4240 - val_accuracy: 0.9257\n","\n","Epoch 00221: val_accuracy did not improve from 0.94595\n","Epoch 222/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4495 - val_accuracy: 0.9257\n","\n","Epoch 00222: val_accuracy did not improve from 0.94595\n","Epoch 223/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.3491 - val_accuracy: 0.9392\n","\n","Epoch 00223: val_accuracy did not improve from 0.94595\n","Epoch 224/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.6076 - val_accuracy: 0.8784\n","\n","Epoch 00224: val_accuracy did not improve from 0.94595\n","Epoch 225/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.5609 - val_accuracy: 0.8784\n","\n","Epoch 00225: val_accuracy did not improve from 0.94595\n","Epoch 226/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.4936 - val_accuracy: 0.8919\n","\n","Epoch 00226: val_accuracy did not improve from 0.94595\n","Epoch 227/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.6821 - val_accuracy: 0.9054\n","\n","Epoch 00227: val_accuracy did not improve from 0.94595\n","Epoch 228/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.7696 - val_accuracy: 0.8851\n","\n","Epoch 00228: val_accuracy did not improve from 0.94595\n","Epoch 229/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.5976 - val_accuracy: 0.8919\n","\n","Epoch 00229: val_accuracy did not improve from 0.94595\n","Epoch 230/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.4385 - val_accuracy: 0.9189\n","\n","Epoch 00230: val_accuracy did not improve from 0.94595\n","Epoch 231/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.5561 - val_accuracy: 0.8784\n","\n","Epoch 00231: val_accuracy did not improve from 0.94595\n","Epoch 232/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.5324 - val_accuracy: 0.9257\n","\n","Epoch 00232: val_accuracy did not improve from 0.94595\n","Epoch 233/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.5002 - val_accuracy: 0.9122\n","\n","Epoch 00233: val_accuracy did not improve from 0.94595\n","Epoch 234/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0299 - accuracy: 0.9937 - val_loss: 0.5370 - val_accuracy: 0.8986\n","\n","Epoch 00234: val_accuracy did not improve from 0.94595\n","Epoch 235/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.5477 - val_accuracy: 0.9122\n","\n","Epoch 00235: val_accuracy did not improve from 0.94595\n","Epoch 236/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.5157 - val_accuracy: 0.8919\n","\n","Epoch 00236: val_accuracy did not improve from 0.94595\n","Epoch 237/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.4002 - val_accuracy: 0.9054\n","\n","Epoch 00237: val_accuracy did not improve from 0.94595\n","Epoch 238/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.4824 - val_accuracy: 0.8784\n","\n","Epoch 00238: val_accuracy did not improve from 0.94595\n","Epoch 239/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.4826 - val_accuracy: 0.9122\n","\n","Epoch 00239: val_accuracy did not improve from 0.94595\n","Epoch 240/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.5310 - val_accuracy: 0.9189\n","\n","Epoch 00240: val_accuracy did not improve from 0.94595\n","Epoch 241/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9054\n","\n","Epoch 00241: val_accuracy did not improve from 0.94595\n","Epoch 242/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4220 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.94595\n","Epoch 243/500\n","238/238 [==============================] - 28s 119ms/step - loss: 8.7397e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9324\n","\n","Epoch 00243: val_accuracy did not improve from 0.94595\n","Epoch 244/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4488 - val_accuracy: 0.9189\n","\n","Epoch 00244: val_accuracy did not improve from 0.94595\n","Epoch 245/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.5861 - val_accuracy: 0.8986\n","\n","Epoch 00245: val_accuracy did not improve from 0.94595\n","Epoch 246/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0595 - accuracy: 0.9837 - val_loss: 0.7145 - val_accuracy: 0.8919\n","\n","Epoch 00246: val_accuracy did not improve from 0.94595\n","Epoch 247/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.4358 - val_accuracy: 0.9189\n","\n","Epoch 00247: val_accuracy did not improve from 0.94595\n","Epoch 248/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.3933 - val_accuracy: 0.9392\n","\n","Epoch 00248: val_accuracy did not improve from 0.94595\n","Epoch 249/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 0.3556 - val_accuracy: 0.9392\n","\n","Epoch 00249: val_accuracy did not improve from 0.94595\n","Epoch 250/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.6965 - val_accuracy: 0.8851\n","\n","Epoch 00250: val_accuracy did not improve from 0.94595\n","Epoch 251/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.5343 - val_accuracy: 0.9054\n","\n","Epoch 00251: val_accuracy did not improve from 0.94595\n","Epoch 252/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.5514 - val_accuracy: 0.9054\n","\n","Epoch 00252: val_accuracy did not improve from 0.94595\n","Epoch 253/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.3848 - val_accuracy: 0.9257\n","\n","Epoch 00253: val_accuracy did not improve from 0.94595\n","Epoch 254/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.4892 - val_accuracy: 0.8851\n","\n","Epoch 00254: val_accuracy did not improve from 0.94595\n","Epoch 255/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9257\n","\n","Epoch 00255: val_accuracy did not improve from 0.94595\n","Epoch 256/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.4564 - val_accuracy: 0.9054\n","\n","Epoch 00256: val_accuracy did not improve from 0.94595\n","Epoch 257/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.5152 - val_accuracy: 0.9257\n","\n","Epoch 00257: val_accuracy did not improve from 0.94595\n","Epoch 258/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.3146 - val_accuracy: 0.9257\n","\n","Epoch 00258: val_accuracy did not improve from 0.94595\n","Epoch 259/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5841 - val_accuracy: 0.8919\n","\n","Epoch 00259: val_accuracy did not improve from 0.94595\n","Epoch 260/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.5002 - val_accuracy: 0.9257\n","\n","Epoch 00260: val_accuracy did not improve from 0.94595\n","Epoch 261/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.6998 - val_accuracy: 0.8851\n","\n","Epoch 00261: val_accuracy did not improve from 0.94595\n","Epoch 262/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.6268 - val_accuracy: 0.8986\n","\n","Epoch 00262: val_accuracy did not improve from 0.94595\n","Epoch 263/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4045 - val_accuracy: 0.9122\n","\n","Epoch 00263: val_accuracy did not improve from 0.94595\n","Epoch 264/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4636 - val_accuracy: 0.9122\n","\n","Epoch 00264: val_accuracy did not improve from 0.94595\n","Epoch 265/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.3956 - val_accuracy: 0.9257\n","\n","Epoch 00265: val_accuracy did not improve from 0.94595\n","Epoch 266/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.3741 - val_accuracy: 0.9054\n","\n","Epoch 00266: val_accuracy did not improve from 0.94595\n","Epoch 267/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.3851 - val_accuracy: 0.8986\n","\n","Epoch 00267: val_accuracy did not improve from 0.94595\n","Epoch 268/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3954 - val_accuracy: 0.9122\n","\n","Epoch 00268: val_accuracy did not improve from 0.94595\n","Epoch 269/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5796 - val_accuracy: 0.9122\n","\n","Epoch 00269: val_accuracy did not improve from 0.94595\n","Epoch 270/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9122\n","\n","Epoch 00270: val_accuracy did not improve from 0.94595\n","Epoch 271/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.5923 - val_accuracy: 0.8919\n","\n","Epoch 00271: val_accuracy did not improve from 0.94595\n","Epoch 272/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.4683 - val_accuracy: 0.8986\n","\n","Epoch 00272: val_accuracy did not improve from 0.94595\n","Epoch 273/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.3345 - val_accuracy: 0.9122\n","\n","Epoch 00273: val_accuracy did not improve from 0.94595\n","Epoch 274/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.4927 - val_accuracy: 0.9054\n","\n","Epoch 00274: val_accuracy did not improve from 0.94595\n","Epoch 275/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0214 - accuracy: 0.9900 - val_loss: 0.5119 - val_accuracy: 0.8986\n","\n","Epoch 00275: val_accuracy did not improve from 0.94595\n","Epoch 276/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.2636 - val_accuracy: 0.9257\n","\n","Epoch 00276: val_accuracy did not improve from 0.94595\n","Epoch 277/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4210 - val_accuracy: 0.9257\n","\n","Epoch 00277: val_accuracy did not improve from 0.94595\n","Epoch 278/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.3753 - val_accuracy: 0.9257\n","\n","Epoch 00278: val_accuracy did not improve from 0.94595\n","Epoch 279/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.2432 - val_accuracy: 0.9189\n","\n","Epoch 00279: val_accuracy did not improve from 0.94595\n","Epoch 280/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.3942 - val_accuracy: 0.9257\n","\n","Epoch 00280: val_accuracy did not improve from 0.94595\n","Epoch 281/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.5063 - val_accuracy: 0.9054\n","\n","Epoch 00281: val_accuracy did not improve from 0.94595\n","Epoch 282/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.7017 - val_accuracy: 0.8649\n","\n","Epoch 00282: val_accuracy did not improve from 0.94595\n","Epoch 283/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.4321 - val_accuracy: 0.9189\n","\n","Epoch 00283: val_accuracy did not improve from 0.94595\n","Epoch 284/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.6145 - val_accuracy: 0.8986\n","\n","Epoch 00284: val_accuracy did not improve from 0.94595\n","Epoch 285/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.6807 - val_accuracy: 0.8851\n","\n","Epoch 00285: val_accuracy did not improve from 0.94595\n","Epoch 286/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5297 - val_accuracy: 0.8784\n","\n","Epoch 00286: val_accuracy did not improve from 0.94595\n","Epoch 287/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.5098 - val_accuracy: 0.9054\n","\n","Epoch 00287: val_accuracy did not improve from 0.94595\n","Epoch 288/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.3145 - val_accuracy: 0.9324\n","\n","Epoch 00288: val_accuracy did not improve from 0.94595\n","Epoch 289/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5563 - val_accuracy: 0.9257\n","\n","Epoch 00289: val_accuracy did not improve from 0.94595\n","Epoch 290/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3738 - val_accuracy: 0.9257\n","\n","Epoch 00290: val_accuracy did not improve from 0.94595\n","Epoch 291/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.4874 - val_accuracy: 0.8986\n","\n","Epoch 00291: val_accuracy did not improve from 0.94595\n","Epoch 292/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.6212 - val_accuracy: 0.9122\n","\n","Epoch 00292: val_accuracy did not improve from 0.94595\n","Epoch 293/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.5730 - val_accuracy: 0.8919\n","\n","Epoch 00293: val_accuracy did not improve from 0.94595\n","Epoch 294/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.6239 - val_accuracy: 0.8851\n","\n","Epoch 00294: val_accuracy did not improve from 0.94595\n","Epoch 295/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.8469 - val_accuracy: 0.8514\n","\n","Epoch 00295: val_accuracy did not improve from 0.94595\n","Epoch 296/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.5253 - val_accuracy: 0.8851\n","\n","Epoch 00296: val_accuracy did not improve from 0.94595\n","Epoch 297/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4918 - val_accuracy: 0.9189\n","\n","Epoch 00297: val_accuracy did not improve from 0.94595\n","Epoch 298/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.6283 - val_accuracy: 0.8851\n","\n","Epoch 00298: val_accuracy did not improve from 0.94595\n","Epoch 299/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4063 - val_accuracy: 0.9122\n","\n","Epoch 00299: val_accuracy did not improve from 0.94595\n","Epoch 300/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.5745 - val_accuracy: 0.8986\n","\n","Epoch 00300: val_accuracy did not improve from 0.94595\n","Epoch 301/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.3571 - val_accuracy: 0.9054\n","\n","Epoch 00301: val_accuracy did not improve from 0.94595\n","Epoch 302/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4337 - val_accuracy: 0.8986\n","\n","Epoch 00302: val_accuracy did not improve from 0.94595\n","Epoch 303/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5075 - val_accuracy: 0.8919\n","\n","Epoch 00303: val_accuracy did not improve from 0.94595\n","Epoch 304/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.5415 - val_accuracy: 0.9122\n","\n","Epoch 00304: val_accuracy did not improve from 0.94595\n","Epoch 305/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.3997 - val_accuracy: 0.9122\n","\n","Epoch 00305: val_accuracy did not improve from 0.94595\n","Epoch 306/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.5543 - val_accuracy: 0.8919\n","\n","Epoch 00306: val_accuracy did not improve from 0.94595\n","Epoch 307/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3377 - val_accuracy: 0.9054\n","\n","Epoch 00307: val_accuracy did not improve from 0.94595\n","Epoch 308/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2882 - val_accuracy: 0.9257\n","\n","Epoch 00308: val_accuracy did not improve from 0.94595\n","Epoch 309/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.5656 - val_accuracy: 0.8784\n","\n","Epoch 00309: val_accuracy did not improve from 0.94595\n","Epoch 310/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.4068 - val_accuracy: 0.9257\n","\n","Epoch 00310: val_accuracy did not improve from 0.94595\n","Epoch 311/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.3703 - val_accuracy: 0.8986\n","\n","Epoch 00311: val_accuracy did not improve from 0.94595\n","Epoch 312/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0485 - accuracy: 0.9853 - val_loss: 0.5440 - val_accuracy: 0.8851\n","\n","Epoch 00312: val_accuracy did not improve from 0.94595\n","Epoch 313/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.9257\n","\n","Epoch 00313: val_accuracy did not improve from 0.94595\n","Epoch 314/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.9054\n","\n","Epoch 00314: val_accuracy did not improve from 0.94595\n","Epoch 315/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6065 - val_accuracy: 0.8851\n","\n","Epoch 00315: val_accuracy did not improve from 0.94595\n","Epoch 316/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9257\n","\n","Epoch 00316: val_accuracy did not improve from 0.94595\n","Epoch 317/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4262 - val_accuracy: 0.9324\n","\n","Epoch 00317: val_accuracy did not improve from 0.94595\n","Epoch 318/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4852 - val_accuracy: 0.9122\n","\n","Epoch 00318: val_accuracy did not improve from 0.94595\n","Epoch 319/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6260 - val_accuracy: 0.9122\n","\n","Epoch 00319: val_accuracy did not improve from 0.94595\n","Epoch 320/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.6456 - val_accuracy: 0.8716\n","\n","Epoch 00320: val_accuracy did not improve from 0.94595\n","Epoch 321/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.7472 - val_accuracy: 0.9054\n","\n","Epoch 00321: val_accuracy did not improve from 0.94595\n","Epoch 322/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.6054 - val_accuracy: 0.8919\n","\n","Epoch 00322: val_accuracy did not improve from 0.94595\n","Epoch 323/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.5039 - val_accuracy: 0.9189\n","\n","Epoch 00323: val_accuracy did not improve from 0.94595\n","Epoch 324/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.6414 - val_accuracy: 0.8851\n","\n","Epoch 00324: val_accuracy did not improve from 0.94595\n","Epoch 325/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.8597 - val_accuracy: 0.8446\n","\n","Epoch 00325: val_accuracy did not improve from 0.94595\n","Epoch 326/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.5654 - val_accuracy: 0.8919\n","\n","Epoch 00326: val_accuracy did not improve from 0.94595\n","Epoch 327/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.5670 - val_accuracy: 0.8851\n","\n","Epoch 00327: val_accuracy did not improve from 0.94595\n","Epoch 328/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4078 - val_accuracy: 0.9189\n","\n","Epoch 00328: val_accuracy did not improve from 0.94595\n","Epoch 329/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9122\n","\n","Epoch 00329: val_accuracy did not improve from 0.94595\n","Epoch 330/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4015 - val_accuracy: 0.9189\n","\n","Epoch 00330: val_accuracy did not improve from 0.94595\n","Epoch 331/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.4009 - val_accuracy: 0.9257\n","\n","Epoch 00331: val_accuracy did not improve from 0.94595\n","Epoch 332/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4175 - val_accuracy: 0.8986\n","\n","Epoch 00332: val_accuracy did not improve from 0.94595\n","Epoch 333/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.5171 - val_accuracy: 0.8986\n","\n","Epoch 00333: val_accuracy did not improve from 0.94595\n","Epoch 334/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5238 - val_accuracy: 0.8986\n","\n","Epoch 00334: val_accuracy did not improve from 0.94595\n","Epoch 335/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.4884 - val_accuracy: 0.9324\n","\n","Epoch 00335: val_accuracy did not improve from 0.94595\n","Epoch 336/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4397 - val_accuracy: 0.8986\n","\n","Epoch 00336: val_accuracy did not improve from 0.94595\n","Epoch 337/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.4254 - val_accuracy: 0.9324\n","\n","Epoch 00337: val_accuracy did not improve from 0.94595\n","Epoch 338/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.3399 - val_accuracy: 0.9189\n","\n","Epoch 00338: val_accuracy did not improve from 0.94595\n","Epoch 339/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.5257 - val_accuracy: 0.8649\n","\n","Epoch 00339: val_accuracy did not improve from 0.94595\n","Epoch 340/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.5312 - val_accuracy: 0.8986\n","\n","Epoch 00340: val_accuracy did not improve from 0.94595\n","Epoch 341/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.3600 - val_accuracy: 0.8986\n","\n","Epoch 00341: val_accuracy did not improve from 0.94595\n","Epoch 342/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.3263 - val_accuracy: 0.9189\n","\n","Epoch 00342: val_accuracy did not improve from 0.94595\n","Epoch 343/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9527\n","\n","Epoch 00343: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_3.h5\n","Epoch 344/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 0.4178 - val_accuracy: 0.9122\n","\n","Epoch 00344: val_accuracy did not improve from 0.95270\n","Epoch 345/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4688 - val_accuracy: 0.9324\n","\n","Epoch 00345: val_accuracy did not improve from 0.95270\n","Epoch 346/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.3333 - val_accuracy: 0.9324\n","\n","Epoch 00346: val_accuracy did not improve from 0.95270\n","Epoch 347/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.2624 - val_accuracy: 0.9459\n","\n","Epoch 00347: val_accuracy did not improve from 0.95270\n","Epoch 348/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5178 - val_accuracy: 0.9122\n","\n","Epoch 00348: val_accuracy did not improve from 0.95270\n","Epoch 349/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.4369 - val_accuracy: 0.8851\n","\n","Epoch 00349: val_accuracy did not improve from 0.95270\n","Epoch 350/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.3746 - val_accuracy: 0.8919\n","\n","Epoch 00350: val_accuracy did not improve from 0.95270\n","Epoch 351/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.4410 - val_accuracy: 0.8919\n","\n","Epoch 00351: val_accuracy did not improve from 0.95270\n","Epoch 352/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4836 - val_accuracy: 0.9122\n","\n","Epoch 00352: val_accuracy did not improve from 0.95270\n","Epoch 353/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.4801 - val_accuracy: 0.8919\n","\n","Epoch 00353: val_accuracy did not improve from 0.95270\n","Epoch 354/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5797 - val_accuracy: 0.8919\n","\n","Epoch 00354: val_accuracy did not improve from 0.95270\n","Epoch 355/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4082 - val_accuracy: 0.9122\n","\n","Epoch 00355: val_accuracy did not improve from 0.95270\n","Epoch 356/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.6481 - val_accuracy: 0.8446\n","\n","Epoch 00356: val_accuracy did not improve from 0.95270\n","Epoch 357/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4014 - val_accuracy: 0.9189\n","\n","Epoch 00357: val_accuracy did not improve from 0.95270\n","Epoch 358/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.4769 - val_accuracy: 0.8919\n","\n","Epoch 00358: val_accuracy did not improve from 0.95270\n","Epoch 359/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2485 - val_accuracy: 0.9257\n","\n","Epoch 00359: val_accuracy did not improve from 0.95270\n","Epoch 360/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.2763 - val_accuracy: 0.9257\n","\n","Epoch 00360: val_accuracy did not improve from 0.95270\n","Epoch 361/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4904 - val_accuracy: 0.9189\n","\n","Epoch 00361: val_accuracy did not improve from 0.95270\n","Epoch 362/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3609 - val_accuracy: 0.9257\n","\n","Epoch 00362: val_accuracy did not improve from 0.95270\n","Epoch 363/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.3347 - val_accuracy: 0.9324\n","\n","Epoch 00363: val_accuracy did not improve from 0.95270\n","Epoch 364/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4683 - val_accuracy: 0.8919\n","\n","Epoch 00364: val_accuracy did not improve from 0.95270\n","Epoch 365/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9122\n","\n","Epoch 00365: val_accuracy did not improve from 0.95270\n","Epoch 366/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4493 - val_accuracy: 0.9054\n","\n","Epoch 00366: val_accuracy did not improve from 0.95270\n","Epoch 367/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.6544 - val_accuracy: 0.9054\n","\n","Epoch 00367: val_accuracy did not improve from 0.95270\n","Epoch 368/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.7937 - val_accuracy: 0.8784\n","\n","Epoch 00368: val_accuracy did not improve from 0.95270\n","Epoch 369/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.4553 - val_accuracy: 0.8919\n","\n","Epoch 00369: val_accuracy did not improve from 0.95270\n","Epoch 370/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.6311 - val_accuracy: 0.9054\n","\n","Epoch 00370: val_accuracy did not improve from 0.95270\n","Epoch 371/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.5293 - val_accuracy: 0.9054\n","\n","Epoch 00371: val_accuracy did not improve from 0.95270\n","Epoch 372/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5598 - val_accuracy: 0.8784\n","\n","Epoch 00372: val_accuracy did not improve from 0.95270\n","Epoch 373/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6603 - val_accuracy: 0.8851\n","\n","Epoch 00373: val_accuracy did not improve from 0.95270\n","Epoch 374/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5748 - val_accuracy: 0.8986\n","\n","Epoch 00374: val_accuracy did not improve from 0.95270\n","Epoch 375/500\n","238/238 [==============================] - 29s 121ms/step - loss: 8.5833e-04 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.8986\n","\n","Epoch 00375: val_accuracy did not improve from 0.95270\n","Epoch 376/500\n","238/238 [==============================] - 29s 121ms/step - loss: 9.7810e-04 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.8851\n","\n","Epoch 00376: val_accuracy did not improve from 0.95270\n","Epoch 377/500\n","238/238 [==============================] - 29s 121ms/step - loss: 6.0406e-04 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9189\n","\n","Epoch 00377: val_accuracy did not improve from 0.95270\n","Epoch 378/500\n","238/238 [==============================] - 29s 120ms/step - loss: 5.5594e-04 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9122\n","\n","Epoch 00378: val_accuracy did not improve from 0.95270\n","Epoch 379/500\n","238/238 [==============================] - 29s 120ms/step - loss: 5.0364e-04 - accuracy: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9054\n","\n","Epoch 00379: val_accuracy did not improve from 0.95270\n","Epoch 380/500\n","238/238 [==============================] - 29s 120ms/step - loss: 3.8151e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9054\n","\n","Epoch 00380: val_accuracy did not improve from 0.95270\n","Epoch 381/500\n","238/238 [==============================] - 29s 120ms/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.8851\n","\n","Epoch 00381: val_accuracy did not improve from 0.95270\n","Epoch 382/500\n","238/238 [==============================] - 29s 120ms/step - loss: 1.2023e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9122\n","\n","Epoch 00382: val_accuracy did not improve from 0.95270\n","Epoch 383/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.8232 - val_accuracy: 0.8649\n","\n","Epoch 00383: val_accuracy did not improve from 0.95270\n","Epoch 384/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.4391 - val_accuracy: 0.8919\n","\n","Epoch 00384: val_accuracy did not improve from 0.95270\n","Epoch 385/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.8548 - val_accuracy: 0.8649\n","\n","Epoch 00385: val_accuracy did not improve from 0.95270\n","Epoch 386/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.4202 - val_accuracy: 0.9054\n","\n","Epoch 00386: val_accuracy did not improve from 0.95270\n","Epoch 387/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.4922 - val_accuracy: 0.8919\n","\n","Epoch 00387: val_accuracy did not improve from 0.95270\n","Epoch 388/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3936 - val_accuracy: 0.9122\n","\n","Epoch 00388: val_accuracy did not improve from 0.95270\n","Epoch 389/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.5222 - val_accuracy: 0.9122\n","\n","Epoch 00389: val_accuracy did not improve from 0.95270\n","Epoch 390/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 0.6613 - val_accuracy: 0.8919\n","\n","Epoch 00390: val_accuracy did not improve from 0.95270\n","Epoch 391/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.4402 - val_accuracy: 0.9122\n","\n","Epoch 00391: val_accuracy did not improve from 0.95270\n","Epoch 392/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.5353 - val_accuracy: 0.9122\n","\n","Epoch 00392: val_accuracy did not improve from 0.95270\n","Epoch 393/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.3875 - val_accuracy: 0.9392\n","\n","Epoch 00393: val_accuracy did not improve from 0.95270\n","Epoch 394/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.5481 - val_accuracy: 0.8919\n","\n","Epoch 00394: val_accuracy did not improve from 0.95270\n","Epoch 395/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.7870 - val_accuracy: 0.8716\n","\n","Epoch 00395: val_accuracy did not improve from 0.95270\n","Epoch 396/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.4621 - val_accuracy: 0.9122\n","\n","Epoch 00396: val_accuracy did not improve from 0.95270\n","Epoch 397/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3567 - val_accuracy: 0.9324\n","\n","Epoch 00397: val_accuracy did not improve from 0.95270\n","Epoch 398/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.7438 - val_accuracy: 0.8716\n","\n","Epoch 00398: val_accuracy did not improve from 0.95270\n","Epoch 399/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.7234 - val_accuracy: 0.8716\n","\n","Epoch 00399: val_accuracy did not improve from 0.95270\n","Epoch 400/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.6212 - val_accuracy: 0.9054\n","\n","Epoch 00400: val_accuracy did not improve from 0.95270\n","Epoch 401/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.3536 - val_accuracy: 0.8919\n","\n","Epoch 00401: val_accuracy did not improve from 0.95270\n","Epoch 402/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4749 - val_accuracy: 0.9054\n","\n","Epoch 00402: val_accuracy did not improve from 0.95270\n","Epoch 403/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.5566 - val_accuracy: 0.9257\n","\n","Epoch 00403: val_accuracy did not improve from 0.95270\n","Epoch 404/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.5863 - val_accuracy: 0.9189\n","\n","Epoch 00404: val_accuracy did not improve from 0.95270\n","Epoch 405/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.5968 - val_accuracy: 0.9054\n","\n","Epoch 00405: val_accuracy did not improve from 0.95270\n","Epoch 406/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.4095 - val_accuracy: 0.9324\n","\n","Epoch 00406: val_accuracy did not improve from 0.95270\n","Epoch 407/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.8585 - val_accuracy: 0.8716\n","\n","Epoch 00407: val_accuracy did not improve from 0.95270\n","Epoch 408/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.5237 - val_accuracy: 0.9257\n","\n","Epoch 00408: val_accuracy did not improve from 0.95270\n","Epoch 409/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0230 - accuracy: 0.9963 - val_loss: 0.6097 - val_accuracy: 0.8986\n","\n","Epoch 00409: val_accuracy did not improve from 0.95270\n","Epoch 410/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.8090 - val_accuracy: 0.8716\n","\n","Epoch 00410: val_accuracy did not improve from 0.95270\n","Epoch 411/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3745 - val_accuracy: 0.9054\n","\n","Epoch 00411: val_accuracy did not improve from 0.95270\n","Epoch 412/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.5380 - val_accuracy: 0.8851\n","\n","Epoch 00412: val_accuracy did not improve from 0.95270\n","Epoch 413/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.3601 - val_accuracy: 0.9324\n","\n","Epoch 00413: val_accuracy did not improve from 0.95270\n","Epoch 414/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5487 - val_accuracy: 0.9054\n","\n","Epoch 00414: val_accuracy did not improve from 0.95270\n","Epoch 415/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.9054\n","\n","Epoch 00415: val_accuracy did not improve from 0.95270\n","Epoch 416/500\n","238/238 [==============================] - 29s 120ms/step - loss: 3.9574e-04 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8986\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 29s 121ms/step - loss: 4.3243e-04 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9122\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5866 - val_accuracy: 0.8986\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9324\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6003 - val_accuracy: 0.9122\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.8127 - val_accuracy: 0.8716\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.5229 - val_accuracy: 0.9257\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0143 - accuracy: 0.9937 - val_loss: 0.4400 - val_accuracy: 0.9459\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.8875 - val_accuracy: 0.8649\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.5381 - val_accuracy: 0.9189\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.4486 - val_accuracy: 0.9257\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.6360 - val_accuracy: 0.8851\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.5354 - val_accuracy: 0.9054\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5168 - val_accuracy: 0.8919\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.8986\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5612 - val_accuracy: 0.8986\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0085 - accuracy: 0.9984 - val_loss: 0.4752 - val_accuracy: 0.9189\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.7786 - val_accuracy: 0.8851\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.8808 - val_accuracy: 0.8784\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.5159 - val_accuracy: 0.8851\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.3957 - val_accuracy: 0.9392\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4267 - val_accuracy: 0.9257\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4636 - val_accuracy: 0.9459\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.7667 - val_accuracy: 0.9122\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.5176 - val_accuracy: 0.9122\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.5817 - val_accuracy: 0.9189\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4931 - val_accuracy: 0.9189\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 29s 121ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.7085 - val_accuracy: 0.8986\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.6355 - val_accuracy: 0.9122\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.6214 - val_accuracy: 0.9122\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.5999 - val_accuracy: 0.8919\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.6408 - val_accuracy: 0.9324\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5994 - val_accuracy: 0.8986\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4382 - val_accuracy: 0.9122\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.3017 - val_accuracy: 0.9189\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.6463 - val_accuracy: 0.8851\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 28s 119ms/step - loss: 9.9957e-04 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9392\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 28s 120ms/step - loss: 2.8783e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9324\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 28s 119ms/step - loss: 4.5558e-04 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.9122\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 28s 119ms/step - loss: 2.1595e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9122\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.7152 - val_accuracy: 0.8851\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0242 - accuracy: 0.9953 - val_loss: 0.7895 - val_accuracy: 0.8784\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.5758 - val_accuracy: 0.9054\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5138 - val_accuracy: 0.8986\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.3732 - val_accuracy: 0.9392\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.4000 - val_accuracy: 0.9257\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5552 - val_accuracy: 0.8986\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 28s 119ms/step - loss: 3.0228e-04 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.9054\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 28s 119ms/step - loss: 6.2387e-04 - accuracy: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.9324\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 28s 119ms/step - loss: 4.5789e-04 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9189\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 29s 120ms/step - loss: 9.5480e-04 - accuracy: 0.9995 - val_loss: 0.5798 - val_accuracy: 0.9122\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 29s 120ms/step - loss: 2.8094e-04 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9257\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 29s 120ms/step - loss: 8.9212e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9122\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 29s 120ms/step - loss: 3.9816e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9257\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.5461 - val_accuracy: 0.9054\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.4334 - val_accuracy: 0.9189\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.7111 - val_accuracy: 0.8716\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.5466 - val_accuracy: 0.9054\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.5131 - val_accuracy: 0.9189\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.4757 - val_accuracy: 0.9122\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.5569 - val_accuracy: 0.8919\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.7792 - val_accuracy: 0.8784\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5694 - val_accuracy: 0.9324\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.4937 - val_accuracy: 0.9122\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 28s 120ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.4270 - val_accuracy: 0.8986\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 28s 119ms/step - loss: 5.0580e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9459\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 28s 119ms/step - loss: 5.0963e-04 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9392\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 28s 120ms/step - loss: 2.8200e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9189\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5658 - val_accuracy: 0.9122\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.3080 - val_accuracy: 0.9459\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4967 - val_accuracy: 0.9054\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.8325 - val_accuracy: 0.8851\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.4453 - val_accuracy: 0.8851\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.7315 - val_accuracy: 0.9054\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9189\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 29s 120ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9189\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 28s 119ms/step - loss: 9.7505e-04 - accuracy: 0.9995 - val_loss: 0.6886 - val_accuracy: 0.9054\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5930 - val_accuracy: 0.8784\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.7854 - val_accuracy: 0.8919\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.6165 - val_accuracy: 0.8919\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.7975 - val_accuracy: 0.8986\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.8558 - val_accuracy: 0.8919\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.6272 - val_accuracy: 0.9054\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.6755 - val_accuracy: 0.8784\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.6356 - val_accuracy: 0.9054\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f02680b9110>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1633011748381,"user_tz":-540,"elapsed":28,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"f52a4ac6-d545-41dd-8316-fa021e8890d9"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1633011833364,"user_tz":-540,"elapsed":84461,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1633011833876,"user_tz":-540,"elapsed":540,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633011834664,"user_tz":-540,"elapsed":799,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"81d5ea4a-87d4-4151-a3ef-b0aa22da9750"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633011885994,"user_tz":-540,"elapsed":51339,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"34da8811-02e6-4fce-dc4d-fa8446da11e9"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1633011886499,"user_tz":-540,"elapsed":535,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1633011886501,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1633011887444,"user_tz":-540,"elapsed":948,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1633011887446,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1633011898327,"user_tz":-540,"elapsed":10888,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1633011898328,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1633011898878,"user_tz":-540,"elapsed":556,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"13256690-c875-4ce7-90a7-ea89947bbd8f"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_4c9f39d4-2f8f-4ea7-b8c3-949e49b879c0\", \"DenseNet201_3.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633011902635,"user_tz":-540,"elapsed":3770,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"e64a3e34-1265-40a1-f2f3-f7248d82f765"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633011903653,"user_tz":-540,"elapsed":1040,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"71572c69-285e-4841-fd2d-3e64882b24fc"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    # 'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # meanideal96@gamil.com\n","    # '895306aa742a46bd095afaf319bd0b9519e1e6e74f4bf98a32c2e4c15aee5026',\n","    # dodo402298@gmail.com\n","    '384b4c250944611e49156214ca31fd554bbc64d22ec31a2726302c22f1a05271',\n","    # d9249.acc002@gmail.com\n","    # 'b28b29dd8d3ed4701f3b4e5b4d95549078e543dbd4a12abd92a3dd9a09d85616',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}