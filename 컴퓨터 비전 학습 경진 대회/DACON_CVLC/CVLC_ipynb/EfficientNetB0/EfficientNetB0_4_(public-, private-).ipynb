{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNetB0_4_(public-, private-).ipynb","provenance":[{"file_id":"1Y2c9MXmZLNEW6WU-oJXgwIvzQ77fxUaR","timestamp":1632815969024},{"file_id":"1Wo8M5eecf-5P8z0ZLjawoNhomWEy4F4z","timestamp":1632815952458},{"file_id":"1Wf0c2C_V_TV76M3yvaCqj4WRhGsfhSR_","timestamp":1632815928461},{"file_id":"1UoAi_OUp5FlBi0pHsVhKqBW3OLHhWd2j","timestamp":1632815272493},{"file_id":"1qZU39IunWaZOPCVpSa0V-8693Jh2Jz0c","timestamp":1632815233099},{"file_id":"1voj3Bcu0zAay7e_kl7qK5f78K9HMMKtM","timestamp":1632806561665},{"file_id":"1zElVRGsS1kg9WNy_6KUvQvaI5xYSdnlD","timestamp":1632806534245},{"file_id":"1OIZKCtwYST5ROVoAH5jE6OyziVLs5YVe","timestamp":1632775577125},{"file_id":"1M8OJEV_AT9MOCy7JGAaVl1j_VfABfzuE","timestamp":1632775493726},{"file_id":"1tLm7xKEM0NUAtTz8MetJXTPqs1Vr30rT","timestamp":1632775476672},{"file_id":"1cQ9_pnDLKsxM2cvx0IWbLgjkO3Cepyu-","timestamp":1632775461739},{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632816335344,"user_tz":-540,"elapsed":470,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"0682366b-7973-4057-8e8f-42edde25c1bf"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 28 08:05:37 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632816352924,"user_tz":-540,"elapsed":17583,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"ec17cefa-f909-4b31-cc6a-3116d6678071"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632816355760,"user_tz":-540,"elapsed":2471,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632816356947,"user_tz":-540,"elapsed":1190,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632816359316,"user_tz":-540,"elapsed":2373,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632816376101,"user_tz":-540,"elapsed":16794,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632816376104,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["nunbering = '0'\n","model_save = 'EfficientNetB' + nunbering + '_4'\n","Target_model = 'EfficientNetB' + nunbering + '_model'\n","Target_predict = 'EfficientNetB' + nunbering + '_predict'\n","Target_acc = 'EfficientNetB' + nunbering + '_acc'\n","Target_val = 'EfficientNetB' + nunbering + '_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632816382197,"user_tz":-540,"elapsed":6105,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.EfficientNetB0(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632816382198,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632816382603,"user_tz":-540,"elapsed":419,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"6d11263b-761c-4294-b54d-78e8f56e139e"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632816382604,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632828509462,"user_tz":-540,"elapsed":12126865,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"a98ca35b-a140-42a8-fd1d-a7c4a90421e8"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 46s 92ms/step - loss: 3.0781 - accuracy: 0.1737 - val_loss: 3.9103 - val_accuracy: 0.0946\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 21s 87ms/step - loss: 2.0116 - accuracy: 0.3221 - val_loss: 2.9667 - val_accuracy: 0.0946\n","\n","Epoch 00002: val_accuracy did not improve from 0.09459\n","Epoch 3/500\n","238/238 [==============================] - 21s 88ms/step - loss: 1.5442 - accuracy: 0.4789 - val_loss: 2.0674 - val_accuracy: 0.3108\n","\n","Epoch 00003: val_accuracy improved from 0.09459 to 0.31081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 4/500\n","238/238 [==============================] - 21s 87ms/step - loss: 1.1613 - accuracy: 0.6153 - val_loss: 1.1179 - val_accuracy: 0.6351\n","\n","Epoch 00004: val_accuracy improved from 0.31081 to 0.63514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 5/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.9959 - accuracy: 0.6784 - val_loss: 4.8582 - val_accuracy: 0.1081\n","\n","Epoch 00005: val_accuracy did not improve from 0.63514\n","Epoch 6/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.8052 - accuracy: 0.7395 - val_loss: 1.1668 - val_accuracy: 0.6486\n","\n","Epoch 00006: val_accuracy improved from 0.63514 to 0.64865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 7/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.7433 - accuracy: 0.7579 - val_loss: 0.4679 - val_accuracy: 0.8243\n","\n","Epoch 00007: val_accuracy improved from 0.64865 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 8/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.6637 - accuracy: 0.7837 - val_loss: 3.3432 - val_accuracy: 0.3716\n","\n","Epoch 00008: val_accuracy did not improve from 0.82432\n","Epoch 9/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.6261 - accuracy: 0.7858 - val_loss: 0.5346 - val_accuracy: 0.8378\n","\n","Epoch 00009: val_accuracy improved from 0.82432 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 10/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.5766 - accuracy: 0.8068 - val_loss: 0.6599 - val_accuracy: 0.8108\n","\n","Epoch 00010: val_accuracy did not improve from 0.83784\n","Epoch 11/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.5420 - accuracy: 0.8132 - val_loss: 4.0810 - val_accuracy: 0.2905\n","\n","Epoch 00011: val_accuracy did not improve from 0.83784\n","Epoch 12/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.4897 - accuracy: 0.8389 - val_loss: 4.6975 - val_accuracy: 0.1892\n","\n","Epoch 00012: val_accuracy did not improve from 0.83784\n","Epoch 13/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.4764 - accuracy: 0.8432 - val_loss: 0.6029 - val_accuracy: 0.7905\n","\n","Epoch 00013: val_accuracy did not improve from 0.83784\n","Epoch 14/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.4160 - accuracy: 0.8553 - val_loss: 0.5833 - val_accuracy: 0.8243\n","\n","Epoch 00014: val_accuracy did not improve from 0.83784\n","Epoch 15/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.4128 - accuracy: 0.8705 - val_loss: 0.7399 - val_accuracy: 0.7905\n","\n","Epoch 00015: val_accuracy did not improve from 0.83784\n","Epoch 16/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.3810 - accuracy: 0.8758 - val_loss: 0.5380 - val_accuracy: 0.8176\n","\n","Epoch 00016: val_accuracy did not improve from 0.83784\n","Epoch 17/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.3843 - accuracy: 0.8716 - val_loss: 0.5256 - val_accuracy: 0.8514\n","\n","Epoch 00017: val_accuracy improved from 0.83784 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 18/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.3520 - accuracy: 0.8821 - val_loss: 0.7489 - val_accuracy: 0.7838\n","\n","Epoch 00018: val_accuracy did not improve from 0.85135\n","Epoch 19/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.3533 - accuracy: 0.8847 - val_loss: 0.6484 - val_accuracy: 0.7905\n","\n","Epoch 00019: val_accuracy did not improve from 0.85135\n","Epoch 20/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2902 - accuracy: 0.9032 - val_loss: 0.4375 - val_accuracy: 0.8581\n","\n","Epoch 00020: val_accuracy improved from 0.85135 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 21/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.3563 - accuracy: 0.8847 - val_loss: 0.5771 - val_accuracy: 0.8311\n","\n","Epoch 00021: val_accuracy did not improve from 0.85811\n","Epoch 22/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.3549 - accuracy: 0.8789 - val_loss: 0.5498 - val_accuracy: 0.8176\n","\n","Epoch 00022: val_accuracy did not improve from 0.85811\n","Epoch 23/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2631 - accuracy: 0.9158 - val_loss: 2.8945 - val_accuracy: 0.3851\n","\n","Epoch 00023: val_accuracy did not improve from 0.85811\n","Epoch 24/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2881 - accuracy: 0.9058 - val_loss: 0.5265 - val_accuracy: 0.8446\n","\n","Epoch 00024: val_accuracy did not improve from 0.85811\n","Epoch 25/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2668 - accuracy: 0.9079 - val_loss: 0.5547 - val_accuracy: 0.8649\n","\n","Epoch 00025: val_accuracy improved from 0.85811 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 26/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.3276 - accuracy: 0.8974 - val_loss: 0.4171 - val_accuracy: 0.8446\n","\n","Epoch 00026: val_accuracy did not improve from 0.86486\n","Epoch 27/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.2666 - accuracy: 0.9079 - val_loss: 0.5833 - val_accuracy: 0.8243\n","\n","Epoch 00027: val_accuracy did not improve from 0.86486\n","Epoch 28/500\n","238/238 [==============================] - 20s 86ms/step - loss: 0.2506 - accuracy: 0.9247 - val_loss: 2.3205 - val_accuracy: 0.5000\n","\n","Epoch 00028: val_accuracy did not improve from 0.86486\n","Epoch 29/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.2316 - accuracy: 0.9216 - val_loss: 6.7881 - val_accuracy: 0.1419\n","\n","Epoch 00029: val_accuracy did not improve from 0.86486\n","Epoch 30/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2440 - accuracy: 0.9189 - val_loss: 0.6268 - val_accuracy: 0.8311\n","\n","Epoch 00030: val_accuracy did not improve from 0.86486\n","Epoch 31/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2071 - accuracy: 0.9289 - val_loss: 5.7429 - val_accuracy: 0.2432\n","\n","Epoch 00031: val_accuracy did not improve from 0.86486\n","Epoch 32/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.2226 - accuracy: 0.9305 - val_loss: 2.7312 - val_accuracy: 0.3851\n","\n","Epoch 00032: val_accuracy did not improve from 0.86486\n","Epoch 33/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2340 - accuracy: 0.9216 - val_loss: 0.5349 - val_accuracy: 0.8851\n","\n","Epoch 00033: val_accuracy improved from 0.86486 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 34/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1953 - accuracy: 0.9379 - val_loss: 1.4359 - val_accuracy: 0.7230\n","\n","Epoch 00034: val_accuracy did not improve from 0.88514\n","Epoch 35/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.2263 - accuracy: 0.9258 - val_loss: 0.3203 - val_accuracy: 0.8919\n","\n","Epoch 00035: val_accuracy improved from 0.88514 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 36/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1832 - accuracy: 0.9411 - val_loss: 0.7751 - val_accuracy: 0.7703\n","\n","Epoch 00036: val_accuracy did not improve from 0.89189\n","Epoch 37/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1592 - accuracy: 0.9495 - val_loss: 0.5084 - val_accuracy: 0.8919\n","\n","Epoch 00037: val_accuracy did not improve from 0.89189\n","Epoch 38/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.2036 - accuracy: 0.9384 - val_loss: 3.0631 - val_accuracy: 0.4932\n","\n","Epoch 00038: val_accuracy did not improve from 0.89189\n","Epoch 39/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.1792 - accuracy: 0.9437 - val_loss: 0.5877 - val_accuracy: 0.8649\n","\n","Epoch 00039: val_accuracy did not improve from 0.89189\n","Epoch 40/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1991 - accuracy: 0.9363 - val_loss: 4.5158 - val_accuracy: 0.3514\n","\n","Epoch 00040: val_accuracy did not improve from 0.89189\n","Epoch 41/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1550 - accuracy: 0.9442 - val_loss: 0.4678 - val_accuracy: 0.8784\n","\n","Epoch 00041: val_accuracy did not improve from 0.89189\n","Epoch 42/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1949 - accuracy: 0.9400 - val_loss: 3.2111 - val_accuracy: 0.3716\n","\n","Epoch 00042: val_accuracy did not improve from 0.89189\n","Epoch 43/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.1131 - accuracy: 0.9653 - val_loss: 4.6401 - val_accuracy: 0.2568\n","\n","Epoch 00043: val_accuracy did not improve from 0.89189\n","Epoch 44/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1307 - accuracy: 0.9584 - val_loss: 0.4909 - val_accuracy: 0.8851\n","\n","Epoch 00044: val_accuracy did not improve from 0.89189\n","Epoch 45/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.1474 - accuracy: 0.9521 - val_loss: 0.6798 - val_accuracy: 0.8514\n","\n","Epoch 00045: val_accuracy did not improve from 0.89189\n","Epoch 46/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1737 - accuracy: 0.9463 - val_loss: 0.4306 - val_accuracy: 0.9054\n","\n","Epoch 00046: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 47/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1664 - accuracy: 0.9489 - val_loss: 1.9642 - val_accuracy: 0.5541\n","\n","Epoch 00047: val_accuracy did not improve from 0.90541\n","Epoch 48/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1344 - accuracy: 0.9553 - val_loss: 0.5908 - val_accuracy: 0.8311\n","\n","Epoch 00048: val_accuracy did not improve from 0.90541\n","Epoch 49/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1098 - accuracy: 0.9647 - val_loss: 6.8183 - val_accuracy: 0.1959\n","\n","Epoch 00049: val_accuracy did not improve from 0.90541\n","Epoch 50/500\n","238/238 [==============================] - 20s 86ms/step - loss: 0.1246 - accuracy: 0.9642 - val_loss: 1.7792 - val_accuracy: 0.6014\n","\n","Epoch 00050: val_accuracy did not improve from 0.90541\n","Epoch 51/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.1342 - accuracy: 0.9589 - val_loss: 0.4562 - val_accuracy: 0.9054\n","\n","Epoch 00051: val_accuracy did not improve from 0.90541\n","Epoch 52/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.1339 - accuracy: 0.9558 - val_loss: 0.3241 - val_accuracy: 0.9189\n","\n","Epoch 00052: val_accuracy improved from 0.90541 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 53/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.3082 - val_accuracy: 0.8986\n","\n","Epoch 00053: val_accuracy did not improve from 0.91892\n","Epoch 54/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1138 - accuracy: 0.9621 - val_loss: 0.4697 - val_accuracy: 0.9054\n","\n","Epoch 00054: val_accuracy did not improve from 0.91892\n","Epoch 55/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1287 - accuracy: 0.9553 - val_loss: 0.4278 - val_accuracy: 0.8851\n","\n","Epoch 00055: val_accuracy did not improve from 0.91892\n","Epoch 56/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1283 - accuracy: 0.9574 - val_loss: 0.5867 - val_accuracy: 0.8176\n","\n","Epoch 00056: val_accuracy did not improve from 0.91892\n","Epoch 57/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0838 - accuracy: 0.9758 - val_loss: 0.9740 - val_accuracy: 0.7770\n","\n","Epoch 00057: val_accuracy did not improve from 0.91892\n","Epoch 58/500\n","238/238 [==============================] - 20s 86ms/step - loss: 0.1080 - accuracy: 0.9642 - val_loss: 0.6144 - val_accuracy: 0.8649\n","\n","Epoch 00058: val_accuracy did not improve from 0.91892\n","Epoch 59/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1229 - accuracy: 0.9574 - val_loss: 0.5229 - val_accuracy: 0.8514\n","\n","Epoch 00059: val_accuracy did not improve from 0.91892\n","Epoch 60/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1073 - accuracy: 0.9637 - val_loss: 0.3409 - val_accuracy: 0.9122\n","\n","Epoch 00060: val_accuracy did not improve from 0.91892\n","Epoch 61/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1195 - accuracy: 0.9647 - val_loss: 0.5160 - val_accuracy: 0.8716\n","\n","Epoch 00061: val_accuracy did not improve from 0.91892\n","Epoch 62/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0769 - accuracy: 0.9789 - val_loss: 0.4820 - val_accuracy: 0.8851\n","\n","Epoch 00062: val_accuracy did not improve from 0.91892\n","Epoch 63/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.0833 - accuracy: 0.9721 - val_loss: 0.7919 - val_accuracy: 0.7770\n","\n","Epoch 00063: val_accuracy did not improve from 0.91892\n","Epoch 64/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.1042 - accuracy: 0.9674 - val_loss: 0.6283 - val_accuracy: 0.8378\n","\n","Epoch 00064: val_accuracy did not improve from 0.91892\n","Epoch 65/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.1039 - accuracy: 0.9658 - val_loss: 0.3113 - val_accuracy: 0.9257\n","\n","Epoch 00065: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 66/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0869 - accuracy: 0.9689 - val_loss: 1.6057 - val_accuracy: 0.6757\n","\n","Epoch 00066: val_accuracy did not improve from 0.92568\n","Epoch 67/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0788 - accuracy: 0.9763 - val_loss: 0.4606 - val_accuracy: 0.8784\n","\n","Epoch 00067: val_accuracy did not improve from 0.92568\n","Epoch 68/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1064 - accuracy: 0.9600 - val_loss: 0.6014 - val_accuracy: 0.8919\n","\n","Epoch 00068: val_accuracy did not improve from 0.92568\n","Epoch 69/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0993 - accuracy: 0.9700 - val_loss: 0.5258 - val_accuracy: 0.8784\n","\n","Epoch 00069: val_accuracy did not improve from 0.92568\n","Epoch 70/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.4148 - val_accuracy: 0.8986\n","\n","Epoch 00070: val_accuracy did not improve from 0.92568\n","Epoch 71/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0817 - accuracy: 0.9742 - val_loss: 0.4098 - val_accuracy: 0.8851\n","\n","Epoch 00071: val_accuracy did not improve from 0.92568\n","Epoch 72/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.5798 - val_accuracy: 0.8919\n","\n","Epoch 00072: val_accuracy did not improve from 0.92568\n","Epoch 73/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1032 - accuracy: 0.9663 - val_loss: 0.5385 - val_accuracy: 0.8649\n","\n","Epoch 00073: val_accuracy did not improve from 0.92568\n","Epoch 74/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0721 - accuracy: 0.9763 - val_loss: 0.3455 - val_accuracy: 0.9054\n","\n","Epoch 00074: val_accuracy did not improve from 0.92568\n","Epoch 75/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0827 - accuracy: 0.9700 - val_loss: 1.1098 - val_accuracy: 0.7770\n","\n","Epoch 00075: val_accuracy did not improve from 0.92568\n","Epoch 76/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0810 - accuracy: 0.9732 - val_loss: 5.7711 - val_accuracy: 0.1824\n","\n","Epoch 00076: val_accuracy did not improve from 0.92568\n","Epoch 77/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0638 - accuracy: 0.9816 - val_loss: 0.5355 - val_accuracy: 0.8649\n","\n","Epoch 00077: val_accuracy did not improve from 0.92568\n","Epoch 78/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.0856 - accuracy: 0.9716 - val_loss: 0.3889 - val_accuracy: 0.8851\n","\n","Epoch 00078: val_accuracy did not improve from 0.92568\n","Epoch 79/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0798 - accuracy: 0.9737 - val_loss: 1.4555 - val_accuracy: 0.7365\n","\n","Epoch 00079: val_accuracy did not improve from 0.92568\n","Epoch 80/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.1028 - accuracy: 0.9663 - val_loss: 3.7082 - val_accuracy: 0.3243\n","\n","Epoch 00080: val_accuracy did not improve from 0.92568\n","Epoch 81/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.5426 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.92568\n","Epoch 82/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.5514 - val_accuracy: 0.8851\n","\n","Epoch 00082: val_accuracy did not improve from 0.92568\n","Epoch 83/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0601 - accuracy: 0.9832 - val_loss: 0.5548 - val_accuracy: 0.8716\n","\n","Epoch 00083: val_accuracy did not improve from 0.92568\n","Epoch 84/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0739 - accuracy: 0.9768 - val_loss: 0.7311 - val_accuracy: 0.7703\n","\n","Epoch 00084: val_accuracy did not improve from 0.92568\n","Epoch 85/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.4594 - val_accuracy: 0.8986\n","\n","Epoch 00085: val_accuracy did not improve from 0.92568\n","Epoch 86/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.1041 - accuracy: 0.9689 - val_loss: 0.4011 - val_accuracy: 0.9122\n","\n","Epoch 00086: val_accuracy did not improve from 0.92568\n","Epoch 87/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.4459 - val_accuracy: 0.8919\n","\n","Epoch 00087: val_accuracy did not improve from 0.92568\n","Epoch 88/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.4058 - val_accuracy: 0.8919\n","\n","Epoch 00088: val_accuracy did not improve from 0.92568\n","Epoch 89/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0682 - accuracy: 0.9789 - val_loss: 0.6591 - val_accuracy: 0.8581\n","\n","Epoch 00089: val_accuracy did not improve from 0.92568\n","Epoch 90/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0882 - accuracy: 0.9768 - val_loss: 0.7501 - val_accuracy: 0.8851\n","\n","Epoch 00090: val_accuracy did not improve from 0.92568\n","Epoch 91/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0846 - accuracy: 0.9768 - val_loss: 0.5491 - val_accuracy: 0.8784\n","\n","Epoch 00091: val_accuracy did not improve from 0.92568\n","Epoch 92/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.5670 - val_accuracy: 0.8784\n","\n","Epoch 00092: val_accuracy did not improve from 0.92568\n","Epoch 93/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.4156 - val_accuracy: 0.9189\n","\n","Epoch 00093: val_accuracy did not improve from 0.92568\n","Epoch 94/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.5617 - val_accuracy: 0.9054\n","\n","Epoch 00094: val_accuracy did not improve from 0.92568\n","Epoch 95/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0546 - accuracy: 0.9784 - val_loss: 2.8805 - val_accuracy: 0.4730\n","\n","Epoch 00095: val_accuracy did not improve from 0.92568\n","Epoch 96/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0856 - accuracy: 0.9716 - val_loss: 0.8543 - val_accuracy: 0.7703\n","\n","Epoch 00096: val_accuracy did not improve from 0.92568\n","Epoch 97/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 0.5270 - val_accuracy: 0.9054\n","\n","Epoch 00097: val_accuracy did not improve from 0.92568\n","Epoch 98/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0779 - accuracy: 0.9805 - val_loss: 0.4920 - val_accuracy: 0.8446\n","\n","Epoch 00098: val_accuracy did not improve from 0.92568\n","Epoch 99/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0899 - accuracy: 0.9721 - val_loss: 1.2948 - val_accuracy: 0.6554\n","\n","Epoch 00099: val_accuracy did not improve from 0.92568\n","Epoch 100/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0377 - accuracy: 0.9853 - val_loss: 0.3977 - val_accuracy: 0.9122\n","\n","Epoch 00100: val_accuracy did not improve from 0.92568\n","Epoch 101/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.7231 - val_accuracy: 0.8514\n","\n","Epoch 00101: val_accuracy did not improve from 0.92568\n","Epoch 102/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.5117 - val_accuracy: 0.8986\n","\n","Epoch 00102: val_accuracy did not improve from 0.92568\n","Epoch 103/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 1.9930 - val_accuracy: 0.5405\n","\n","Epoch 00103: val_accuracy did not improve from 0.92568\n","Epoch 104/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0470 - accuracy: 0.9874 - val_loss: 0.4203 - val_accuracy: 0.9257\n","\n","Epoch 00104: val_accuracy did not improve from 0.92568\n","Epoch 105/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.4687 - val_accuracy: 0.8986\n","\n","Epoch 00105: val_accuracy did not improve from 0.92568\n","Epoch 106/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 0.7896 - val_accuracy: 0.8514\n","\n","Epoch 00106: val_accuracy did not improve from 0.92568\n","Epoch 107/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0428 - accuracy: 0.9826 - val_loss: 0.4949 - val_accuracy: 0.9122\n","\n","Epoch 00107: val_accuracy did not improve from 0.92568\n","Epoch 108/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 0.6935 - val_accuracy: 0.8716\n","\n","Epoch 00108: val_accuracy did not improve from 0.92568\n","Epoch 109/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0964 - accuracy: 0.9674 - val_loss: 1.6040 - val_accuracy: 0.7095\n","\n","Epoch 00109: val_accuracy did not improve from 0.92568\n","Epoch 110/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.3267 - val_accuracy: 0.9122\n","\n","Epoch 00110: val_accuracy did not improve from 0.92568\n","Epoch 111/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.4767 - val_accuracy: 0.8784\n","\n","Epoch 00111: val_accuracy did not improve from 0.92568\n","Epoch 112/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0466 - accuracy: 0.9863 - val_loss: 0.5362 - val_accuracy: 0.8784\n","\n","Epoch 00112: val_accuracy did not improve from 0.92568\n","Epoch 113/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.6038 - val_accuracy: 0.8581\n","\n","Epoch 00113: val_accuracy did not improve from 0.92568\n","Epoch 114/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0581 - accuracy: 0.9816 - val_loss: 0.8071 - val_accuracy: 0.8649\n","\n","Epoch 00114: val_accuracy did not improve from 0.92568\n","Epoch 115/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0602 - accuracy: 0.9826 - val_loss: 0.5290 - val_accuracy: 0.9189\n","\n","Epoch 00115: val_accuracy did not improve from 0.92568\n","Epoch 116/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.3658 - val_accuracy: 0.9189\n","\n","Epoch 00116: val_accuracy did not improve from 0.92568\n","Epoch 117/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 0.4720 - val_accuracy: 0.8716\n","\n","Epoch 00117: val_accuracy did not improve from 0.92568\n","Epoch 118/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.5235 - val_accuracy: 0.8784\n","\n","Epoch 00118: val_accuracy did not improve from 0.92568\n","Epoch 119/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.5916 - val_accuracy: 0.8986\n","\n","Epoch 00119: val_accuracy did not improve from 0.92568\n","Epoch 120/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.4217 - val_accuracy: 0.8919\n","\n","Epoch 00120: val_accuracy did not improve from 0.92568\n","Epoch 121/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.5147 - val_accuracy: 0.8919\n","\n","Epoch 00121: val_accuracy did not improve from 0.92568\n","Epoch 122/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0572 - accuracy: 0.9863 - val_loss: 0.5210 - val_accuracy: 0.8919\n","\n","Epoch 00122: val_accuracy did not improve from 0.92568\n","Epoch 123/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.8528 - val_accuracy: 0.7568\n","\n","Epoch 00123: val_accuracy did not improve from 0.92568\n","Epoch 124/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0687 - accuracy: 0.9774 - val_loss: 2.3601 - val_accuracy: 0.5338\n","\n","Epoch 00124: val_accuracy did not improve from 0.92568\n","Epoch 125/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0481 - accuracy: 0.9832 - val_loss: 2.1275 - val_accuracy: 0.6622\n","\n","Epoch 00125: val_accuracy did not improve from 0.92568\n","Epoch 126/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.3445 - val_accuracy: 0.8919\n","\n","Epoch 00126: val_accuracy did not improve from 0.92568\n","Epoch 127/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0325 - accuracy: 0.9863 - val_loss: 0.3182 - val_accuracy: 0.9527\n","\n","Epoch 00127: val_accuracy improved from 0.92568 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB0_4.h5\n","Epoch 128/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.4033 - val_accuracy: 0.9189\n","\n","Epoch 00128: val_accuracy did not improve from 0.95270\n","Epoch 129/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 2.2885 - val_accuracy: 0.6892\n","\n","Epoch 00129: val_accuracy did not improve from 0.95270\n","Epoch 130/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.6714 - val_accuracy: 0.8581\n","\n","Epoch 00130: val_accuracy did not improve from 0.95270\n","Epoch 131/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.5841 - val_accuracy: 0.8986\n","\n","Epoch 00131: val_accuracy did not improve from 0.95270\n","Epoch 132/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0944 - accuracy: 0.9732 - val_loss: 0.8397 - val_accuracy: 0.8311\n","\n","Epoch 00132: val_accuracy did not improve from 0.95270\n","Epoch 133/500\n","238/238 [==============================] - 21s 86ms/step - loss: 0.0478 - accuracy: 0.9842 - val_loss: 0.5606 - val_accuracy: 0.8986\n","\n","Epoch 00133: val_accuracy did not improve from 0.95270\n","Epoch 134/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0422 - accuracy: 0.9842 - val_loss: 0.4720 - val_accuracy: 0.9122\n","\n","Epoch 00134: val_accuracy did not improve from 0.95270\n","Epoch 135/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0369 - accuracy: 0.9842 - val_loss: 0.6844 - val_accuracy: 0.8784\n","\n","Epoch 00135: val_accuracy did not improve from 0.95270\n","Epoch 136/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0405 - accuracy: 0.9842 - val_loss: 0.8273 - val_accuracy: 0.8311\n","\n","Epoch 00136: val_accuracy did not improve from 0.95270\n","Epoch 137/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.6640 - val_accuracy: 0.8514\n","\n","Epoch 00137: val_accuracy did not improve from 0.95270\n","Epoch 138/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0333 - accuracy: 0.9879 - val_loss: 0.5489 - val_accuracy: 0.8919\n","\n","Epoch 00138: val_accuracy did not improve from 0.95270\n","Epoch 139/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0560 - accuracy: 0.9811 - val_loss: 0.5867 - val_accuracy: 0.8919\n","\n","Epoch 00139: val_accuracy did not improve from 0.95270\n","Epoch 140/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 1.1625 - val_accuracy: 0.7162\n","\n","Epoch 00140: val_accuracy did not improve from 0.95270\n","Epoch 141/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.4520 - val_accuracy: 0.8716\n","\n","Epoch 00141: val_accuracy did not improve from 0.95270\n","Epoch 142/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.5963 - val_accuracy: 0.8986\n","\n","Epoch 00142: val_accuracy did not improve from 0.95270\n","Epoch 143/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0367 - accuracy: 0.9863 - val_loss: 0.4768 - val_accuracy: 0.9189\n","\n","Epoch 00143: val_accuracy did not improve from 0.95270\n","Epoch 144/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.5731 - val_accuracy: 0.9189\n","\n","Epoch 00144: val_accuracy did not improve from 0.95270\n","Epoch 145/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.5487 - val_accuracy: 0.8986\n","\n","Epoch 00145: val_accuracy did not improve from 0.95270\n","Epoch 146/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0284 - accuracy: 0.9932 - val_loss: 0.4286 - val_accuracy: 0.9122\n","\n","Epoch 00146: val_accuracy did not improve from 0.95270\n","Epoch 147/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.4942 - val_accuracy: 0.9054\n","\n","Epoch 00147: val_accuracy did not improve from 0.95270\n","Epoch 148/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0608 - accuracy: 0.9826 - val_loss: 0.3710 - val_accuracy: 0.9392\n","\n","Epoch 00148: val_accuracy did not improve from 0.95270\n","Epoch 149/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.5349 - val_accuracy: 0.8851\n","\n","Epoch 00149: val_accuracy did not improve from 0.95270\n","Epoch 150/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0397 - accuracy: 0.9847 - val_loss: 0.8522 - val_accuracy: 0.8243\n","\n","Epoch 00150: val_accuracy did not improve from 0.95270\n","Epoch 151/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.5233 - val_accuracy: 0.8851\n","\n","Epoch 00151: val_accuracy did not improve from 0.95270\n","Epoch 152/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.5012 - val_accuracy: 0.8919\n","\n","Epoch 00152: val_accuracy did not improve from 0.95270\n","Epoch 153/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.4707 - val_accuracy: 0.8919\n","\n","Epoch 00153: val_accuracy did not improve from 0.95270\n","Epoch 154/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.5758 - val_accuracy: 0.8716\n","\n","Epoch 00154: val_accuracy did not improve from 0.95270\n","Epoch 155/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.4943 - val_accuracy: 0.9054\n","\n","Epoch 00155: val_accuracy did not improve from 0.95270\n","Epoch 156/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.4294 - val_accuracy: 0.9189\n","\n","Epoch 00156: val_accuracy did not improve from 0.95270\n","Epoch 157/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.4564 - val_accuracy: 0.9054\n","\n","Epoch 00157: val_accuracy did not improve from 0.95270\n","Epoch 158/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.5150 - val_accuracy: 0.8851\n","\n","Epoch 00158: val_accuracy did not improve from 0.95270\n","Epoch 159/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0380 - accuracy: 0.9889 - val_loss: 0.6176 - val_accuracy: 0.8784\n","\n","Epoch 00159: val_accuracy did not improve from 0.95270\n","Epoch 160/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.6043 - val_accuracy: 0.8986\n","\n","Epoch 00160: val_accuracy did not improve from 0.95270\n","Epoch 161/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.5055 - val_accuracy: 0.8986\n","\n","Epoch 00161: val_accuracy did not improve from 0.95270\n","Epoch 162/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.8157 - val_accuracy: 0.8919\n","\n","Epoch 00162: val_accuracy did not improve from 0.95270\n","Epoch 163/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0717 - accuracy: 0.9816 - val_loss: 0.7122 - val_accuracy: 0.8649\n","\n","Epoch 00163: val_accuracy did not improve from 0.95270\n","Epoch 164/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.4583 - val_accuracy: 0.9054\n","\n","Epoch 00164: val_accuracy did not improve from 0.95270\n","Epoch 165/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.5797 - val_accuracy: 0.9122\n","\n","Epoch 00165: val_accuracy did not improve from 0.95270\n","Epoch 166/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.4625 - val_accuracy: 0.9257\n","\n","Epoch 00166: val_accuracy did not improve from 0.95270\n","Epoch 167/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.6195 - val_accuracy: 0.9054\n","\n","Epoch 00167: val_accuracy did not improve from 0.95270\n","Epoch 168/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4948 - val_accuracy: 0.9189\n","\n","Epoch 00168: val_accuracy did not improve from 0.95270\n","Epoch 169/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.3498 - val_accuracy: 0.9392\n","\n","Epoch 00169: val_accuracy did not improve from 0.95270\n","Epoch 170/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0265 - accuracy: 0.9895 - val_loss: 0.4210 - val_accuracy: 0.9257\n","\n","Epoch 00170: val_accuracy did not improve from 0.95270\n","Epoch 171/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 0.6010 - val_accuracy: 0.8716\n","\n","Epoch 00171: val_accuracy did not improve from 0.95270\n","Epoch 172/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0623 - accuracy: 0.9784 - val_loss: 0.6000 - val_accuracy: 0.8649\n","\n","Epoch 00172: val_accuracy did not improve from 0.95270\n","Epoch 173/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 0.6485 - val_accuracy: 0.8784\n","\n","Epoch 00173: val_accuracy did not improve from 0.95270\n","Epoch 174/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5133 - val_accuracy: 0.8851\n","\n","Epoch 00174: val_accuracy did not improve from 0.95270\n","Epoch 175/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.5706 - val_accuracy: 0.8986\n","\n","Epoch 00175: val_accuracy did not improve from 0.95270\n","Epoch 176/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 1.0204 - val_accuracy: 0.7905\n","\n","Epoch 00176: val_accuracy did not improve from 0.95270\n","Epoch 177/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.3649 - val_accuracy: 0.9324\n","\n","Epoch 00177: val_accuracy did not improve from 0.95270\n","Epoch 178/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.5343 - val_accuracy: 0.9054\n","\n","Epoch 00178: val_accuracy did not improve from 0.95270\n","Epoch 179/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.3834 - val_accuracy: 0.9122\n","\n","Epoch 00179: val_accuracy did not improve from 0.95270\n","Epoch 180/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0548 - accuracy: 0.9842 - val_loss: 0.6580 - val_accuracy: 0.8649\n","\n","Epoch 00180: val_accuracy did not improve from 0.95270\n","Epoch 181/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.5342 - val_accuracy: 0.8851\n","\n","Epoch 00181: val_accuracy did not improve from 0.95270\n","Epoch 182/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.5539 - val_accuracy: 0.8649\n","\n","Epoch 00182: val_accuracy did not improve from 0.95270\n","Epoch 183/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.5922 - val_accuracy: 0.8986\n","\n","Epoch 00183: val_accuracy did not improve from 0.95270\n","Epoch 184/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.9232 - val_accuracy: 0.8784\n","\n","Epoch 00184: val_accuracy did not improve from 0.95270\n","Epoch 185/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 1.5062 - val_accuracy: 0.7297\n","\n","Epoch 00185: val_accuracy did not improve from 0.95270\n","Epoch 186/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.5260 - val_accuracy: 0.9122\n","\n","Epoch 00186: val_accuracy did not improve from 0.95270\n","Epoch 187/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.7024 - val_accuracy: 0.8784\n","\n","Epoch 00187: val_accuracy did not improve from 0.95270\n","Epoch 188/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0409 - accuracy: 0.9879 - val_loss: 1.8687 - val_accuracy: 0.6892\n","\n","Epoch 00188: val_accuracy did not improve from 0.95270\n","Epoch 189/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5274 - val_accuracy: 0.8919\n","\n","Epoch 00189: val_accuracy did not improve from 0.95270\n","Epoch 190/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.7179 - val_accuracy: 0.9122\n","\n","Epoch 00190: val_accuracy did not improve from 0.95270\n","Epoch 191/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.5867 - val_accuracy: 0.9257\n","\n","Epoch 00191: val_accuracy did not improve from 0.95270\n","Epoch 192/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0323 - accuracy: 0.9879 - val_loss: 0.5951 - val_accuracy: 0.8919\n","\n","Epoch 00192: val_accuracy did not improve from 0.95270\n","Epoch 193/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.5331 - val_accuracy: 0.9054\n","\n","Epoch 00193: val_accuracy did not improve from 0.95270\n","Epoch 194/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0356 - accuracy: 0.9879 - val_loss: 0.5343 - val_accuracy: 0.8851\n","\n","Epoch 00194: val_accuracy did not improve from 0.95270\n","Epoch 195/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.5953 - val_accuracy: 0.9054\n","\n","Epoch 00195: val_accuracy did not improve from 0.95270\n","Epoch 196/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.5785 - val_accuracy: 0.8716\n","\n","Epoch 00196: val_accuracy did not improve from 0.95270\n","Epoch 197/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0220 - accuracy: 0.9911 - val_loss: 0.6083 - val_accuracy: 0.8919\n","\n","Epoch 00197: val_accuracy did not improve from 0.95270\n","Epoch 198/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.4777 - val_accuracy: 0.9122\n","\n","Epoch 00198: val_accuracy did not improve from 0.95270\n","Epoch 199/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.5747 - val_accuracy: 0.8986\n","\n","Epoch 00199: val_accuracy did not improve from 0.95270\n","Epoch 200/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.4499 - val_accuracy: 0.8919\n","\n","Epoch 00200: val_accuracy did not improve from 0.95270\n","Epoch 201/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.5827 - val_accuracy: 0.8784\n","\n","Epoch 00201: val_accuracy did not improve from 0.95270\n","Epoch 202/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.6250 - val_accuracy: 0.8986\n","\n","Epoch 00202: val_accuracy did not improve from 0.95270\n","Epoch 203/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.5352 - val_accuracy: 0.9122\n","\n","Epoch 00203: val_accuracy did not improve from 0.95270\n","Epoch 204/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.4687 - val_accuracy: 0.8986\n","\n","Epoch 00204: val_accuracy did not improve from 0.95270\n","Epoch 205/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 1.3526 - val_accuracy: 0.7230\n","\n","Epoch 00205: val_accuracy did not improve from 0.95270\n","Epoch 206/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.3909 - val_accuracy: 0.9324\n","\n","Epoch 00206: val_accuracy did not improve from 0.95270\n","Epoch 207/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.3825 - val_accuracy: 0.9122\n","\n","Epoch 00207: val_accuracy did not improve from 0.95270\n","Epoch 208/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4838 - val_accuracy: 0.9054\n","\n","Epoch 00208: val_accuracy did not improve from 0.95270\n","Epoch 209/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.5221 - val_accuracy: 0.8919\n","\n","Epoch 00209: val_accuracy did not improve from 0.95270\n","Epoch 210/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.5495 - val_accuracy: 0.9054\n","\n","Epoch 00210: val_accuracy did not improve from 0.95270\n","Epoch 211/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.5530 - val_accuracy: 0.8986\n","\n","Epoch 00211: val_accuracy did not improve from 0.95270\n","Epoch 212/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.5203 - val_accuracy: 0.8986\n","\n","Epoch 00212: val_accuracy did not improve from 0.95270\n","Epoch 213/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.8353 - val_accuracy: 0.8851\n","\n","Epoch 00213: val_accuracy did not improve from 0.95270\n","Epoch 214/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.7337 - val_accuracy: 0.8716\n","\n","Epoch 00214: val_accuracy did not improve from 0.95270\n","Epoch 215/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.4301 - val_accuracy: 0.8784\n","\n","Epoch 00215: val_accuracy did not improve from 0.95270\n","Epoch 216/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.3852 - val_accuracy: 0.9257\n","\n","Epoch 00216: val_accuracy did not improve from 0.95270\n","Epoch 217/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.6714 - val_accuracy: 0.8716\n","\n","Epoch 00217: val_accuracy did not improve from 0.95270\n","Epoch 218/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.7759 - val_accuracy: 0.8581\n","\n","Epoch 00218: val_accuracy did not improve from 0.95270\n","Epoch 219/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.6933 - val_accuracy: 0.8919\n","\n","Epoch 00219: val_accuracy did not improve from 0.95270\n","Epoch 220/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0184 - accuracy: 0.9921 - val_loss: 0.5614 - val_accuracy: 0.9122\n","\n","Epoch 00220: val_accuracy did not improve from 0.95270\n","Epoch 221/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6887 - val_accuracy: 0.8919\n","\n","Epoch 00221: val_accuracy did not improve from 0.95270\n","Epoch 222/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.5352 - val_accuracy: 0.8986\n","\n","Epoch 00222: val_accuracy did not improve from 0.95270\n","Epoch 223/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.5368 - val_accuracy: 0.9054\n","\n","Epoch 00223: val_accuracy did not improve from 0.95270\n","Epoch 224/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.3851 - val_accuracy: 0.9257\n","\n","Epoch 00224: val_accuracy did not improve from 0.95270\n","Epoch 225/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.6538 - val_accuracy: 0.9054\n","\n","Epoch 00225: val_accuracy did not improve from 0.95270\n","Epoch 226/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.4593 - val_accuracy: 0.9054\n","\n","Epoch 00226: val_accuracy did not improve from 0.95270\n","Epoch 227/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.5154 - val_accuracy: 0.8986\n","\n","Epoch 00227: val_accuracy did not improve from 0.95270\n","Epoch 228/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.5008 - val_accuracy: 0.9122\n","\n","Epoch 00228: val_accuracy did not improve from 0.95270\n","Epoch 229/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.6642 - val_accuracy: 0.9324\n","\n","Epoch 00229: val_accuracy did not improve from 0.95270\n","Epoch 230/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0164 - accuracy: 0.9932 - val_loss: 0.5896 - val_accuracy: 0.9324\n","\n","Epoch 00230: val_accuracy did not improve from 0.95270\n","Epoch 231/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.5140 - val_accuracy: 0.9122\n","\n","Epoch 00231: val_accuracy did not improve from 0.95270\n","Epoch 232/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.6037 - val_accuracy: 0.9189\n","\n","Epoch 00232: val_accuracy did not improve from 0.95270\n","Epoch 233/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 0.6390 - val_accuracy: 0.8919\n","\n","Epoch 00233: val_accuracy did not improve from 0.95270\n","Epoch 234/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.6502 - val_accuracy: 0.9054\n","\n","Epoch 00234: val_accuracy did not improve from 0.95270\n","Epoch 235/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.6292 - val_accuracy: 0.8716\n","\n","Epoch 00235: val_accuracy did not improve from 0.95270\n","Epoch 236/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 0.6688 - val_accuracy: 0.9054\n","\n","Epoch 00236: val_accuracy did not improve from 0.95270\n","Epoch 237/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5866 - val_accuracy: 0.8986\n","\n","Epoch 00237: val_accuracy did not improve from 0.95270\n","Epoch 238/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.6256 - val_accuracy: 0.9189\n","\n","Epoch 00238: val_accuracy did not improve from 0.95270\n","Epoch 239/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.6325 - val_accuracy: 0.8986\n","\n","Epoch 00239: val_accuracy did not improve from 0.95270\n","Epoch 240/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.6734 - val_accuracy: 0.8784\n","\n","Epoch 00240: val_accuracy did not improve from 0.95270\n","Epoch 241/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.6550 - val_accuracy: 0.9122\n","\n","Epoch 00241: val_accuracy did not improve from 0.95270\n","Epoch 242/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0397 - accuracy: 0.9900 - val_loss: 0.6127 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.95270\n","Epoch 243/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.5654 - val_accuracy: 0.8986\n","\n","Epoch 00243: val_accuracy did not improve from 0.95270\n","Epoch 244/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 2.0969 - val_accuracy: 0.7162\n","\n","Epoch 00244: val_accuracy did not improve from 0.95270\n","Epoch 245/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.3445 - val_accuracy: 0.9189\n","\n","Epoch 00245: val_accuracy did not improve from 0.95270\n","Epoch 246/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.6519 - val_accuracy: 0.8919\n","\n","Epoch 00246: val_accuracy did not improve from 0.95270\n","Epoch 247/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.5511 - val_accuracy: 0.8919\n","\n","Epoch 00247: val_accuracy did not improve from 0.95270\n","Epoch 248/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.6925 - val_accuracy: 0.8378\n","\n","Epoch 00248: val_accuracy did not improve from 0.95270\n","Epoch 249/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5754 - val_accuracy: 0.9189\n","\n","Epoch 00249: val_accuracy did not improve from 0.95270\n","Epoch 250/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.9010 - val_accuracy: 0.8581\n","\n","Epoch 00250: val_accuracy did not improve from 0.95270\n","Epoch 251/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0266 - accuracy: 0.9926 - val_loss: 0.6285 - val_accuracy: 0.8581\n","\n","Epoch 00251: val_accuracy did not improve from 0.95270\n","Epoch 252/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.6540 - val_accuracy: 0.8851\n","\n","Epoch 00252: val_accuracy did not improve from 0.95270\n","Epoch 253/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.9821 - val_accuracy: 0.8041\n","\n","Epoch 00253: val_accuracy did not improve from 0.95270\n","Epoch 254/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.5549 - val_accuracy: 0.8919\n","\n","Epoch 00254: val_accuracy did not improve from 0.95270\n","Epoch 255/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.6137 - val_accuracy: 0.8986\n","\n","Epoch 00255: val_accuracy did not improve from 0.95270\n","Epoch 256/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0286 - accuracy: 0.9937 - val_loss: 0.6607 - val_accuracy: 0.8986\n","\n","Epoch 00256: val_accuracy did not improve from 0.95270\n","Epoch 257/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.7923 - val_accuracy: 0.8851\n","\n","Epoch 00257: val_accuracy did not improve from 0.95270\n","Epoch 258/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 1.0640 - val_accuracy: 0.7703\n","\n","Epoch 00258: val_accuracy did not improve from 0.95270\n","Epoch 259/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 0.3960 - val_accuracy: 0.9054\n","\n","Epoch 00259: val_accuracy did not improve from 0.95270\n","Epoch 260/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.4155 - val_accuracy: 0.9189\n","\n","Epoch 00260: val_accuracy did not improve from 0.95270\n","Epoch 261/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5379 - val_accuracy: 0.9324\n","\n","Epoch 00261: val_accuracy did not improve from 0.95270\n","Epoch 262/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0211 - accuracy: 0.9911 - val_loss: 0.6840 - val_accuracy: 0.8784\n","\n","Epoch 00262: val_accuracy did not improve from 0.95270\n","Epoch 263/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6791 - val_accuracy: 0.8851\n","\n","Epoch 00263: val_accuracy did not improve from 0.95270\n","Epoch 264/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.4249 - val_accuracy: 0.9189\n","\n","Epoch 00264: val_accuracy did not improve from 0.95270\n","Epoch 265/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.8113 - val_accuracy: 0.8919\n","\n","Epoch 00265: val_accuracy did not improve from 0.95270\n","Epoch 266/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.4579 - val_accuracy: 0.9257\n","\n","Epoch 00266: val_accuracy did not improve from 0.95270\n","Epoch 267/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.5564 - val_accuracy: 0.9122\n","\n","Epoch 00267: val_accuracy did not improve from 0.95270\n","Epoch 268/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.6870 - val_accuracy: 0.8986\n","\n","Epoch 00268: val_accuracy did not improve from 0.95270\n","Epoch 269/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.4231 - val_accuracy: 0.9122\n","\n","Epoch 00269: val_accuracy did not improve from 0.95270\n","Epoch 270/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 0.4134 - val_accuracy: 0.9122\n","\n","Epoch 00270: val_accuracy did not improve from 0.95270\n","Epoch 271/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.4382 - val_accuracy: 0.9122\n","\n","Epoch 00271: val_accuracy did not improve from 0.95270\n","Epoch 272/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5081 - val_accuracy: 0.9189\n","\n","Epoch 00272: val_accuracy did not improve from 0.95270\n","Epoch 273/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5519 - val_accuracy: 0.9054\n","\n","Epoch 00273: val_accuracy did not improve from 0.95270\n","Epoch 274/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.6994 - val_accuracy: 0.8986\n","\n","Epoch 00274: val_accuracy did not improve from 0.95270\n","Epoch 275/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.4714 - val_accuracy: 0.8919\n","\n","Epoch 00275: val_accuracy did not improve from 0.95270\n","Epoch 276/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.5037 - val_accuracy: 0.9189\n","\n","Epoch 00276: val_accuracy did not improve from 0.95270\n","Epoch 277/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3821 - val_accuracy: 0.9527\n","\n","Epoch 00277: val_accuracy did not improve from 0.95270\n","Epoch 278/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.9860 - val_accuracy: 0.8581\n","\n","Epoch 00278: val_accuracy did not improve from 0.95270\n","Epoch 279/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.6730 - val_accuracy: 0.8311\n","\n","Epoch 00279: val_accuracy did not improve from 0.95270\n","Epoch 280/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.5995 - val_accuracy: 0.8919\n","\n","Epoch 00280: val_accuracy did not improve from 0.95270\n","Epoch 281/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.4964 - val_accuracy: 0.8919\n","\n","Epoch 00281: val_accuracy did not improve from 0.95270\n","Epoch 282/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.3668 - val_accuracy: 0.9324\n","\n","Epoch 00282: val_accuracy did not improve from 0.95270\n","Epoch 283/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.3350 - val_accuracy: 0.9257\n","\n","Epoch 00283: val_accuracy did not improve from 0.95270\n","Epoch 284/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5516 - val_accuracy: 0.8851\n","\n","Epoch 00284: val_accuracy did not improve from 0.95270\n","Epoch 285/500\n","238/238 [==============================] - 21s 87ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.4741 - val_accuracy: 0.9392\n","\n","Epoch 00285: val_accuracy did not improve from 0.95270\n","Epoch 286/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.4709 - val_accuracy: 0.8851\n","\n","Epoch 00286: val_accuracy did not improve from 0.95270\n","Epoch 287/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.3172 - val_accuracy: 0.9392\n","\n","Epoch 00287: val_accuracy did not improve from 0.95270\n","Epoch 288/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.6667 - val_accuracy: 0.9189\n","\n","Epoch 00288: val_accuracy did not improve from 0.95270\n","Epoch 289/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4368 - val_accuracy: 0.9122\n","\n","Epoch 00289: val_accuracy did not improve from 0.95270\n","Epoch 290/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0282 - accuracy: 0.9937 - val_loss: 0.5671 - val_accuracy: 0.9257\n","\n","Epoch 00290: val_accuracy did not improve from 0.95270\n","Epoch 291/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 0.5885 - val_accuracy: 0.8919\n","\n","Epoch 00291: val_accuracy did not improve from 0.95270\n","Epoch 292/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.5620 - val_accuracy: 0.9122\n","\n","Epoch 00292: val_accuracy did not improve from 0.95270\n","Epoch 293/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.4953 - val_accuracy: 0.9189\n","\n","Epoch 00293: val_accuracy did not improve from 0.95270\n","Epoch 294/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.4354 - val_accuracy: 0.9189\n","\n","Epoch 00294: val_accuracy did not improve from 0.95270\n","Epoch 295/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.5043 - val_accuracy: 0.8851\n","\n","Epoch 00295: val_accuracy did not improve from 0.95270\n","Epoch 296/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5672 - val_accuracy: 0.9189\n","\n","Epoch 00296: val_accuracy did not improve from 0.95270\n","Epoch 297/500\n","238/238 [==============================] - 21s 88ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4929 - val_accuracy: 0.9324\n","\n","Epoch 00297: val_accuracy did not improve from 0.95270\n","Epoch 298/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.5746 - val_accuracy: 0.9189\n","\n","Epoch 00298: val_accuracy did not improve from 0.95270\n","Epoch 299/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6453 - val_accuracy: 0.8716\n","\n","Epoch 00299: val_accuracy did not improve from 0.95270\n","Epoch 300/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.7551 - val_accuracy: 0.8851\n","\n","Epoch 00300: val_accuracy did not improve from 0.95270\n","Epoch 301/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0321 - accuracy: 0.9932 - val_loss: 0.5610 - val_accuracy: 0.8919\n","\n","Epoch 00301: val_accuracy did not improve from 0.95270\n","Epoch 302/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.7932 - val_accuracy: 0.8514\n","\n","Epoch 00302: val_accuracy did not improve from 0.95270\n","Epoch 303/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0399 - accuracy: 0.9905 - val_loss: 0.9532 - val_accuracy: 0.8243\n","\n","Epoch 00303: val_accuracy did not improve from 0.95270\n","Epoch 304/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.6202 - val_accuracy: 0.8919\n","\n","Epoch 00304: val_accuracy did not improve from 0.95270\n","Epoch 305/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5863 - val_accuracy: 0.9122\n","\n","Epoch 00305: val_accuracy did not improve from 0.95270\n","Epoch 306/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0325 - accuracy: 0.9921 - val_loss: 0.4717 - val_accuracy: 0.9054\n","\n","Epoch 00306: val_accuracy did not improve from 0.95270\n","Epoch 307/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.4883 - val_accuracy: 0.9324\n","\n","Epoch 00307: val_accuracy did not improve from 0.95270\n","Epoch 308/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.5114 - val_accuracy: 0.8919\n","\n","Epoch 00308: val_accuracy did not improve from 0.95270\n","Epoch 309/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.6278 - val_accuracy: 0.9122\n","\n","Epoch 00309: val_accuracy did not improve from 0.95270\n","Epoch 310/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.7789 - val_accuracy: 0.8716\n","\n","Epoch 00310: val_accuracy did not improve from 0.95270\n","Epoch 311/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5509 - val_accuracy: 0.8986\n","\n","Epoch 00311: val_accuracy did not improve from 0.95270\n","Epoch 312/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5230 - val_accuracy: 0.9054\n","\n","Epoch 00312: val_accuracy did not improve from 0.95270\n","Epoch 313/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.4611 - val_accuracy: 0.8919\n","\n","Epoch 00313: val_accuracy did not improve from 0.95270\n","Epoch 314/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.6105 - val_accuracy: 0.9054\n","\n","Epoch 00314: val_accuracy did not improve from 0.95270\n","Epoch 315/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 2.4999 - val_accuracy: 0.6689\n","\n","Epoch 00315: val_accuracy did not improve from 0.95270\n","Epoch 316/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.7648 - val_accuracy: 0.8986\n","\n","Epoch 00316: val_accuracy did not improve from 0.95270\n","Epoch 317/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.6926 - val_accuracy: 0.8784\n","\n","Epoch 00317: val_accuracy did not improve from 0.95270\n","Epoch 318/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.5869 - val_accuracy: 0.9189\n","\n","Epoch 00318: val_accuracy did not improve from 0.95270\n","Epoch 319/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.4209 - val_accuracy: 0.9257\n","\n","Epoch 00319: val_accuracy did not improve from 0.95270\n","Epoch 320/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.8425 - val_accuracy: 0.8851\n","\n","Epoch 00320: val_accuracy did not improve from 0.95270\n","Epoch 321/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 1.4025 - val_accuracy: 0.7500\n","\n","Epoch 00321: val_accuracy did not improve from 0.95270\n","Epoch 322/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0343 - accuracy: 0.9911 - val_loss: 0.5787 - val_accuracy: 0.9257\n","\n","Epoch 00322: val_accuracy did not improve from 0.95270\n","Epoch 323/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.7294 - val_accuracy: 0.9122\n","\n","Epoch 00323: val_accuracy did not improve from 0.95270\n","Epoch 324/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4298 - val_accuracy: 0.9324\n","\n","Epoch 00324: val_accuracy did not improve from 0.95270\n","Epoch 325/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5202 - val_accuracy: 0.8986\n","\n","Epoch 00325: val_accuracy did not improve from 0.95270\n","Epoch 326/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 0.5738 - val_accuracy: 0.8986\n","\n","Epoch 00326: val_accuracy did not improve from 0.95270\n","Epoch 327/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.4857 - val_accuracy: 0.9189\n","\n","Epoch 00327: val_accuracy did not improve from 0.95270\n","Epoch 328/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.5853 - val_accuracy: 0.8919\n","\n","Epoch 00328: val_accuracy did not improve from 0.95270\n","Epoch 329/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.5636 - val_accuracy: 0.9054\n","\n","Epoch 00329: val_accuracy did not improve from 0.95270\n","Epoch 330/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.6192 - val_accuracy: 0.8851\n","\n","Epoch 00330: val_accuracy did not improve from 0.95270\n","Epoch 331/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5028 - val_accuracy: 0.8851\n","\n","Epoch 00331: val_accuracy did not improve from 0.95270\n","Epoch 332/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6659 - val_accuracy: 0.8716\n","\n","Epoch 00332: val_accuracy did not improve from 0.95270\n","Epoch 333/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.7304 - val_accuracy: 0.8784\n","\n","Epoch 00333: val_accuracy did not improve from 0.95270\n","Epoch 334/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.7936 - val_accuracy: 0.8446\n","\n","Epoch 00334: val_accuracy did not improve from 0.95270\n","Epoch 335/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.6227 - val_accuracy: 0.8784\n","\n","Epoch 00335: val_accuracy did not improve from 0.95270\n","Epoch 336/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0300 - accuracy: 0.9926 - val_loss: 0.7796 - val_accuracy: 0.8649\n","\n","Epoch 00336: val_accuracy did not improve from 0.95270\n","Epoch 337/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.5711 - val_accuracy: 0.9122\n","\n","Epoch 00337: val_accuracy did not improve from 0.95270\n","Epoch 338/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.6098 - val_accuracy: 0.8919\n","\n","Epoch 00338: val_accuracy did not improve from 0.95270\n","Epoch 339/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.7910 - val_accuracy: 0.8649\n","\n","Epoch 00339: val_accuracy did not improve from 0.95270\n","Epoch 340/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.5825 - val_accuracy: 0.9189\n","\n","Epoch 00340: val_accuracy did not improve from 0.95270\n","Epoch 341/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6726 - val_accuracy: 0.9054\n","\n","Epoch 00341: val_accuracy did not improve from 0.95270\n","Epoch 342/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.5390 - val_accuracy: 0.9054\n","\n","Epoch 00342: val_accuracy did not improve from 0.95270\n","Epoch 343/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.5711 - val_accuracy: 0.8851\n","\n","Epoch 00343: val_accuracy did not improve from 0.95270\n","Epoch 344/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.6398 - val_accuracy: 0.8986\n","\n","Epoch 00344: val_accuracy did not improve from 0.95270\n","Epoch 345/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.7854 - val_accuracy: 0.8986\n","\n","Epoch 00345: val_accuracy did not improve from 0.95270\n","Epoch 346/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.6902 - val_accuracy: 0.8851\n","\n","Epoch 00346: val_accuracy did not improve from 0.95270\n","Epoch 347/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.7235 - val_accuracy: 0.8851\n","\n","Epoch 00347: val_accuracy did not improve from 0.95270\n","Epoch 348/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.8235 - val_accuracy: 0.8716\n","\n","Epoch 00348: val_accuracy did not improve from 0.95270\n","Epoch 349/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.4908 - val_accuracy: 0.8919\n","\n","Epoch 00349: val_accuracy did not improve from 0.95270\n","Epoch 350/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.5795 - val_accuracy: 0.9122\n","\n","Epoch 00350: val_accuracy did not improve from 0.95270\n","Epoch 351/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.5568 - val_accuracy: 0.9122\n","\n","Epoch 00351: val_accuracy did not improve from 0.95270\n","Epoch 352/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.8008 - val_accuracy: 0.8581\n","\n","Epoch 00352: val_accuracy did not improve from 0.95270\n","Epoch 353/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.7453 - val_accuracy: 0.9054\n","\n","Epoch 00353: val_accuracy did not improve from 0.95270\n","Epoch 354/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.8734 - val_accuracy: 0.8784\n","\n","Epoch 00354: val_accuracy did not improve from 0.95270\n","Epoch 355/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0300 - accuracy: 0.9942 - val_loss: 0.7576 - val_accuracy: 0.8581\n","\n","Epoch 00355: val_accuracy did not improve from 0.95270\n","Epoch 356/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0402 - accuracy: 0.9921 - val_loss: 0.5931 - val_accuracy: 0.8851\n","\n","Epoch 00356: val_accuracy did not improve from 0.95270\n","Epoch 357/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.5527 - val_accuracy: 0.8986\n","\n","Epoch 00357: val_accuracy did not improve from 0.95270\n","Epoch 358/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.6674 - val_accuracy: 0.8986\n","\n","Epoch 00358: val_accuracy did not improve from 0.95270\n","Epoch 359/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0119 - accuracy: 0.9937 - val_loss: 0.8834 - val_accuracy: 0.8716\n","\n","Epoch 00359: val_accuracy did not improve from 0.95270\n","Epoch 360/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.5353 - val_accuracy: 0.9257\n","\n","Epoch 00360: val_accuracy did not improve from 0.95270\n","Epoch 361/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.8892 - val_accuracy: 0.8784\n","\n","Epoch 00361: val_accuracy did not improve from 0.95270\n","Epoch 362/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.6996 - val_accuracy: 0.9189\n","\n","Epoch 00362: val_accuracy did not improve from 0.95270\n","Epoch 363/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.6556 - val_accuracy: 0.8919\n","\n","Epoch 00363: val_accuracy did not improve from 0.95270\n","Epoch 364/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.7213 - val_accuracy: 0.8851\n","\n","Epoch 00364: val_accuracy did not improve from 0.95270\n","Epoch 365/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.8483 - val_accuracy: 0.8986\n","\n","Epoch 00365: val_accuracy did not improve from 0.95270\n","Epoch 366/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.5664 - val_accuracy: 0.9122\n","\n","Epoch 00366: val_accuracy did not improve from 0.95270\n","Epoch 367/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.8269 - val_accuracy: 0.8716\n","\n","Epoch 00367: val_accuracy did not improve from 0.95270\n","Epoch 368/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 0.6939 - val_accuracy: 0.9122\n","\n","Epoch 00368: val_accuracy did not improve from 0.95270\n","Epoch 369/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0164 - accuracy: 0.9932 - val_loss: 1.0276 - val_accuracy: 0.8784\n","\n","Epoch 00369: val_accuracy did not improve from 0.95270\n","Epoch 370/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.6656 - val_accuracy: 0.8986\n","\n","Epoch 00370: val_accuracy did not improve from 0.95270\n","Epoch 371/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.0471 - val_accuracy: 0.8716\n","\n","Epoch 00371: val_accuracy did not improve from 0.95270\n","Epoch 372/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.6872 - val_accuracy: 0.9257\n","\n","Epoch 00372: val_accuracy did not improve from 0.95270\n","Epoch 373/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.7783 - val_accuracy: 0.8919\n","\n","Epoch 00373: val_accuracy did not improve from 0.95270\n","Epoch 374/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0444 - accuracy: 0.9868 - val_loss: 1.0604 - val_accuracy: 0.8716\n","\n","Epoch 00374: val_accuracy did not improve from 0.95270\n","Epoch 375/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.6670 - val_accuracy: 0.8784\n","\n","Epoch 00375: val_accuracy did not improve from 0.95270\n","Epoch 376/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.6051 - val_accuracy: 0.8986\n","\n","Epoch 00376: val_accuracy did not improve from 0.95270\n","Epoch 377/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.6857 - val_accuracy: 0.8986\n","\n","Epoch 00377: val_accuracy did not improve from 0.95270\n","Epoch 378/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.7138 - val_accuracy: 0.9054\n","\n","Epoch 00378: val_accuracy did not improve from 0.95270\n","Epoch 379/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5283 - val_accuracy: 0.9054\n","\n","Epoch 00379: val_accuracy did not improve from 0.95270\n","Epoch 380/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.8072 - val_accuracy: 0.8851\n","\n","Epoch 00380: val_accuracy did not improve from 0.95270\n","Epoch 381/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.5385 - val_accuracy: 0.8986\n","\n","Epoch 00381: val_accuracy did not improve from 0.95270\n","Epoch 382/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.7826 - val_accuracy: 0.8919\n","\n","Epoch 00382: val_accuracy did not improve from 0.95270\n","Epoch 383/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0081 - accuracy: 0.9958 - val_loss: 0.6400 - val_accuracy: 0.9054\n","\n","Epoch 00383: val_accuracy did not improve from 0.95270\n","Epoch 384/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4639 - val_accuracy: 0.8986\n","\n","Epoch 00384: val_accuracy did not improve from 0.95270\n","Epoch 385/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0121 - accuracy: 0.9947 - val_loss: 0.8048 - val_accuracy: 0.8986\n","\n","Epoch 00385: val_accuracy did not improve from 0.95270\n","Epoch 386/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 1.0376 - val_accuracy: 0.8378\n","\n","Epoch 00386: val_accuracy did not improve from 0.95270\n","Epoch 387/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.5622 - val_accuracy: 0.8851\n","\n","Epoch 00387: val_accuracy did not improve from 0.95270\n","Epoch 388/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0159 - accuracy: 0.9937 - val_loss: 0.5451 - val_accuracy: 0.9122\n","\n","Epoch 00388: val_accuracy did not improve from 0.95270\n","Epoch 389/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.5206 - val_accuracy: 0.9122\n","\n","Epoch 00389: val_accuracy did not improve from 0.95270\n","Epoch 390/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5578 - val_accuracy: 0.8784\n","\n","Epoch 00390: val_accuracy did not improve from 0.95270\n","Epoch 391/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.7458 - val_accuracy: 0.8649\n","\n","Epoch 00391: val_accuracy did not improve from 0.95270\n","Epoch 392/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.4170 - val_accuracy: 0.9122\n","\n","Epoch 00392: val_accuracy did not improve from 0.95270\n","Epoch 393/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6151 - val_accuracy: 0.8784\n","\n","Epoch 00393: val_accuracy did not improve from 0.95270\n","Epoch 394/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.6164 - val_accuracy: 0.8919\n","\n","Epoch 00394: val_accuracy did not improve from 0.95270\n","Epoch 395/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.5333 - val_accuracy: 0.8919\n","\n","Epoch 00395: val_accuracy did not improve from 0.95270\n","Epoch 396/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5444 - val_accuracy: 0.9122\n","\n","Epoch 00396: val_accuracy did not improve from 0.95270\n","Epoch 397/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0227 - accuracy: 0.9953 - val_loss: 0.5576 - val_accuracy: 0.9054\n","\n","Epoch 00397: val_accuracy did not improve from 0.95270\n","Epoch 398/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5923 - val_accuracy: 0.9054\n","\n","Epoch 00398: val_accuracy did not improve from 0.95270\n","Epoch 399/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.9082 - val_accuracy: 0.8581\n","\n","Epoch 00399: val_accuracy did not improve from 0.95270\n","Epoch 400/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0146 - accuracy: 0.9937 - val_loss: 0.5156 - val_accuracy: 0.8986\n","\n","Epoch 00400: val_accuracy did not improve from 0.95270\n","Epoch 401/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.7072 - val_accuracy: 0.8851\n","\n","Epoch 00401: val_accuracy did not improve from 0.95270\n","Epoch 402/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.7224 - val_accuracy: 0.8716\n","\n","Epoch 00402: val_accuracy did not improve from 0.95270\n","Epoch 403/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.7352 - val_accuracy: 0.8649\n","\n","Epoch 00403: val_accuracy did not improve from 0.95270\n","Epoch 404/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.6449 - val_accuracy: 0.8986\n","\n","Epoch 00404: val_accuracy did not improve from 0.95270\n","Epoch 405/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0256 - accuracy: 0.9947 - val_loss: 0.6071 - val_accuracy: 0.8919\n","\n","Epoch 00405: val_accuracy did not improve from 0.95270\n","Epoch 406/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.4761 - val_accuracy: 0.8986\n","\n","Epoch 00406: val_accuracy did not improve from 0.95270\n","Epoch 407/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.5332 - val_accuracy: 0.9257\n","\n","Epoch 00407: val_accuracy did not improve from 0.95270\n","Epoch 408/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 0.5904 - val_accuracy: 0.8986\n","\n","Epoch 00408: val_accuracy did not improve from 0.95270\n","Epoch 409/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 0.7592 - val_accuracy: 0.8986\n","\n","Epoch 00409: val_accuracy did not improve from 0.95270\n","Epoch 410/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.6821 - val_accuracy: 0.9054\n","\n","Epoch 00410: val_accuracy did not improve from 0.95270\n","Epoch 411/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.5237 - val_accuracy: 0.8851\n","\n","Epoch 00411: val_accuracy did not improve from 0.95270\n","Epoch 412/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 2.3662 - val_accuracy: 0.6351\n","\n","Epoch 00412: val_accuracy did not improve from 0.95270\n","Epoch 413/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.7958 - val_accuracy: 0.9054\n","\n","Epoch 00413: val_accuracy did not improve from 0.95270\n","Epoch 414/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.8269 - val_accuracy: 0.8784\n","\n","Epoch 00414: val_accuracy did not improve from 0.95270\n","Epoch 415/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7897 - val_accuracy: 0.8851\n","\n","Epoch 00415: val_accuracy did not improve from 0.95270\n","Epoch 416/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.7088 - val_accuracy: 0.8919\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.4253 - val_accuracy: 0.9189\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6604 - val_accuracy: 0.9122\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.5548 - val_accuracy: 0.9054\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6267 - val_accuracy: 0.9189\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.5096 - val_accuracy: 0.9189\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.8390 - val_accuracy: 0.8581\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.7025 - val_accuracy: 0.8919\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.5071 - val_accuracy: 0.9324\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 21s 89ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.4919 - val_accuracy: 0.8986\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.7222 - val_accuracy: 0.9054\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.5839 - val_accuracy: 0.8919\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.7536 - val_accuracy: 0.8919\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.9602 - val_accuracy: 0.8851\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.6190 - val_accuracy: 0.8986\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.5820 - val_accuracy: 0.9122\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6021 - val_accuracy: 0.9054\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6196 - val_accuracy: 0.8851\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.6553 - val_accuracy: 0.8986\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.7444 - val_accuracy: 0.9054\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.7792 - val_accuracy: 0.9054\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.6634 - val_accuracy: 0.9054\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5957 - val_accuracy: 0.8986\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.7155 - val_accuracy: 0.8851\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.6680 - val_accuracy: 0.8919\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.6523 - val_accuracy: 0.8986\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.7498 - val_accuracy: 0.8716\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5955 - val_accuracy: 0.9122\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.5821 - val_accuracy: 0.9054\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.6073 - val_accuracy: 0.9257\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6121 - val_accuracy: 0.8919\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.6762 - val_accuracy: 0.8919\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.7341 - val_accuracy: 0.8919\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.8401 - val_accuracy: 0.9054\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.9189\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.7959 - val_accuracy: 0.9189\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.6417 - val_accuracy: 0.9122\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.4927 - val_accuracy: 0.9324\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.5187 - val_accuracy: 0.9324\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.7251 - val_accuracy: 0.8649\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 0.7495 - val_accuracy: 0.8851\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.4881 - val_accuracy: 0.9324\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.5452 - val_accuracy: 0.8919\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.6178 - val_accuracy: 0.8919\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0054 - accuracy: 0.9968 - val_loss: 0.5674 - val_accuracy: 0.9324\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4415 - val_accuracy: 0.9459\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5648 - val_accuracy: 0.9257\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.6556 - val_accuracy: 0.9122\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0064 - accuracy: 0.9968 - val_loss: 0.6070 - val_accuracy: 0.8851\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0184 - accuracy: 0.9926 - val_loss: 0.5465 - val_accuracy: 0.9324\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.8824 - val_accuracy: 0.8851\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.6398 - val_accuracy: 0.9122\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.8113 - val_accuracy: 0.9054\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.8161 - val_accuracy: 0.8716\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.5219 - val_accuracy: 0.8986\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.7355 - val_accuracy: 0.9122\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.5658 - val_accuracy: 0.9189\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.7205 - val_accuracy: 0.8784\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.6067 - val_accuracy: 0.9189\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.6121 - val_accuracy: 0.9324\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5666 - val_accuracy: 0.9122\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.6105 - val_accuracy: 0.9122\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.5161 - val_accuracy: 0.9054\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.9541 - val_accuracy: 0.8851\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.8361 - val_accuracy: 0.8851\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.8660 - val_accuracy: 0.8784\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 1.0088 - val_accuracy: 0.9054\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.7791 - val_accuracy: 0.9054\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.6709 - val_accuracy: 0.8986\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.8305 - val_accuracy: 0.8986\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6567 - val_accuracy: 0.8919\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6052 - val_accuracy: 0.9257\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.6957 - val_accuracy: 0.8716\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.7709 - val_accuracy: 0.8851\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 22s 90ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.9122\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.4841 - val_accuracy: 0.9054\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.6356 - val_accuracy: 0.8851\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.7834 - val_accuracy: 0.8919\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.6684 - val_accuracy: 0.9054\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.6454 - val_accuracy: 0.9054\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 21s 90ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.7148 - val_accuracy: 0.8919\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 22s 92ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.6099 - val_accuracy: 0.9054\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.7185 - val_accuracy: 0.9054\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 1.3610 - val_accuracy: 0.8041\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 22s 91ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.5226 - val_accuracy: 0.9189\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7a5a141490>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632828509463,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"8dbb95bc-ec4f-4db2-f698-5bc73969d6b9"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632828520062,"user_tz":-540,"elapsed":10608,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1632828520849,"user_tz":-540,"elapsed":791,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632828521276,"user_tz":-540,"elapsed":430,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"046862ba-03ae-4963-b9dc-1b9f94e5e31f"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632828543227,"user_tz":-540,"elapsed":21957,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"3d327fc6-3566-4a7c-d2b7-0c974a0c9af1"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1632828543230,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1632828543231,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1632828544389,"user_tz":-540,"elapsed":1172,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632828544392,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632828555821,"user_tz":-540,"elapsed":11433,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1632828555826,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632828555827,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"54306050-e957-49a4-f187-d6835798ec98"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_58841779-b70d-432d-877f-d29ff33c16ea\", \"EfficientNetB0_4.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632828558714,"user_tz":-540,"elapsed":2895,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"706fbfdf-6a0a-4c1f-a62b-d0e47f7ebe35"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632828559642,"user_tz":-540,"elapsed":932,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"03bc5772-5dd9-48ab-f067-2d99519edfba"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}