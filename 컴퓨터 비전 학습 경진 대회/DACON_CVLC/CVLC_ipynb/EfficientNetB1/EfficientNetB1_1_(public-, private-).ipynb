{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNetB1_1_(public-, private-).ipynb","provenance":[{"file_id":"1dMHbUndZGr2BzmZeH2YxAL0QbjsqA8qm","timestamp":1632826763787},{"file_id":"12T8xAJ67HUnP5ZUGTt9syM3xjvOavh6p","timestamp":1632816088595},{"file_id":"1Y2c9MXmZLNEW6WU-oJXgwIvzQ77fxUaR","timestamp":1632815969024},{"file_id":"1Wo8M5eecf-5P8z0ZLjawoNhomWEy4F4z","timestamp":1632815952458},{"file_id":"1Wf0c2C_V_TV76M3yvaCqj4WRhGsfhSR_","timestamp":1632815928461},{"file_id":"1UoAi_OUp5FlBi0pHsVhKqBW3OLHhWd2j","timestamp":1632815272493},{"file_id":"1qZU39IunWaZOPCVpSa0V-8693Jh2Jz0c","timestamp":1632815233099},{"file_id":"1voj3Bcu0zAay7e_kl7qK5f78K9HMMKtM","timestamp":1632806561665},{"file_id":"1zElVRGsS1kg9WNy_6KUvQvaI5xYSdnlD","timestamp":1632806534245},{"file_id":"1OIZKCtwYST5ROVoAH5jE6OyziVLs5YVe","timestamp":1632775577125},{"file_id":"1M8OJEV_AT9MOCy7JGAaVl1j_VfABfzuE","timestamp":1632775493726},{"file_id":"1tLm7xKEM0NUAtTz8MetJXTPqs1Vr30rT","timestamp":1632775476672},{"file_id":"1cQ9_pnDLKsxM2cvx0IWbLgjkO3Cepyu-","timestamp":1632775461739},{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632844069420,"user_tz":-540,"elapsed":648,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"70aa4716-9aa6-42a5-9679-be91aec6b8fc"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 28 15:47:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632844085812,"user_tz":-540,"elapsed":16404,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"f042f191-79e5-4a01-bdb9-095acb03316b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632844090176,"user_tz":-540,"elapsed":4369,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632844091230,"user_tz":-540,"elapsed":1059,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632844094369,"user_tz":-540,"elapsed":3142,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632844114049,"user_tz":-540,"elapsed":19693,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632844114051,"user_tz":-540,"elapsed":22,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["nunbering = '1'\n","model_save = 'EfficientNetB' + nunbering + '_1'\n","Target_model = 'EfficientNetB' + nunbering + '_model'\n","Target_predict = 'EfficientNetB' + nunbering + '_predict'\n","Target_acc = 'EfficientNetB' + nunbering + '_acc'\n","Target_val = 'EfficientNetB' + nunbering + '_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632844121456,"user_tz":-540,"elapsed":7422,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.EfficientNetB1(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632844121778,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632844122186,"user_tz":-540,"elapsed":418,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"d2c1573c-6639-4a8d-b9b1-08bf857fcbc7"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632844122187,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861693048,"user_tz":-540,"elapsed":17570871,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"842582e7-29ce-47fb-c1e6-f262e147fca0"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 66s 151ms/step - loss: 3.2450 - accuracy: 0.1195 - val_loss: 2.6668 - val_accuracy: 0.0946\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 34s 141ms/step - loss: 2.2355 - accuracy: 0.2232 - val_loss: 2.7435 - val_accuracy: 0.1014\n","\n","Epoch 00002: val_accuracy improved from 0.09459 to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 3/500\n","238/238 [==============================] - 34s 142ms/step - loss: 1.8771 - accuracy: 0.3468 - val_loss: 3.3996 - val_accuracy: 0.0608\n","\n","Epoch 00003: val_accuracy did not improve from 0.10135\n","Epoch 4/500\n","238/238 [==============================] - 33s 139ms/step - loss: 1.4794 - accuracy: 0.5016 - val_loss: 1.3187 - val_accuracy: 0.5811\n","\n","Epoch 00004: val_accuracy improved from 0.10135 to 0.58108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 5/500\n","238/238 [==============================] - 34s 141ms/step - loss: 1.2333 - accuracy: 0.5832 - val_loss: 1.4180 - val_accuracy: 0.5541\n","\n","Epoch 00005: val_accuracy did not improve from 0.58108\n","Epoch 6/500\n","238/238 [==============================] - 33s 140ms/step - loss: 1.0141 - accuracy: 0.6742 - val_loss: 1.0633 - val_accuracy: 0.6689\n","\n","Epoch 00006: val_accuracy improved from 0.58108 to 0.66892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 7/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.8656 - accuracy: 0.7342 - val_loss: 0.7891 - val_accuracy: 0.7365\n","\n","Epoch 00007: val_accuracy improved from 0.66892 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 8/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.7654 - accuracy: 0.7474 - val_loss: 1.9980 - val_accuracy: 0.5405\n","\n","Epoch 00008: val_accuracy did not improve from 0.73649\n","Epoch 9/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.7046 - accuracy: 0.7763 - val_loss: 1.2731 - val_accuracy: 0.6959\n","\n","Epoch 00009: val_accuracy did not improve from 0.73649\n","Epoch 10/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.6582 - accuracy: 0.7847 - val_loss: 2.0764 - val_accuracy: 0.4730\n","\n","Epoch 00010: val_accuracy did not improve from 0.73649\n","Epoch 11/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.6319 - accuracy: 0.7932 - val_loss: 1.5674 - val_accuracy: 0.5405\n","\n","Epoch 00011: val_accuracy did not improve from 0.73649\n","Epoch 12/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.5966 - accuracy: 0.8184 - val_loss: 0.5194 - val_accuracy: 0.8243\n","\n","Epoch 00012: val_accuracy improved from 0.73649 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 13/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.5095 - accuracy: 0.8353 - val_loss: 0.4621 - val_accuracy: 0.8243\n","\n","Epoch 00013: val_accuracy did not improve from 0.82432\n","Epoch 14/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.4738 - accuracy: 0.8495 - val_loss: 1.1806 - val_accuracy: 0.6757\n","\n","Epoch 00014: val_accuracy did not improve from 0.82432\n","Epoch 15/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.4719 - accuracy: 0.8511 - val_loss: 0.9659 - val_accuracy: 0.6959\n","\n","Epoch 00015: val_accuracy did not improve from 0.82432\n","Epoch 16/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.4581 - accuracy: 0.8595 - val_loss: 1.1422 - val_accuracy: 0.6757\n","\n","Epoch 00016: val_accuracy did not improve from 0.82432\n","Epoch 17/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.4236 - accuracy: 0.8547 - val_loss: 0.8521 - val_accuracy: 0.8041\n","\n","Epoch 00017: val_accuracy did not improve from 0.82432\n","Epoch 18/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.4095 - accuracy: 0.8611 - val_loss: 0.3905 - val_accuracy: 0.8716\n","\n","Epoch 00018: val_accuracy improved from 0.82432 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 19/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.3792 - accuracy: 0.8795 - val_loss: 0.4511 - val_accuracy: 0.8581\n","\n","Epoch 00019: val_accuracy did not improve from 0.87162\n","Epoch 20/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.3789 - accuracy: 0.8742 - val_loss: 0.7585 - val_accuracy: 0.7905\n","\n","Epoch 00020: val_accuracy did not improve from 0.87162\n","Epoch 21/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.4010 - accuracy: 0.8689 - val_loss: 0.5361 - val_accuracy: 0.8378\n","\n","Epoch 00021: val_accuracy did not improve from 0.87162\n","Epoch 22/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.3305 - accuracy: 0.8863 - val_loss: 0.5990 - val_accuracy: 0.8243\n","\n","Epoch 00022: val_accuracy did not improve from 0.87162\n","Epoch 23/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.3447 - accuracy: 0.8847 - val_loss: 0.5270 - val_accuracy: 0.8243\n","\n","Epoch 00023: val_accuracy did not improve from 0.87162\n","Epoch 24/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.3519 - accuracy: 0.8853 - val_loss: 0.5777 - val_accuracy: 0.8311\n","\n","Epoch 00024: val_accuracy did not improve from 0.87162\n","Epoch 25/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.3070 - accuracy: 0.9011 - val_loss: 0.4324 - val_accuracy: 0.8378\n","\n","Epoch 00025: val_accuracy did not improve from 0.87162\n","Epoch 26/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.2812 - accuracy: 0.9126 - val_loss: 0.8083 - val_accuracy: 0.8243\n","\n","Epoch 00026: val_accuracy did not improve from 0.87162\n","Epoch 27/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2712 - accuracy: 0.9174 - val_loss: 2.5186 - val_accuracy: 0.4527\n","\n","Epoch 00027: val_accuracy did not improve from 0.87162\n","Epoch 28/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.3161 - accuracy: 0.8921 - val_loss: 0.7383 - val_accuracy: 0.7905\n","\n","Epoch 00028: val_accuracy did not improve from 0.87162\n","Epoch 29/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2917 - accuracy: 0.8968 - val_loss: 0.6968 - val_accuracy: 0.7635\n","\n","Epoch 00029: val_accuracy did not improve from 0.87162\n","Epoch 30/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.2208 - accuracy: 0.9316 - val_loss: 1.0440 - val_accuracy: 0.7838\n","\n","Epoch 00030: val_accuracy did not improve from 0.87162\n","Epoch 31/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2669 - accuracy: 0.9142 - val_loss: 0.6128 - val_accuracy: 0.8514\n","\n","Epoch 00031: val_accuracy did not improve from 0.87162\n","Epoch 32/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2745 - accuracy: 0.9100 - val_loss: 1.2886 - val_accuracy: 0.6419\n","\n","Epoch 00032: val_accuracy did not improve from 0.87162\n","Epoch 33/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.2277 - accuracy: 0.9300 - val_loss: 0.4540 - val_accuracy: 0.8514\n","\n","Epoch 00033: val_accuracy did not improve from 0.87162\n","Epoch 34/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1998 - accuracy: 0.9363 - val_loss: 0.5728 - val_accuracy: 0.8311\n","\n","Epoch 00034: val_accuracy did not improve from 0.87162\n","Epoch 35/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.2659 - accuracy: 0.9179 - val_loss: 1.5026 - val_accuracy: 0.6284\n","\n","Epoch 00035: val_accuracy did not improve from 0.87162\n","Epoch 36/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1916 - accuracy: 0.9389 - val_loss: 0.4112 - val_accuracy: 0.8919\n","\n","Epoch 00036: val_accuracy improved from 0.87162 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 37/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.2119 - accuracy: 0.9389 - val_loss: 0.4517 - val_accuracy: 0.8784\n","\n","Epoch 00037: val_accuracy did not improve from 0.89189\n","Epoch 38/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1823 - accuracy: 0.9395 - val_loss: 0.4755 - val_accuracy: 0.8784\n","\n","Epoch 00038: val_accuracy did not improve from 0.89189\n","Epoch 39/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2011 - accuracy: 0.9321 - val_loss: 0.3881 - val_accuracy: 0.9054\n","\n","Epoch 00039: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 40/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.2154 - accuracy: 0.9268 - val_loss: 0.4469 - val_accuracy: 0.8446\n","\n","Epoch 00040: val_accuracy did not improve from 0.90541\n","Epoch 41/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.2167 - accuracy: 0.9289 - val_loss: 0.6751 - val_accuracy: 0.8311\n","\n","Epoch 00041: val_accuracy did not improve from 0.90541\n","Epoch 42/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1938 - accuracy: 0.9421 - val_loss: 0.6000 - val_accuracy: 0.8243\n","\n","Epoch 00042: val_accuracy did not improve from 0.90541\n","Epoch 43/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1580 - accuracy: 0.9516 - val_loss: 0.3025 - val_accuracy: 0.9122\n","\n","Epoch 00043: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 44/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.1487 - accuracy: 0.9521 - val_loss: 0.5358 - val_accuracy: 0.8378\n","\n","Epoch 00044: val_accuracy did not improve from 0.91216\n","Epoch 45/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1498 - accuracy: 0.9553 - val_loss: 0.5497 - val_accuracy: 0.8919\n","\n","Epoch 00045: val_accuracy did not improve from 0.91216\n","Epoch 46/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1862 - accuracy: 0.9432 - val_loss: 0.5075 - val_accuracy: 0.8446\n","\n","Epoch 00046: val_accuracy did not improve from 0.91216\n","Epoch 47/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1633 - accuracy: 0.9447 - val_loss: 0.8947 - val_accuracy: 0.7973\n","\n","Epoch 00047: val_accuracy did not improve from 0.91216\n","Epoch 48/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1443 - accuracy: 0.9547 - val_loss: 0.3012 - val_accuracy: 0.8716\n","\n","Epoch 00048: val_accuracy did not improve from 0.91216\n","Epoch 49/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1272 - accuracy: 0.9605 - val_loss: 0.6158 - val_accuracy: 0.8649\n","\n","Epoch 00049: val_accuracy did not improve from 0.91216\n","Epoch 50/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1319 - accuracy: 0.9495 - val_loss: 1.1045 - val_accuracy: 0.7500\n","\n","Epoch 00050: val_accuracy did not improve from 0.91216\n","Epoch 51/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1572 - accuracy: 0.9537 - val_loss: 1.1366 - val_accuracy: 0.7230\n","\n","Epoch 00051: val_accuracy did not improve from 0.91216\n","Epoch 52/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1259 - accuracy: 0.9579 - val_loss: 0.4114 - val_accuracy: 0.8851\n","\n","Epoch 00052: val_accuracy did not improve from 0.91216\n","Epoch 53/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1343 - accuracy: 0.9563 - val_loss: 0.4876 - val_accuracy: 0.8649\n","\n","Epoch 00053: val_accuracy did not improve from 0.91216\n","Epoch 54/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1326 - accuracy: 0.9542 - val_loss: 0.6786 - val_accuracy: 0.8378\n","\n","Epoch 00054: val_accuracy did not improve from 0.91216\n","Epoch 55/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1040 - accuracy: 0.9647 - val_loss: 0.3273 - val_accuracy: 0.9257\n","\n","Epoch 00055: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 56/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.1183 - accuracy: 0.9600 - val_loss: 0.6021 - val_accuracy: 0.8784\n","\n","Epoch 00056: val_accuracy did not improve from 0.92568\n","Epoch 57/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1079 - accuracy: 0.9653 - val_loss: 0.5830 - val_accuracy: 0.8514\n","\n","Epoch 00057: val_accuracy did not improve from 0.92568\n","Epoch 58/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1625 - accuracy: 0.9484 - val_loss: 0.5408 - val_accuracy: 0.8919\n","\n","Epoch 00058: val_accuracy did not improve from 0.92568\n","Epoch 59/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1193 - accuracy: 0.9679 - val_loss: 0.5060 - val_accuracy: 0.8986\n","\n","Epoch 00059: val_accuracy did not improve from 0.92568\n","Epoch 60/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0882 - accuracy: 0.9726 - val_loss: 0.5980 - val_accuracy: 0.8649\n","\n","Epoch 00060: val_accuracy did not improve from 0.92568\n","Epoch 61/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1293 - accuracy: 0.9611 - val_loss: 1.4226 - val_accuracy: 0.7230\n","\n","Epoch 00061: val_accuracy did not improve from 0.92568\n","Epoch 62/500\n","238/238 [==============================] - 33s 138ms/step - loss: 0.1299 - accuracy: 0.9621 - val_loss: 0.3144 - val_accuracy: 0.9324\n","\n","Epoch 00062: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 63/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1007 - accuracy: 0.9658 - val_loss: 0.5794 - val_accuracy: 0.8378\n","\n","Epoch 00063: val_accuracy did not improve from 0.93243\n","Epoch 64/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1623 - accuracy: 0.9553 - val_loss: 0.4193 - val_accuracy: 0.8851\n","\n","Epoch 00064: val_accuracy did not improve from 0.93243\n","Epoch 65/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1048 - accuracy: 0.9705 - val_loss: 0.4867 - val_accuracy: 0.8986\n","\n","Epoch 00065: val_accuracy did not improve from 0.93243\n","Epoch 66/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1094 - accuracy: 0.9632 - val_loss: 0.4379 - val_accuracy: 0.8716\n","\n","Epoch 00066: val_accuracy did not improve from 0.93243\n","Epoch 67/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0806 - accuracy: 0.9753 - val_loss: 0.6005 - val_accuracy: 0.8446\n","\n","Epoch 00067: val_accuracy did not improve from 0.93243\n","Epoch 68/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.3644 - val_accuracy: 0.9189\n","\n","Epoch 00068: val_accuracy did not improve from 0.93243\n","Epoch 69/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0771 - accuracy: 0.9742 - val_loss: 0.3853 - val_accuracy: 0.9122\n","\n","Epoch 00069: val_accuracy did not improve from 0.93243\n","Epoch 70/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 0.3939 - val_accuracy: 0.9122\n","\n","Epoch 00070: val_accuracy did not improve from 0.93243\n","Epoch 71/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0913 - accuracy: 0.9679 - val_loss: 0.5678 - val_accuracy: 0.8986\n","\n","Epoch 00071: val_accuracy did not improve from 0.93243\n","Epoch 72/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.4742 - val_accuracy: 0.8784\n","\n","Epoch 00072: val_accuracy did not improve from 0.93243\n","Epoch 73/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1186 - accuracy: 0.9611 - val_loss: 0.2923 - val_accuracy: 0.9257\n","\n","Epoch 00073: val_accuracy did not improve from 0.93243\n","Epoch 74/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0989 - accuracy: 0.9721 - val_loss: 0.4262 - val_accuracy: 0.8784\n","\n","Epoch 00074: val_accuracy did not improve from 0.93243\n","Epoch 75/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0920 - accuracy: 0.9726 - val_loss: 0.4606 - val_accuracy: 0.8851\n","\n","Epoch 00075: val_accuracy did not improve from 0.93243\n","Epoch 76/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0882 - accuracy: 0.9747 - val_loss: 0.6253 - val_accuracy: 0.8581\n","\n","Epoch 00076: val_accuracy did not improve from 0.93243\n","Epoch 77/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.1060 - accuracy: 0.9695 - val_loss: 0.3308 - val_accuracy: 0.9122\n","\n","Epoch 00077: val_accuracy did not improve from 0.93243\n","Epoch 78/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0882 - accuracy: 0.9753 - val_loss: 0.4807 - val_accuracy: 0.8784\n","\n","Epoch 00078: val_accuracy did not improve from 0.93243\n","Epoch 79/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 0.4372 - val_accuracy: 0.8919\n","\n","Epoch 00079: val_accuracy did not improve from 0.93243\n","Epoch 80/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.1042 - accuracy: 0.9658 - val_loss: 0.4817 - val_accuracy: 0.8919\n","\n","Epoch 00080: val_accuracy did not improve from 0.93243\n","Epoch 81/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0881 - accuracy: 0.9689 - val_loss: 0.4569 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.93243\n","Epoch 82/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0697 - accuracy: 0.9795 - val_loss: 0.4042 - val_accuracy: 0.9054\n","\n","Epoch 00082: val_accuracy did not improve from 0.93243\n","Epoch 83/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0719 - accuracy: 0.9758 - val_loss: 0.5709 - val_accuracy: 0.8716\n","\n","Epoch 00083: val_accuracy did not improve from 0.93243\n","Epoch 84/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0493 - accuracy: 0.9805 - val_loss: 0.6387 - val_accuracy: 0.8851\n","\n","Epoch 00084: val_accuracy did not improve from 0.93243\n","Epoch 85/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.4223 - val_accuracy: 0.9189\n","\n","Epoch 00085: val_accuracy did not improve from 0.93243\n","Epoch 86/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0860 - accuracy: 0.9747 - val_loss: 0.6260 - val_accuracy: 0.8716\n","\n","Epoch 00086: val_accuracy did not improve from 0.93243\n","Epoch 87/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0909 - accuracy: 0.9705 - val_loss: 0.4791 - val_accuracy: 0.8784\n","\n","Epoch 00087: val_accuracy did not improve from 0.93243\n","Epoch 88/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0726 - accuracy: 0.9779 - val_loss: 0.3460 - val_accuracy: 0.9324\n","\n","Epoch 00088: val_accuracy did not improve from 0.93243\n","Epoch 89/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 0.6554 - val_accuracy: 0.8649\n","\n","Epoch 00089: val_accuracy did not improve from 0.93243\n","Epoch 90/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0880 - accuracy: 0.9700 - val_loss: 1.2997 - val_accuracy: 0.7770\n","\n","Epoch 00090: val_accuracy did not improve from 0.93243\n","Epoch 91/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0724 - accuracy: 0.9747 - val_loss: 0.4485 - val_accuracy: 0.9054\n","\n","Epoch 00091: val_accuracy did not improve from 0.93243\n","Epoch 92/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.5622 - val_accuracy: 0.8919\n","\n","Epoch 00092: val_accuracy did not improve from 0.93243\n","Epoch 93/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0975 - accuracy: 0.9721 - val_loss: 0.5095 - val_accuracy: 0.8784\n","\n","Epoch 00093: val_accuracy did not improve from 0.93243\n","Epoch 94/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.4714 - val_accuracy: 0.8986\n","\n","Epoch 00094: val_accuracy did not improve from 0.93243\n","Epoch 95/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 4.1474 - val_accuracy: 0.4054\n","\n","Epoch 00095: val_accuracy did not improve from 0.93243\n","Epoch 96/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0857 - accuracy: 0.9700 - val_loss: 0.3178 - val_accuracy: 0.9054\n","\n","Epoch 00096: val_accuracy did not improve from 0.93243\n","Epoch 97/500\n","238/238 [==============================] - 33s 139ms/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 0.5005 - val_accuracy: 0.9189\n","\n","Epoch 00097: val_accuracy did not improve from 0.93243\n","Epoch 98/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.2844 - val_accuracy: 0.9054\n","\n","Epoch 00098: val_accuracy did not improve from 0.93243\n","Epoch 99/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0578 - accuracy: 0.9826 - val_loss: 0.4307 - val_accuracy: 0.8851\n","\n","Epoch 00099: val_accuracy did not improve from 0.93243\n","Epoch 100/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 0.4814 - val_accuracy: 0.8851\n","\n","Epoch 00100: val_accuracy did not improve from 0.93243\n","Epoch 101/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0652 - accuracy: 0.9795 - val_loss: 0.5885 - val_accuracy: 0.8919\n","\n","Epoch 00101: val_accuracy did not improve from 0.93243\n","Epoch 102/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 0.6979 - val_accuracy: 0.9189\n","\n","Epoch 00102: val_accuracy did not improve from 0.93243\n","Epoch 103/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.6640 - val_accuracy: 0.8919\n","\n","Epoch 00103: val_accuracy did not improve from 0.93243\n","Epoch 104/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.6794 - val_accuracy: 0.8649\n","\n","Epoch 00104: val_accuracy did not improve from 0.93243\n","Epoch 105/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.4104 - val_accuracy: 0.9054\n","\n","Epoch 00105: val_accuracy did not improve from 0.93243\n","Epoch 106/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.1031 - accuracy: 0.9758 - val_loss: 0.4668 - val_accuracy: 0.8851\n","\n","Epoch 00106: val_accuracy did not improve from 0.93243\n","Epoch 107/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0423 - accuracy: 0.9889 - val_loss: 0.3431 - val_accuracy: 0.9189\n","\n","Epoch 00107: val_accuracy did not improve from 0.93243\n","Epoch 108/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.5010 - val_accuracy: 0.9054\n","\n","Epoch 00108: val_accuracy did not improve from 0.93243\n","Epoch 109/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.5535 - val_accuracy: 0.9054\n","\n","Epoch 00109: val_accuracy did not improve from 0.93243\n","Epoch 110/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0608 - accuracy: 0.9832 - val_loss: 0.9241 - val_accuracy: 0.8176\n","\n","Epoch 00110: val_accuracy did not improve from 0.93243\n","Epoch 111/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.5726 - val_accuracy: 0.8784\n","\n","Epoch 00111: val_accuracy did not improve from 0.93243\n","Epoch 112/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0774 - accuracy: 0.9732 - val_loss: 0.6195 - val_accuracy: 0.9054\n","\n","Epoch 00112: val_accuracy did not improve from 0.93243\n","Epoch 113/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0581 - accuracy: 0.9805 - val_loss: 0.6871 - val_accuracy: 0.8986\n","\n","Epoch 00113: val_accuracy did not improve from 0.93243\n","Epoch 114/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0578 - accuracy: 0.9789 - val_loss: 0.6894 - val_accuracy: 0.8784\n","\n","Epoch 00114: val_accuracy did not improve from 0.93243\n","Epoch 115/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0932 - accuracy: 0.9711 - val_loss: 0.4682 - val_accuracy: 0.8986\n","\n","Epoch 00115: val_accuracy did not improve from 0.93243\n","Epoch 116/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.3264 - val_accuracy: 0.8986\n","\n","Epoch 00116: val_accuracy did not improve from 0.93243\n","Epoch 117/500\n","238/238 [==============================] - 33s 140ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.3366 - val_accuracy: 0.9189\n","\n","Epoch 00117: val_accuracy did not improve from 0.93243\n","Epoch 118/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.3764 - val_accuracy: 0.9324\n","\n","Epoch 00118: val_accuracy did not improve from 0.93243\n","Epoch 119/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.4269 - val_accuracy: 0.9122\n","\n","Epoch 00119: val_accuracy did not improve from 0.93243\n","Epoch 120/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.7477 - val_accuracy: 0.8649\n","\n","Epoch 00120: val_accuracy did not improve from 0.93243\n","Epoch 121/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: 0.3981 - val_accuracy: 0.8851\n","\n","Epoch 00121: val_accuracy did not improve from 0.93243\n","Epoch 122/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.4175 - val_accuracy: 0.9122\n","\n","Epoch 00122: val_accuracy did not improve from 0.93243\n","Epoch 123/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.4024 - val_accuracy: 0.9122\n","\n","Epoch 00123: val_accuracy did not improve from 0.93243\n","Epoch 124/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 0.3646 - val_accuracy: 0.9122\n","\n","Epoch 00124: val_accuracy did not improve from 0.93243\n","Epoch 125/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0511 - accuracy: 0.9858 - val_loss: 0.5168 - val_accuracy: 0.8919\n","\n","Epoch 00125: val_accuracy did not improve from 0.93243\n","Epoch 126/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.6494 - val_accuracy: 0.8851\n","\n","Epoch 00126: val_accuracy did not improve from 0.93243\n","Epoch 127/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0412 - accuracy: 0.9863 - val_loss: 0.5364 - val_accuracy: 0.8851\n","\n","Epoch 00127: val_accuracy did not improve from 0.93243\n","Epoch 128/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.4602 - val_accuracy: 0.9189\n","\n","Epoch 00128: val_accuracy did not improve from 0.93243\n","Epoch 129/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0404 - accuracy: 0.9826 - val_loss: 0.3939 - val_accuracy: 0.9054\n","\n","Epoch 00129: val_accuracy did not improve from 0.93243\n","Epoch 130/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.5730 - val_accuracy: 0.9054\n","\n","Epoch 00130: val_accuracy did not improve from 0.93243\n","Epoch 131/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0474 - accuracy: 0.9884 - val_loss: 0.4415 - val_accuracy: 0.8851\n","\n","Epoch 00131: val_accuracy did not improve from 0.93243\n","Epoch 132/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.4734 - val_accuracy: 0.8986\n","\n","Epoch 00132: val_accuracy did not improve from 0.93243\n","Epoch 133/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.4916 - val_accuracy: 0.9054\n","\n","Epoch 00133: val_accuracy did not improve from 0.93243\n","Epoch 134/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.4562 - val_accuracy: 0.9189\n","\n","Epoch 00134: val_accuracy did not improve from 0.93243\n","Epoch 135/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.5119 - val_accuracy: 0.8986\n","\n","Epoch 00135: val_accuracy did not improve from 0.93243\n","Epoch 136/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0588 - accuracy: 0.9837 - val_loss: 0.6878 - val_accuracy: 0.8716\n","\n","Epoch 00136: val_accuracy did not improve from 0.93243\n","Epoch 137/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.4505 - val_accuracy: 0.9054\n","\n","Epoch 00137: val_accuracy did not improve from 0.93243\n","Epoch 138/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.6056 - val_accuracy: 0.9122\n","\n","Epoch 00138: val_accuracy did not improve from 0.93243\n","Epoch 139/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0383 - accuracy: 0.9853 - val_loss: 0.5859 - val_accuracy: 0.8851\n","\n","Epoch 00139: val_accuracy did not improve from 0.93243\n","Epoch 140/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.3710 - val_accuracy: 0.9324\n","\n","Epoch 00140: val_accuracy did not improve from 0.93243\n","Epoch 141/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 1.1281 - val_accuracy: 0.7905\n","\n","Epoch 00141: val_accuracy did not improve from 0.93243\n","Epoch 142/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.4487 - val_accuracy: 0.9189\n","\n","Epoch 00142: val_accuracy did not improve from 0.93243\n","Epoch 143/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.5887 - val_accuracy: 0.9054\n","\n","Epoch 00143: val_accuracy did not improve from 0.93243\n","Epoch 144/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.6877 - val_accuracy: 0.8716\n","\n","Epoch 00144: val_accuracy did not improve from 0.93243\n","Epoch 145/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.6406 - val_accuracy: 0.8446\n","\n","Epoch 00145: val_accuracy did not improve from 0.93243\n","Epoch 146/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.5188 - val_accuracy: 0.9054\n","\n","Epoch 00146: val_accuracy did not improve from 0.93243\n","Epoch 147/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.3696 - val_accuracy: 0.8986\n","\n","Epoch 00147: val_accuracy did not improve from 0.93243\n","Epoch 148/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0752 - accuracy: 0.9800 - val_loss: 1.1197 - val_accuracy: 0.8108\n","\n","Epoch 00148: val_accuracy did not improve from 0.93243\n","Epoch 149/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.6418 - val_accuracy: 0.8784\n","\n","Epoch 00149: val_accuracy did not improve from 0.93243\n","Epoch 150/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.4317 - val_accuracy: 0.9189\n","\n","Epoch 00150: val_accuracy did not improve from 0.93243\n","Epoch 151/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.5261 - val_accuracy: 0.8851\n","\n","Epoch 00151: val_accuracy did not improve from 0.93243\n","Epoch 152/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.4787 - val_accuracy: 0.9189\n","\n","Epoch 00152: val_accuracy did not improve from 0.93243\n","Epoch 153/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.4155 - val_accuracy: 0.9122\n","\n","Epoch 00153: val_accuracy did not improve from 0.93243\n","Epoch 154/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.9181 - val_accuracy: 0.8514\n","\n","Epoch 00154: val_accuracy did not improve from 0.93243\n","Epoch 155/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0253 - accuracy: 0.9889 - val_loss: 0.7527 - val_accuracy: 0.8851\n","\n","Epoch 00155: val_accuracy did not improve from 0.93243\n","Epoch 156/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.4574 - val_accuracy: 0.9257\n","\n","Epoch 00156: val_accuracy did not improve from 0.93243\n","Epoch 157/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.7607 - val_accuracy: 0.8784\n","\n","Epoch 00157: val_accuracy did not improve from 0.93243\n","Epoch 158/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.5515 - val_accuracy: 0.8851\n","\n","Epoch 00158: val_accuracy did not improve from 0.93243\n","Epoch 159/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.8427 - val_accuracy: 0.8716\n","\n","Epoch 00159: val_accuracy did not improve from 0.93243\n","Epoch 160/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.5681 - val_accuracy: 0.8784\n","\n","Epoch 00160: val_accuracy did not improve from 0.93243\n","Epoch 161/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.7546 - val_accuracy: 0.8851\n","\n","Epoch 00161: val_accuracy did not improve from 0.93243\n","Epoch 162/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0558 - accuracy: 0.9847 - val_loss: 0.5157 - val_accuracy: 0.8851\n","\n","Epoch 00162: val_accuracy did not improve from 0.93243\n","Epoch 163/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.4012 - val_accuracy: 0.9257\n","\n","Epoch 00163: val_accuracy did not improve from 0.93243\n","Epoch 164/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 1.6985 - val_accuracy: 0.7365\n","\n","Epoch 00164: val_accuracy did not improve from 0.93243\n","Epoch 165/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.4515 - val_accuracy: 0.9054\n","\n","Epoch 00165: val_accuracy did not improve from 0.93243\n","Epoch 166/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.6813 - val_accuracy: 0.8649\n","\n","Epoch 00166: val_accuracy did not improve from 0.93243\n","Epoch 167/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.5924 - val_accuracy: 0.8851\n","\n","Epoch 00167: val_accuracy did not improve from 0.93243\n","Epoch 168/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.6208 - val_accuracy: 0.8716\n","\n","Epoch 00168: val_accuracy did not improve from 0.93243\n","Epoch 169/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.6729 - val_accuracy: 0.8784\n","\n","Epoch 00169: val_accuracy did not improve from 0.93243\n","Epoch 170/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.4655 - val_accuracy: 0.9054\n","\n","Epoch 00170: val_accuracy did not improve from 0.93243\n","Epoch 171/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.5211 - val_accuracy: 0.8919\n","\n","Epoch 00171: val_accuracy did not improve from 0.93243\n","Epoch 172/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0299 - accuracy: 0.9889 - val_loss: 0.5526 - val_accuracy: 0.8919\n","\n","Epoch 00172: val_accuracy did not improve from 0.93243\n","Epoch 173/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.6179 - val_accuracy: 0.9122\n","\n","Epoch 00173: val_accuracy did not improve from 0.93243\n","Epoch 174/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.7563 - val_accuracy: 0.8311\n","\n","Epoch 00174: val_accuracy did not improve from 0.93243\n","Epoch 175/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 0.5761 - val_accuracy: 0.9122\n","\n","Epoch 00175: val_accuracy did not improve from 0.93243\n","Epoch 176/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.4190 - val_accuracy: 0.9257\n","\n","Epoch 00176: val_accuracy did not improve from 0.93243\n","Epoch 177/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0536 - accuracy: 0.9858 - val_loss: 0.3521 - val_accuracy: 0.9122\n","\n","Epoch 00177: val_accuracy did not improve from 0.93243\n","Epoch 178/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0438 - accuracy: 0.9874 - val_loss: 0.4710 - val_accuracy: 0.8919\n","\n","Epoch 00178: val_accuracy did not improve from 0.93243\n","Epoch 179/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.5151 - val_accuracy: 0.8919\n","\n","Epoch 00179: val_accuracy did not improve from 0.93243\n","Epoch 180/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.4396 - val_accuracy: 0.9122\n","\n","Epoch 00180: val_accuracy did not improve from 0.93243\n","Epoch 181/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.7434 - val_accuracy: 0.8919\n","\n","Epoch 00181: val_accuracy did not improve from 0.93243\n","Epoch 182/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.6470 - val_accuracy: 0.9122\n","\n","Epoch 00182: val_accuracy did not improve from 0.93243\n","Epoch 183/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.4251 - val_accuracy: 0.8716\n","\n","Epoch 00183: val_accuracy did not improve from 0.93243\n","Epoch 184/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.5769 - val_accuracy: 0.9189\n","\n","Epoch 00184: val_accuracy did not improve from 0.93243\n","Epoch 185/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.4753 - val_accuracy: 0.9324\n","\n","Epoch 00185: val_accuracy did not improve from 0.93243\n","Epoch 186/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4842 - val_accuracy: 0.8986\n","\n","Epoch 00186: val_accuracy did not improve from 0.93243\n","Epoch 187/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0319 - accuracy: 0.9868 - val_loss: 0.7099 - val_accuracy: 0.8851\n","\n","Epoch 00187: val_accuracy did not improve from 0.93243\n","Epoch 188/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0501 - accuracy: 0.9863 - val_loss: 0.6321 - val_accuracy: 0.9122\n","\n","Epoch 00188: val_accuracy did not improve from 0.93243\n","Epoch 189/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.6207 - val_accuracy: 0.8784\n","\n","Epoch 00189: val_accuracy did not improve from 0.93243\n","Epoch 190/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 0.7613 - val_accuracy: 0.8986\n","\n","Epoch 00190: val_accuracy did not improve from 0.93243\n","Epoch 191/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0417 - accuracy: 0.9879 - val_loss: 0.6180 - val_accuracy: 0.9257\n","\n","Epoch 00191: val_accuracy did not improve from 0.93243\n","Epoch 192/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 1.8875 - val_accuracy: 0.7297\n","\n","Epoch 00192: val_accuracy did not improve from 0.93243\n","Epoch 193/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.6513 - val_accuracy: 0.8986\n","\n","Epoch 00193: val_accuracy did not improve from 0.93243\n","Epoch 194/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0453 - accuracy: 0.9879 - val_loss: 0.5880 - val_accuracy: 0.8986\n","\n","Epoch 00194: val_accuracy did not improve from 0.93243\n","Epoch 195/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0408 - accuracy: 0.9847 - val_loss: 0.6164 - val_accuracy: 0.8986\n","\n","Epoch 00195: val_accuracy did not improve from 0.93243\n","Epoch 196/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.5116 - val_accuracy: 0.8986\n","\n","Epoch 00196: val_accuracy did not improve from 0.93243\n","Epoch 197/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.8101 - val_accuracy: 0.8919\n","\n","Epoch 00197: val_accuracy did not improve from 0.93243\n","Epoch 198/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 1.1611 - val_accuracy: 0.8378\n","\n","Epoch 00198: val_accuracy did not improve from 0.93243\n","Epoch 199/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.6428 - val_accuracy: 0.8649\n","\n","Epoch 00199: val_accuracy did not improve from 0.93243\n","Epoch 200/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.4771 - val_accuracy: 0.9257\n","\n","Epoch 00200: val_accuracy did not improve from 0.93243\n","Epoch 201/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.5651 - val_accuracy: 0.8851\n","\n","Epoch 00201: val_accuracy did not improve from 0.93243\n","Epoch 202/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.4544 - val_accuracy: 0.9122\n","\n","Epoch 00202: val_accuracy did not improve from 0.93243\n","Epoch 203/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.5368 - val_accuracy: 0.8851\n","\n","Epoch 00203: val_accuracy did not improve from 0.93243\n","Epoch 204/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0503 - accuracy: 0.9832 - val_loss: 0.9159 - val_accuracy: 0.8581\n","\n","Epoch 00204: val_accuracy did not improve from 0.93243\n","Epoch 205/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0622 - accuracy: 0.9816 - val_loss: 0.5063 - val_accuracy: 0.9189\n","\n","Epoch 00205: val_accuracy did not improve from 0.93243\n","Epoch 206/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.4989 - val_accuracy: 0.8716\n","\n","Epoch 00206: val_accuracy did not improve from 0.93243\n","Epoch 207/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.5753 - val_accuracy: 0.9122\n","\n","Epoch 00207: val_accuracy did not improve from 0.93243\n","Epoch 208/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4790 - val_accuracy: 0.8986\n","\n","Epoch 00208: val_accuracy did not improve from 0.93243\n","Epoch 209/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.3317 - val_accuracy: 0.9054\n","\n","Epoch 00209: val_accuracy did not improve from 0.93243\n","Epoch 210/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6275 - val_accuracy: 0.8851\n","\n","Epoch 00210: val_accuracy did not improve from 0.93243\n","Epoch 211/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0478 - accuracy: 0.9853 - val_loss: 0.7770 - val_accuracy: 0.8986\n","\n","Epoch 00211: val_accuracy did not improve from 0.93243\n","Epoch 212/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 0.6718 - val_accuracy: 0.9122\n","\n","Epoch 00212: val_accuracy did not improve from 0.93243\n","Epoch 213/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.7413 - val_accuracy: 0.8851\n","\n","Epoch 00213: val_accuracy did not improve from 0.93243\n","Epoch 214/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.6111 - val_accuracy: 0.8851\n","\n","Epoch 00214: val_accuracy did not improve from 0.93243\n","Epoch 215/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0439 - accuracy: 0.9884 - val_loss: 0.7073 - val_accuracy: 0.8851\n","\n","Epoch 00215: val_accuracy did not improve from 0.93243\n","Epoch 216/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.6506 - val_accuracy: 0.8919\n","\n","Epoch 00216: val_accuracy did not improve from 0.93243\n","Epoch 217/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.6960 - val_accuracy: 0.9054\n","\n","Epoch 00217: val_accuracy did not improve from 0.93243\n","Epoch 218/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.7239 - val_accuracy: 0.8851\n","\n","Epoch 00218: val_accuracy did not improve from 0.93243\n","Epoch 219/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.6948 - val_accuracy: 0.8919\n","\n","Epoch 00219: val_accuracy did not improve from 0.93243\n","Epoch 220/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0314 - accuracy: 0.9916 - val_loss: 0.5380 - val_accuracy: 0.8919\n","\n","Epoch 00220: val_accuracy did not improve from 0.93243\n","Epoch 221/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.7120 - val_accuracy: 0.8851\n","\n","Epoch 00221: val_accuracy did not improve from 0.93243\n","Epoch 222/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.6517 - val_accuracy: 0.8851\n","\n","Epoch 00222: val_accuracy did not improve from 0.93243\n","Epoch 223/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.5749 - val_accuracy: 0.9054\n","\n","Epoch 00223: val_accuracy did not improve from 0.93243\n","Epoch 224/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.4289 - val_accuracy: 0.9324\n","\n","Epoch 00224: val_accuracy did not improve from 0.93243\n","Epoch 225/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.4365 - val_accuracy: 0.9257\n","\n","Epoch 00225: val_accuracy did not improve from 0.93243\n","Epoch 226/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.5759 - val_accuracy: 0.9122\n","\n","Epoch 00226: val_accuracy did not improve from 0.93243\n","Epoch 227/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.4794 - val_accuracy: 0.9054\n","\n","Epoch 00227: val_accuracy did not improve from 0.93243\n","Epoch 228/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.6313 - val_accuracy: 0.8851\n","\n","Epoch 00228: val_accuracy did not improve from 0.93243\n","Epoch 229/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.5984 - val_accuracy: 0.9054\n","\n","Epoch 00229: val_accuracy did not improve from 0.93243\n","Epoch 230/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.8525 - val_accuracy: 0.8919\n","\n","Epoch 00230: val_accuracy did not improve from 0.93243\n","Epoch 231/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.4518 - val_accuracy: 0.8986\n","\n","Epoch 00231: val_accuracy did not improve from 0.93243\n","Epoch 232/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.4357 - val_accuracy: 0.9122\n","\n","Epoch 00232: val_accuracy did not improve from 0.93243\n","Epoch 233/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.4454 - val_accuracy: 0.9054\n","\n","Epoch 00233: val_accuracy did not improve from 0.93243\n","Epoch 234/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.4143 - val_accuracy: 0.9054\n","\n","Epoch 00234: val_accuracy did not improve from 0.93243\n","Epoch 235/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.5249 - val_accuracy: 0.8986\n","\n","Epoch 00235: val_accuracy did not improve from 0.93243\n","Epoch 236/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.4498 - val_accuracy: 0.9122\n","\n","Epoch 00236: val_accuracy did not improve from 0.93243\n","Epoch 237/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.5080 - val_accuracy: 0.9122\n","\n","Epoch 00237: val_accuracy did not improve from 0.93243\n","Epoch 238/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.5585 - val_accuracy: 0.8986\n","\n","Epoch 00238: val_accuracy did not improve from 0.93243\n","Epoch 239/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.4229 - val_accuracy: 0.8919\n","\n","Epoch 00239: val_accuracy did not improve from 0.93243\n","Epoch 240/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.4865 - val_accuracy: 0.9324\n","\n","Epoch 00240: val_accuracy did not improve from 0.93243\n","Epoch 241/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.4783 - val_accuracy: 0.9054\n","\n","Epoch 00241: val_accuracy did not improve from 0.93243\n","Epoch 242/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.6369 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.93243\n","Epoch 243/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.6498 - val_accuracy: 0.8851\n","\n","Epoch 00243: val_accuracy did not improve from 0.93243\n","Epoch 244/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0401 - accuracy: 0.9905 - val_loss: 0.4841 - val_accuracy: 0.9189\n","\n","Epoch 00244: val_accuracy did not improve from 0.93243\n","Epoch 245/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.4708 - val_accuracy: 0.9459\n","\n","Epoch 00245: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 246/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.4822 - val_accuracy: 0.8986\n","\n","Epoch 00246: val_accuracy did not improve from 0.94595\n","Epoch 247/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.5915 - val_accuracy: 0.9054\n","\n","Epoch 00247: val_accuracy did not improve from 0.94595\n","Epoch 248/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.4631 - val_accuracy: 0.9054\n","\n","Epoch 00248: val_accuracy did not improve from 0.94595\n","Epoch 249/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.3965 - val_accuracy: 0.9324\n","\n","Epoch 00249: val_accuracy did not improve from 0.94595\n","Epoch 250/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.4294 - val_accuracy: 0.8986\n","\n","Epoch 00250: val_accuracy did not improve from 0.94595\n","Epoch 251/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.3927 - val_accuracy: 0.9054\n","\n","Epoch 00251: val_accuracy did not improve from 0.94595\n","Epoch 252/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.5142 - val_accuracy: 0.9189\n","\n","Epoch 00252: val_accuracy did not improve from 0.94595\n","Epoch 253/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0171 - accuracy: 0.9926 - val_loss: 0.6758 - val_accuracy: 0.8986\n","\n","Epoch 00253: val_accuracy did not improve from 0.94595\n","Epoch 254/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.5672 - val_accuracy: 0.8986\n","\n","Epoch 00254: val_accuracy did not improve from 0.94595\n","Epoch 255/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 1.3392 - val_accuracy: 0.7635\n","\n","Epoch 00255: val_accuracy did not improve from 0.94595\n","Epoch 256/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.5575 - val_accuracy: 0.8986\n","\n","Epoch 00256: val_accuracy did not improve from 0.94595\n","Epoch 257/500\n","238/238 [==============================] - 34s 141ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.4594 - val_accuracy: 0.8986\n","\n","Epoch 00257: val_accuracy did not improve from 0.94595\n","Epoch 258/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.5449 - val_accuracy: 0.9324\n","\n","Epoch 00258: val_accuracy did not improve from 0.94595\n","Epoch 259/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.6356 - val_accuracy: 0.9122\n","\n","Epoch 00259: val_accuracy did not improve from 0.94595\n","Epoch 260/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.8382 - val_accuracy: 0.8919\n","\n","Epoch 00260: val_accuracy did not improve from 0.94595\n","Epoch 261/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.6471 - val_accuracy: 0.9054\n","\n","Epoch 00261: val_accuracy did not improve from 0.94595\n","Epoch 262/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.5229 - val_accuracy: 0.8851\n","\n","Epoch 00262: val_accuracy did not improve from 0.94595\n","Epoch 263/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.4160 - val_accuracy: 0.8986\n","\n","Epoch 00263: val_accuracy did not improve from 0.94595\n","Epoch 264/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.4777 - val_accuracy: 0.9122\n","\n","Epoch 00264: val_accuracy did not improve from 0.94595\n","Epoch 265/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0249 - accuracy: 0.9905 - val_loss: 0.5663 - val_accuracy: 0.9054\n","\n","Epoch 00265: val_accuracy did not improve from 0.94595\n","Epoch 266/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 0.4992 - val_accuracy: 0.9122\n","\n","Epoch 00266: val_accuracy did not improve from 0.94595\n","Epoch 267/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.5464 - val_accuracy: 0.8919\n","\n","Epoch 00267: val_accuracy did not improve from 0.94595\n","Epoch 268/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.4011 - val_accuracy: 0.9324\n","\n","Epoch 00268: val_accuracy did not improve from 0.94595\n","Epoch 269/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.4011 - val_accuracy: 0.9324\n","\n","Epoch 00269: val_accuracy did not improve from 0.94595\n","Epoch 270/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.4292 - val_accuracy: 0.9189\n","\n","Epoch 00270: val_accuracy did not improve from 0.94595\n","Epoch 271/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.5770 - val_accuracy: 0.8986\n","\n","Epoch 00271: val_accuracy did not improve from 0.94595\n","Epoch 272/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.4105 - val_accuracy: 0.8919\n","\n","Epoch 00272: val_accuracy did not improve from 0.94595\n","Epoch 273/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.6493 - val_accuracy: 0.8986\n","\n","Epoch 00273: val_accuracy did not improve from 0.94595\n","Epoch 274/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.4480 - val_accuracy: 0.9122\n","\n","Epoch 00274: val_accuracy did not improve from 0.94595\n","Epoch 275/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.4514 - val_accuracy: 0.9257\n","\n","Epoch 00275: val_accuracy did not improve from 0.94595\n","Epoch 276/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6242 - val_accuracy: 0.9122\n","\n","Epoch 00276: val_accuracy did not improve from 0.94595\n","Epoch 277/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.6184 - val_accuracy: 0.9054\n","\n","Epoch 00277: val_accuracy did not improve from 0.94595\n","Epoch 278/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.3848 - val_accuracy: 0.9122\n","\n","Epoch 00278: val_accuracy did not improve from 0.94595\n","Epoch 279/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0210 - accuracy: 0.9911 - val_loss: 0.4961 - val_accuracy: 0.9324\n","\n","Epoch 00279: val_accuracy did not improve from 0.94595\n","Epoch 280/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.7029 - val_accuracy: 0.8919\n","\n","Epoch 00280: val_accuracy did not improve from 0.94595\n","Epoch 281/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0279 - accuracy: 0.9932 - val_loss: 0.4396 - val_accuracy: 0.8919\n","\n","Epoch 00281: val_accuracy did not improve from 0.94595\n","Epoch 282/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 0.4889 - val_accuracy: 0.9054\n","\n","Epoch 00282: val_accuracy did not improve from 0.94595\n","Epoch 283/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.7437 - val_accuracy: 0.8851\n","\n","Epoch 00283: val_accuracy did not improve from 0.94595\n","Epoch 284/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.5898 - val_accuracy: 0.8986\n","\n","Epoch 00284: val_accuracy did not improve from 0.94595\n","Epoch 285/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.3960 - val_accuracy: 0.9257\n","\n","Epoch 00285: val_accuracy did not improve from 0.94595\n","Epoch 286/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.5965 - val_accuracy: 0.9054\n","\n","Epoch 00286: val_accuracy did not improve from 0.94595\n","Epoch 287/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.5406 - val_accuracy: 0.8851\n","\n","Epoch 00287: val_accuracy did not improve from 0.94595\n","Epoch 288/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.4901 - val_accuracy: 0.9054\n","\n","Epoch 00288: val_accuracy did not improve from 0.94595\n","Epoch 289/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.5439 - val_accuracy: 0.8919\n","\n","Epoch 00289: val_accuracy did not improve from 0.94595\n","Epoch 290/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0161 - accuracy: 0.9932 - val_loss: 0.4583 - val_accuracy: 0.8784\n","\n","Epoch 00290: val_accuracy did not improve from 0.94595\n","Epoch 291/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.5164 - val_accuracy: 0.9189\n","\n","Epoch 00291: val_accuracy did not improve from 0.94595\n","Epoch 292/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.5883 - val_accuracy: 0.9054\n","\n","Epoch 00292: val_accuracy did not improve from 0.94595\n","Epoch 293/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.4650 - val_accuracy: 0.9054\n","\n","Epoch 00293: val_accuracy did not improve from 0.94595\n","Epoch 294/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.5498 - val_accuracy: 0.9324\n","\n","Epoch 00294: val_accuracy did not improve from 0.94595\n","Epoch 295/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.6881 - val_accuracy: 0.9054\n","\n","Epoch 00295: val_accuracy did not improve from 0.94595\n","Epoch 296/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.7895 - val_accuracy: 0.8919\n","\n","Epoch 00296: val_accuracy did not improve from 0.94595\n","Epoch 297/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7540 - val_accuracy: 0.8851\n","\n","Epoch 00297: val_accuracy did not improve from 0.94595\n","Epoch 298/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.4776 - val_accuracy: 0.9257\n","\n","Epoch 00298: val_accuracy did not improve from 0.94595\n","Epoch 299/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.3200 - val_accuracy: 0.9527\n","\n","Epoch 00299: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_1.h5\n","Epoch 300/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.5565 - val_accuracy: 0.8919\n","\n","Epoch 00300: val_accuracy did not improve from 0.95270\n","Epoch 301/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.4720 - val_accuracy: 0.9257\n","\n","Epoch 00301: val_accuracy did not improve from 0.95270\n","Epoch 302/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0444 - accuracy: 0.9868 - val_loss: 0.5167 - val_accuracy: 0.9324\n","\n","Epoch 00302: val_accuracy did not improve from 0.95270\n","Epoch 303/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.6539 - val_accuracy: 0.9122\n","\n","Epoch 00303: val_accuracy did not improve from 0.95270\n","Epoch 304/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4493 - val_accuracy: 0.9189\n","\n","Epoch 00304: val_accuracy did not improve from 0.95270\n","Epoch 305/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.6306 - val_accuracy: 0.9122\n","\n","Epoch 00305: val_accuracy did not improve from 0.95270\n","Epoch 306/500\n","238/238 [==============================] - 34s 142ms/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.5086 - val_accuracy: 0.9257\n","\n","Epoch 00306: val_accuracy did not improve from 0.95270\n","Epoch 307/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5234 - val_accuracy: 0.8986\n","\n","Epoch 00307: val_accuracy did not improve from 0.95270\n","Epoch 308/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 0.5120 - val_accuracy: 0.8919\n","\n","Epoch 00308: val_accuracy did not improve from 0.95270\n","Epoch 309/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.4991 - val_accuracy: 0.9189\n","\n","Epoch 00309: val_accuracy did not improve from 0.95270\n","Epoch 310/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.5475 - val_accuracy: 0.9122\n","\n","Epoch 00310: val_accuracy did not improve from 0.95270\n","Epoch 311/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.7235 - val_accuracy: 0.8716\n","\n","Epoch 00311: val_accuracy did not improve from 0.95270\n","Epoch 312/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5883 - val_accuracy: 0.8986\n","\n","Epoch 00312: val_accuracy did not improve from 0.95270\n","Epoch 313/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.5311 - val_accuracy: 0.8986\n","\n","Epoch 00313: val_accuracy did not improve from 0.95270\n","Epoch 314/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.0228 - accuracy: 0.9958 - val_loss: 0.7486 - val_accuracy: 0.8986\n","\n","Epoch 00314: val_accuracy did not improve from 0.95270\n","Epoch 315/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.7406 - val_accuracy: 0.8986\n","\n","Epoch 00315: val_accuracy did not improve from 0.95270\n","Epoch 316/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4005 - val_accuracy: 0.9189\n","\n","Epoch 00316: val_accuracy did not improve from 0.95270\n","Epoch 317/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3031 - val_accuracy: 0.9324\n","\n","Epoch 00317: val_accuracy did not improve from 0.95270\n","Epoch 318/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.5056 - val_accuracy: 0.9054\n","\n","Epoch 00318: val_accuracy did not improve from 0.95270\n","Epoch 319/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.4903 - val_accuracy: 0.9122\n","\n","Epoch 00319: val_accuracy did not improve from 0.95270\n","Epoch 320/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.5392 - val_accuracy: 0.8986\n","\n","Epoch 00320: val_accuracy did not improve from 0.95270\n","Epoch 321/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6458 - val_accuracy: 0.8851\n","\n","Epoch 00321: val_accuracy did not improve from 0.95270\n","Epoch 322/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.7182 - val_accuracy: 0.8919\n","\n","Epoch 00322: val_accuracy did not improve from 0.95270\n","Epoch 323/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.5229 - val_accuracy: 0.9257\n","\n","Epoch 00323: val_accuracy did not improve from 0.95270\n","Epoch 324/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.5252 - val_accuracy: 0.8851\n","\n","Epoch 00324: val_accuracy did not improve from 0.95270\n","Epoch 325/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0454 - accuracy: 0.9900 - val_loss: 0.5426 - val_accuracy: 0.8716\n","\n","Epoch 00325: val_accuracy did not improve from 0.95270\n","Epoch 326/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.4507 - val_accuracy: 0.9257\n","\n","Epoch 00326: val_accuracy did not improve from 0.95270\n","Epoch 327/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0303 - accuracy: 0.9853 - val_loss: 0.4583 - val_accuracy: 0.9189\n","\n","Epoch 00327: val_accuracy did not improve from 0.95270\n","Epoch 328/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.4019 - val_accuracy: 0.9392\n","\n","Epoch 00328: val_accuracy did not improve from 0.95270\n","Epoch 329/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.5513 - val_accuracy: 0.9392\n","\n","Epoch 00329: val_accuracy did not improve from 0.95270\n","Epoch 330/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6267 - val_accuracy: 0.9189\n","\n","Epoch 00330: val_accuracy did not improve from 0.95270\n","Epoch 331/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.5280 - val_accuracy: 0.9257\n","\n","Epoch 00331: val_accuracy did not improve from 0.95270\n","Epoch 332/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.4419 - val_accuracy: 0.9122\n","\n","Epoch 00332: val_accuracy did not improve from 0.95270\n","Epoch 333/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.6918 - val_accuracy: 0.8919\n","\n","Epoch 00333: val_accuracy did not improve from 0.95270\n","Epoch 334/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.4528 - val_accuracy: 0.8986\n","\n","Epoch 00334: val_accuracy did not improve from 0.95270\n","Epoch 335/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.6062 - val_accuracy: 0.8919\n","\n","Epoch 00335: val_accuracy did not improve from 0.95270\n","Epoch 336/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.3954 - val_accuracy: 0.9324\n","\n","Epoch 00336: val_accuracy did not improve from 0.95270\n","Epoch 337/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0249 - accuracy: 0.9942 - val_loss: 0.5491 - val_accuracy: 0.9054\n","\n","Epoch 00337: val_accuracy did not improve from 0.95270\n","Epoch 338/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0174 - accuracy: 0.9921 - val_loss: 0.5273 - val_accuracy: 0.9189\n","\n","Epoch 00338: val_accuracy did not improve from 0.95270\n","Epoch 339/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.6124 - val_accuracy: 0.9122\n","\n","Epoch 00339: val_accuracy did not improve from 0.95270\n","Epoch 340/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.7617 - val_accuracy: 0.8919\n","\n","Epoch 00340: val_accuracy did not improve from 0.95270\n","Epoch 341/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.7187 - val_accuracy: 0.9054\n","\n","Epoch 00341: val_accuracy did not improve from 0.95270\n","Epoch 342/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.7597 - val_accuracy: 0.8716\n","\n","Epoch 00342: val_accuracy did not improve from 0.95270\n","Epoch 343/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.8034 - val_accuracy: 0.8851\n","\n","Epoch 00343: val_accuracy did not improve from 0.95270\n","Epoch 344/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.0370 - accuracy: 0.9905 - val_loss: 0.7542 - val_accuracy: 0.8986\n","\n","Epoch 00344: val_accuracy did not improve from 0.95270\n","Epoch 345/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 0.5480 - val_accuracy: 0.8986\n","\n","Epoch 00345: val_accuracy did not improve from 0.95270\n","Epoch 346/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.6565 - val_accuracy: 0.8851\n","\n","Epoch 00346: val_accuracy did not improve from 0.95270\n","Epoch 347/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6383 - val_accuracy: 0.9257\n","\n","Epoch 00347: val_accuracy did not improve from 0.95270\n","Epoch 348/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.7145 - val_accuracy: 0.9054\n","\n","Epoch 00348: val_accuracy did not improve from 0.95270\n","Epoch 349/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.6949 - val_accuracy: 0.9189\n","\n","Epoch 00349: val_accuracy did not improve from 0.95270\n","Epoch 350/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.4877 - val_accuracy: 0.8986\n","\n","Epoch 00350: val_accuracy did not improve from 0.95270\n","Epoch 351/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.5935 - val_accuracy: 0.8784\n","\n","Epoch 00351: val_accuracy did not improve from 0.95270\n","Epoch 352/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.5710 - val_accuracy: 0.8919\n","\n","Epoch 00352: val_accuracy did not improve from 0.95270\n","Epoch 353/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.9839 - val_accuracy: 0.8784\n","\n","Epoch 00353: val_accuracy did not improve from 0.95270\n","Epoch 354/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.5630 - val_accuracy: 0.8919\n","\n","Epoch 00354: val_accuracy did not improve from 0.95270\n","Epoch 355/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 0.8529 - val_accuracy: 0.8581\n","\n","Epoch 00355: val_accuracy did not improve from 0.95270\n","Epoch 356/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.8196 - val_accuracy: 0.8851\n","\n","Epoch 00356: val_accuracy did not improve from 0.95270\n","Epoch 357/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.6407 - val_accuracy: 0.9122\n","\n","Epoch 00357: val_accuracy did not improve from 0.95270\n","Epoch 358/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.5963 - val_accuracy: 0.9122\n","\n","Epoch 00358: val_accuracy did not improve from 0.95270\n","Epoch 359/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.5073 - val_accuracy: 0.8986\n","\n","Epoch 00359: val_accuracy did not improve from 0.95270\n","Epoch 360/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.5214 - val_accuracy: 0.8919\n","\n","Epoch 00360: val_accuracy did not improve from 0.95270\n","Epoch 361/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5205 - val_accuracy: 0.8919\n","\n","Epoch 00361: val_accuracy did not improve from 0.95270\n","Epoch 362/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3758 - val_accuracy: 0.9324\n","\n","Epoch 00362: val_accuracy did not improve from 0.95270\n","Epoch 363/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.4635 - val_accuracy: 0.9054\n","\n","Epoch 00363: val_accuracy did not improve from 0.95270\n","Epoch 364/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.5136 - val_accuracy: 0.9189\n","\n","Epoch 00364: val_accuracy did not improve from 0.95270\n","Epoch 365/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6640 - val_accuracy: 0.9054\n","\n","Epoch 00365: val_accuracy did not improve from 0.95270\n","Epoch 366/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.7673 - val_accuracy: 0.8986\n","\n","Epoch 00366: val_accuracy did not improve from 0.95270\n","Epoch 367/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0253 - accuracy: 0.9889 - val_loss: 0.7547 - val_accuracy: 0.9054\n","\n","Epoch 00367: val_accuracy did not improve from 0.95270\n","Epoch 368/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.6949 - val_accuracy: 0.9189\n","\n","Epoch 00368: val_accuracy did not improve from 0.95270\n","Epoch 369/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.6856 - val_accuracy: 0.9054\n","\n","Epoch 00369: val_accuracy did not improve from 0.95270\n","Epoch 370/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.6813 - val_accuracy: 0.9054\n","\n","Epoch 00370: val_accuracy did not improve from 0.95270\n","Epoch 371/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.6568 - val_accuracy: 0.8851\n","\n","Epoch 00371: val_accuracy did not improve from 0.95270\n","Epoch 372/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.4450 - val_accuracy: 0.8919\n","\n","Epoch 00372: val_accuracy did not improve from 0.95270\n","Epoch 373/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.6750 - val_accuracy: 0.8986\n","\n","Epoch 00373: val_accuracy did not improve from 0.95270\n","Epoch 374/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.5262 - val_accuracy: 0.9189\n","\n","Epoch 00374: val_accuracy did not improve from 0.95270\n","Epoch 375/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.7651 - val_accuracy: 0.9054\n","\n","Epoch 00375: val_accuracy did not improve from 0.95270\n","Epoch 376/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.5428 - val_accuracy: 0.9257\n","\n","Epoch 00376: val_accuracy did not improve from 0.95270\n","Epoch 377/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.8214 - val_accuracy: 0.8986\n","\n","Epoch 00377: val_accuracy did not improve from 0.95270\n","Epoch 378/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.7089 - val_accuracy: 0.8919\n","\n","Epoch 00378: val_accuracy did not improve from 0.95270\n","Epoch 379/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.5591 - val_accuracy: 0.8851\n","\n","Epoch 00379: val_accuracy did not improve from 0.95270\n","Epoch 380/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0158 - accuracy: 0.9926 - val_loss: 0.6017 - val_accuracy: 0.8851\n","\n","Epoch 00380: val_accuracy did not improve from 0.95270\n","Epoch 381/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.9731 - val_accuracy: 0.8784\n","\n","Epoch 00381: val_accuracy did not improve from 0.95270\n","Epoch 382/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.7180 - val_accuracy: 0.8986\n","\n","Epoch 00382: val_accuracy did not improve from 0.95270\n","Epoch 383/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.6655 - val_accuracy: 0.9054\n","\n","Epoch 00383: val_accuracy did not improve from 0.95270\n","Epoch 384/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.7294 - val_accuracy: 0.8784\n","\n","Epoch 00384: val_accuracy did not improve from 0.95270\n","Epoch 385/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.9875 - val_accuracy: 0.8784\n","\n","Epoch 00385: val_accuracy did not improve from 0.95270\n","Epoch 386/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.7639 - val_accuracy: 0.8851\n","\n","Epoch 00386: val_accuracy did not improve from 0.95270\n","Epoch 387/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.6153 - val_accuracy: 0.9054\n","\n","Epoch 00387: val_accuracy did not improve from 0.95270\n","Epoch 388/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5400 - val_accuracy: 0.9257\n","\n","Epoch 00388: val_accuracy did not improve from 0.95270\n","Epoch 389/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.6089 - val_accuracy: 0.9122\n","\n","Epoch 00389: val_accuracy did not improve from 0.95270\n","Epoch 390/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.5323 - val_accuracy: 0.9324\n","\n","Epoch 00390: val_accuracy did not improve from 0.95270\n","Epoch 391/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.4223 - val_accuracy: 0.9392\n","\n","Epoch 00391: val_accuracy did not improve from 0.95270\n","Epoch 392/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0247 - accuracy: 0.9905 - val_loss: 0.8218 - val_accuracy: 0.8986\n","\n","Epoch 00392: val_accuracy did not improve from 0.95270\n","Epoch 393/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.7707 - val_accuracy: 0.8851\n","\n","Epoch 00393: val_accuracy did not improve from 0.95270\n","Epoch 394/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.7019 - val_accuracy: 0.8919\n","\n","Epoch 00394: val_accuracy did not improve from 0.95270\n","Epoch 395/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.6733 - val_accuracy: 0.9122\n","\n","Epoch 00395: val_accuracy did not improve from 0.95270\n","Epoch 396/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6242 - val_accuracy: 0.9189\n","\n","Epoch 00396: val_accuracy did not improve from 0.95270\n","Epoch 397/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.8471 - val_accuracy: 0.8716\n","\n","Epoch 00397: val_accuracy did not improve from 0.95270\n","Epoch 398/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.5593 - val_accuracy: 0.9122\n","\n","Epoch 00398: val_accuracy did not improve from 0.95270\n","Epoch 399/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.6394 - val_accuracy: 0.9122\n","\n","Epoch 00399: val_accuracy did not improve from 0.95270\n","Epoch 400/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 0.6079 - val_accuracy: 0.9189\n","\n","Epoch 00400: val_accuracy did not improve from 0.95270\n","Epoch 401/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5833 - val_accuracy: 0.8986\n","\n","Epoch 00401: val_accuracy did not improve from 0.95270\n","Epoch 402/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.7374 - val_accuracy: 0.8851\n","\n","Epoch 00402: val_accuracy did not improve from 0.95270\n","Epoch 403/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.5984 - val_accuracy: 0.9054\n","\n","Epoch 00403: val_accuracy did not improve from 0.95270\n","Epoch 404/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.6375 - val_accuracy: 0.9189\n","\n","Epoch 00404: val_accuracy did not improve from 0.95270\n","Epoch 405/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.6298 - val_accuracy: 0.9122\n","\n","Epoch 00405: val_accuracy did not improve from 0.95270\n","Epoch 406/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.6797 - val_accuracy: 0.9054\n","\n","Epoch 00406: val_accuracy did not improve from 0.95270\n","Epoch 407/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.6524 - val_accuracy: 0.8784\n","\n","Epoch 00407: val_accuracy did not improve from 0.95270\n","Epoch 408/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.7630 - val_accuracy: 0.9189\n","\n","Epoch 00408: val_accuracy did not improve from 0.95270\n","Epoch 409/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.5080 - val_accuracy: 0.9257\n","\n","Epoch 00409: val_accuracy did not improve from 0.95270\n","Epoch 410/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.6089 - val_accuracy: 0.9189\n","\n","Epoch 00410: val_accuracy did not improve from 0.95270\n","Epoch 411/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.6474 - val_accuracy: 0.8986\n","\n","Epoch 00411: val_accuracy did not improve from 0.95270\n","Epoch 412/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.9692 - val_accuracy: 0.8716\n","\n","Epoch 00412: val_accuracy did not improve from 0.95270\n","Epoch 413/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.6094 - val_accuracy: 0.9189\n","\n","Epoch 00413: val_accuracy did not improve from 0.95270\n","Epoch 414/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.6932 - val_accuracy: 0.8986\n","\n","Epoch 00414: val_accuracy did not improve from 0.95270\n","Epoch 415/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.6200 - val_accuracy: 0.9122\n","\n","Epoch 00415: val_accuracy did not improve from 0.95270\n","Epoch 416/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.6017 - val_accuracy: 0.9189\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.4596 - val_accuracy: 0.9392\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.6920 - val_accuracy: 0.9054\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.9889 - val_accuracy: 0.8986\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.5328 - val_accuracy: 0.9122\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.6768 - val_accuracy: 0.9054\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5845 - val_accuracy: 0.9392\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.6800 - val_accuracy: 0.9054\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5315 - val_accuracy: 0.9189\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.7302 - val_accuracy: 0.8784\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.4460 - val_accuracy: 0.9257\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4550 - val_accuracy: 0.9324\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.6476 - val_accuracy: 0.8784\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.4974 - val_accuracy: 0.9189\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.6015 - val_accuracy: 0.9459\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.5634 - val_accuracy: 0.9054\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6557 - val_accuracy: 0.9122\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.8900 - val_accuracy: 0.8986\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.8127 - val_accuracy: 0.8649\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.6790 - val_accuracy: 0.8986\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.6779 - val_accuracy: 0.9324\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.8021 - val_accuracy: 0.9122\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.7153 - val_accuracy: 0.9122\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.8845 - val_accuracy: 0.8919\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.5546 - val_accuracy: 0.9324\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.6326 - val_accuracy: 0.9257\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.7409 - val_accuracy: 0.8986\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.6046 - val_accuracy: 0.9257\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.6700 - val_accuracy: 0.8919\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.7180 - val_accuracy: 0.9122\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.6610 - val_accuracy: 0.9324\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5717 - val_accuracy: 0.9189\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.6131 - val_accuracy: 0.9324\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.6481 - val_accuracy: 0.9257\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.6880 - val_accuracy: 0.9054\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.8906 - val_accuracy: 0.9189\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.6321 - val_accuracy: 0.9324\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.6584 - val_accuracy: 0.9257\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.9464 - val_accuracy: 0.9054\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.6686 - val_accuracy: 0.9324\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.6825 - val_accuracy: 0.9122\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0244 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.8851\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.6523 - val_accuracy: 0.8986\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.5264 - val_accuracy: 0.9257\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.4919 - val_accuracy: 0.9324\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.5319 - val_accuracy: 0.9257\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.7710 - val_accuracy: 0.9122\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5862 - val_accuracy: 0.9324\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0039 - accuracy: 0.9974 - val_loss: 0.5668 - val_accuracy: 0.9257\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.5999 - val_accuracy: 0.9122\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.7304 - val_accuracy: 0.8986\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.5380 - val_accuracy: 0.9189\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.4898 - val_accuracy: 0.8986\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.5517 - val_accuracy: 0.9257\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.5326 - val_accuracy: 0.9122\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.4848 - val_accuracy: 0.8986\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5391 - val_accuracy: 0.9257\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.5680 - val_accuracy: 0.9122\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.6318 - val_accuracy: 0.9257\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6234 - val_accuracy: 0.9122\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.8834 - val_accuracy: 0.8851\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6441 - val_accuracy: 0.9122\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.8520 - val_accuracy: 0.8716\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5911 - val_accuracy: 0.9122\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.5274 - val_accuracy: 0.9054\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.4986 - val_accuracy: 0.9189\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.8487 - val_accuracy: 0.9054\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.7522 - val_accuracy: 0.9257\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.5413 - val_accuracy: 0.9122\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.7472 - val_accuracy: 0.9324\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.7515 - val_accuracy: 0.8986\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.5975 - val_accuracy: 0.9054\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.6473 - val_accuracy: 0.9189\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0128 - accuracy: 0.9937 - val_loss: 0.8403 - val_accuracy: 0.8986\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.5569 - val_accuracy: 0.9459\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0204 - accuracy: 0.9974 - val_loss: 0.6614 - val_accuracy: 0.9122\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6886 - val_accuracy: 0.9122\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.7569 - val_accuracy: 0.9122\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6961 - val_accuracy: 0.9257\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.8800 - val_accuracy: 0.9054\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.4512 - val_accuracy: 0.9054\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.5773 - val_accuracy: 0.9054\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4152 - val_accuracy: 0.9459\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.5119 - val_accuracy: 0.9257\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0326 - accuracy: 0.9937 - val_loss: 0.5313 - val_accuracy: 0.9122\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2da01ba090>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632861693051,"user_tz":-540,"elapsed":38,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"85d904a0-c339-40c1-f137-eb4cca6e837d"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632861708329,"user_tz":-540,"elapsed":14867,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1632861709153,"user_tz":-540,"elapsed":838,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861709590,"user_tz":-540,"elapsed":441,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"75e6041a-5f33-429b-cbd9-00452cd79ee7"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861740927,"user_tz":-540,"elapsed":31341,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"8019351e-dd94-4512-c6f7-bf365e5ce8cd"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1632861740929,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1632861740930,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1632861742867,"user_tz":-540,"elapsed":1950,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632861742869,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632861758363,"user_tz":-540,"elapsed":15500,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1632861758364,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632861758365,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"ca38ed89-2614-42a9-e7d7-6fba7da33ef6"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e0473494-8334-42cd-b30a-c1edd18fc511\", \"EfficientNetB1_1.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861762283,"user_tz":-540,"elapsed":3928,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"ae1c93a6-154b-426a-f4b9-1f78dc0371ba"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861763144,"user_tz":-540,"elapsed":865,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380496351473480944"}},"outputId":"4c67453e-0efa-4e7c-b473-df7f15903ae0"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}