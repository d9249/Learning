{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EfficientNetB2_5_(public-, private-).ipynb","provenance":[{"file_id":"1gY_56-XfX-oBZHchFryt_6D9bWOzTJhr","timestamp":1632857703938},{"file_id":"1cG9A1qtLS9c3uxTcl3xu4w5F3TJXkCUX","timestamp":1632856658598},{"file_id":"1Y-_YxYpVOO320qtN6kIts1woIuT4Qnpd","timestamp":1632856641252},{"file_id":"1GhZutwETDh0OrTj9bllcoGlpbaFyvh3j","timestamp":1632853674087},{"file_id":"1ea7CxCY7eB-saFgGFrv2wFMQT_pwl4b5","timestamp":1632853647338},{"file_id":"1MjnIkYhA8n1g73Fhsmx0fFKRn0WYCbDA","timestamp":1632844305319},{"file_id":"16Rs6rfEl4lL3a8MQQ8r9xCoDqFfgKoT4","timestamp":1632844125508},{"file_id":"1YDClRz4UKnFw8POxo1MVhsz73zXeosj3","timestamp":1632826849503},{"file_id":"1zurWApRKXwWSa-ehvU_c4xi9sJSnPOuC","timestamp":1632826831799},{"file_id":"1dMHbUndZGr2BzmZeH2YxAL0QbjsqA8qm","timestamp":1632826763787},{"file_id":"12T8xAJ67HUnP5ZUGTt9syM3xjvOavh6p","timestamp":1632816088595},{"file_id":"1Y2c9MXmZLNEW6WU-oJXgwIvzQ77fxUaR","timestamp":1632815969024},{"file_id":"1Wo8M5eecf-5P8z0ZLjawoNhomWEy4F4z","timestamp":1632815952458},{"file_id":"1Wf0c2C_V_TV76M3yvaCqj4WRhGsfhSR_","timestamp":1632815928461},{"file_id":"1UoAi_OUp5FlBi0pHsVhKqBW3OLHhWd2j","timestamp":1632815272493},{"file_id":"1qZU39IunWaZOPCVpSa0V-8693Jh2Jz0c","timestamp":1632815233099},{"file_id":"1voj3Bcu0zAay7e_kl7qK5f78K9HMMKtM","timestamp":1632806561665},{"file_id":"1zElVRGsS1kg9WNy_6KUvQvaI5xYSdnlD","timestamp":1632806534245},{"file_id":"1OIZKCtwYST5ROVoAH5jE6OyziVLs5YVe","timestamp":1632775577125},{"file_id":"1M8OJEV_AT9MOCy7JGAaVl1j_VfABfzuE","timestamp":1632775493726},{"file_id":"1tLm7xKEM0NUAtTz8MetJXTPqs1Vr30rT","timestamp":1632775476672},{"file_id":"1cQ9_pnDLKsxM2cvx0IWbLgjkO3Cepyu-","timestamp":1632775461739},{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861144091,"user_tz":-540,"elapsed":63,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"294cd35a-3111-41a5-9570-6d5890d09db9"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 28 20:32:26 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861194417,"user_tz":-540,"elapsed":50343,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"6c063cc2-ac01-4879-8d32-286fbffe919e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632861200141,"user_tz":-540,"elapsed":5729,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632861201140,"user_tz":-540,"elapsed":1021,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632861204083,"user_tz":-540,"elapsed":2947,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632861223719,"user_tz":-540,"elapsed":19640,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632861223728,"user_tz":-540,"elapsed":35,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["nunbering = '2'\n","model_save = 'EfficientNetB' + nunbering + '_5'\n","Target_model = 'EfficientNetB' + nunbering + '_model'\n","Target_predict = 'EfficientNetB' + nunbering + '_predict'\n","Target_acc = 'EfficientNetB' + nunbering + '_acc'\n","Target_val = 'EfficientNetB' + nunbering + '_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632861231349,"user_tz":-540,"elapsed":7650,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.EfficientNetB2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632861231350,"user_tz":-540,"elapsed":34,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632861231351,"user_tz":-540,"elapsed":33,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"c9f1e05e-df06-4507-ad5a-3b31b1770c13"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632861231352,"user_tz":-540,"elapsed":24,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632879495635,"user_tz":-540,"elapsed":4912213,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"a4c0ffb6-e0d4-479c-ea55-ebd30595a903"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/500\n","238/238 [==============================] - 68s 158ms/step - loss: 3.4973 - accuracy: 0.1479 - val_loss: 2.5491 - val_accuracy: 0.1014\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 35s 147ms/step - loss: 2.3290 - accuracy: 0.2068 - val_loss: 2.6175 - val_accuracy: 0.1014\n","\n","Epoch 00002: val_accuracy did not improve from 0.10135\n","Epoch 3/500\n","238/238 [==============================] - 35s 145ms/step - loss: 1.9223 - accuracy: 0.3358 - val_loss: 3.3532 - val_accuracy: 0.0946\n","\n","Epoch 00003: val_accuracy did not improve from 0.10135\n","Epoch 4/500\n","238/238 [==============================] - 35s 147ms/step - loss: 1.5620 - accuracy: 0.4537 - val_loss: 4.8016 - val_accuracy: 0.1824\n","\n","Epoch 00004: val_accuracy improved from 0.10135 to 0.18243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 5/500\n","238/238 [==============================] - 35s 148ms/step - loss: 1.2192 - accuracy: 0.5900 - val_loss: 0.8579 - val_accuracy: 0.6824\n","\n","Epoch 00005: val_accuracy improved from 0.18243 to 0.68243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 6/500\n","238/238 [==============================] - 35s 146ms/step - loss: 1.0046 - accuracy: 0.6721 - val_loss: 1.1755 - val_accuracy: 0.6622\n","\n","Epoch 00006: val_accuracy did not improve from 0.68243\n","Epoch 7/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.9100 - accuracy: 0.7142 - val_loss: 0.6759 - val_accuracy: 0.7973\n","\n","Epoch 00007: val_accuracy improved from 0.68243 to 0.79730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 8/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.7944 - accuracy: 0.7484 - val_loss: 3.1482 - val_accuracy: 0.2568\n","\n","Epoch 00008: val_accuracy did not improve from 0.79730\n","Epoch 9/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.7008 - accuracy: 0.7805 - val_loss: 3.7827 - val_accuracy: 0.0946\n","\n","Epoch 00009: val_accuracy did not improve from 0.79730\n","Epoch 10/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.6437 - accuracy: 0.7895 - val_loss: 0.6318 - val_accuracy: 0.8041\n","\n","Epoch 00010: val_accuracy improved from 0.79730 to 0.80405, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 11/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.5775 - accuracy: 0.8205 - val_loss: 0.6079 - val_accuracy: 0.7703\n","\n","Epoch 00011: val_accuracy did not improve from 0.80405\n","Epoch 12/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.5886 - accuracy: 0.8168 - val_loss: 1.0738 - val_accuracy: 0.6892\n","\n","Epoch 00012: val_accuracy did not improve from 0.80405\n","Epoch 13/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.5044 - accuracy: 0.8411 - val_loss: 0.7489 - val_accuracy: 0.7905\n","\n","Epoch 00013: val_accuracy did not improve from 0.80405\n","Epoch 14/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.4970 - accuracy: 0.8411 - val_loss: 0.8050 - val_accuracy: 0.7703\n","\n","Epoch 00014: val_accuracy did not improve from 0.80405\n","Epoch 15/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.4718 - accuracy: 0.8489 - val_loss: 0.7140 - val_accuracy: 0.8108\n","\n","Epoch 00015: val_accuracy improved from 0.80405 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 16/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.4787 - accuracy: 0.8437 - val_loss: 0.5853 - val_accuracy: 0.8176\n","\n","Epoch 00016: val_accuracy improved from 0.81081 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 17/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.4605 - accuracy: 0.8558 - val_loss: 0.4853 - val_accuracy: 0.8514\n","\n","Epoch 00017: val_accuracy improved from 0.81757 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 18/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.4395 - accuracy: 0.8568 - val_loss: 0.5661 - val_accuracy: 0.8649\n","\n","Epoch 00018: val_accuracy improved from 0.85135 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 19/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.3999 - accuracy: 0.8663 - val_loss: 1.2336 - val_accuracy: 0.6689\n","\n","Epoch 00019: val_accuracy did not improve from 0.86486\n","Epoch 20/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.3919 - accuracy: 0.8674 - val_loss: 0.8463 - val_accuracy: 0.7770\n","\n","Epoch 00020: val_accuracy did not improve from 0.86486\n","Epoch 21/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.3843 - accuracy: 0.8821 - val_loss: 0.5263 - val_accuracy: 0.8108\n","\n","Epoch 00021: val_accuracy did not improve from 0.86486\n","Epoch 22/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.3623 - accuracy: 0.8858 - val_loss: 0.5695 - val_accuracy: 0.8378\n","\n","Epoch 00022: val_accuracy did not improve from 0.86486\n","Epoch 23/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.3319 - accuracy: 0.8974 - val_loss: 0.5506 - val_accuracy: 0.8243\n","\n","Epoch 00023: val_accuracy did not improve from 0.86486\n","Epoch 24/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.3180 - accuracy: 0.9000 - val_loss: 0.6001 - val_accuracy: 0.8243\n","\n","Epoch 00024: val_accuracy did not improve from 0.86486\n","Epoch 25/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.3136 - accuracy: 0.9000 - val_loss: 2.8596 - val_accuracy: 0.4324\n","\n","Epoch 00025: val_accuracy did not improve from 0.86486\n","Epoch 26/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.3042 - accuracy: 0.9068 - val_loss: 3.7741 - val_accuracy: 0.3514\n","\n","Epoch 00026: val_accuracy did not improve from 0.86486\n","Epoch 27/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.2780 - accuracy: 0.9142 - val_loss: 1.0858 - val_accuracy: 0.7635\n","\n","Epoch 00027: val_accuracy did not improve from 0.86486\n","Epoch 28/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.2682 - accuracy: 0.9100 - val_loss: 2.8019 - val_accuracy: 0.4459\n","\n","Epoch 00028: val_accuracy did not improve from 0.86486\n","Epoch 29/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.3410 - accuracy: 0.8979 - val_loss: 0.3957 - val_accuracy: 0.8784\n","\n","Epoch 00029: val_accuracy improved from 0.86486 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 30/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.2516 - accuracy: 0.9247 - val_loss: 0.3790 - val_accuracy: 0.8716\n","\n","Epoch 00030: val_accuracy did not improve from 0.87838\n","Epoch 31/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.2607 - accuracy: 0.9158 - val_loss: 0.6573 - val_accuracy: 0.8311\n","\n","Epoch 00031: val_accuracy did not improve from 0.87838\n","Epoch 32/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.2497 - accuracy: 0.9284 - val_loss: 0.6072 - val_accuracy: 0.8243\n","\n","Epoch 00032: val_accuracy did not improve from 0.87838\n","Epoch 33/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.2364 - accuracy: 0.9268 - val_loss: 4.0742 - val_accuracy: 0.2432\n","\n","Epoch 00033: val_accuracy did not improve from 0.87838\n","Epoch 34/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.2321 - accuracy: 0.9253 - val_loss: 0.3292 - val_accuracy: 0.8851\n","\n","Epoch 00034: val_accuracy improved from 0.87838 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 35/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.2731 - accuracy: 0.9147 - val_loss: 5.8101 - val_accuracy: 0.0878\n","\n","Epoch 00035: val_accuracy did not improve from 0.88514\n","Epoch 36/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.2387 - accuracy: 0.9237 - val_loss: 0.4525 - val_accuracy: 0.8649\n","\n","Epoch 00036: val_accuracy did not improve from 0.88514\n","Epoch 37/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1965 - accuracy: 0.9426 - val_loss: 2.7765 - val_accuracy: 0.4324\n","\n","Epoch 00037: val_accuracy did not improve from 0.88514\n","Epoch 38/500\n","238/238 [==============================] - 34s 143ms/step - loss: 0.2083 - accuracy: 0.9342 - val_loss: 0.4400 - val_accuracy: 0.8851\n","\n","Epoch 00038: val_accuracy did not improve from 0.88514\n","Epoch 39/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1994 - accuracy: 0.9342 - val_loss: 0.3847 - val_accuracy: 0.8919\n","\n","Epoch 00039: val_accuracy improved from 0.88514 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 40/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.2239 - accuracy: 0.9300 - val_loss: 3.6579 - val_accuracy: 0.2568\n","\n","Epoch 00040: val_accuracy did not improve from 0.89189\n","Epoch 41/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.2135 - accuracy: 0.9300 - val_loss: 0.4576 - val_accuracy: 0.8514\n","\n","Epoch 00041: val_accuracy did not improve from 0.89189\n","Epoch 42/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1583 - accuracy: 0.9605 - val_loss: 0.4831 - val_accuracy: 0.8716\n","\n","Epoch 00042: val_accuracy did not improve from 0.89189\n","Epoch 43/500\n","238/238 [==============================] - 34s 145ms/step - loss: 0.1616 - accuracy: 0.9489 - val_loss: 0.5288 - val_accuracy: 0.8649\n","\n","Epoch 00043: val_accuracy did not improve from 0.89189\n","Epoch 44/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1966 - accuracy: 0.9384 - val_loss: 0.5512 - val_accuracy: 0.8649\n","\n","Epoch 00044: val_accuracy did not improve from 0.89189\n","Epoch 45/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.1656 - accuracy: 0.9468 - val_loss: 0.9537 - val_accuracy: 0.7838\n","\n","Epoch 00045: val_accuracy did not improve from 0.89189\n","Epoch 46/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1661 - accuracy: 0.9479 - val_loss: 0.4605 - val_accuracy: 0.8716\n","\n","Epoch 00046: val_accuracy did not improve from 0.89189\n","Epoch 47/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.1774 - accuracy: 0.9458 - val_loss: 0.6978 - val_accuracy: 0.8108\n","\n","Epoch 00047: val_accuracy did not improve from 0.89189\n","Epoch 48/500\n","238/238 [==============================] - 34s 144ms/step - loss: 0.1417 - accuracy: 0.9511 - val_loss: 0.6749 - val_accuracy: 0.8446\n","\n","Epoch 00048: val_accuracy did not improve from 0.89189\n","Epoch 49/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1387 - accuracy: 0.9584 - val_loss: 0.9811 - val_accuracy: 0.7770\n","\n","Epoch 00049: val_accuracy did not improve from 0.89189\n","Epoch 50/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1491 - accuracy: 0.9532 - val_loss: 2.1730 - val_accuracy: 0.6351\n","\n","Epoch 00050: val_accuracy did not improve from 0.89189\n","Epoch 51/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1327 - accuracy: 0.9600 - val_loss: 0.4262 - val_accuracy: 0.8784\n","\n","Epoch 00051: val_accuracy did not improve from 0.89189\n","Epoch 52/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0894 - accuracy: 0.9689 - val_loss: 0.9861 - val_accuracy: 0.7297\n","\n","Epoch 00052: val_accuracy did not improve from 0.89189\n","Epoch 53/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.1381 - accuracy: 0.9605 - val_loss: 1.2673 - val_accuracy: 0.7230\n","\n","Epoch 00053: val_accuracy did not improve from 0.89189\n","Epoch 54/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1425 - accuracy: 0.9495 - val_loss: 6.3196 - val_accuracy: 0.2095\n","\n","Epoch 00054: val_accuracy did not improve from 0.89189\n","Epoch 55/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.1356 - accuracy: 0.9547 - val_loss: 0.5975 - val_accuracy: 0.8919\n","\n","Epoch 00055: val_accuracy did not improve from 0.89189\n","Epoch 56/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.1235 - accuracy: 0.9632 - val_loss: 0.5349 - val_accuracy: 0.8649\n","\n","Epoch 00056: val_accuracy did not improve from 0.89189\n","Epoch 57/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1305 - accuracy: 0.9584 - val_loss: 0.3642 - val_accuracy: 0.8986\n","\n","Epoch 00057: val_accuracy improved from 0.89189 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 58/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1248 - accuracy: 0.9563 - val_loss: 3.7799 - val_accuracy: 0.4865\n","\n","Epoch 00058: val_accuracy did not improve from 0.89865\n","Epoch 59/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.1257 - accuracy: 0.9621 - val_loss: 0.5935 - val_accuracy: 0.8784\n","\n","Epoch 00059: val_accuracy did not improve from 0.89865\n","Epoch 60/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1067 - accuracy: 0.9679 - val_loss: 0.6638 - val_accuracy: 0.8446\n","\n","Epoch 00060: val_accuracy did not improve from 0.89865\n","Epoch 61/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.7361 - val_accuracy: 0.8311\n","\n","Epoch 00061: val_accuracy did not improve from 0.89865\n","Epoch 62/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1251 - accuracy: 0.9626 - val_loss: 3.8896 - val_accuracy: 0.2500\n","\n","Epoch 00062: val_accuracy did not improve from 0.89865\n","Epoch 63/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 0.5398 - val_accuracy: 0.8716\n","\n","Epoch 00063: val_accuracy did not improve from 0.89865\n","Epoch 64/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1257 - accuracy: 0.9600 - val_loss: 0.3760 - val_accuracy: 0.8716\n","\n","Epoch 00064: val_accuracy did not improve from 0.89865\n","Epoch 65/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0919 - accuracy: 0.9684 - val_loss: 0.4717 - val_accuracy: 0.8784\n","\n","Epoch 00065: val_accuracy did not improve from 0.89865\n","Epoch 66/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0643 - accuracy: 0.9779 - val_loss: 0.7394 - val_accuracy: 0.8311\n","\n","Epoch 00066: val_accuracy did not improve from 0.89865\n","Epoch 67/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.1053 - accuracy: 0.9689 - val_loss: 0.7940 - val_accuracy: 0.8716\n","\n","Epoch 00067: val_accuracy did not improve from 0.89865\n","Epoch 68/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.1162 - accuracy: 0.9658 - val_loss: 0.5341 - val_accuracy: 0.8986\n","\n","Epoch 00068: val_accuracy did not improve from 0.89865\n","Epoch 69/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.1265 - accuracy: 0.9589 - val_loss: 0.6029 - val_accuracy: 0.8581\n","\n","Epoch 00069: val_accuracy did not improve from 0.89865\n","Epoch 70/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1141 - accuracy: 0.9653 - val_loss: 0.4342 - val_accuracy: 0.8851\n","\n","Epoch 00070: val_accuracy did not improve from 0.89865\n","Epoch 71/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0870 - accuracy: 0.9711 - val_loss: 0.4076 - val_accuracy: 0.9054\n","\n","Epoch 00071: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 72/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 1.8500 - val_accuracy: 0.7365\n","\n","Epoch 00072: val_accuracy did not improve from 0.90541\n","Epoch 73/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0927 - accuracy: 0.9721 - val_loss: 0.4616 - val_accuracy: 0.8784\n","\n","Epoch 00073: val_accuracy did not improve from 0.90541\n","Epoch 74/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 2.0352 - val_accuracy: 0.6081\n","\n","Epoch 00074: val_accuracy did not improve from 0.90541\n","Epoch 75/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.1054 - accuracy: 0.9732 - val_loss: 0.5211 - val_accuracy: 0.8784\n","\n","Epoch 00075: val_accuracy did not improve from 0.90541\n","Epoch 76/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.1048 - accuracy: 0.9589 - val_loss: 4.1978 - val_accuracy: 0.2770\n","\n","Epoch 00076: val_accuracy did not improve from 0.90541\n","Epoch 77/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0980 - accuracy: 0.9689 - val_loss: 0.3915 - val_accuracy: 0.9054\n","\n","Epoch 00077: val_accuracy did not improve from 0.90541\n","Epoch 78/500\n","238/238 [==============================] - 35s 145ms/step - loss: 0.0753 - accuracy: 0.9768 - val_loss: 0.3818 - val_accuracy: 0.9122\n","\n","Epoch 00078: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 79/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0755 - accuracy: 0.9753 - val_loss: 0.5684 - val_accuracy: 0.9122\n","\n","Epoch 00079: val_accuracy did not improve from 0.91216\n","Epoch 80/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0782 - accuracy: 0.9747 - val_loss: 1.3477 - val_accuracy: 0.7432\n","\n","Epoch 00080: val_accuracy did not improve from 0.91216\n","Epoch 81/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 0.6395 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.91216\n","Epoch 82/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0965 - accuracy: 0.9721 - val_loss: 2.5812 - val_accuracy: 0.5000\n","\n","Epoch 00082: val_accuracy did not improve from 0.91216\n","Epoch 83/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0917 - accuracy: 0.9679 - val_loss: 0.8370 - val_accuracy: 0.8581\n","\n","Epoch 00083: val_accuracy did not improve from 0.91216\n","Epoch 84/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 0.4764 - val_accuracy: 0.9122\n","\n","Epoch 00084: val_accuracy did not improve from 0.91216\n","Epoch 85/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0822 - accuracy: 0.9742 - val_loss: 0.5398 - val_accuracy: 0.8716\n","\n","Epoch 00085: val_accuracy did not improve from 0.91216\n","Epoch 86/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0861 - accuracy: 0.9732 - val_loss: 0.4434 - val_accuracy: 0.8986\n","\n","Epoch 00086: val_accuracy did not improve from 0.91216\n","Epoch 87/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0598 - accuracy: 0.9826 - val_loss: 0.5329 - val_accuracy: 0.8919\n","\n","Epoch 00087: val_accuracy did not improve from 0.91216\n","Epoch 88/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0704 - accuracy: 0.9726 - val_loss: 0.9408 - val_accuracy: 0.8311\n","\n","Epoch 00088: val_accuracy did not improve from 0.91216\n","Epoch 89/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.1091 - accuracy: 0.9647 - val_loss: 0.5827 - val_accuracy: 0.8851\n","\n","Epoch 00089: val_accuracy did not improve from 0.91216\n","Epoch 90/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0603 - accuracy: 0.9816 - val_loss: 0.4044 - val_accuracy: 0.9122\n","\n","Epoch 00090: val_accuracy did not improve from 0.91216\n","Epoch 91/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0860 - accuracy: 0.9711 - val_loss: 0.9005 - val_accuracy: 0.8311\n","\n","Epoch 00091: val_accuracy did not improve from 0.91216\n","Epoch 92/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.7441 - val_accuracy: 0.8311\n","\n","Epoch 00092: val_accuracy did not improve from 0.91216\n","Epoch 93/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0765 - accuracy: 0.9774 - val_loss: 3.3121 - val_accuracy: 0.5068\n","\n","Epoch 00093: val_accuracy did not improve from 0.91216\n","Epoch 94/500\n","238/238 [==============================] - 35s 146ms/step - loss: 0.0886 - accuracy: 0.9737 - val_loss: 0.6053 - val_accuracy: 0.8716\n","\n","Epoch 00094: val_accuracy did not improve from 0.91216\n","Epoch 95/500\n","238/238 [==============================] - 35s 147ms/step - loss: 0.0858 - accuracy: 0.9737 - val_loss: 0.4970 - val_accuracy: 0.8649\n","\n","Epoch 00095: val_accuracy did not improve from 0.91216\n","Epoch 96/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0768 - accuracy: 0.9763 - val_loss: 0.7769 - val_accuracy: 0.8514\n","\n","Epoch 00096: val_accuracy did not improve from 0.91216\n","Epoch 97/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0459 - accuracy: 0.9874 - val_loss: 4.6561 - val_accuracy: 0.3108\n","\n","Epoch 00097: val_accuracy did not improve from 0.91216\n","Epoch 98/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.5922 - val_accuracy: 0.8986\n","\n","Epoch 00098: val_accuracy did not improve from 0.91216\n","Epoch 99/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0582 - accuracy: 0.9837 - val_loss: 0.6272 - val_accuracy: 0.8784\n","\n","Epoch 00099: val_accuracy did not improve from 0.91216\n","Epoch 100/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 0.6108 - val_accuracy: 0.8851\n","\n","Epoch 00100: val_accuracy did not improve from 0.91216\n","Epoch 101/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0661 - accuracy: 0.9826 - val_loss: 0.8666 - val_accuracy: 0.8041\n","\n","Epoch 00101: val_accuracy did not improve from 0.91216\n","Epoch 102/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 0.6498 - val_accuracy: 0.8649\n","\n","Epoch 00102: val_accuracy did not improve from 0.91216\n","Epoch 103/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.5254 - val_accuracy: 0.9122\n","\n","Epoch 00103: val_accuracy did not improve from 0.91216\n","Epoch 104/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 0.8720 - val_accuracy: 0.7905\n","\n","Epoch 00104: val_accuracy did not improve from 0.91216\n","Epoch 105/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0665 - accuracy: 0.9837 - val_loss: 0.8375 - val_accuracy: 0.8243\n","\n","Epoch 00105: val_accuracy did not improve from 0.91216\n","Epoch 106/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0651 - accuracy: 0.9832 - val_loss: 0.9626 - val_accuracy: 0.8176\n","\n","Epoch 00106: val_accuracy did not improve from 0.91216\n","Epoch 107/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0689 - accuracy: 0.9795 - val_loss: 0.4981 - val_accuracy: 0.8716\n","\n","Epoch 00107: val_accuracy did not improve from 0.91216\n","Epoch 108/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0763 - accuracy: 0.9747 - val_loss: 0.6006 - val_accuracy: 0.8986\n","\n","Epoch 00108: val_accuracy did not improve from 0.91216\n","Epoch 109/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.6105 - val_accuracy: 0.8716\n","\n","Epoch 00109: val_accuracy did not improve from 0.91216\n","Epoch 110/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0340 - accuracy: 0.9895 - val_loss: 0.6029 - val_accuracy: 0.8716\n","\n","Epoch 00110: val_accuracy did not improve from 0.91216\n","Epoch 111/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0905 - accuracy: 0.9726 - val_loss: 0.7404 - val_accuracy: 0.8581\n","\n","Epoch 00111: val_accuracy did not improve from 0.91216\n","Epoch 112/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0808 - accuracy: 0.9732 - val_loss: 0.4568 - val_accuracy: 0.8649\n","\n","Epoch 00112: val_accuracy did not improve from 0.91216\n","Epoch 113/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0638 - accuracy: 0.9837 - val_loss: 0.4416 - val_accuracy: 0.8919\n","\n","Epoch 00113: val_accuracy did not improve from 0.91216\n","Epoch 114/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 0.4899 - val_accuracy: 0.8851\n","\n","Epoch 00114: val_accuracy did not improve from 0.91216\n","Epoch 115/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.3610 - val_accuracy: 0.8851\n","\n","Epoch 00115: val_accuracy did not improve from 0.91216\n","Epoch 116/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0767 - accuracy: 0.9774 - val_loss: 0.7682 - val_accuracy: 0.8311\n","\n","Epoch 00116: val_accuracy did not improve from 0.91216\n","Epoch 117/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 4.0778 - val_accuracy: 0.3986\n","\n","Epoch 00117: val_accuracy did not improve from 0.91216\n","Epoch 118/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.8327 - val_accuracy: 0.8311\n","\n","Epoch 00118: val_accuracy did not improve from 0.91216\n","Epoch 119/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0652 - accuracy: 0.9811 - val_loss: 0.6735 - val_accuracy: 0.8581\n","\n","Epoch 00119: val_accuracy did not improve from 0.91216\n","Epoch 120/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0588 - accuracy: 0.9832 - val_loss: 2.9249 - val_accuracy: 0.4730\n","\n","Epoch 00120: val_accuracy did not improve from 0.91216\n","Epoch 121/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.5565 - val_accuracy: 0.8716\n","\n","Epoch 00121: val_accuracy did not improve from 0.91216\n","Epoch 122/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0695 - accuracy: 0.9784 - val_loss: 0.4214 - val_accuracy: 0.9122\n","\n","Epoch 00122: val_accuracy did not improve from 0.91216\n","Epoch 123/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.4259 - val_accuracy: 0.9122\n","\n","Epoch 00123: val_accuracy did not improve from 0.91216\n","Epoch 124/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.6499 - val_accuracy: 0.8851\n","\n","Epoch 00124: val_accuracy did not improve from 0.91216\n","Epoch 125/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0800 - accuracy: 0.9768 - val_loss: 1.5841 - val_accuracy: 0.7500\n","\n","Epoch 00125: val_accuracy did not improve from 0.91216\n","Epoch 126/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.5043 - val_accuracy: 0.8919\n","\n","Epoch 00126: val_accuracy did not improve from 0.91216\n","Epoch 127/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.4448 - val_accuracy: 0.9324\n","\n","Epoch 00127: val_accuracy improved from 0.91216 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 128/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.5073 - val_accuracy: 0.8986\n","\n","Epoch 00128: val_accuracy did not improve from 0.93243\n","Epoch 129/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0439 - accuracy: 0.9874 - val_loss: 0.4831 - val_accuracy: 0.8986\n","\n","Epoch 00129: val_accuracy did not improve from 0.93243\n","Epoch 130/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.4850 - val_accuracy: 0.9189\n","\n","Epoch 00130: val_accuracy did not improve from 0.93243\n","Epoch 131/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0602 - accuracy: 0.9795 - val_loss: 6.9464 - val_accuracy: 0.2027\n","\n","Epoch 00131: val_accuracy did not improve from 0.93243\n","Epoch 132/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0456 - accuracy: 0.9879 - val_loss: 0.8140 - val_accuracy: 0.8784\n","\n","Epoch 00132: val_accuracy did not improve from 0.93243\n","Epoch 133/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0357 - accuracy: 0.9932 - val_loss: 0.5744 - val_accuracy: 0.8986\n","\n","Epoch 00133: val_accuracy did not improve from 0.93243\n","Epoch 134/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.3186 - val_accuracy: 0.9324\n","\n","Epoch 00134: val_accuracy did not improve from 0.93243\n","Epoch 135/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 2.1426 - val_accuracy: 0.6689\n","\n","Epoch 00135: val_accuracy did not improve from 0.93243\n","Epoch 136/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0816 - accuracy: 0.9784 - val_loss: 0.7543 - val_accuracy: 0.8649\n","\n","Epoch 00136: val_accuracy did not improve from 0.93243\n","Epoch 137/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0546 - accuracy: 0.9805 - val_loss: 0.7314 - val_accuracy: 0.8851\n","\n","Epoch 00137: val_accuracy did not improve from 0.93243\n","Epoch 138/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0643 - accuracy: 0.9821 - val_loss: 0.5115 - val_accuracy: 0.8919\n","\n","Epoch 00138: val_accuracy did not improve from 0.93243\n","Epoch 139/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0392 - accuracy: 0.9863 - val_loss: 0.6456 - val_accuracy: 0.8851\n","\n","Epoch 00139: val_accuracy did not improve from 0.93243\n","Epoch 140/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.5634 - val_accuracy: 0.8851\n","\n","Epoch 00140: val_accuracy did not improve from 0.93243\n","Epoch 141/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.4826 - val_accuracy: 0.8986\n","\n","Epoch 00141: val_accuracy did not improve from 0.93243\n","Epoch 142/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 1.4275 - val_accuracy: 0.7838\n","\n","Epoch 00142: val_accuracy did not improve from 0.93243\n","Epoch 143/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.5476 - val_accuracy: 0.8919\n","\n","Epoch 00143: val_accuracy did not improve from 0.93243\n","Epoch 144/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.7341 - val_accuracy: 0.8919\n","\n","Epoch 00144: val_accuracy did not improve from 0.93243\n","Epoch 145/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.6350 - val_accuracy: 0.9054\n","\n","Epoch 00145: val_accuracy did not improve from 0.93243\n","Epoch 146/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0696 - accuracy: 0.9816 - val_loss: 0.6682 - val_accuracy: 0.8716\n","\n","Epoch 00146: val_accuracy did not improve from 0.93243\n","Epoch 147/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.4769 - val_accuracy: 0.9122\n","\n","Epoch 00147: val_accuracy did not improve from 0.93243\n","Epoch 148/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.7779 - val_accuracy: 0.8716\n","\n","Epoch 00148: val_accuracy did not improve from 0.93243\n","Epoch 149/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0383 - accuracy: 0.9863 - val_loss: 0.6459 - val_accuracy: 0.8784\n","\n","Epoch 00149: val_accuracy did not improve from 0.93243\n","Epoch 150/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.7647 - val_accuracy: 0.8446\n","\n","Epoch 00150: val_accuracy did not improve from 0.93243\n","Epoch 151/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.7197 - val_accuracy: 0.8243\n","\n","Epoch 00151: val_accuracy did not improve from 0.93243\n","Epoch 152/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: 1.0142 - val_accuracy: 0.8243\n","\n","Epoch 00152: val_accuracy did not improve from 0.93243\n","Epoch 153/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 0.4483 - val_accuracy: 0.9054\n","\n","Epoch 00153: val_accuracy did not improve from 0.93243\n","Epoch 154/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0451 - accuracy: 0.9832 - val_loss: 0.5435 - val_accuracy: 0.8581\n","\n","Epoch 00154: val_accuracy did not improve from 0.93243\n","Epoch 155/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.5553 - val_accuracy: 0.9189\n","\n","Epoch 00155: val_accuracy did not improve from 0.93243\n","Epoch 156/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.3796 - val_accuracy: 0.9122\n","\n","Epoch 00156: val_accuracy did not improve from 0.93243\n","Epoch 157/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0519 - accuracy: 0.9821 - val_loss: 1.7248 - val_accuracy: 0.7568\n","\n","Epoch 00157: val_accuracy did not improve from 0.93243\n","Epoch 158/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.4157 - val_accuracy: 0.9122\n","\n","Epoch 00158: val_accuracy did not improve from 0.93243\n","Epoch 159/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.5562 - val_accuracy: 0.8919\n","\n","Epoch 00159: val_accuracy did not improve from 0.93243\n","Epoch 160/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.6866 - val_accuracy: 0.9054\n","\n","Epoch 00160: val_accuracy did not improve from 0.93243\n","Epoch 161/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.5525 - val_accuracy: 0.8986\n","\n","Epoch 00161: val_accuracy did not improve from 0.93243\n","Epoch 162/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.8008 - val_accuracy: 0.8716\n","\n","Epoch 00162: val_accuracy did not improve from 0.93243\n","Epoch 163/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.4547 - val_accuracy: 0.9189\n","\n","Epoch 00163: val_accuracy did not improve from 0.93243\n","Epoch 164/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.6640 - val_accuracy: 0.8784\n","\n","Epoch 00164: val_accuracy did not improve from 0.93243\n","Epoch 165/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0491 - accuracy: 0.9868 - val_loss: 0.5869 - val_accuracy: 0.8919\n","\n","Epoch 00165: val_accuracy did not improve from 0.93243\n","Epoch 166/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.7260 - val_accuracy: 0.8581\n","\n","Epoch 00166: val_accuracy did not improve from 0.93243\n","Epoch 167/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0606 - accuracy: 0.9832 - val_loss: 0.5142 - val_accuracy: 0.8986\n","\n","Epoch 00167: val_accuracy did not improve from 0.93243\n","Epoch 168/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.6237 - val_accuracy: 0.8851\n","\n","Epoch 00168: val_accuracy did not improve from 0.93243\n","Epoch 169/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.6027 - val_accuracy: 0.8919\n","\n","Epoch 00169: val_accuracy did not improve from 0.93243\n","Epoch 170/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.5874 - val_accuracy: 0.8784\n","\n","Epoch 00170: val_accuracy did not improve from 0.93243\n","Epoch 171/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 1.3735 - val_accuracy: 0.7905\n","\n","Epoch 00171: val_accuracy did not improve from 0.93243\n","Epoch 172/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0324 - accuracy: 0.9879 - val_loss: 0.5318 - val_accuracy: 0.9122\n","\n","Epoch 00172: val_accuracy did not improve from 0.93243\n","Epoch 173/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.8562 - val_accuracy: 0.8581\n","\n","Epoch 00173: val_accuracy did not improve from 0.93243\n","Epoch 174/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.5449 - val_accuracy: 0.9122\n","\n","Epoch 00174: val_accuracy did not improve from 0.93243\n","Epoch 175/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0330 - accuracy: 0.9937 - val_loss: 0.6760 - val_accuracy: 0.8986\n","\n","Epoch 00175: val_accuracy did not improve from 0.93243\n","Epoch 176/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.8415 - val_accuracy: 0.8851\n","\n","Epoch 00176: val_accuracy did not improve from 0.93243\n","Epoch 177/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.7087 - val_accuracy: 0.8716\n","\n","Epoch 00177: val_accuracy did not improve from 0.93243\n","Epoch 178/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0555 - accuracy: 0.9821 - val_loss: 0.5444 - val_accuracy: 0.8784\n","\n","Epoch 00178: val_accuracy did not improve from 0.93243\n","Epoch 179/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0448 - accuracy: 0.9879 - val_loss: 0.4259 - val_accuracy: 0.9122\n","\n","Epoch 00179: val_accuracy did not improve from 0.93243\n","Epoch 180/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.5408 - val_accuracy: 0.8986\n","\n","Epoch 00180: val_accuracy did not improve from 0.93243\n","Epoch 181/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.5142 - val_accuracy: 0.8986\n","\n","Epoch 00181: val_accuracy did not improve from 0.93243\n","Epoch 182/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.5105 - val_accuracy: 0.8716\n","\n","Epoch 00182: val_accuracy did not improve from 0.93243\n","Epoch 183/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.5492 - val_accuracy: 0.9054\n","\n","Epoch 00183: val_accuracy did not improve from 0.93243\n","Epoch 184/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.6743 - val_accuracy: 0.8919\n","\n","Epoch 00184: val_accuracy did not improve from 0.93243\n","Epoch 185/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.6107 - val_accuracy: 0.9122\n","\n","Epoch 00185: val_accuracy did not improve from 0.93243\n","Epoch 186/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.5026 - val_accuracy: 0.9257\n","\n","Epoch 00186: val_accuracy did not improve from 0.93243\n","Epoch 187/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0231 - accuracy: 0.9958 - val_loss: 0.4957 - val_accuracy: 0.9324\n","\n","Epoch 00187: val_accuracy did not improve from 0.93243\n","Epoch 188/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.7209 - val_accuracy: 0.8716\n","\n","Epoch 00188: val_accuracy did not improve from 0.93243\n","Epoch 189/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.6006 - val_accuracy: 0.8986\n","\n","Epoch 00189: val_accuracy did not improve from 0.93243\n","Epoch 190/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.4919 - val_accuracy: 0.9054\n","\n","Epoch 00190: val_accuracy did not improve from 0.93243\n","Epoch 191/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.9481 - val_accuracy: 0.8378\n","\n","Epoch 00191: val_accuracy did not improve from 0.93243\n","Epoch 192/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.5258 - val_accuracy: 0.9189\n","\n","Epoch 00192: val_accuracy did not improve from 0.93243\n","Epoch 193/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.5684 - val_accuracy: 0.9054\n","\n","Epoch 00193: val_accuracy did not improve from 0.93243\n","Epoch 194/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.5509 - val_accuracy: 0.9122\n","\n","Epoch 00194: val_accuracy did not improve from 0.93243\n","Epoch 195/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 0.3586 - val_accuracy: 0.9054\n","\n","Epoch 00195: val_accuracy did not improve from 0.93243\n","Epoch 196/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.4514 - val_accuracy: 0.8919\n","\n","Epoch 00196: val_accuracy did not improve from 0.93243\n","Epoch 197/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.5010 - val_accuracy: 0.9054\n","\n","Epoch 00197: val_accuracy did not improve from 0.93243\n","Epoch 198/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.7444 - val_accuracy: 0.8784\n","\n","Epoch 00198: val_accuracy did not improve from 0.93243\n","Epoch 199/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 1.9538 - val_accuracy: 0.7095\n","\n","Epoch 00199: val_accuracy did not improve from 0.93243\n","Epoch 200/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.8738 - val_accuracy: 0.8581\n","\n","Epoch 00200: val_accuracy did not improve from 0.93243\n","Epoch 201/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.7687 - val_accuracy: 0.9189\n","\n","Epoch 00201: val_accuracy did not improve from 0.93243\n","Epoch 202/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.7215 - val_accuracy: 0.8716\n","\n","Epoch 00202: val_accuracy did not improve from 0.93243\n","Epoch 203/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 0.7359 - val_accuracy: 0.9054\n","\n","Epoch 00203: val_accuracy did not improve from 0.93243\n","Epoch 204/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0220 - accuracy: 0.9905 - val_loss: 0.5974 - val_accuracy: 0.9122\n","\n","Epoch 00204: val_accuracy did not improve from 0.93243\n","Epoch 205/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.4345 - val_accuracy: 0.9189\n","\n","Epoch 00205: val_accuracy did not improve from 0.93243\n","Epoch 206/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 0.6342 - val_accuracy: 0.8784\n","\n","Epoch 00206: val_accuracy did not improve from 0.93243\n","Epoch 207/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0714 - accuracy: 0.9795 - val_loss: 0.7819 - val_accuracy: 0.8716\n","\n","Epoch 00207: val_accuracy did not improve from 0.93243\n","Epoch 208/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0336 - accuracy: 0.9868 - val_loss: 0.5195 - val_accuracy: 0.9122\n","\n","Epoch 00208: val_accuracy did not improve from 0.93243\n","Epoch 209/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.5639 - val_accuracy: 0.9122\n","\n","Epoch 00209: val_accuracy did not improve from 0.93243\n","Epoch 210/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0183 - accuracy: 0.9921 - val_loss: 0.9993 - val_accuracy: 0.8649\n","\n","Epoch 00210: val_accuracy did not improve from 0.93243\n","Epoch 211/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.7050 - val_accuracy: 0.9122\n","\n","Epoch 00211: val_accuracy did not improve from 0.93243\n","Epoch 212/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.8856 - val_accuracy: 0.8581\n","\n","Epoch 00212: val_accuracy did not improve from 0.93243\n","Epoch 213/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.5266 - val_accuracy: 0.9054\n","\n","Epoch 00213: val_accuracy did not improve from 0.93243\n","Epoch 214/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.8013 - val_accuracy: 0.8649\n","\n","Epoch 00214: val_accuracy did not improve from 0.93243\n","Epoch 215/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 1.3027 - val_accuracy: 0.8041\n","\n","Epoch 00215: val_accuracy did not improve from 0.93243\n","Epoch 216/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.4495 - val_accuracy: 0.8919\n","\n","Epoch 00216: val_accuracy did not improve from 0.93243\n","Epoch 217/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0289 - accuracy: 0.9937 - val_loss: 0.6221 - val_accuracy: 0.8851\n","\n","Epoch 00217: val_accuracy did not improve from 0.93243\n","Epoch 218/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.3892 - val_accuracy: 0.9324\n","\n","Epoch 00218: val_accuracy did not improve from 0.93243\n","Epoch 219/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0696 - accuracy: 0.9805 - val_loss: 0.6542 - val_accuracy: 0.8649\n","\n","Epoch 00219: val_accuracy did not improve from 0.93243\n","Epoch 220/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 0.4279 - val_accuracy: 0.9054\n","\n","Epoch 00220: val_accuracy did not improve from 0.93243\n","Epoch 221/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.6485 - val_accuracy: 0.8986\n","\n","Epoch 00221: val_accuracy did not improve from 0.93243\n","Epoch 222/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5171 - val_accuracy: 0.9122\n","\n","Epoch 00222: val_accuracy did not improve from 0.93243\n","Epoch 223/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.6630 - val_accuracy: 0.8716\n","\n","Epoch 00223: val_accuracy did not improve from 0.93243\n","Epoch 224/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.5310 - val_accuracy: 0.8919\n","\n","Epoch 00224: val_accuracy did not improve from 0.93243\n","Epoch 225/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.6766 - val_accuracy: 0.9189\n","\n","Epoch 00225: val_accuracy did not improve from 0.93243\n","Epoch 226/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.6582 - val_accuracy: 0.9122\n","\n","Epoch 00226: val_accuracy did not improve from 0.93243\n","Epoch 227/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.5418 - val_accuracy: 0.8919\n","\n","Epoch 00227: val_accuracy did not improve from 0.93243\n","Epoch 228/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.5224 - val_accuracy: 0.9054\n","\n","Epoch 00228: val_accuracy did not improve from 0.93243\n","Epoch 229/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.5020 - val_accuracy: 0.8986\n","\n","Epoch 00229: val_accuracy did not improve from 0.93243\n","Epoch 230/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.8072 - val_accuracy: 0.8716\n","\n","Epoch 00230: val_accuracy did not improve from 0.93243\n","Epoch 231/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.4876 - val_accuracy: 0.9054\n","\n","Epoch 00231: val_accuracy did not improve from 0.93243\n","Epoch 232/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.4217 - val_accuracy: 0.9189\n","\n","Epoch 00232: val_accuracy did not improve from 0.93243\n","Epoch 233/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.7321 - val_accuracy: 0.9054\n","\n","Epoch 00233: val_accuracy did not improve from 0.93243\n","Epoch 234/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.6170 - val_accuracy: 0.8919\n","\n","Epoch 00234: val_accuracy did not improve from 0.93243\n","Epoch 235/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4689 - val_accuracy: 0.9189\n","\n","Epoch 00235: val_accuracy did not improve from 0.93243\n","Epoch 236/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.6524 - val_accuracy: 0.9054\n","\n","Epoch 00236: val_accuracy did not improve from 0.93243\n","Epoch 237/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.7513 - val_accuracy: 0.8649\n","\n","Epoch 00237: val_accuracy did not improve from 0.93243\n","Epoch 238/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 0.9500 - val_accuracy: 0.8581\n","\n","Epoch 00238: val_accuracy did not improve from 0.93243\n","Epoch 239/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.4481 - val_accuracy: 0.9324\n","\n","Epoch 00239: val_accuracy did not improve from 0.93243\n","Epoch 240/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.6384 - val_accuracy: 0.8784\n","\n","Epoch 00240: val_accuracy did not improve from 0.93243\n","Epoch 241/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.5501 - val_accuracy: 0.8919\n","\n","Epoch 00241: val_accuracy did not improve from 0.93243\n","Epoch 242/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.6120 - val_accuracy: 0.8649\n","\n","Epoch 00242: val_accuracy did not improve from 0.93243\n","Epoch 243/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.8121 - val_accuracy: 0.8784\n","\n","Epoch 00243: val_accuracy did not improve from 0.93243\n","Epoch 244/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 1.5036 - val_accuracy: 0.7500\n","\n","Epoch 00244: val_accuracy did not improve from 0.93243\n","Epoch 245/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0497 - accuracy: 0.9842 - val_loss: 0.6057 - val_accuracy: 0.8581\n","\n","Epoch 00245: val_accuracy did not improve from 0.93243\n","Epoch 246/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0440 - accuracy: 0.9879 - val_loss: 0.6309 - val_accuracy: 0.8986\n","\n","Epoch 00246: val_accuracy did not improve from 0.93243\n","Epoch 247/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.7112 - val_accuracy: 0.8919\n","\n","Epoch 00247: val_accuracy did not improve from 0.93243\n","Epoch 248/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.6561 - val_accuracy: 0.8851\n","\n","Epoch 00248: val_accuracy did not improve from 0.93243\n","Epoch 249/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.5817 - val_accuracy: 0.9189\n","\n","Epoch 00249: val_accuracy did not improve from 0.93243\n","Epoch 250/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.8048 - val_accuracy: 0.8716\n","\n","Epoch 00250: val_accuracy did not improve from 0.93243\n","Epoch 251/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.7163 - val_accuracy: 0.9054\n","\n","Epoch 00251: val_accuracy did not improve from 0.93243\n","Epoch 252/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 1.5596 - val_accuracy: 0.7838\n","\n","Epoch 00252: val_accuracy did not improve from 0.93243\n","Epoch 253/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.7166 - val_accuracy: 0.9054\n","\n","Epoch 00253: val_accuracy did not improve from 0.93243\n","Epoch 254/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.9684 - val_accuracy: 0.8649\n","\n","Epoch 00254: val_accuracy did not improve from 0.93243\n","Epoch 255/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.6930 - val_accuracy: 0.8784\n","\n","Epoch 00255: val_accuracy did not improve from 0.93243\n","Epoch 256/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.8020 - val_accuracy: 0.8716\n","\n","Epoch 00256: val_accuracy did not improve from 0.93243\n","Epoch 257/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.5894 - val_accuracy: 0.8919\n","\n","Epoch 00257: val_accuracy did not improve from 0.93243\n","Epoch 258/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0366 - accuracy: 0.9911 - val_loss: 0.8633 - val_accuracy: 0.8649\n","\n","Epoch 00258: val_accuracy did not improve from 0.93243\n","Epoch 259/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.8256 - val_accuracy: 0.8716\n","\n","Epoch 00259: val_accuracy did not improve from 0.93243\n","Epoch 260/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.7018 - val_accuracy: 0.9054\n","\n","Epoch 00260: val_accuracy did not improve from 0.93243\n","Epoch 261/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.9253 - val_accuracy: 0.8649\n","\n","Epoch 00261: val_accuracy did not improve from 0.93243\n","Epoch 262/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.7313 - val_accuracy: 0.8716\n","\n","Epoch 00262: val_accuracy did not improve from 0.93243\n","Epoch 263/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.6450 - val_accuracy: 0.8986\n","\n","Epoch 00263: val_accuracy did not improve from 0.93243\n","Epoch 264/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.7679 - val_accuracy: 0.8986\n","\n","Epoch 00264: val_accuracy did not improve from 0.93243\n","Epoch 265/500\n","238/238 [==============================] - 35s 148ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.6215 - val_accuracy: 0.8986\n","\n","Epoch 00265: val_accuracy did not improve from 0.93243\n","Epoch 266/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 0.5713 - val_accuracy: 0.8986\n","\n","Epoch 00266: val_accuracy did not improve from 0.93243\n","Epoch 267/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.6432 - val_accuracy: 0.8986\n","\n","Epoch 00267: val_accuracy did not improve from 0.93243\n","Epoch 268/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.7176 - val_accuracy: 0.8986\n","\n","Epoch 00268: val_accuracy did not improve from 0.93243\n","Epoch 269/500\n","238/238 [==============================] - 35s 149ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.5334 - val_accuracy: 0.9122\n","\n","Epoch 00269: val_accuracy did not improve from 0.93243\n","Epoch 270/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 1.9784 - val_accuracy: 0.7635\n","\n","Epoch 00270: val_accuracy did not improve from 0.93243\n","Epoch 271/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.6428 - val_accuracy: 0.8986\n","\n","Epoch 00271: val_accuracy did not improve from 0.93243\n","Epoch 272/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.6877 - val_accuracy: 0.8919\n","\n","Epoch 00272: val_accuracy did not improve from 0.93243\n","Epoch 273/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0376 - accuracy: 0.9900 - val_loss: 0.9455 - val_accuracy: 0.8784\n","\n","Epoch 00273: val_accuracy did not improve from 0.93243\n","Epoch 274/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0254 - accuracy: 0.9895 - val_loss: 2.3681 - val_accuracy: 0.7162\n","\n","Epoch 00274: val_accuracy did not improve from 0.93243\n","Epoch 275/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.6714 - val_accuracy: 0.8919\n","\n","Epoch 00275: val_accuracy did not improve from 0.93243\n","Epoch 276/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.6564 - val_accuracy: 0.8986\n","\n","Epoch 00276: val_accuracy did not improve from 0.93243\n","Epoch 277/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.8551 - val_accuracy: 0.8919\n","\n","Epoch 00277: val_accuracy did not improve from 0.93243\n","Epoch 278/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.8542 - val_accuracy: 0.8919\n","\n","Epoch 00278: val_accuracy did not improve from 0.93243\n","Epoch 279/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0493 - accuracy: 0.9889 - val_loss: 0.6837 - val_accuracy: 0.8716\n","\n","Epoch 00279: val_accuracy did not improve from 0.93243\n","Epoch 280/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0289 - accuracy: 0.9932 - val_loss: 0.6733 - val_accuracy: 0.8851\n","\n","Epoch 00280: val_accuracy did not improve from 0.93243\n","Epoch 281/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.6031 - val_accuracy: 0.9324\n","\n","Epoch 00281: val_accuracy did not improve from 0.93243\n","Epoch 282/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.6253 - val_accuracy: 0.8851\n","\n","Epoch 00282: val_accuracy did not improve from 0.93243\n","Epoch 283/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.5682 - val_accuracy: 0.8986\n","\n","Epoch 00283: val_accuracy did not improve from 0.93243\n","Epoch 284/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.6839 - val_accuracy: 0.9189\n","\n","Epoch 00284: val_accuracy did not improve from 0.93243\n","Epoch 285/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.5543 - val_accuracy: 0.8919\n","\n","Epoch 00285: val_accuracy did not improve from 0.93243\n","Epoch 286/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.8422 - val_accuracy: 0.8986\n","\n","Epoch 00286: val_accuracy did not improve from 0.93243\n","Epoch 287/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.6401 - val_accuracy: 0.8986\n","\n","Epoch 00287: val_accuracy did not improve from 0.93243\n","Epoch 288/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 1.1110 - val_accuracy: 0.7973\n","\n","Epoch 00288: val_accuracy did not improve from 0.93243\n","Epoch 289/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.7929 - val_accuracy: 0.8986\n","\n","Epoch 00289: val_accuracy did not improve from 0.93243\n","Epoch 290/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6316 - val_accuracy: 0.9054\n","\n","Epoch 00290: val_accuracy did not improve from 0.93243\n","Epoch 291/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 0.5191 - val_accuracy: 0.9189\n","\n","Epoch 00291: val_accuracy did not improve from 0.93243\n","Epoch 292/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.6741 - val_accuracy: 0.9122\n","\n","Epoch 00292: val_accuracy did not improve from 0.93243\n","Epoch 293/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.7651 - val_accuracy: 0.9054\n","\n","Epoch 00293: val_accuracy did not improve from 0.93243\n","Epoch 294/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.6776 - val_accuracy: 0.9054\n","\n","Epoch 00294: val_accuracy did not improve from 0.93243\n","Epoch 295/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0517 - accuracy: 0.9847 - val_loss: 0.4928 - val_accuracy: 0.9189\n","\n","Epoch 00295: val_accuracy did not improve from 0.93243\n","Epoch 296/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0387 - accuracy: 0.9889 - val_loss: 0.6885 - val_accuracy: 0.8649\n","\n","Epoch 00296: val_accuracy did not improve from 0.93243\n","Epoch 297/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.6558 - val_accuracy: 0.9054\n","\n","Epoch 00297: val_accuracy did not improve from 0.93243\n","Epoch 298/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.5892 - val_accuracy: 0.9324\n","\n","Epoch 00298: val_accuracy did not improve from 0.93243\n","Epoch 299/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.7190 - val_accuracy: 0.9122\n","\n","Epoch 00299: val_accuracy did not improve from 0.93243\n","Epoch 300/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.6343 - val_accuracy: 0.9054\n","\n","Epoch 00300: val_accuracy did not improve from 0.93243\n","Epoch 301/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.6380 - val_accuracy: 0.9189\n","\n","Epoch 00301: val_accuracy did not improve from 0.93243\n","Epoch 302/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.6787 - val_accuracy: 0.9122\n","\n","Epoch 00302: val_accuracy did not improve from 0.93243\n","Epoch 303/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5714 - val_accuracy: 0.9324\n","\n","Epoch 00303: val_accuracy did not improve from 0.93243\n","Epoch 304/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.8122 - val_accuracy: 0.8514\n","\n","Epoch 00304: val_accuracy did not improve from 0.93243\n","Epoch 305/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 0.6632 - val_accuracy: 0.9122\n","\n","Epoch 00305: val_accuracy did not improve from 0.93243\n","Epoch 306/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.8343 - val_accuracy: 0.8784\n","\n","Epoch 00306: val_accuracy did not improve from 0.93243\n","Epoch 307/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.6220 - val_accuracy: 0.9122\n","\n","Epoch 00307: val_accuracy did not improve from 0.93243\n","Epoch 308/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.5844 - val_accuracy: 0.8986\n","\n","Epoch 00308: val_accuracy did not improve from 0.93243\n","Epoch 309/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.6967 - val_accuracy: 0.8919\n","\n","Epoch 00309: val_accuracy did not improve from 0.93243\n","Epoch 310/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.5765 - val_accuracy: 0.9054\n","\n","Epoch 00310: val_accuracy did not improve from 0.93243\n","Epoch 311/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.4369 - val_accuracy: 0.9122\n","\n","Epoch 00311: val_accuracy did not improve from 0.93243\n","Epoch 312/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.8410 - val_accuracy: 0.9054\n","\n","Epoch 00312: val_accuracy did not improve from 0.93243\n","Epoch 313/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.6430 - val_accuracy: 0.9054\n","\n","Epoch 00313: val_accuracy did not improve from 0.93243\n","Epoch 314/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0357 - accuracy: 0.9932 - val_loss: 0.7145 - val_accuracy: 0.8716\n","\n","Epoch 00314: val_accuracy did not improve from 0.93243\n","Epoch 315/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.7019 - val_accuracy: 0.9054\n","\n","Epoch 00315: val_accuracy did not improve from 0.93243\n","Epoch 316/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.5916 - val_accuracy: 0.9122\n","\n","Epoch 00316: val_accuracy did not improve from 0.93243\n","Epoch 317/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.7607 - val_accuracy: 0.8851\n","\n","Epoch 00317: val_accuracy did not improve from 0.93243\n","Epoch 318/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.7378 - val_accuracy: 0.8851\n","\n","Epoch 00318: val_accuracy did not improve from 0.93243\n","Epoch 319/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.8128 - val_accuracy: 0.9122\n","\n","Epoch 00319: val_accuracy did not improve from 0.93243\n","Epoch 320/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.8415 - val_accuracy: 0.9054\n","\n","Epoch 00320: val_accuracy did not improve from 0.93243\n","Epoch 321/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0434 - accuracy: 0.9879 - val_loss: 0.7670 - val_accuracy: 0.8919\n","\n","Epoch 00321: val_accuracy did not improve from 0.93243\n","Epoch 322/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.9952 - val_accuracy: 0.8784\n","\n","Epoch 00322: val_accuracy did not improve from 0.93243\n","Epoch 323/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.7953 - val_accuracy: 0.8986\n","\n","Epoch 00323: val_accuracy did not improve from 0.93243\n","Epoch 324/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.6785 - val_accuracy: 0.8986\n","\n","Epoch 00324: val_accuracy did not improve from 0.93243\n","Epoch 325/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.7254 - val_accuracy: 0.8851\n","\n","Epoch 00325: val_accuracy did not improve from 0.93243\n","Epoch 326/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0294 - accuracy: 0.9884 - val_loss: 0.8479 - val_accuracy: 0.8784\n","\n","Epoch 00326: val_accuracy did not improve from 0.93243\n","Epoch 327/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0209 - accuracy: 0.9900 - val_loss: 0.9456 - val_accuracy: 0.8986\n","\n","Epoch 00327: val_accuracy did not improve from 0.93243\n","Epoch 328/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.9656 - val_accuracy: 0.8986\n","\n","Epoch 00328: val_accuracy did not improve from 0.93243\n","Epoch 329/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0108 - accuracy: 0.9984 - val_loss: 0.6817 - val_accuracy: 0.8986\n","\n","Epoch 00329: val_accuracy did not improve from 0.93243\n","Epoch 330/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0460 - accuracy: 0.9911 - val_loss: 2.6214 - val_accuracy: 0.7230\n","\n","Epoch 00330: val_accuracy did not improve from 0.93243\n","Epoch 331/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.5688 - val_accuracy: 0.8986\n","\n","Epoch 00331: val_accuracy did not improve from 0.93243\n","Epoch 332/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.8488 - val_accuracy: 0.8716\n","\n","Epoch 00332: val_accuracy did not improve from 0.93243\n","Epoch 333/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.6286 - val_accuracy: 0.9054\n","\n","Epoch 00333: val_accuracy did not improve from 0.93243\n","Epoch 334/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.8781 - val_accuracy: 0.8716\n","\n","Epoch 00334: val_accuracy did not improve from 0.93243\n","Epoch 335/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.5486 - val_accuracy: 0.8919\n","\n","Epoch 00335: val_accuracy did not improve from 0.93243\n","Epoch 336/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.7439 - val_accuracy: 0.8919\n","\n","Epoch 00336: val_accuracy did not improve from 0.93243\n","Epoch 337/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.7019 - val_accuracy: 0.9054\n","\n","Epoch 00337: val_accuracy did not improve from 0.93243\n","Epoch 338/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.6195 - val_accuracy: 0.9054\n","\n","Epoch 00338: val_accuracy did not improve from 0.93243\n","Epoch 339/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.6196 - val_accuracy: 0.9054\n","\n","Epoch 00339: val_accuracy did not improve from 0.93243\n","Epoch 340/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5758 - val_accuracy: 0.8986\n","\n","Epoch 00340: val_accuracy did not improve from 0.93243\n","Epoch 341/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.6480 - val_accuracy: 0.9054\n","\n","Epoch 00341: val_accuracy did not improve from 0.93243\n","Epoch 342/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.8057 - val_accuracy: 0.8716\n","\n","Epoch 00342: val_accuracy did not improve from 0.93243\n","Epoch 343/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 0.7329 - val_accuracy: 0.8851\n","\n","Epoch 00343: val_accuracy did not improve from 0.93243\n","Epoch 344/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.6433 - val_accuracy: 0.8919\n","\n","Epoch 00344: val_accuracy did not improve from 0.93243\n","Epoch 345/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.7995 - val_accuracy: 0.8919\n","\n","Epoch 00345: val_accuracy did not improve from 0.93243\n","Epoch 346/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.6679 - val_accuracy: 0.8851\n","\n","Epoch 00346: val_accuracy did not improve from 0.93243\n","Epoch 347/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6675 - val_accuracy: 0.8919\n","\n","Epoch 00347: val_accuracy did not improve from 0.93243\n","Epoch 348/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.6832 - val_accuracy: 0.8919\n","\n","Epoch 00348: val_accuracy did not improve from 0.93243\n","Epoch 349/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.6242 - val_accuracy: 0.8919\n","\n","Epoch 00349: val_accuracy did not improve from 0.93243\n","Epoch 350/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.6286 - val_accuracy: 0.8716\n","\n","Epoch 00350: val_accuracy did not improve from 0.93243\n","Epoch 351/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 1.1732 - val_accuracy: 0.8041\n","\n","Epoch 00351: val_accuracy did not improve from 0.93243\n","Epoch 352/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 1.1361 - val_accuracy: 0.8514\n","\n","Epoch 00352: val_accuracy did not improve from 0.93243\n","Epoch 353/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.7649 - val_accuracy: 0.8851\n","\n","Epoch 00353: val_accuracy did not improve from 0.93243\n","Epoch 354/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.6988 - val_accuracy: 0.9054\n","\n","Epoch 00354: val_accuracy did not improve from 0.93243\n","Epoch 355/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0119 - accuracy: 0.9947 - val_loss: 0.6434 - val_accuracy: 0.9054\n","\n","Epoch 00355: val_accuracy did not improve from 0.93243\n","Epoch 356/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0167 - accuracy: 0.9916 - val_loss: 0.6966 - val_accuracy: 0.8784\n","\n","Epoch 00356: val_accuracy did not improve from 0.93243\n","Epoch 357/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4150 - val_accuracy: 0.9189\n","\n","Epoch 00357: val_accuracy did not improve from 0.93243\n","Epoch 358/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5372 - val_accuracy: 0.8986\n","\n","Epoch 00358: val_accuracy did not improve from 0.93243\n","Epoch 359/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.8813 - val_accuracy: 0.8649\n","\n","Epoch 00359: val_accuracy did not improve from 0.93243\n","Epoch 360/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.7398 - val_accuracy: 0.8851\n","\n","Epoch 00360: val_accuracy did not improve from 0.93243\n","Epoch 361/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0334 - accuracy: 0.9916 - val_loss: 0.7117 - val_accuracy: 0.9054\n","\n","Epoch 00361: val_accuracy did not improve from 0.93243\n","Epoch 362/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.5376 - val_accuracy: 0.9189\n","\n","Epoch 00362: val_accuracy did not improve from 0.93243\n","Epoch 363/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.7192 - val_accuracy: 0.9122\n","\n","Epoch 00363: val_accuracy did not improve from 0.93243\n","Epoch 364/500\n","238/238 [==============================] - 37s 156ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6476 - val_accuracy: 0.9122\n","\n","Epoch 00364: val_accuracy did not improve from 0.93243\n","Epoch 365/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.7708 - val_accuracy: 0.8986\n","\n","Epoch 00365: val_accuracy did not improve from 0.93243\n","Epoch 366/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.6313 - val_accuracy: 0.8919\n","\n","Epoch 00366: val_accuracy did not improve from 0.93243\n","Epoch 367/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6879 - val_accuracy: 0.9054\n","\n","Epoch 00367: val_accuracy did not improve from 0.93243\n","Epoch 368/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.8725 - val_accuracy: 0.8784\n","\n","Epoch 00368: val_accuracy did not improve from 0.93243\n","Epoch 369/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0273 - accuracy: 0.9926 - val_loss: 0.6687 - val_accuracy: 0.8851\n","\n","Epoch 00369: val_accuracy did not improve from 0.93243\n","Epoch 370/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.8758 - val_accuracy: 0.8446\n","\n","Epoch 00370: val_accuracy did not improve from 0.93243\n","Epoch 371/500\n","238/238 [==============================] - 37s 157ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.4695 - val_accuracy: 0.9122\n","\n","Epoch 00371: val_accuracy did not improve from 0.93243\n","Epoch 372/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.6452 - val_accuracy: 0.8919\n","\n","Epoch 00372: val_accuracy did not improve from 0.93243\n","Epoch 373/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5836 - val_accuracy: 0.9189\n","\n","Epoch 00373: val_accuracy did not improve from 0.93243\n","Epoch 374/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.6513 - val_accuracy: 0.8919\n","\n","Epoch 00374: val_accuracy did not improve from 0.93243\n","Epoch 375/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5883 - val_accuracy: 0.8986\n","\n","Epoch 00375: val_accuracy did not improve from 0.93243\n","Epoch 376/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.7208 - val_accuracy: 0.8851\n","\n","Epoch 00376: val_accuracy did not improve from 0.93243\n","Epoch 377/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.9762 - val_accuracy: 0.8784\n","\n","Epoch 00377: val_accuracy did not improve from 0.93243\n","Epoch 378/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.8522 - val_accuracy: 0.8716\n","\n","Epoch 00378: val_accuracy did not improve from 0.93243\n","Epoch 379/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.7044 - val_accuracy: 0.8919\n","\n","Epoch 00379: val_accuracy did not improve from 0.93243\n","Epoch 380/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0345 - accuracy: 0.9921 - val_loss: 0.7446 - val_accuracy: 0.9054\n","\n","Epoch 00380: val_accuracy did not improve from 0.93243\n","Epoch 381/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.7459 - val_accuracy: 0.8986\n","\n","Epoch 00381: val_accuracy did not improve from 0.93243\n","Epoch 382/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5820 - val_accuracy: 0.9324\n","\n","Epoch 00382: val_accuracy did not improve from 0.93243\n","Epoch 383/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5346 - val_accuracy: 0.9054\n","\n","Epoch 00383: val_accuracy did not improve from 0.93243\n","Epoch 384/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.6210 - val_accuracy: 0.9054\n","\n","Epoch 00384: val_accuracy did not improve from 0.93243\n","Epoch 385/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8986\n","\n","Epoch 00385: val_accuracy did not improve from 0.93243\n","Epoch 386/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 1.0867 - val_accuracy: 0.8851\n","\n","Epoch 00386: val_accuracy did not improve from 0.93243\n","Epoch 387/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.6807 - val_accuracy: 0.8919\n","\n","Epoch 00387: val_accuracy did not improve from 0.93243\n","Epoch 388/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.7164 - val_accuracy: 0.9122\n","\n","Epoch 00388: val_accuracy did not improve from 0.93243\n","Epoch 389/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6675 - val_accuracy: 0.9054\n","\n","Epoch 00389: val_accuracy did not improve from 0.93243\n","Epoch 390/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.6790 - val_accuracy: 0.8986\n","\n","Epoch 00390: val_accuracy did not improve from 0.93243\n","Epoch 391/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.8066 - val_accuracy: 0.9054\n","\n","Epoch 00391: val_accuracy did not improve from 0.93243\n","Epoch 392/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 0.9447 - val_accuracy: 0.8716\n","\n","Epoch 00392: val_accuracy did not improve from 0.93243\n","Epoch 393/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.7090 - val_accuracy: 0.9189\n","\n","Epoch 00393: val_accuracy did not improve from 0.93243\n","Epoch 394/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.6984 - val_accuracy: 0.9189\n","\n","Epoch 00394: val_accuracy did not improve from 0.93243\n","Epoch 395/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.7026 - val_accuracy: 0.8986\n","\n","Epoch 00395: val_accuracy did not improve from 0.93243\n","Epoch 396/500\n","238/238 [==============================] - 36s 149ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.7230 - val_accuracy: 0.8919\n","\n","Epoch 00396: val_accuracy did not improve from 0.93243\n","Epoch 397/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.5227 - val_accuracy: 0.9257\n","\n","Epoch 00397: val_accuracy did not improve from 0.93243\n","Epoch 398/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0100 - accuracy: 0.9947 - val_loss: 0.5081 - val_accuracy: 0.9189\n","\n","Epoch 00398: val_accuracy did not improve from 0.93243\n","Epoch 399/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.3208 - val_accuracy: 0.9324\n","\n","Epoch 00399: val_accuracy did not improve from 0.93243\n","Epoch 400/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5919 - val_accuracy: 0.9189\n","\n","Epoch 00400: val_accuracy did not improve from 0.93243\n","Epoch 401/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0068 - accuracy: 0.9958 - val_loss: 0.5418 - val_accuracy: 0.9122\n","\n","Epoch 00401: val_accuracy did not improve from 0.93243\n","Epoch 402/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.8420 - val_accuracy: 0.8851\n","\n","Epoch 00402: val_accuracy did not improve from 0.93243\n","Epoch 403/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.5939 - val_accuracy: 0.9054\n","\n","Epoch 00403: val_accuracy did not improve from 0.93243\n","Epoch 404/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.5910 - val_accuracy: 0.9054\n","\n","Epoch 00404: val_accuracy did not improve from 0.93243\n","Epoch 405/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.6198 - val_accuracy: 0.9122\n","\n","Epoch 00405: val_accuracy did not improve from 0.93243\n","Epoch 406/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.8730 - val_accuracy: 0.8716\n","\n","Epoch 00406: val_accuracy did not improve from 0.93243\n","Epoch 407/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6710 - val_accuracy: 0.9122\n","\n","Epoch 00407: val_accuracy did not improve from 0.93243\n","Epoch 408/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.7988 - val_accuracy: 0.8986\n","\n","Epoch 00408: val_accuracy did not improve from 0.93243\n","Epoch 409/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.6467 - val_accuracy: 0.9054\n","\n","Epoch 00409: val_accuracy did not improve from 0.93243\n","Epoch 410/500\n","238/238 [==============================] - 36s 150ms/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.6675 - val_accuracy: 0.9054\n","\n","Epoch 00410: val_accuracy did not improve from 0.93243\n","Epoch 411/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.8631 - val_accuracy: 0.8784\n","\n","Epoch 00411: val_accuracy did not improve from 0.93243\n","Epoch 412/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.0568 - val_accuracy: 0.8649\n","\n","Epoch 00412: val_accuracy did not improve from 0.93243\n","Epoch 413/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4812 - val_accuracy: 0.9257\n","\n","Epoch 00413: val_accuracy did not improve from 0.93243\n","Epoch 414/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.5071 - val_accuracy: 0.9189\n","\n","Epoch 00414: val_accuracy did not improve from 0.93243\n","Epoch 415/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5166 - val_accuracy: 0.9527\n","\n","Epoch 00415: val_accuracy improved from 0.93243 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB2_5.h5\n","Epoch 416/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.7453 - val_accuracy: 0.8986\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.7564 - val_accuracy: 0.8986\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.6951 - val_accuracy: 0.8986\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6498 - val_accuracy: 0.8919\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5717 - val_accuracy: 0.9257\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6442 - val_accuracy: 0.9257\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.6477 - val_accuracy: 0.9122\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.7116 - val_accuracy: 0.8851\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.6466 - val_accuracy: 0.9122\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.9427 - val_accuracy: 0.9054\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.6110 - val_accuracy: 0.9054\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0332 - accuracy: 0.9905 - val_loss: 0.9524 - val_accuracy: 0.8851\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 1.0668 - val_accuracy: 0.8716\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 2.2385 - val_accuracy: 0.7095\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.8161 - val_accuracy: 0.8919\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.7097 - val_accuracy: 0.8986\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 1.1674 - val_accuracy: 0.8311\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.8109 - val_accuracy: 0.9054\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5465 - val_accuracy: 0.9189\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.5480 - val_accuracy: 0.9324\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.6487 - val_accuracy: 0.8851\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.4354 - val_accuracy: 0.9122\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5831 - val_accuracy: 0.9122\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.5726 - val_accuracy: 0.8986\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.6084 - val_accuracy: 0.9122\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.5390 - val_accuracy: 0.9054\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.6093 - val_accuracy: 0.9257\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.6694 - val_accuracy: 0.9054\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 37s 157ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.7598 - val_accuracy: 0.8716\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.8887 - val_accuracy: 0.8784\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.5886 - val_accuracy: 0.9257\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.7137 - val_accuracy: 0.8986\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.7365 - val_accuracy: 0.8986\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.6117 - val_accuracy: 0.8919\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.7293 - val_accuracy: 0.9122\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.6250 - val_accuracy: 0.9324\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.4974 - val_accuracy: 0.9257\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.5265 - val_accuracy: 0.9189\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.6332 - val_accuracy: 0.9054\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.6153 - val_accuracy: 0.9324\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4954 - val_accuracy: 0.8986\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.7119 - val_accuracy: 0.9054\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.7810 - val_accuracy: 0.9189\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.7261 - val_accuracy: 0.8649\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.6523 - val_accuracy: 0.9257\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.9095 - val_accuracy: 0.8649\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.6660 - val_accuracy: 0.9054\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5211 - val_accuracy: 0.9189\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5747 - val_accuracy: 0.9054\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0289 - accuracy: 0.9937 - val_loss: 2.3302 - val_accuracy: 0.7365\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.6594 - val_accuracy: 0.9054\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 38s 158ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.6379 - val_accuracy: 0.8919\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.6881 - val_accuracy: 0.8851\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.7974 - val_accuracy: 0.8784\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 0.7682 - val_accuracy: 0.9257\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.7429 - val_accuracy: 0.9054\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.9081 - val_accuracy: 0.9054\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.9636 - val_accuracy: 0.8784\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.8514\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.7642 - val_accuracy: 0.9122\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.7104 - val_accuracy: 0.9054\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.6857 - val_accuracy: 0.9189\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 36s 151ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 0.7915 - val_accuracy: 0.8919\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.8244 - val_accuracy: 0.8919\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.8927 - val_accuracy: 0.9122\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0311 - accuracy: 0.9926 - val_loss: 0.7089 - val_accuracy: 0.8851\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.7474 - val_accuracy: 0.8919\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.7241 - val_accuracy: 0.9122\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.7461 - val_accuracy: 0.8851\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.7886 - val_accuracy: 0.9122\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 37s 154ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.7630 - val_accuracy: 0.8986\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0180 - accuracy: 0.9926 - val_loss: 0.9882 - val_accuracy: 0.8784\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.8709 - val_accuracy: 0.9054\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.7005 - val_accuracy: 0.9122\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.5957 - val_accuracy: 0.9122\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 36s 152ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.7680 - val_accuracy: 0.9054\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 36s 153ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.8910 - val_accuracy: 0.8784\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 37s 153ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.6442 - val_accuracy: 0.9392\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 37s 156ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.7144 - val_accuracy: 0.9122\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 37s 156ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.9444 - val_accuracy: 0.9122\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 37s 155ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.7237 - val_accuracy: 0.8986\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 37s 157ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.8285 - val_accuracy: 0.9189\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 37s 157ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.8340 - val_accuracy: 0.9122\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 37s 157ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 0.8953 - val_accuracy: 0.8851\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 38s 159ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.7625 - val_accuracy: 0.8784\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3d1a1c6890>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632879495637,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"c64798b6-4a25-4080-ff09-5f88fec9e8b6"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632879524659,"user_tz":-540,"elapsed":29026,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-"},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632879558663,"user_tz":-540,"elapsed":32276,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"05785ac8-ead6-4cc5-aedc-d399a0b1aceb"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK"},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632879561061,"user_tz":-540,"elapsed":2,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632879576600,"user_tz":-540,"elapsed":15540,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS"},"source":["submission = submission[['id', 'digit']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632879583070,"user_tz":-540,"elapsed":29,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"4bbd2e05-36c6-4a2f-f32d-866ff413bed2"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}