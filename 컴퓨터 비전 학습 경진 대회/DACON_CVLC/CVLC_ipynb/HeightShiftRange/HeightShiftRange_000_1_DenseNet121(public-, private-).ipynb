{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_000_1_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO147ZdrpIPPE0kk1c/gDeJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630483820447,"user_tz":-540,"elapsed":356,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7861b482-780d-486c-bbf4-f55cde9185cb"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 08:10:19 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630483837769,"user_tz":-540,"elapsed":17325,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6c144b6d-7082-4bd1-ae6b-af03efe7f30a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630483840633,"user_tz":-540,"elapsed":2869,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630483841796,"user_tz":-540,"elapsed":1166,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630483843893,"user_tz":-540,"elapsed":2104,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630483860296,"user_tz":-540,"elapsed":16407,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630483867249,"user_tz":-540,"elapsed":6960,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630483867250,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"20774cbf-9938-409c-9229-ae2b08486357"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630483867250,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"acc1ff6d-904a-4640-ba1c-00b95470967d"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.0)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630483867253,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630489461353,"user_tz":-540,"elapsed":5594109,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a130a523-584f-44eb-da73-de65a0b9178b"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 38s 258ms/step - loss: 1.7683 - accuracy: 0.3672 - val_loss: 25.9706 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1270 - accuracy: 0.6230 - val_loss: 8.6144 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.8364 - accuracy: 0.7278 - val_loss: 11.4564 - val_accuracy: 0.1034\n","\n","Epoch 00003: val_accuracy improved from 0.10099 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.7424 - accuracy: 0.7497 - val_loss: 12.3799 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10345\n","Epoch 5/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.6264 - accuracy: 0.7899 - val_loss: 7.9885 - val_accuracy: 0.1281\n","\n","Epoch 00005: val_accuracy improved from 0.10345 to 0.12808, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.5969 - accuracy: 0.7954 - val_loss: 4.5735 - val_accuracy: 0.3276\n","\n","Epoch 00006: val_accuracy improved from 0.12808 to 0.32759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.5290 - accuracy: 0.8276 - val_loss: 5.9205 - val_accuracy: 0.2094\n","\n","Epoch 00007: val_accuracy did not improve from 0.32759\n","Epoch 8/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4686 - accuracy: 0.8447 - val_loss: 5.9213 - val_accuracy: 0.2094\n","\n","Epoch 00008: val_accuracy did not improve from 0.32759\n","Epoch 9/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4140 - accuracy: 0.8648 - val_loss: 4.4239 - val_accuracy: 0.3941\n","\n","Epoch 00009: val_accuracy improved from 0.32759 to 0.39409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4059 - accuracy: 0.8587 - val_loss: 1.7058 - val_accuracy: 0.5764\n","\n","Epoch 00010: val_accuracy improved from 0.39409 to 0.57635, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.4166 - accuracy: 0.8660 - val_loss: 1.1976 - val_accuracy: 0.7143\n","\n","Epoch 00011: val_accuracy improved from 0.57635 to 0.71429, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3253 - accuracy: 0.8892 - val_loss: 0.5138 - val_accuracy: 0.8399\n","\n","Epoch 00012: val_accuracy improved from 0.71429 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3339 - accuracy: 0.8812 - val_loss: 0.7222 - val_accuracy: 0.8153\n","\n","Epoch 00013: val_accuracy did not improve from 0.83990\n","Epoch 14/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2524 - accuracy: 0.9135 - val_loss: 0.6947 - val_accuracy: 0.8030\n","\n","Epoch 00014: val_accuracy did not improve from 0.83990\n","Epoch 15/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2857 - accuracy: 0.8989 - val_loss: 0.9625 - val_accuracy: 0.7340\n","\n","Epoch 00015: val_accuracy did not improve from 0.83990\n","Epoch 16/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2407 - accuracy: 0.9141 - val_loss: 0.8879 - val_accuracy: 0.7833\n","\n","Epoch 00016: val_accuracy did not improve from 0.83990\n","Epoch 17/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2208 - accuracy: 0.9294 - val_loss: 1.4622 - val_accuracy: 0.6700\n","\n","Epoch 00017: val_accuracy did not improve from 0.83990\n","Epoch 18/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2355 - accuracy: 0.9233 - val_loss: 0.8747 - val_accuracy: 0.7660\n","\n","Epoch 00018: val_accuracy did not improve from 0.83990\n","Epoch 19/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2349 - accuracy: 0.9220 - val_loss: 1.4461 - val_accuracy: 0.7044\n","\n","Epoch 00019: val_accuracy did not improve from 0.83990\n","Epoch 20/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1543 - accuracy: 0.9482 - val_loss: 0.6647 - val_accuracy: 0.8128\n","\n","Epoch 00020: val_accuracy did not improve from 0.83990\n","Epoch 21/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2006 - accuracy: 0.9300 - val_loss: 0.7432 - val_accuracy: 0.7857\n","\n","Epoch 00021: val_accuracy did not improve from 0.83990\n","Epoch 22/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2460 - accuracy: 0.9166 - val_loss: 0.6578 - val_accuracy: 0.8202\n","\n","Epoch 00022: val_accuracy did not improve from 0.83990\n","Epoch 23/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1546 - accuracy: 0.9440 - val_loss: 0.6894 - val_accuracy: 0.8054\n","\n","Epoch 00023: val_accuracy did not improve from 0.83990\n","Epoch 24/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1475 - accuracy: 0.9476 - val_loss: 0.5279 - val_accuracy: 0.8596\n","\n","Epoch 00024: val_accuracy improved from 0.83990 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1235 - accuracy: 0.9580 - val_loss: 0.3844 - val_accuracy: 0.8719\n","\n","Epoch 00025: val_accuracy improved from 0.85961 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1180 - accuracy: 0.9598 - val_loss: 0.5846 - val_accuracy: 0.8325\n","\n","Epoch 00026: val_accuracy did not improve from 0.87192\n","Epoch 27/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1496 - accuracy: 0.9464 - val_loss: 0.5467 - val_accuracy: 0.8719\n","\n","Epoch 00027: val_accuracy did not improve from 0.87192\n","Epoch 28/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2048 - accuracy: 0.9300 - val_loss: 1.3239 - val_accuracy: 0.6970\n","\n","Epoch 00028: val_accuracy did not improve from 0.87192\n","Epoch 29/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1986 - accuracy: 0.9348 - val_loss: 0.9379 - val_accuracy: 0.7857\n","\n","Epoch 00029: val_accuracy did not improve from 0.87192\n","Epoch 30/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1330 - accuracy: 0.9562 - val_loss: 0.5424 - val_accuracy: 0.8300\n","\n","Epoch 00030: val_accuracy did not improve from 0.87192\n","Epoch 31/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1471 - accuracy: 0.9525 - val_loss: 1.3954 - val_accuracy: 0.7291\n","\n","Epoch 00031: val_accuracy did not improve from 0.87192\n","Epoch 32/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1007 - accuracy: 0.9683 - val_loss: 0.4479 - val_accuracy: 0.8719\n","\n","Epoch 00032: val_accuracy did not improve from 0.87192\n","Epoch 33/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.5730 - val_accuracy: 0.8350\n","\n","Epoch 00033: val_accuracy did not improve from 0.87192\n","Epoch 34/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0996 - accuracy: 0.9635 - val_loss: 0.5676 - val_accuracy: 0.8768\n","\n","Epoch 00034: val_accuracy improved from 0.87192 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 35/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 0.7253 - val_accuracy: 0.8276\n","\n","Epoch 00035: val_accuracy did not improve from 0.87685\n","Epoch 36/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0835 - accuracy: 0.9732 - val_loss: 0.5330 - val_accuracy: 0.8670\n","\n","Epoch 00036: val_accuracy did not improve from 0.87685\n","Epoch 37/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0850 - accuracy: 0.9702 - val_loss: 3.1277 - val_accuracy: 0.5197\n","\n","Epoch 00037: val_accuracy did not improve from 0.87685\n","Epoch 38/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0951 - accuracy: 0.9665 - val_loss: 0.9501 - val_accuracy: 0.7783\n","\n","Epoch 00038: val_accuracy did not improve from 0.87685\n","Epoch 39/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0827 - accuracy: 0.9695 - val_loss: 0.6381 - val_accuracy: 0.8498\n","\n","Epoch 00039: val_accuracy did not improve from 0.87685\n","Epoch 40/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1934 - accuracy: 0.9361 - val_loss: 1.3745 - val_accuracy: 0.7537\n","\n","Epoch 00040: val_accuracy did not improve from 0.87685\n","Epoch 41/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1915 - accuracy: 0.9391 - val_loss: 1.2498 - val_accuracy: 0.7833\n","\n","Epoch 00041: val_accuracy did not improve from 0.87685\n","Epoch 42/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1513 - accuracy: 0.9543 - val_loss: 0.8766 - val_accuracy: 0.8251\n","\n","Epoch 00042: val_accuracy did not improve from 0.87685\n","Epoch 43/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 0.4582 - val_accuracy: 0.8621\n","\n","Epoch 00043: val_accuracy did not improve from 0.87685\n","Epoch 44/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0840 - accuracy: 0.9708 - val_loss: 0.5823 - val_accuracy: 0.8522\n","\n","Epoch 00044: val_accuracy did not improve from 0.87685\n","Epoch 45/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0955 - accuracy: 0.9659 - val_loss: 0.5486 - val_accuracy: 0.8571\n","\n","Epoch 00045: val_accuracy did not improve from 0.87685\n","Epoch 46/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1412 - accuracy: 0.9568 - val_loss: 1.0920 - val_accuracy: 0.7956\n","\n","Epoch 00046: val_accuracy did not improve from 0.87685\n","Epoch 47/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0716 - accuracy: 0.9750 - val_loss: 0.4669 - val_accuracy: 0.8670\n","\n","Epoch 00047: val_accuracy did not improve from 0.87685\n","Epoch 48/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0519 - accuracy: 0.9854 - val_loss: 0.5624 - val_accuracy: 0.8793\n","\n","Epoch 00048: val_accuracy improved from 0.87685 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 49/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 0.4333 - val_accuracy: 0.8842\n","\n","Epoch 00049: val_accuracy improved from 0.87931 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 50/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.3686 - val_accuracy: 0.8990\n","\n","Epoch 00050: val_accuracy improved from 0.88424 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 51/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.3554 - val_accuracy: 0.9015\n","\n","Epoch 00051: val_accuracy improved from 0.89901 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 52/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0668 - accuracy: 0.9817 - val_loss: 0.9571 - val_accuracy: 0.8030\n","\n","Epoch 00052: val_accuracy did not improve from 0.90148\n","Epoch 53/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.5726 - val_accuracy: 0.8695\n","\n","Epoch 00053: val_accuracy did not improve from 0.90148\n","Epoch 54/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.5146 - val_accuracy: 0.8892\n","\n","Epoch 00054: val_accuracy did not improve from 0.90148\n","Epoch 55/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.4672 - val_accuracy: 0.8818\n","\n","Epoch 00055: val_accuracy did not improve from 0.90148\n","Epoch 56/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0934 - accuracy: 0.9689 - val_loss: 0.7386 - val_accuracy: 0.8424\n","\n","Epoch 00056: val_accuracy did not improve from 0.90148\n","Epoch 57/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.8087 - val_accuracy: 0.8079\n","\n","Epoch 00057: val_accuracy did not improve from 0.90148\n","Epoch 58/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 0.5445 - val_accuracy: 0.8522\n","\n","Epoch 00058: val_accuracy did not improve from 0.90148\n","Epoch 59/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0603 - accuracy: 0.9793 - val_loss: 0.7159 - val_accuracy: 0.8547\n","\n","Epoch 00059: val_accuracy did not improve from 0.90148\n","Epoch 60/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.7996 - val_accuracy: 0.8374\n","\n","Epoch 00060: val_accuracy did not improve from 0.90148\n","Epoch 61/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1297 - accuracy: 0.9592 - val_loss: 1.2948 - val_accuracy: 0.7759\n","\n","Epoch 00061: val_accuracy did not improve from 0.90148\n","Epoch 62/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0896 - accuracy: 0.9720 - val_loss: 0.5913 - val_accuracy: 0.8498\n","\n","Epoch 00062: val_accuracy did not improve from 0.90148\n","Epoch 63/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.7265 - val_accuracy: 0.8350\n","\n","Epoch 00063: val_accuracy did not improve from 0.90148\n","Epoch 64/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.5030 - val_accuracy: 0.8670\n","\n","Epoch 00064: val_accuracy did not improve from 0.90148\n","Epoch 65/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.5189 - val_accuracy: 0.8793\n","\n","Epoch 00065: val_accuracy did not improve from 0.90148\n","Epoch 66/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.8557 - val_accuracy: 0.8251\n","\n","Epoch 00066: val_accuracy did not improve from 0.90148\n","Epoch 67/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.8528 - val_accuracy: 0.8128\n","\n","Epoch 00067: val_accuracy did not improve from 0.90148\n","Epoch 68/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.5901 - val_accuracy: 0.8744\n","\n","Epoch 00068: val_accuracy did not improve from 0.90148\n","Epoch 69/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0743 - accuracy: 0.9744 - val_loss: 1.2915 - val_accuracy: 0.7660\n","\n","Epoch 00069: val_accuracy did not improve from 0.90148\n","Epoch 70/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0582 - accuracy: 0.9793 - val_loss: 0.5370 - val_accuracy: 0.8645\n","\n","Epoch 00070: val_accuracy did not improve from 0.90148\n","Epoch 71/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0379 - accuracy: 0.9842 - val_loss: 0.8245 - val_accuracy: 0.8399\n","\n","Epoch 00071: val_accuracy did not improve from 0.90148\n","Epoch 72/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.5046 - val_accuracy: 0.8768\n","\n","Epoch 00072: val_accuracy did not improve from 0.90148\n","Epoch 73/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.4914 - val_accuracy: 0.8793\n","\n","Epoch 00073: val_accuracy did not improve from 0.90148\n","Epoch 74/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.4937 - val_accuracy: 0.8916\n","\n","Epoch 00074: val_accuracy did not improve from 0.90148\n","Epoch 75/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.5195 - val_accuracy: 0.8916\n","\n","Epoch 00075: val_accuracy did not improve from 0.90148\n","Epoch 76/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.5298 - val_accuracy: 0.8867\n","\n","Epoch 00076: val_accuracy did not improve from 0.90148\n","Epoch 77/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.5345 - val_accuracy: 0.8744\n","\n","Epoch 00077: val_accuracy did not improve from 0.90148\n","Epoch 78/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 0.9022 - val_accuracy: 0.8374\n","\n","Epoch 00078: val_accuracy did not improve from 0.90148\n","Epoch 79/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.4523 - val_accuracy: 0.8990\n","\n","Epoch 00079: val_accuracy did not improve from 0.90148\n","Epoch 80/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.8912 - val_accuracy: 0.8103\n","\n","Epoch 00080: val_accuracy did not improve from 0.90148\n","Epoch 81/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.7103 - val_accuracy: 0.8695\n","\n","Epoch 00081: val_accuracy did not improve from 0.90148\n","Epoch 82/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0873 - accuracy: 0.9647 - val_loss: 1.0578 - val_accuracy: 0.8374\n","\n","Epoch 00082: val_accuracy did not improve from 0.90148\n","Epoch 83/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0788 - accuracy: 0.9726 - val_loss: 0.7510 - val_accuracy: 0.8251\n","\n","Epoch 00083: val_accuracy did not improve from 0.90148\n","Epoch 84/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.9210 - val_accuracy: 0.8276\n","\n","Epoch 00084: val_accuracy did not improve from 0.90148\n","Epoch 85/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.6761 - val_accuracy: 0.8596\n","\n","Epoch 00085: val_accuracy did not improve from 0.90148\n","Epoch 86/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.4938 - val_accuracy: 0.8818\n","\n","Epoch 00086: val_accuracy did not improve from 0.90148\n","Epoch 87/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.4597 - val_accuracy: 0.8842\n","\n","Epoch 00087: val_accuracy did not improve from 0.90148\n","Epoch 88/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.5079 - val_accuracy: 0.8966\n","\n","Epoch 00088: val_accuracy did not improve from 0.90148\n","Epoch 89/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 1.2074 - val_accuracy: 0.7931\n","\n","Epoch 00089: val_accuracy did not improve from 0.90148\n","Epoch 90/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1248 - accuracy: 0.9586 - val_loss: 4.4407 - val_accuracy: 0.5148\n","\n","Epoch 00090: val_accuracy did not improve from 0.90148\n","Epoch 91/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0654 - accuracy: 0.9775 - val_loss: 1.1859 - val_accuracy: 0.7906\n","\n","Epoch 00091: val_accuracy did not improve from 0.90148\n","Epoch 92/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 0.6231 - val_accuracy: 0.8645\n","\n","Epoch 00092: val_accuracy did not improve from 0.90148\n","Epoch 93/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 0.6995 - val_accuracy: 0.8621\n","\n","Epoch 00093: val_accuracy did not improve from 0.90148\n","Epoch 94/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.6449 - val_accuracy: 0.8621\n","\n","Epoch 00094: val_accuracy did not improve from 0.90148\n","Epoch 95/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.3622 - val_accuracy: 0.8966\n","\n","Epoch 00095: val_accuracy did not improve from 0.90148\n","Epoch 96/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.5186 - val_accuracy: 0.8941\n","\n","Epoch 00096: val_accuracy did not improve from 0.90148\n","Epoch 97/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5054 - val_accuracy: 0.9089\n","\n","Epoch 00097: val_accuracy improved from 0.90148 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 98/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.4592 - val_accuracy: 0.8916\n","\n","Epoch 00098: val_accuracy did not improve from 0.90887\n","Epoch 99/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.8334 - val_accuracy: 0.8227\n","\n","Epoch 00099: val_accuracy did not improve from 0.90887\n","Epoch 100/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.5274 - val_accuracy: 0.8892\n","\n","Epoch 00100: val_accuracy did not improve from 0.90887\n","Epoch 101/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 1.0220 - val_accuracy: 0.8448\n","\n","Epoch 00101: val_accuracy did not improve from 0.90887\n","Epoch 102/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0445 - accuracy: 0.9878 - val_loss: 0.4487 - val_accuracy: 0.8966\n","\n","Epoch 00102: val_accuracy did not improve from 0.90887\n","Epoch 103/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.5459 - val_accuracy: 0.8892\n","\n","Epoch 00103: val_accuracy did not improve from 0.90887\n","Epoch 104/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.6011 - val_accuracy: 0.8719\n","\n","Epoch 00104: val_accuracy did not improve from 0.90887\n","Epoch 105/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.6345 - val_accuracy: 0.8842\n","\n","Epoch 00105: val_accuracy did not improve from 0.90887\n","Epoch 106/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.4798 - val_accuracy: 0.8867\n","\n","Epoch 00106: val_accuracy did not improve from 0.90887\n","Epoch 107/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.4731 - val_accuracy: 0.9064\n","\n","Epoch 00107: val_accuracy did not improve from 0.90887\n","Epoch 108/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.5633 - val_accuracy: 0.8818\n","\n","Epoch 00108: val_accuracy did not improve from 0.90887\n","Epoch 109/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.5131 - val_accuracy: 0.8793\n","\n","Epoch 00109: val_accuracy did not improve from 0.90887\n","Epoch 110/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.9726 - val_accuracy: 0.7956\n","\n","Epoch 00110: val_accuracy did not improve from 0.90887\n","Epoch 111/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0334 - accuracy: 0.9872 - val_loss: 0.7787 - val_accuracy: 0.8645\n","\n","Epoch 00111: val_accuracy did not improve from 0.90887\n","Epoch 112/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.6290 - val_accuracy: 0.8498\n","\n","Epoch 00112: val_accuracy did not improve from 0.90887\n","Epoch 113/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.7227 - val_accuracy: 0.8793\n","\n","Epoch 00113: val_accuracy did not improve from 0.90887\n","Epoch 114/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.6535 - val_accuracy: 0.8695\n","\n","Epoch 00114: val_accuracy did not improve from 0.90887\n","Epoch 115/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.6264 - val_accuracy: 0.8793\n","\n","Epoch 00115: val_accuracy did not improve from 0.90887\n","Epoch 116/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0420 - accuracy: 0.9890 - val_loss: 0.5965 - val_accuracy: 0.8842\n","\n","Epoch 00116: val_accuracy did not improve from 0.90887\n","Epoch 117/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0537 - accuracy: 0.9817 - val_loss: 0.9172 - val_accuracy: 0.8251\n","\n","Epoch 00117: val_accuracy did not improve from 0.90887\n","Epoch 118/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 1.1250 - val_accuracy: 0.8177\n","\n","Epoch 00118: val_accuracy did not improve from 0.90887\n","Epoch 119/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0501 - accuracy: 0.9854 - val_loss: 0.7625 - val_accuracy: 0.8596\n","\n","Epoch 00119: val_accuracy did not improve from 0.90887\n","Epoch 120/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.9421 - val_accuracy: 0.8153\n","\n","Epoch 00120: val_accuracy did not improve from 0.90887\n","Epoch 121/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.7162 - val_accuracy: 0.8424\n","\n","Epoch 00121: val_accuracy did not improve from 0.90887\n","Epoch 122/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0396 - accuracy: 0.9915 - val_loss: 0.5468 - val_accuracy: 0.8990\n","\n","Epoch 00122: val_accuracy did not improve from 0.90887\n","Epoch 123/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4541 - val_accuracy: 0.8916\n","\n","Epoch 00123: val_accuracy did not improve from 0.90887\n","Epoch 124/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5383 - val_accuracy: 0.9039\n","\n","Epoch 00124: val_accuracy did not improve from 0.90887\n","Epoch 125/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4912 - val_accuracy: 0.9089\n","\n","Epoch 00125: val_accuracy did not improve from 0.90887\n","Epoch 126/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8990\n","\n","Epoch 00126: val_accuracy did not improve from 0.90887\n","Epoch 127/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 1.0098 - val_accuracy: 0.8251\n","\n","Epoch 00127: val_accuracy did not improve from 0.90887\n","Epoch 128/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.5896 - val_accuracy: 0.8941\n","\n","Epoch 00128: val_accuracy did not improve from 0.90887\n","Epoch 129/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.6457 - val_accuracy: 0.8768\n","\n","Epoch 00129: val_accuracy did not improve from 0.90887\n","Epoch 130/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5281 - val_accuracy: 0.8842\n","\n","Epoch 00130: val_accuracy did not improve from 0.90887\n","Epoch 131/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.7140 - val_accuracy: 0.8571\n","\n","Epoch 00131: val_accuracy did not improve from 0.90887\n","Epoch 132/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0432 - accuracy: 0.9829 - val_loss: 1.0565 - val_accuracy: 0.8374\n","\n","Epoch 00132: val_accuracy did not improve from 0.90887\n","Epoch 133/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.6482 - val_accuracy: 0.8892\n","\n","Epoch 00133: val_accuracy did not improve from 0.90887\n","Epoch 134/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.6357 - val_accuracy: 0.8941\n","\n","Epoch 00134: val_accuracy did not improve from 0.90887\n","Epoch 135/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.5251 - val_accuracy: 0.8916\n","\n","Epoch 00135: val_accuracy did not improve from 0.90887\n","Epoch 136/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.6324 - val_accuracy: 0.8867\n","\n","Epoch 00136: val_accuracy did not improve from 0.90887\n","Epoch 137/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.6491 - val_accuracy: 0.9015\n","\n","Epoch 00137: val_accuracy did not improve from 0.90887\n","Epoch 138/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5360 - val_accuracy: 0.9064\n","\n","Epoch 00138: val_accuracy did not improve from 0.90887\n","Epoch 139/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.5224 - val_accuracy: 0.9138\n","\n","Epoch 00139: val_accuracy improved from 0.90887 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 140/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4385 - val_accuracy: 0.9187\n","\n","Epoch 00140: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 141/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6127 - val_accuracy: 0.8990\n","\n","Epoch 00141: val_accuracy did not improve from 0.91872\n","Epoch 142/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.9777 - val_accuracy: 0.8621\n","\n","Epoch 00142: val_accuracy did not improve from 0.91872\n","Epoch 143/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1509 - accuracy: 0.9604 - val_loss: 0.9342 - val_accuracy: 0.8621\n","\n","Epoch 00143: val_accuracy did not improve from 0.91872\n","Epoch 144/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0849 - accuracy: 0.9720 - val_loss: 1.2297 - val_accuracy: 0.8128\n","\n","Epoch 00144: val_accuracy did not improve from 0.91872\n","Epoch 145/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0333 - accuracy: 0.9829 - val_loss: 0.6665 - val_accuracy: 0.8867\n","\n","Epoch 00145: val_accuracy did not improve from 0.91872\n","Epoch 146/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.5201 - val_accuracy: 0.8842\n","\n","Epoch 00146: val_accuracy did not improve from 0.91872\n","Epoch 147/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.4570 - val_accuracy: 0.9089\n","\n","Epoch 00147: val_accuracy did not improve from 0.91872\n","Epoch 148/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.5228 - val_accuracy: 0.8990\n","\n","Epoch 00148: val_accuracy did not improve from 0.91872\n","Epoch 149/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5008 - val_accuracy: 0.8941\n","\n","Epoch 00149: val_accuracy did not improve from 0.91872\n","Epoch 150/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9064\n","\n","Epoch 00150: val_accuracy did not improve from 0.91872\n","Epoch 151/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9039\n","\n","Epoch 00151: val_accuracy did not improve from 0.91872\n","Epoch 152/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.6619 - val_accuracy: 0.8941\n","\n","Epoch 00152: val_accuracy did not improve from 0.91872\n","Epoch 153/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.5537 - val_accuracy: 0.9015\n","\n","Epoch 00153: val_accuracy did not improve from 0.91872\n","Epoch 154/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.7756 - val_accuracy: 0.8768\n","\n","Epoch 00154: val_accuracy did not improve from 0.91872\n","Epoch 155/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.7322 - val_accuracy: 0.8621\n","\n","Epoch 00155: val_accuracy did not improve from 0.91872\n","Epoch 156/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.6866 - val_accuracy: 0.8670\n","\n","Epoch 00156: val_accuracy did not improve from 0.91872\n","Epoch 157/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0411 - accuracy: 0.9842 - val_loss: 0.9206 - val_accuracy: 0.8424\n","\n","Epoch 00157: val_accuracy did not improve from 0.91872\n","Epoch 158/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 1.0426 - val_accuracy: 0.8227\n","\n","Epoch 00158: val_accuracy did not improve from 0.91872\n","Epoch 159/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.7210 - val_accuracy: 0.8744\n","\n","Epoch 00159: val_accuracy did not improve from 0.91872\n","Epoch 160/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0358 - accuracy: 0.9854 - val_loss: 0.6821 - val_accuracy: 0.9015\n","\n","Epoch 00160: val_accuracy did not improve from 0.91872\n","Epoch 161/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.4673 - val_accuracy: 0.9113\n","\n","Epoch 00161: val_accuracy did not improve from 0.91872\n","Epoch 162/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5151 - val_accuracy: 0.9187\n","\n","Epoch 00162: val_accuracy did not improve from 0.91872\n","Epoch 163/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.5284 - val_accuracy: 0.9089\n","\n","Epoch 00163: val_accuracy did not improve from 0.91872\n","Epoch 164/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5219 - val_accuracy: 0.9039\n","\n","Epoch 00164: val_accuracy did not improve from 0.91872\n","Epoch 165/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.5492 - val_accuracy: 0.9064\n","\n","Epoch 00165: val_accuracy did not improve from 0.91872\n","Epoch 166/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.6726 - val_accuracy: 0.8744\n","\n","Epoch 00166: val_accuracy did not improve from 0.91872\n","Epoch 167/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4733 - val_accuracy: 0.9015\n","\n","Epoch 00167: val_accuracy did not improve from 0.91872\n","Epoch 168/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.8097 - val_accuracy: 0.8842\n","\n","Epoch 00168: val_accuracy did not improve from 0.91872\n","Epoch 169/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.4411 - val_accuracy: 0.9039\n","\n","Epoch 00169: val_accuracy did not improve from 0.91872\n","Epoch 170/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9163\n","\n","Epoch 00170: val_accuracy did not improve from 0.91872\n","Epoch 171/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9335\n","\n","Epoch 00171: val_accuracy improved from 0.91872 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5\n","Epoch 172/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.1447e-04 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9261\n","\n","Epoch 00172: val_accuracy did not improve from 0.93350\n","Epoch 173/500\n","52/52 [==============================] - 11s 204ms/step - loss: 9.2837e-04 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9236\n","\n","Epoch 00173: val_accuracy did not improve from 0.93350\n","Epoch 174/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5282 - val_accuracy: 0.9138\n","\n","Epoch 00174: val_accuracy did not improve from 0.93350\n","Epoch 175/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9089\n","\n","Epoch 00175: val_accuracy did not improve from 0.93350\n","Epoch 176/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4917 - val_accuracy: 0.9187\n","\n","Epoch 00176: val_accuracy did not improve from 0.93350\n","Epoch 177/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.8008 - val_accuracy: 0.8645\n","\n","Epoch 00177: val_accuracy did not improve from 0.93350\n","Epoch 178/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0241 - accuracy: 0.9945 - val_loss: 0.6814 - val_accuracy: 0.8916\n","\n","Epoch 00178: val_accuracy did not improve from 0.93350\n","Epoch 179/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 0.7852 - val_accuracy: 0.8744\n","\n","Epoch 00179: val_accuracy did not improve from 0.93350\n","Epoch 180/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0814 - accuracy: 0.9738 - val_loss: 1.2029 - val_accuracy: 0.7980\n","\n","Epoch 00180: val_accuracy did not improve from 0.93350\n","Epoch 181/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0650 - accuracy: 0.9811 - val_loss: 0.5779 - val_accuracy: 0.8892\n","\n","Epoch 00181: val_accuracy did not improve from 0.93350\n","Epoch 182/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 0.8817 - val_accuracy: 0.8498\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.5392 - val_accuracy: 0.8818\n","\n","Epoch 00183: val_accuracy did not improve from 0.93350\n","Epoch 184/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 0.5659 - val_accuracy: 0.8941\n","\n","Epoch 00184: val_accuracy did not improve from 0.93350\n","Epoch 185/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.5838 - val_accuracy: 0.8867\n","\n","Epoch 00185: val_accuracy did not improve from 0.93350\n","Epoch 186/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5984 - val_accuracy: 0.8867\n","\n","Epoch 00186: val_accuracy did not improve from 0.93350\n","Epoch 187/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.4574 - val_accuracy: 0.9163\n","\n","Epoch 00187: val_accuracy did not improve from 0.93350\n","Epoch 188/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4290 - val_accuracy: 0.9187\n","\n","Epoch 00188: val_accuracy did not improve from 0.93350\n","Epoch 189/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.5761 - val_accuracy: 0.8768\n","\n","Epoch 00189: val_accuracy did not improve from 0.93350\n","Epoch 190/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4633 - val_accuracy: 0.9064\n","\n","Epoch 00190: val_accuracy did not improve from 0.93350\n","Epoch 191/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5201 - val_accuracy: 0.8916\n","\n","Epoch 00191: val_accuracy did not improve from 0.93350\n","Epoch 192/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.2765e-04 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9138\n","\n","Epoch 00192: val_accuracy did not improve from 0.93350\n","Epoch 193/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9236\n","\n","Epoch 00193: val_accuracy did not improve from 0.93350\n","Epoch 194/500\n","52/52 [==============================] - 11s 204ms/step - loss: 5.8646e-04 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9212\n","\n","Epoch 00194: val_accuracy did not improve from 0.93350\n","Epoch 195/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.6391 - val_accuracy: 0.8867\n","\n","Epoch 00195: val_accuracy did not improve from 0.93350\n","Epoch 196/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9039\n","\n","Epoch 00196: val_accuracy did not improve from 0.93350\n","Epoch 197/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.0345e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9212\n","\n","Epoch 00197: val_accuracy did not improve from 0.93350\n","Epoch 198/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.1192e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9039\n","\n","Epoch 00198: val_accuracy did not improve from 0.93350\n","Epoch 199/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.2632e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9064\n","\n","Epoch 00199: val_accuracy did not improve from 0.93350\n","Epoch 200/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.7900e-04 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9212\n","\n","Epoch 00200: val_accuracy did not improve from 0.93350\n","Epoch 201/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9064\n","\n","Epoch 00201: val_accuracy did not improve from 0.93350\n","Epoch 202/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.6264e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.8941\n","\n","Epoch 00202: val_accuracy did not improve from 0.93350\n","Epoch 203/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.6170e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9212\n","\n","Epoch 00203: val_accuracy did not improve from 0.93350\n","Epoch 204/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.4995e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9212\n","\n","Epoch 00204: val_accuracy did not improve from 0.93350\n","Epoch 205/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.9906e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9261\n","\n","Epoch 00205: val_accuracy did not improve from 0.93350\n","Epoch 206/500\n","52/52 [==============================] - 11s 207ms/step - loss: 1.7009e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9089\n","\n","Epoch 00206: val_accuracy did not improve from 0.93350\n","Epoch 207/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.8396e-04 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9261\n","\n","Epoch 00207: val_accuracy did not improve from 0.93350\n","Epoch 208/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.4965e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9064\n","\n","Epoch 00208: val_accuracy did not improve from 0.93350\n","Epoch 209/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.3258e-04 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.8966\n","\n","Epoch 00209: val_accuracy did not improve from 0.93350\n","Epoch 210/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.4201 - val_accuracy: 0.9236\n","\n","Epoch 00210: val_accuracy did not improve from 0.93350\n","Epoch 211/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.7721 - val_accuracy: 0.8596\n","\n","Epoch 00211: val_accuracy did not improve from 0.93350\n","Epoch 212/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1819 - accuracy: 0.9574 - val_loss: 4.2244 - val_accuracy: 0.6330\n","\n","Epoch 00212: val_accuracy did not improve from 0.93350\n","Epoch 213/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1431 - accuracy: 0.9537 - val_loss: 1.1627 - val_accuracy: 0.8300\n","\n","Epoch 00213: val_accuracy did not improve from 0.93350\n","Epoch 214/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.7294 - val_accuracy: 0.8818\n","\n","Epoch 00214: val_accuracy did not improve from 0.93350\n","Epoch 215/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 1.1829 - val_accuracy: 0.8522\n","\n","Epoch 00215: val_accuracy did not improve from 0.93350\n","Epoch 216/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.7925 - val_accuracy: 0.8596\n","\n","Epoch 00216: val_accuracy did not improve from 0.93350\n","Epoch 217/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0245 - accuracy: 0.9945 - val_loss: 0.6541 - val_accuracy: 0.8768\n","\n","Epoch 00217: val_accuracy did not improve from 0.93350\n","Epoch 218/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.5048 - val_accuracy: 0.9064\n","\n","Epoch 00218: val_accuracy did not improve from 0.93350\n","Epoch 219/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4253 - val_accuracy: 0.9261\n","\n","Epoch 00219: val_accuracy did not improve from 0.93350\n","Epoch 220/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4180 - val_accuracy: 0.9064\n","\n","Epoch 00220: val_accuracy did not improve from 0.93350\n","Epoch 221/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4745 - val_accuracy: 0.9187\n","\n","Epoch 00221: val_accuracy did not improve from 0.93350\n","Epoch 222/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4670 - val_accuracy: 0.9138\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5086 - val_accuracy: 0.8990\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5864 - val_accuracy: 0.9015\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.4904 - val_accuracy: 0.9187\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9138\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4792 - val_accuracy: 0.9187\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4566 - val_accuracy: 0.9163\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5471 - val_accuracy: 0.9039\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9212\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4414 - val_accuracy: 0.9089\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6060 - val_accuracy: 0.9039\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5200 - val_accuracy: 0.8966\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.4579 - val_accuracy: 0.9236\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9187\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9138\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.6639 - val_accuracy: 0.9089\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.7573 - val_accuracy: 0.8695\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.6670 - val_accuracy: 0.8966\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9951 - val_loss: 0.7471 - val_accuracy: 0.8892\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.7897 - val_accuracy: 0.8670\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.9614 - val_accuracy: 0.8596\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.6001 - val_accuracy: 0.8695\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0502 - accuracy: 0.9854 - val_loss: 0.9576 - val_accuracy: 0.8522\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.7712 - val_accuracy: 0.8571\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.7032 - val_accuracy: 0.8892\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.7287 - val_accuracy: 0.8768\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.7592 - val_accuracy: 0.8793\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5345 - val_accuracy: 0.9064\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6178 - val_accuracy: 0.8941\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.7595e-04 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9015\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5463 - val_accuracy: 0.9015\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.9039\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5068 - val_accuracy: 0.9212\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 1.0291 - val_accuracy: 0.8596\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.8728 - val_accuracy: 0.8596\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.5447 - val_accuracy: 0.8966\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.8616 - val_accuracy: 0.8522\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0588 - accuracy: 0.9781 - val_loss: 1.6323 - val_accuracy: 0.7709\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 1.2482 - val_accuracy: 0.8276\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.5743 - val_accuracy: 0.8892\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5573 - val_accuracy: 0.8990\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5984 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.7242e-04 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.9039\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.6341 - val_accuracy: 0.8941\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5746 - val_accuracy: 0.9113\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.9064\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 11s 204ms/step - loss: 9.3532e-04 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9113\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 11s 204ms/step - loss: 7.1367e-04 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9113\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.0084e-04 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9261\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5223 - val_accuracy: 0.9113\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 11s 204ms/step - loss: 7.7446e-04 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.9236\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 11s 203ms/step - loss: 6.6759e-04 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.9064\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.6237e-04 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.9039\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.8267e-04 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9212\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.5001e-04 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9039\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.8483 - val_accuracy: 0.8916\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 1.0590 - val_accuracy: 0.8300\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 1.4029 - val_accuracy: 0.8030\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.9732 - val_accuracy: 0.8621\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 1.2212 - val_accuracy: 0.8300\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.6174 - val_accuracy: 0.8768\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.7151 - val_accuracy: 0.8768\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5748 - val_accuracy: 0.8941\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5651 - val_accuracy: 0.9015\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5902 - val_accuracy: 0.8990\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6345 - val_accuracy: 0.8990\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5238 - val_accuracy: 0.9138\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.7581 - val_accuracy: 0.8621\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5875 - val_accuracy: 0.8990\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5967 - val_accuracy: 0.8916\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.6356 - val_accuracy: 0.8941\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.6665 - val_accuracy: 0.8818\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.8985 - val_accuracy: 0.8719\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0180 - accuracy: 0.9927 - val_loss: 0.6863 - val_accuracy: 0.8793\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8744\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.8760 - val_accuracy: 0.8793\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7045 - val_accuracy: 0.8966\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.6683 - val_accuracy: 0.8793\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.1420e-04 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.9015\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.9235e-04 - accuracy: 0.9994 - val_loss: 0.5686 - val_accuracy: 0.8966\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.8930e-04 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.9039\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.0325e-04 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8990\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.4138e-04 - accuracy: 1.0000 - val_loss: 0.5602 - val_accuracy: 0.8966\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.2060e-04 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9015\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.5421e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8990\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 11s 204ms/step - loss: 3.3157e-04 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.8966\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 11s 204ms/step - loss: 8.1132e-04 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8990\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 1.0330 - val_accuracy: 0.8374\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 1.0298 - val_accuracy: 0.8424\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.7168 - val_accuracy: 0.8892\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.8761 - val_accuracy: 0.8498\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.6086 - val_accuracy: 0.8867\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 1.0792 - val_accuracy: 0.8325\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.4050 - val_accuracy: 0.9039\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.8502 - val_accuracy: 0.8670\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0415 - accuracy: 0.9909 - val_loss: 0.5338 - val_accuracy: 0.8941\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.9174 - val_accuracy: 0.8547\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0628 - accuracy: 0.9836 - val_loss: 1.1688 - val_accuracy: 0.8399\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.6047 - val_accuracy: 0.9064\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.7524 - val_accuracy: 0.8744\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4670 - val_accuracy: 0.8916\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4600 - val_accuracy: 0.9113\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4869 - val_accuracy: 0.9039\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5271 - val_accuracy: 0.9113\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4391 - val_accuracy: 0.9039\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3939 - val_accuracy: 0.9236\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9138\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.5628e-04 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9113\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 11s 204ms/step - loss: 8.2790e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9212\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 11s 204ms/step - loss: 9.6666e-04 - accuracy: 0.9994 - val_loss: 0.3935 - val_accuracy: 0.9310\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.3729e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8966\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.1117e-04 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9138\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.3528e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9286\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.6970e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9039\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 11s 204ms/step - loss: 3.1186e-04 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9236\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 11s 204ms/step - loss: 1.9660e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9212\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.5921e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9163\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 11s 204ms/step - loss: 1.8654e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9064\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.2476e-04 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9187\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.6605e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9286\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.7254e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9212\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.3019e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9163\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4839 - val_accuracy: 0.9039\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.6886e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9039\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.9671e-04 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.9039\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.0020e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9113\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.1101e-04 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9163\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 11s 204ms/step - loss: 5.5690e-04 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8941\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.1307e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9015\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.8903e-04 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9015\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.7416 - val_accuracy: 0.8941\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0753 - accuracy: 0.9775 - val_loss: 2.0730 - val_accuracy: 0.7783\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0873 - accuracy: 0.9720 - val_loss: 1.0476 - val_accuracy: 0.8547\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.8830 - val_accuracy: 0.8744\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.5674 - val_accuracy: 0.8941\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.5913 - val_accuracy: 0.8867\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5092 - val_accuracy: 0.8892\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5633 - val_accuracy: 0.8892\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.8990\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5539 - val_accuracy: 0.9015\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5956 - val_accuracy: 0.9089\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.5273 - val_accuracy: 0.9064\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 11s 204ms/step - loss: 8.4600e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9113\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4187 - val_accuracy: 0.9138\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9187\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6957 - val_accuracy: 0.8768\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5787 - val_accuracy: 0.9015\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5286 - val_accuracy: 0.8941\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9970 - val_loss: 0.6011 - val_accuracy: 0.9039\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.7165 - val_accuracy: 0.8941\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.7418 - val_accuracy: 0.8621\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5794 - val_accuracy: 0.8744\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.9081 - val_accuracy: 0.8793\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.7897 - val_accuracy: 0.8695\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5808 - val_accuracy: 0.9064\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.6894 - val_accuracy: 0.8768\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 0.6858 - val_accuracy: 0.8818\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5884 - val_accuracy: 0.8768\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5409 - val_accuracy: 0.8990\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.5296e-04 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.9015\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.7263e-04 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.9039\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.6017 - val_accuracy: 0.9039\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5488 - val_accuracy: 0.9039\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.8229 - val_accuracy: 0.8793\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 0.7420 - val_accuracy: 0.8941\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.8037 - val_accuracy: 0.8768\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.9367 - val_accuracy: 0.8695\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6827 - val_accuracy: 0.8990\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.6450 - val_accuracy: 0.8990\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6492 - val_accuracy: 0.8941\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.6888 - val_accuracy: 0.8941\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.7988 - val_accuracy: 0.8941\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4879 - val_accuracy: 0.9286\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5008 - val_accuracy: 0.9089\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5034 - val_accuracy: 0.9064\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9138\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.9163\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 1.0730 - val_accuracy: 0.8399\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.6824 - val_accuracy: 0.8818\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5868 - val_accuracy: 0.8916\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5769 - val_accuracy: 0.9187\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6013 - val_accuracy: 0.8990\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5500 - val_accuracy: 0.9113\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5576 - val_accuracy: 0.9089\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.9639 - val_accuracy: 0.8768\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.6009 - val_accuracy: 0.8990\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5289 - val_accuracy: 0.9015\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.6100 - val_accuracy: 0.8916\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.5974 - val_accuracy: 0.9015\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.7120 - val_accuracy: 0.8842\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.5321e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8941\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.3731e-04 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.9212\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 11s 204ms/step - loss: 5.2859e-04 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.9039\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.7192e-04 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.1864e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9138\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6620 - val_accuracy: 0.8941\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.6567 - val_accuracy: 0.9064\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5619 - val_accuracy: 0.9015\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.7299 - val_accuracy: 0.8966\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.9138\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6664 - val_accuracy: 0.9039\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5800 - val_accuracy: 0.9089\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 11s 204ms/step - loss: 7.8176e-04 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9236\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.8589e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9089\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 11s 204ms/step - loss: 1.3506e-04 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.9138\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9015\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.1786e-04 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9089\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.4879e-04 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.9113\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4294 - val_accuracy: 0.9212\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.6077 - val_accuracy: 0.9089\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 0.6066 - val_accuracy: 0.8966\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 1.0270 - val_accuracy: 0.8645\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.7090 - val_accuracy: 0.9039\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9138\n","\n","Epoch 00435: val_accuracy did not improve from 0.93350\n","Epoch 436/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.7354e-04 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.93350\n","Epoch 437/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.2527e-04 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.9236\n","\n","Epoch 00437: val_accuracy did not improve from 0.93350\n","Epoch 438/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.1762e-04 - accuracy: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.9236\n","\n","Epoch 00438: val_accuracy did not improve from 0.93350\n","Epoch 439/500\n","52/52 [==============================] - 11s 204ms/step - loss: 3.2713e-04 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.9138\n","\n","Epoch 00439: val_accuracy did not improve from 0.93350\n","Epoch 440/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.5328e-04 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9187\n","\n","Epoch 00440: val_accuracy did not improve from 0.93350\n","Epoch 441/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.8389e-04 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9113\n","\n","Epoch 00441: val_accuracy did not improve from 0.93350\n","Epoch 442/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.3839e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9138\n","\n","Epoch 00442: val_accuracy did not improve from 0.93350\n","Epoch 443/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.9160e-04 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9163\n","\n","Epoch 00443: val_accuracy did not improve from 0.93350\n","Epoch 444/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.5153e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9187\n","\n","Epoch 00444: val_accuracy did not improve from 0.93350\n","Epoch 445/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5461 - val_accuracy: 0.9039\n","\n","Epoch 00445: val_accuracy did not improve from 0.93350\n","Epoch 446/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.8566 - val_accuracy: 0.8941\n","\n","Epoch 00446: val_accuracy did not improve from 0.93350\n","Epoch 447/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1105 - accuracy: 0.9744 - val_loss: 1.9795 - val_accuracy: 0.7833\n","\n","Epoch 00447: val_accuracy did not improve from 0.93350\n","Epoch 448/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0830 - accuracy: 0.9793 - val_loss: 0.7220 - val_accuracy: 0.8842\n","\n","Epoch 00448: val_accuracy did not improve from 0.93350\n","Epoch 449/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.8024 - val_accuracy: 0.8842\n","\n","Epoch 00449: val_accuracy did not improve from 0.93350\n","Epoch 450/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6053 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.93350\n","Epoch 451/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4709 - val_accuracy: 0.9286\n","\n","Epoch 00451: val_accuracy did not improve from 0.93350\n","Epoch 452/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4897 - val_accuracy: 0.9212\n","\n","Epoch 00452: val_accuracy did not improve from 0.93350\n","Epoch 453/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4916 - val_accuracy: 0.9163\n","\n","Epoch 00453: val_accuracy did not improve from 0.93350\n","Epoch 454/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9138\n","\n","Epoch 00454: val_accuracy did not improve from 0.93350\n","Epoch 455/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.8432e-04 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9310\n","\n","Epoch 00455: val_accuracy did not improve from 0.93350\n","Epoch 456/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.7425e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9163\n","\n","Epoch 00456: val_accuracy did not improve from 0.93350\n","Epoch 457/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.7665e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9236\n","\n","Epoch 00457: val_accuracy did not improve from 0.93350\n","Epoch 458/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.4260e-04 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9261\n","\n","Epoch 00458: val_accuracy did not improve from 0.93350\n","Epoch 459/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.0193e-04 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9310\n","\n","Epoch 00459: val_accuracy did not improve from 0.93350\n","Epoch 460/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.5345e-04 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9335\n","\n","Epoch 00460: val_accuracy did not improve from 0.93350\n","Epoch 461/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.6543e-04 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.9212\n","\n","Epoch 00461: val_accuracy did not improve from 0.93350\n","Epoch 462/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.3859e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9163\n","\n","Epoch 00462: val_accuracy did not improve from 0.93350\n","Epoch 463/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.7511e-04 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9163\n","\n","Epoch 00463: val_accuracy did not improve from 0.93350\n","Epoch 464/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.2941e-04 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9261\n","\n","Epoch 00464: val_accuracy did not improve from 0.93350\n","Epoch 465/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.7231 - val_accuracy: 0.8867\n","\n","Epoch 00465: val_accuracy did not improve from 0.93350\n","Epoch 466/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.8332 - val_accuracy: 0.8719\n","\n","Epoch 00466: val_accuracy did not improve from 0.93350\n","Epoch 467/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.7655 - val_accuracy: 0.8916\n","\n","Epoch 00467: val_accuracy did not improve from 0.93350\n","Epoch 468/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.7457 - val_accuracy: 0.8842\n","\n","Epoch 00468: val_accuracy did not improve from 0.93350\n","Epoch 469/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.6008 - val_accuracy: 0.8842\n","\n","Epoch 00469: val_accuracy did not improve from 0.93350\n","Epoch 470/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.8018 - val_accuracy: 0.8744\n","\n","Epoch 00470: val_accuracy did not improve from 0.93350\n","Epoch 471/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.9113\n","\n","Epoch 00471: val_accuracy did not improve from 0.93350\n","Epoch 472/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.9138\n","\n","Epoch 00472: val_accuracy did not improve from 0.93350\n","Epoch 473/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5074 - val_accuracy: 0.9261\n","\n","Epoch 00473: val_accuracy did not improve from 0.93350\n","Epoch 474/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.7128 - val_accuracy: 0.8842\n","\n","Epoch 00474: val_accuracy did not improve from 0.93350\n","Epoch 475/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.5658 - val_accuracy: 0.9015\n","\n","Epoch 00475: val_accuracy did not improve from 0.93350\n","Epoch 476/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0083 - accuracy: 0.9957 - val_loss: 0.5536 - val_accuracy: 0.8990\n","\n","Epoch 00476: val_accuracy did not improve from 0.93350\n","Epoch 477/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4952 - val_accuracy: 0.9039\n","\n","Epoch 00477: val_accuracy did not improve from 0.93350\n","Epoch 478/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9236\n","\n","Epoch 00478: val_accuracy did not improve from 0.93350\n","Epoch 479/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4840 - val_accuracy: 0.9138\n","\n","Epoch 00479: val_accuracy did not improve from 0.93350\n","Epoch 480/500\n","52/52 [==============================] - 11s 204ms/step - loss: 7.8562e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9089\n","\n","Epoch 00480: val_accuracy did not improve from 0.93350\n","Epoch 481/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.0410e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9212\n","\n","Epoch 00481: val_accuracy did not improve from 0.93350\n","Epoch 482/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.6369e-04 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.9138\n","\n","Epoch 00482: val_accuracy did not improve from 0.93350\n","Epoch 483/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.5742e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9138\n","\n","Epoch 00483: val_accuracy did not improve from 0.93350\n","Epoch 484/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.8762e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9064\n","\n","Epoch 00484: val_accuracy did not improve from 0.93350\n","Epoch 485/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.2771e-04 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9138\n","\n","Epoch 00485: val_accuracy did not improve from 0.93350\n","Epoch 486/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8343 - val_accuracy: 0.8744\n","\n","Epoch 00486: val_accuracy did not improve from 0.93350\n","Epoch 487/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0340 - accuracy: 0.9854 - val_loss: 0.7039 - val_accuracy: 0.9015\n","\n","Epoch 00487: val_accuracy did not improve from 0.93350\n","Epoch 488/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.7828 - val_accuracy: 0.8744\n","\n","Epoch 00488: val_accuracy did not improve from 0.93350\n","Epoch 489/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.5634 - val_accuracy: 0.8966\n","\n","Epoch 00489: val_accuracy did not improve from 0.93350\n","Epoch 490/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5068 - val_accuracy: 0.9064\n","\n","Epoch 00490: val_accuracy did not improve from 0.93350\n","Epoch 491/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5404 - val_accuracy: 0.8990\n","\n","Epoch 00491: val_accuracy did not improve from 0.93350\n","Epoch 492/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9015\n","\n","Epoch 00492: val_accuracy did not improve from 0.93350\n","Epoch 493/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.9039\n","\n","Epoch 00493: val_accuracy did not improve from 0.93350\n","Epoch 494/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5967 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.93350\n","Epoch 495/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.5644 - val_accuracy: 0.8990\n","\n","Epoch 00495: val_accuracy did not improve from 0.93350\n","Epoch 496/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.5582 - val_accuracy: 0.9113\n","\n","Epoch 00496: val_accuracy did not improve from 0.93350\n","Epoch 497/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9212\n","\n","Epoch 00497: val_accuracy did not improve from 0.93350\n","Epoch 498/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.6078e-04 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8695\n","\n","Epoch 00498: val_accuracy did not improve from 0.93350\n","Epoch 499/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7102 - val_accuracy: 0.8818\n","\n","Epoch 00499: val_accuracy did not improve from 0.93350\n","Epoch 500/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0044 - accuracy: 0.9970 - val_loss: 0.5214 - val_accuracy: 0.9064\n","\n","Epoch 00500: val_accuracy did not improve from 0.93350\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fdda227cb50>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630489461356,"user_tz":-540,"elapsed":24,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9a7e3fad-61c4-4a4d-beee-f2f1f3e8b0b5"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630489479399,"user_tz":-540,"elapsed":18058,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_000_1_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630489479818,"user_tz":-540,"elapsed":427,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630489480691,"user_tz":-540,"elapsed":876,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"76c95f00-cbd8-4ba4-a7ad-d9c372acd200"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630489511287,"user_tz":-540,"elapsed":30606,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0474d63b-8985-4d38-85ba-1da33b8afe74"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630489511288,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630489511289,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630489512182,"user_tz":-540,"elapsed":899,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630489512183,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630489523112,"user_tz":-540,"elapsed":10935,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630489523113,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"62c0c0f6-e35c-42ec-a767-bb80924f3279"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1630489525077,"user_tz":-540,"elapsed":1984,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0b09ef74-6e2b-4cb1-f79c-ed5959a233a2"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_000_1_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_000_1_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b88e8f5d-ef26-4ed6-b345-b86130a00814\", \"HeightShiftRange_000_1_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}