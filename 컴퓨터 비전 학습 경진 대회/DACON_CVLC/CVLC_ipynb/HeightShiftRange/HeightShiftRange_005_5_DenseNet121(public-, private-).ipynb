{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_005_5_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP0NbUK3eg5nndAj/izFCQC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630502328548,"user_tz":-540,"elapsed":288,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"aeffbf56-10da-4fc4-c45a-e070f83adc1d"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 13:18:48 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630502345627,"user_tz":-540,"elapsed":17084,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4290a951-9d39-4905-f09c-5fffdc760227"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630502348914,"user_tz":-540,"elapsed":3036,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630502350321,"user_tz":-540,"elapsed":1413,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630502352114,"user_tz":-540,"elapsed":1797,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630502369009,"user_tz":-540,"elapsed":16898,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630502375623,"user_tz":-540,"elapsed":6617,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630502375628,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dde08c02-e0d9-4c90-b829-08a5122680e8"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630502375629,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"09f551b5-e62a-4510-af1e-6acf77aab034"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.05)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630502376072,"user_tz":-540,"elapsed":451,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630507986065,"user_tz":-540,"elapsed":5609999,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8a48d69c-0718-48d1-913e-13694ec19985"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 38s 257ms/step - loss: 1.8360 - accuracy: 0.3587 - val_loss: 18.6691 - val_accuracy: 0.0911\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09113, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 204ms/step - loss: 1.1877 - accuracy: 0.5932 - val_loss: 25.8711 - val_accuracy: 0.1034\n","\n","Epoch 00002: val_accuracy improved from 0.09113 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.9310 - accuracy: 0.6839 - val_loss: 7.4958 - val_accuracy: 0.1084\n","\n","Epoch 00003: val_accuracy improved from 0.10345 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 4/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.7994 - accuracy: 0.7278 - val_loss: 9.4523 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.10837\n","Epoch 5/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.7124 - accuracy: 0.7655 - val_loss: 14.0808 - val_accuracy: 0.1478\n","\n","Epoch 00005: val_accuracy improved from 0.10837 to 0.14778, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.5826 - accuracy: 0.8051 - val_loss: 4.9687 - val_accuracy: 0.2266\n","\n","Epoch 00006: val_accuracy improved from 0.14778 to 0.22660, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.5242 - accuracy: 0.8264 - val_loss: 3.7121 - val_accuracy: 0.2463\n","\n","Epoch 00007: val_accuracy improved from 0.22660 to 0.24631, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.4880 - accuracy: 0.8350 - val_loss: 2.4014 - val_accuracy: 0.3916\n","\n","Epoch 00008: val_accuracy improved from 0.24631 to 0.39163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.4915 - accuracy: 0.8374 - val_loss: 1.7843 - val_accuracy: 0.5443\n","\n","Epoch 00009: val_accuracy improved from 0.39163 to 0.54433, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4193 - accuracy: 0.8599 - val_loss: 1.4229 - val_accuracy: 0.6010\n","\n","Epoch 00010: val_accuracy improved from 0.54433 to 0.60099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3984 - accuracy: 0.8569 - val_loss: 0.8687 - val_accuracy: 0.7660\n","\n","Epoch 00011: val_accuracy improved from 0.60099 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3594 - accuracy: 0.8745 - val_loss: 1.0663 - val_accuracy: 0.7241\n","\n","Epoch 00012: val_accuracy did not improve from 0.76601\n","Epoch 13/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.3192 - accuracy: 0.8831 - val_loss: 0.8484 - val_accuracy: 0.7512\n","\n","Epoch 00013: val_accuracy did not improve from 0.76601\n","Epoch 14/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.3181 - accuracy: 0.8879 - val_loss: 0.8074 - val_accuracy: 0.7783\n","\n","Epoch 00014: val_accuracy improved from 0.76601 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.3728 - accuracy: 0.8770 - val_loss: 3.1007 - val_accuracy: 0.4975\n","\n","Epoch 00015: val_accuracy did not improve from 0.77833\n","Epoch 16/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3309 - accuracy: 0.8959 - val_loss: 0.6403 - val_accuracy: 0.8005\n","\n","Epoch 00016: val_accuracy improved from 0.77833 to 0.80049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2653 - accuracy: 0.9153 - val_loss: 0.5034 - val_accuracy: 0.8424\n","\n","Epoch 00017: val_accuracy improved from 0.80049 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.3020 - accuracy: 0.8959 - val_loss: 0.7043 - val_accuracy: 0.7833\n","\n","Epoch 00018: val_accuracy did not improve from 0.84236\n","Epoch 19/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2472 - accuracy: 0.9153 - val_loss: 1.7991 - val_accuracy: 0.6305\n","\n","Epoch 00019: val_accuracy did not improve from 0.84236\n","Epoch 20/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1989 - accuracy: 0.9354 - val_loss: 1.4226 - val_accuracy: 0.6995\n","\n","Epoch 00020: val_accuracy did not improve from 0.84236\n","Epoch 21/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.2672 - accuracy: 0.9099 - val_loss: 0.4963 - val_accuracy: 0.8719\n","\n","Epoch 00021: val_accuracy improved from 0.84236 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 22/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2340 - accuracy: 0.9214 - val_loss: 0.9266 - val_accuracy: 0.7414\n","\n","Epoch 00022: val_accuracy did not improve from 0.87192\n","Epoch 23/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2012 - accuracy: 0.9385 - val_loss: 0.4692 - val_accuracy: 0.8842\n","\n","Epoch 00023: val_accuracy improved from 0.87192 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1802 - accuracy: 0.9294 - val_loss: 0.7918 - val_accuracy: 0.7808\n","\n","Epoch 00024: val_accuracy did not improve from 0.88424\n","Epoch 25/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2426 - accuracy: 0.9184 - val_loss: 1.8866 - val_accuracy: 0.6330\n","\n","Epoch 00025: val_accuracy did not improve from 0.88424\n","Epoch 26/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1996 - accuracy: 0.9300 - val_loss: 1.3523 - val_accuracy: 0.7069\n","\n","Epoch 00026: val_accuracy did not improve from 0.88424\n","Epoch 27/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1465 - accuracy: 0.9568 - val_loss: 0.6525 - val_accuracy: 0.8448\n","\n","Epoch 00027: val_accuracy did not improve from 0.88424\n","Epoch 28/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1533 - accuracy: 0.9476 - val_loss: 0.7761 - val_accuracy: 0.8054\n","\n","Epoch 00028: val_accuracy did not improve from 0.88424\n","Epoch 29/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1901 - accuracy: 0.9300 - val_loss: 0.6992 - val_accuracy: 0.8276\n","\n","Epoch 00029: val_accuracy did not improve from 0.88424\n","Epoch 30/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2008 - accuracy: 0.9269 - val_loss: 0.6553 - val_accuracy: 0.8374\n","\n","Epoch 00030: val_accuracy did not improve from 0.88424\n","Epoch 31/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1456 - accuracy: 0.9482 - val_loss: 0.4991 - val_accuracy: 0.8522\n","\n","Epoch 00031: val_accuracy did not improve from 0.88424\n","Epoch 32/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1798 - accuracy: 0.9409 - val_loss: 0.5002 - val_accuracy: 0.8793\n","\n","Epoch 00032: val_accuracy did not improve from 0.88424\n","Epoch 33/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1478 - accuracy: 0.9488 - val_loss: 0.3919 - val_accuracy: 0.8916\n","\n","Epoch 00033: val_accuracy improved from 0.88424 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 34/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1068 - accuracy: 0.9647 - val_loss: 0.4264 - val_accuracy: 0.8571\n","\n","Epoch 00034: val_accuracy did not improve from 0.89163\n","Epoch 35/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1055 - accuracy: 0.9671 - val_loss: 0.7247 - val_accuracy: 0.8300\n","\n","Epoch 00035: val_accuracy did not improve from 0.89163\n","Epoch 36/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1140 - accuracy: 0.9647 - val_loss: 0.3716 - val_accuracy: 0.8916\n","\n","Epoch 00036: val_accuracy did not improve from 0.89163\n","Epoch 37/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1671 - accuracy: 0.9476 - val_loss: 0.6432 - val_accuracy: 0.8227\n","\n","Epoch 00037: val_accuracy did not improve from 0.89163\n","Epoch 38/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1370 - accuracy: 0.9549 - val_loss: 0.7628 - val_accuracy: 0.8054\n","\n","Epoch 00038: val_accuracy did not improve from 0.89163\n","Epoch 39/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1130 - accuracy: 0.9616 - val_loss: 0.6727 - val_accuracy: 0.8054\n","\n","Epoch 00039: val_accuracy did not improve from 0.89163\n","Epoch 40/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0891 - accuracy: 0.9726 - val_loss: 0.6427 - val_accuracy: 0.8325\n","\n","Epoch 00040: val_accuracy did not improve from 0.89163\n","Epoch 41/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0749 - accuracy: 0.9726 - val_loss: 0.6582 - val_accuracy: 0.8424\n","\n","Epoch 00041: val_accuracy did not improve from 0.89163\n","Epoch 42/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.4838 - val_accuracy: 0.8793\n","\n","Epoch 00042: val_accuracy did not improve from 0.89163\n","Epoch 43/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.1065 - accuracy: 0.9641 - val_loss: 0.5613 - val_accuracy: 0.8621\n","\n","Epoch 00043: val_accuracy did not improve from 0.89163\n","Epoch 44/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1130 - accuracy: 0.9549 - val_loss: 0.7853 - val_accuracy: 0.8227\n","\n","Epoch 00044: val_accuracy did not improve from 0.89163\n","Epoch 45/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1213 - accuracy: 0.9586 - val_loss: 0.4190 - val_accuracy: 0.9039\n","\n","Epoch 00045: val_accuracy improved from 0.89163 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 46/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1147 - accuracy: 0.9610 - val_loss: 0.6430 - val_accuracy: 0.8374\n","\n","Epoch 00046: val_accuracy did not improve from 0.90394\n","Epoch 47/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 0.3852 - val_accuracy: 0.8793\n","\n","Epoch 00047: val_accuracy did not improve from 0.90394\n","Epoch 48/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0929 - accuracy: 0.9708 - val_loss: 0.9312 - val_accuracy: 0.8079\n","\n","Epoch 00048: val_accuracy did not improve from 0.90394\n","Epoch 49/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0813 - accuracy: 0.9677 - val_loss: 0.4478 - val_accuracy: 0.8768\n","\n","Epoch 00049: val_accuracy did not improve from 0.90394\n","Epoch 50/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0636 - accuracy: 0.9744 - val_loss: 0.7394 - val_accuracy: 0.8079\n","\n","Epoch 00050: val_accuracy did not improve from 0.90394\n","Epoch 51/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1124 - accuracy: 0.9659 - val_loss: 0.7584 - val_accuracy: 0.8276\n","\n","Epoch 00051: val_accuracy did not improve from 0.90394\n","Epoch 52/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.5846 - val_accuracy: 0.8596\n","\n","Epoch 00052: val_accuracy did not improve from 0.90394\n","Epoch 53/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0866 - accuracy: 0.9695 - val_loss: 0.4397 - val_accuracy: 0.8842\n","\n","Epoch 00053: val_accuracy did not improve from 0.90394\n","Epoch 54/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0616 - accuracy: 0.9775 - val_loss: 0.4948 - val_accuracy: 0.8842\n","\n","Epoch 00054: val_accuracy did not improve from 0.90394\n","Epoch 55/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.5868 - val_accuracy: 0.8744\n","\n","Epoch 00055: val_accuracy did not improve from 0.90394\n","Epoch 56/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0899 - accuracy: 0.9714 - val_loss: 0.6090 - val_accuracy: 0.8547\n","\n","Epoch 00056: val_accuracy did not improve from 0.90394\n","Epoch 57/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1212 - accuracy: 0.9586 - val_loss: 0.4797 - val_accuracy: 0.8744\n","\n","Epoch 00057: val_accuracy did not improve from 0.90394\n","Epoch 58/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0886 - accuracy: 0.9714 - val_loss: 0.7123 - val_accuracy: 0.8251\n","\n","Epoch 00058: val_accuracy did not improve from 0.90394\n","Epoch 59/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.7038 - val_accuracy: 0.8374\n","\n","Epoch 00059: val_accuracy did not improve from 0.90394\n","Epoch 60/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 0.3987 - val_accuracy: 0.8966\n","\n","Epoch 00060: val_accuracy did not improve from 0.90394\n","Epoch 61/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.4425 - val_accuracy: 0.8990\n","\n","Epoch 00061: val_accuracy did not improve from 0.90394\n","Epoch 62/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.3568 - val_accuracy: 0.9064\n","\n","Epoch 00062: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 63/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.4431 - val_accuracy: 0.9015\n","\n","Epoch 00063: val_accuracy did not improve from 0.90640\n","Epoch 64/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1087 - accuracy: 0.9641 - val_loss: 0.6963 - val_accuracy: 0.8325\n","\n","Epoch 00064: val_accuracy did not improve from 0.90640\n","Epoch 65/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0671 - accuracy: 0.9799 - val_loss: 0.7261 - val_accuracy: 0.8498\n","\n","Epoch 00065: val_accuracy did not improve from 0.90640\n","Epoch 66/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0581 - accuracy: 0.9775 - val_loss: 0.5579 - val_accuracy: 0.8547\n","\n","Epoch 00066: val_accuracy did not improve from 0.90640\n","Epoch 67/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0670 - accuracy: 0.9762 - val_loss: 0.4643 - val_accuracy: 0.8842\n","\n","Epoch 00067: val_accuracy did not improve from 0.90640\n","Epoch 68/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0532 - accuracy: 0.9799 - val_loss: 0.7629 - val_accuracy: 0.8547\n","\n","Epoch 00068: val_accuracy did not improve from 0.90640\n","Epoch 69/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0747 - accuracy: 0.9708 - val_loss: 0.5888 - val_accuracy: 0.8670\n","\n","Epoch 00069: val_accuracy did not improve from 0.90640\n","Epoch 70/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1137 - accuracy: 0.9653 - val_loss: 0.9177 - val_accuracy: 0.8153\n","\n","Epoch 00070: val_accuracy did not improve from 0.90640\n","Epoch 71/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0837 - accuracy: 0.9689 - val_loss: 0.5992 - val_accuracy: 0.8522\n","\n","Epoch 00071: val_accuracy did not improve from 0.90640\n","Epoch 72/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.8373 - val_accuracy: 0.8153\n","\n","Epoch 00072: val_accuracy did not improve from 0.90640\n","Epoch 73/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0627 - accuracy: 0.9769 - val_loss: 0.3560 - val_accuracy: 0.9138\n","\n","Epoch 00073: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 74/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.4090 - val_accuracy: 0.8793\n","\n","Epoch 00074: val_accuracy did not improve from 0.91379\n","Epoch 75/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.4090 - val_accuracy: 0.9015\n","\n","Epoch 00075: val_accuracy did not improve from 0.91379\n","Epoch 76/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 0.3771 - val_accuracy: 0.9039\n","\n","Epoch 00076: val_accuracy did not improve from 0.91379\n","Epoch 77/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.3382 - val_accuracy: 0.9236\n","\n","Epoch 00077: val_accuracy improved from 0.91379 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 78/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0202 - accuracy: 0.9890 - val_loss: 0.4148 - val_accuracy: 0.8916\n","\n","Epoch 00078: val_accuracy did not improve from 0.92365\n","Epoch 79/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.4869 - val_accuracy: 0.9089\n","\n","Epoch 00079: val_accuracy did not improve from 0.92365\n","Epoch 80/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0340 - accuracy: 0.9848 - val_loss: 0.5001 - val_accuracy: 0.8842\n","\n","Epoch 00080: val_accuracy did not improve from 0.92365\n","Epoch 81/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.8244 - val_accuracy: 0.8177\n","\n","Epoch 00081: val_accuracy did not improve from 0.92365\n","Epoch 82/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0619 - accuracy: 0.9793 - val_loss: 0.4452 - val_accuracy: 0.8818\n","\n","Epoch 00082: val_accuracy did not improve from 0.92365\n","Epoch 83/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.7517 - val_accuracy: 0.8571\n","\n","Epoch 00083: val_accuracy did not improve from 0.92365\n","Epoch 84/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0655 - accuracy: 0.9781 - val_loss: 0.4368 - val_accuracy: 0.9039\n","\n","Epoch 00084: val_accuracy did not improve from 0.92365\n","Epoch 85/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0633 - accuracy: 0.9781 - val_loss: 0.6529 - val_accuracy: 0.8596\n","\n","Epoch 00085: val_accuracy did not improve from 0.92365\n","Epoch 86/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.6463 - val_accuracy: 0.8498\n","\n","Epoch 00086: val_accuracy did not improve from 0.92365\n","Epoch 87/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0571 - accuracy: 0.9817 - val_loss: 0.4231 - val_accuracy: 0.8842\n","\n","Epoch 00087: val_accuracy did not improve from 0.92365\n","Epoch 88/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.5384 - val_accuracy: 0.8966\n","\n","Epoch 00088: val_accuracy did not improve from 0.92365\n","Epoch 89/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 0.7222 - val_accuracy: 0.8719\n","\n","Epoch 00089: val_accuracy did not improve from 0.92365\n","Epoch 90/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 0.5597 - val_accuracy: 0.8916\n","\n","Epoch 00090: val_accuracy did not improve from 0.92365\n","Epoch 91/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.5276 - val_accuracy: 0.8768\n","\n","Epoch 00091: val_accuracy did not improve from 0.92365\n","Epoch 92/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.4188 - val_accuracy: 0.9212\n","\n","Epoch 00092: val_accuracy did not improve from 0.92365\n","Epoch 93/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 1.0666 - val_accuracy: 0.8177\n","\n","Epoch 00093: val_accuracy did not improve from 0.92365\n","Epoch 94/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.6090 - val_accuracy: 0.8818\n","\n","Epoch 00094: val_accuracy did not improve from 0.92365\n","Epoch 95/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0491 - accuracy: 0.9829 - val_loss: 0.5526 - val_accuracy: 0.8990\n","\n","Epoch 00095: val_accuracy did not improve from 0.92365\n","Epoch 96/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.5251 - val_accuracy: 0.8867\n","\n","Epoch 00096: val_accuracy did not improve from 0.92365\n","Epoch 97/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0398 - accuracy: 0.9860 - val_loss: 0.5468 - val_accuracy: 0.8916\n","\n","Epoch 00097: val_accuracy did not improve from 0.92365\n","Epoch 98/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.6482 - val_accuracy: 0.8325\n","\n","Epoch 00098: val_accuracy did not improve from 0.92365\n","Epoch 99/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0358 - accuracy: 0.9860 - val_loss: 0.4394 - val_accuracy: 0.9113\n","\n","Epoch 00099: val_accuracy did not improve from 0.92365\n","Epoch 100/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.3821 - val_accuracy: 0.9286\n","\n","Epoch 00100: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 101/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.5445 - val_accuracy: 0.8867\n","\n","Epoch 00101: val_accuracy did not improve from 0.92857\n","Epoch 102/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.4839 - val_accuracy: 0.8966\n","\n","Epoch 00102: val_accuracy did not improve from 0.92857\n","Epoch 103/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.4746 - val_accuracy: 0.9064\n","\n","Epoch 00103: val_accuracy did not improve from 0.92857\n","Epoch 104/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1669 - accuracy: 0.9555 - val_loss: 1.2056 - val_accuracy: 0.8251\n","\n","Epoch 00104: val_accuracy did not improve from 0.92857\n","Epoch 105/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.7521 - val_accuracy: 0.8596\n","\n","Epoch 00105: val_accuracy did not improve from 0.92857\n","Epoch 106/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0943 - accuracy: 0.9647 - val_loss: 0.7192 - val_accuracy: 0.8621\n","\n","Epoch 00106: val_accuracy did not improve from 0.92857\n","Epoch 107/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0430 - accuracy: 0.9848 - val_loss: 0.5253 - val_accuracy: 0.8941\n","\n","Epoch 00107: val_accuracy did not improve from 0.92857\n","Epoch 108/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.4482 - val_accuracy: 0.8941\n","\n","Epoch 00108: val_accuracy did not improve from 0.92857\n","Epoch 109/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.4513 - val_accuracy: 0.9039\n","\n","Epoch 00109: val_accuracy did not improve from 0.92857\n","Epoch 110/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.4643 - val_accuracy: 0.9039\n","\n","Epoch 00110: val_accuracy did not improve from 0.92857\n","Epoch 111/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.4214 - val_accuracy: 0.9039\n","\n","Epoch 00111: val_accuracy did not improve from 0.92857\n","Epoch 112/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.3970 - val_accuracy: 0.9163\n","\n","Epoch 00112: val_accuracy did not improve from 0.92857\n","Epoch 113/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4713 - val_accuracy: 0.9039\n","\n","Epoch 00113: val_accuracy did not improve from 0.92857\n","Epoch 114/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.7213 - val_accuracy: 0.8645\n","\n","Epoch 00114: val_accuracy did not improve from 0.92857\n","Epoch 115/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0482 - accuracy: 0.9860 - val_loss: 0.7917 - val_accuracy: 0.8547\n","\n","Epoch 00115: val_accuracy did not improve from 0.92857\n","Epoch 116/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.6612 - val_accuracy: 0.8522\n","\n","Epoch 00116: val_accuracy did not improve from 0.92857\n","Epoch 117/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0242 - accuracy: 0.9872 - val_loss: 0.5815 - val_accuracy: 0.8867\n","\n","Epoch 00117: val_accuracy did not improve from 0.92857\n","Epoch 118/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.6796 - val_accuracy: 0.8670\n","\n","Epoch 00118: val_accuracy did not improve from 0.92857\n","Epoch 119/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 0.4566 - val_accuracy: 0.9089\n","\n","Epoch 00119: val_accuracy did not improve from 0.92857\n","Epoch 120/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.6073 - val_accuracy: 0.8719\n","\n","Epoch 00120: val_accuracy did not improve from 0.92857\n","Epoch 121/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.4398 - val_accuracy: 0.9089\n","\n","Epoch 00121: val_accuracy did not improve from 0.92857\n","Epoch 122/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.5160 - val_accuracy: 0.9064\n","\n","Epoch 00122: val_accuracy did not improve from 0.92857\n","Epoch 123/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0313 - accuracy: 0.9866 - val_loss: 0.4617 - val_accuracy: 0.9113\n","\n","Epoch 00123: val_accuracy did not improve from 0.92857\n","Epoch 124/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.5772 - val_accuracy: 0.9089\n","\n","Epoch 00124: val_accuracy did not improve from 0.92857\n","Epoch 125/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.6714 - val_accuracy: 0.8892\n","\n","Epoch 00125: val_accuracy did not improve from 0.92857\n","Epoch 126/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.7441 - val_accuracy: 0.8571\n","\n","Epoch 00126: val_accuracy did not improve from 0.92857\n","Epoch 127/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 0.7809 - val_accuracy: 0.8571\n","\n","Epoch 00127: val_accuracy did not improve from 0.92857\n","Epoch 128/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0607 - accuracy: 0.9793 - val_loss: 0.7674 - val_accuracy: 0.8670\n","\n","Epoch 00128: val_accuracy did not improve from 0.92857\n","Epoch 129/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0380 - accuracy: 0.9848 - val_loss: 0.5802 - val_accuracy: 0.8793\n","\n","Epoch 00129: val_accuracy did not improve from 0.92857\n","Epoch 130/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0201 - accuracy: 0.9915 - val_loss: 0.6596 - val_accuracy: 0.8645\n","\n","Epoch 00130: val_accuracy did not improve from 0.92857\n","Epoch 131/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.4835 - val_accuracy: 0.8916\n","\n","Epoch 00131: val_accuracy did not improve from 0.92857\n","Epoch 132/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.6498 - val_accuracy: 0.8645\n","\n","Epoch 00132: val_accuracy did not improve from 0.92857\n","Epoch 133/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4096 - val_accuracy: 0.9015\n","\n","Epoch 00133: val_accuracy did not improve from 0.92857\n","Epoch 134/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.5524 - val_accuracy: 0.8892\n","\n","Epoch 00134: val_accuracy did not improve from 0.92857\n","Epoch 135/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.6555 - val_accuracy: 0.8522\n","\n","Epoch 00135: val_accuracy did not improve from 0.92857\n","Epoch 136/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.4958 - val_accuracy: 0.9089\n","\n","Epoch 00136: val_accuracy did not improve from 0.92857\n","Epoch 137/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 0.8263 - val_accuracy: 0.8547\n","\n","Epoch 00137: val_accuracy did not improve from 0.92857\n","Epoch 138/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.7537 - val_accuracy: 0.8325\n","\n","Epoch 00138: val_accuracy did not improve from 0.92857\n","Epoch 139/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.7038 - val_accuracy: 0.8596\n","\n","Epoch 00139: val_accuracy did not improve from 0.92857\n","Epoch 140/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.5476 - val_accuracy: 0.8941\n","\n","Epoch 00140: val_accuracy did not improve from 0.92857\n","Epoch 141/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.5718 - val_accuracy: 0.8966\n","\n","Epoch 00141: val_accuracy did not improve from 0.92857\n","Epoch 142/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 0.5838 - val_accuracy: 0.8793\n","\n","Epoch 00142: val_accuracy did not improve from 0.92857\n","Epoch 143/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 1.0438 - val_accuracy: 0.8325\n","\n","Epoch 00143: val_accuracy did not improve from 0.92857\n","Epoch 144/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.6331 - val_accuracy: 0.8695\n","\n","Epoch 00144: val_accuracy did not improve from 0.92857\n","Epoch 145/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.6410 - val_accuracy: 0.8744\n","\n","Epoch 00145: val_accuracy did not improve from 0.92857\n","Epoch 146/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.4885 - val_accuracy: 0.9163\n","\n","Epoch 00146: val_accuracy did not improve from 0.92857\n","Epoch 147/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4787 - val_accuracy: 0.9212\n","\n","Epoch 00147: val_accuracy did not improve from 0.92857\n","Epoch 148/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.4481 - val_accuracy: 0.9113\n","\n","Epoch 00148: val_accuracy did not improve from 0.92857\n","Epoch 149/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.4672 - val_accuracy: 0.9064\n","\n","Epoch 00149: val_accuracy did not improve from 0.92857\n","Epoch 150/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5594 - val_accuracy: 0.8892\n","\n","Epoch 00150: val_accuracy did not improve from 0.92857\n","Epoch 151/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.4465 - val_accuracy: 0.9113\n","\n","Epoch 00151: val_accuracy did not improve from 0.92857\n","Epoch 152/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 0.6043 - val_accuracy: 0.8842\n","\n","Epoch 00152: val_accuracy did not improve from 0.92857\n","Epoch 153/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0221 - accuracy: 0.9909 - val_loss: 0.4662 - val_accuracy: 0.8916\n","\n","Epoch 00153: val_accuracy did not improve from 0.92857\n","Epoch 154/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.4356 - val_accuracy: 0.9039\n","\n","Epoch 00154: val_accuracy did not improve from 0.92857\n","Epoch 155/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.6183 - val_accuracy: 0.8768\n","\n","Epoch 00155: val_accuracy did not improve from 0.92857\n","Epoch 156/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.7006 - val_accuracy: 0.8596\n","\n","Epoch 00156: val_accuracy did not improve from 0.92857\n","Epoch 157/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 1.0640 - val_accuracy: 0.8128\n","\n","Epoch 00157: val_accuracy did not improve from 0.92857\n","Epoch 158/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.4965 - val_accuracy: 0.9015\n","\n","Epoch 00158: val_accuracy did not improve from 0.92857\n","Epoch 159/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.6433 - val_accuracy: 0.8867\n","\n","Epoch 00159: val_accuracy did not improve from 0.92857\n","Epoch 160/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.6089 - val_accuracy: 0.8966\n","\n","Epoch 00160: val_accuracy did not improve from 0.92857\n","Epoch 161/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.5204 - val_accuracy: 0.9015\n","\n","Epoch 00161: val_accuracy did not improve from 0.92857\n","Epoch 162/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.6251 - val_accuracy: 0.8818\n","\n","Epoch 00162: val_accuracy did not improve from 0.92857\n","Epoch 163/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.5330 - val_accuracy: 0.8867\n","\n","Epoch 00163: val_accuracy did not improve from 0.92857\n","Epoch 164/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0388 - accuracy: 0.9854 - val_loss: 0.6727 - val_accuracy: 0.8916\n","\n","Epoch 00164: val_accuracy did not improve from 0.92857\n","Epoch 165/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 0.8665 - val_accuracy: 0.8522\n","\n","Epoch 00165: val_accuracy did not improve from 0.92857\n","Epoch 166/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0296 - accuracy: 0.9878 - val_loss: 0.8074 - val_accuracy: 0.8719\n","\n","Epoch 00166: val_accuracy did not improve from 0.92857\n","Epoch 167/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.5702 - val_accuracy: 0.8916\n","\n","Epoch 00167: val_accuracy did not improve from 0.92857\n","Epoch 168/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.4311 - val_accuracy: 0.9089\n","\n","Epoch 00168: val_accuracy did not improve from 0.92857\n","Epoch 169/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9163\n","\n","Epoch 00169: val_accuracy did not improve from 0.92857\n","Epoch 170/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.3934 - val_accuracy: 0.9138\n","\n","Epoch 00170: val_accuracy did not improve from 0.92857\n","Epoch 171/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.5097 - val_accuracy: 0.8867\n","\n","Epoch 00171: val_accuracy did not improve from 0.92857\n","Epoch 172/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.5712 - val_accuracy: 0.8916\n","\n","Epoch 00172: val_accuracy did not improve from 0.92857\n","Epoch 173/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.5314 - val_accuracy: 0.9064\n","\n","Epoch 00173: val_accuracy did not improve from 0.92857\n","Epoch 174/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.7742 - val_accuracy: 0.8768\n","\n","Epoch 00174: val_accuracy did not improve from 0.92857\n","Epoch 175/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0372 - accuracy: 0.9909 - val_loss: 0.7372 - val_accuracy: 0.8670\n","\n","Epoch 00175: val_accuracy did not improve from 0.92857\n","Epoch 176/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0757 - accuracy: 0.9708 - val_loss: 0.5838 - val_accuracy: 0.8793\n","\n","Epoch 00176: val_accuracy did not improve from 0.92857\n","Epoch 177/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.5784 - val_accuracy: 0.8818\n","\n","Epoch 00177: val_accuracy did not improve from 0.92857\n","Epoch 178/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0577 - accuracy: 0.9787 - val_loss: 0.6923 - val_accuracy: 0.8941\n","\n","Epoch 00178: val_accuracy did not improve from 0.92857\n","Epoch 179/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.6704 - val_accuracy: 0.8818\n","\n","Epoch 00179: val_accuracy did not improve from 0.92857\n","Epoch 180/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.8938 - val_accuracy: 0.8670\n","\n","Epoch 00180: val_accuracy did not improve from 0.92857\n","Epoch 181/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.4831 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.92857\n","Epoch 182/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0164 - accuracy: 0.9970 - val_loss: 0.4663 - val_accuracy: 0.9064\n","\n","Epoch 00182: val_accuracy did not improve from 0.92857\n","Epoch 183/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3867 - val_accuracy: 0.9089\n","\n","Epoch 00183: val_accuracy did not improve from 0.92857\n","Epoch 184/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4548 - val_accuracy: 0.9113\n","\n","Epoch 00184: val_accuracy did not improve from 0.92857\n","Epoch 185/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4296 - val_accuracy: 0.9138\n","\n","Epoch 00185: val_accuracy did not improve from 0.92857\n","Epoch 186/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5053 - val_accuracy: 0.9039\n","\n","Epoch 00186: val_accuracy did not improve from 0.92857\n","Epoch 187/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.6078 - val_accuracy: 0.8892\n","\n","Epoch 00187: val_accuracy did not improve from 0.92857\n","Epoch 188/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.6159 - val_accuracy: 0.9015\n","\n","Epoch 00188: val_accuracy did not improve from 0.92857\n","Epoch 189/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0243 - accuracy: 0.9896 - val_loss: 0.7431 - val_accuracy: 0.8842\n","\n","Epoch 00189: val_accuracy did not improve from 0.92857\n","Epoch 190/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0226 - accuracy: 0.9903 - val_loss: 0.8462 - val_accuracy: 0.8645\n","\n","Epoch 00190: val_accuracy did not improve from 0.92857\n","Epoch 191/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6399 - val_accuracy: 0.8719\n","\n","Epoch 00191: val_accuracy did not improve from 0.92857\n","Epoch 192/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.7095 - val_accuracy: 0.8867\n","\n","Epoch 00192: val_accuracy did not improve from 0.92857\n","Epoch 193/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5043 - val_accuracy: 0.8990\n","\n","Epoch 00193: val_accuracy did not improve from 0.92857\n","Epoch 194/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.6701 - val_accuracy: 0.8645\n","\n","Epoch 00194: val_accuracy did not improve from 0.92857\n","Epoch 195/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.8296 - val_accuracy: 0.8768\n","\n","Epoch 00195: val_accuracy did not improve from 0.92857\n","Epoch 196/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.5915 - val_accuracy: 0.8744\n","\n","Epoch 00196: val_accuracy did not improve from 0.92857\n","Epoch 197/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.4940 - val_accuracy: 0.8990\n","\n","Epoch 00197: val_accuracy did not improve from 0.92857\n","Epoch 198/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.5965 - val_accuracy: 0.9039\n","\n","Epoch 00198: val_accuracy did not improve from 0.92857\n","Epoch 199/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3817 - val_accuracy: 0.9163\n","\n","Epoch 00199: val_accuracy did not improve from 0.92857\n","Epoch 200/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.6881 - val_accuracy: 0.8695\n","\n","Epoch 00200: val_accuracy did not improve from 0.92857\n","Epoch 201/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.5333 - val_accuracy: 0.8867\n","\n","Epoch 00201: val_accuracy did not improve from 0.92857\n","Epoch 202/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0460 - accuracy: 0.9884 - val_loss: 0.6100 - val_accuracy: 0.8818\n","\n","Epoch 00202: val_accuracy did not improve from 0.92857\n","Epoch 203/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 0.4613 - val_accuracy: 0.8916\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4403 - val_accuracy: 0.9064\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3388 - val_accuracy: 0.9310\n","\n","Epoch 00205: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 206/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9286\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.3797 - val_accuracy: 0.9163\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9458\n","\n","Epoch 00208: val_accuracy improved from 0.93103 to 0.94581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5\n","Epoch 209/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.3847 - val_accuracy: 0.9261\n","\n","Epoch 00209: val_accuracy did not improve from 0.94581\n","Epoch 210/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.6379 - val_accuracy: 0.8621\n","\n","Epoch 00210: val_accuracy did not improve from 0.94581\n","Epoch 211/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0863 - accuracy: 0.9750 - val_loss: 0.7761 - val_accuracy: 0.8645\n","\n","Epoch 00211: val_accuracy did not improve from 0.94581\n","Epoch 212/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.6872 - val_accuracy: 0.8793\n","\n","Epoch 00212: val_accuracy did not improve from 0.94581\n","Epoch 213/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.3844 - val_accuracy: 0.9187\n","\n","Epoch 00213: val_accuracy did not improve from 0.94581\n","Epoch 214/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5372 - val_accuracy: 0.9163\n","\n","Epoch 00214: val_accuracy did not improve from 0.94581\n","Epoch 215/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.4584 - val_accuracy: 0.9212\n","\n","Epoch 00215: val_accuracy did not improve from 0.94581\n","Epoch 216/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.5071 - val_accuracy: 0.9015\n","\n","Epoch 00216: val_accuracy did not improve from 0.94581\n","Epoch 217/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4679 - val_accuracy: 0.9212\n","\n","Epoch 00217: val_accuracy did not improve from 0.94581\n","Epoch 218/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.4979 - val_accuracy: 0.9187\n","\n","Epoch 00218: val_accuracy did not improve from 0.94581\n","Epoch 219/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.4519 - val_accuracy: 0.9187\n","\n","Epoch 00219: val_accuracy did not improve from 0.94581\n","Epoch 220/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.3971 - val_accuracy: 0.9138\n","\n","Epoch 00220: val_accuracy did not improve from 0.94581\n","Epoch 221/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9236\n","\n","Epoch 00221: val_accuracy did not improve from 0.94581\n","Epoch 222/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.3425 - val_accuracy: 0.9236\n","\n","Epoch 00222: val_accuracy did not improve from 0.94581\n","Epoch 223/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9212\n","\n","Epoch 00223: val_accuracy did not improve from 0.94581\n","Epoch 224/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.1829e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9335\n","\n","Epoch 00224: val_accuracy did not improve from 0.94581\n","Epoch 225/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3840 - val_accuracy: 0.9261\n","\n","Epoch 00225: val_accuracy did not improve from 0.94581\n","Epoch 226/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4554 - val_accuracy: 0.9138\n","\n","Epoch 00226: val_accuracy did not improve from 0.94581\n","Epoch 227/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.3090 - val_accuracy: 0.9286\n","\n","Epoch 00227: val_accuracy did not improve from 0.94581\n","Epoch 228/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4868 - val_accuracy: 0.9089\n","\n","Epoch 00228: val_accuracy did not improve from 0.94581\n","Epoch 229/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.7964 - val_accuracy: 0.8719\n","\n","Epoch 00229: val_accuracy did not improve from 0.94581\n","Epoch 230/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 0.5065 - val_accuracy: 0.9039\n","\n","Epoch 00230: val_accuracy did not improve from 0.94581\n","Epoch 231/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.5205 - val_accuracy: 0.9212\n","\n","Epoch 00231: val_accuracy did not improve from 0.94581\n","Epoch 232/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.9191 - val_accuracy: 0.8177\n","\n","Epoch 00232: val_accuracy did not improve from 0.94581\n","Epoch 233/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.7501 - val_accuracy: 0.8768\n","\n","Epoch 00233: val_accuracy did not improve from 0.94581\n","Epoch 234/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.5132 - val_accuracy: 0.9039\n","\n","Epoch 00234: val_accuracy did not improve from 0.94581\n","Epoch 235/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.8378 - val_accuracy: 0.8547\n","\n","Epoch 00235: val_accuracy did not improve from 0.94581\n","Epoch 236/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0447 - accuracy: 0.9823 - val_loss: 0.7463 - val_accuracy: 0.8670\n","\n","Epoch 00236: val_accuracy did not improve from 0.94581\n","Epoch 237/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.6281 - val_accuracy: 0.8966\n","\n","Epoch 00237: val_accuracy did not improve from 0.94581\n","Epoch 238/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.6270 - val_accuracy: 0.8768\n","\n","Epoch 00238: val_accuracy did not improve from 0.94581\n","Epoch 239/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.5028 - val_accuracy: 0.9089\n","\n","Epoch 00239: val_accuracy did not improve from 0.94581\n","Epoch 240/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.4771 - val_accuracy: 0.9163\n","\n","Epoch 00240: val_accuracy did not improve from 0.94581\n","Epoch 241/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5797 - val_accuracy: 0.8990\n","\n","Epoch 00241: val_accuracy did not improve from 0.94581\n","Epoch 242/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4981 - val_accuracy: 0.9113\n","\n","Epoch 00242: val_accuracy did not improve from 0.94581\n","Epoch 243/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.3274 - val_accuracy: 0.9310\n","\n","Epoch 00243: val_accuracy did not improve from 0.94581\n","Epoch 244/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.5368 - val_accuracy: 0.8990\n","\n","Epoch 00244: val_accuracy did not improve from 0.94581\n","Epoch 245/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0201 - accuracy: 0.9921 - val_loss: 0.5906 - val_accuracy: 0.9039\n","\n","Epoch 00245: val_accuracy did not improve from 0.94581\n","Epoch 246/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.5913 - val_accuracy: 0.8818\n","\n","Epoch 00246: val_accuracy did not improve from 0.94581\n","Epoch 247/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.4933 - val_accuracy: 0.9236\n","\n","Epoch 00247: val_accuracy did not improve from 0.94581\n","Epoch 248/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4768 - val_accuracy: 0.9138\n","\n","Epoch 00248: val_accuracy did not improve from 0.94581\n","Epoch 249/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4522 - val_accuracy: 0.9384\n","\n","Epoch 00249: val_accuracy did not improve from 0.94581\n","Epoch 250/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.4344 - val_accuracy: 0.9089\n","\n","Epoch 00250: val_accuracy did not improve from 0.94581\n","Epoch 251/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9236\n","\n","Epoch 00251: val_accuracy did not improve from 0.94581\n","Epoch 252/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9212\n","\n","Epoch 00252: val_accuracy did not improve from 0.94581\n","Epoch 253/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.6276 - val_accuracy: 0.8916\n","\n","Epoch 00253: val_accuracy did not improve from 0.94581\n","Epoch 254/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.5783 - val_accuracy: 0.9039\n","\n","Epoch 00254: val_accuracy did not improve from 0.94581\n","Epoch 255/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4391 - val_accuracy: 0.9212\n","\n","Epoch 00255: val_accuracy did not improve from 0.94581\n","Epoch 256/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5082 - val_accuracy: 0.8966\n","\n","Epoch 00256: val_accuracy did not improve from 0.94581\n","Epoch 257/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.4399 - val_accuracy: 0.9212\n","\n","Epoch 00257: val_accuracy did not improve from 0.94581\n","Epoch 258/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5523 - val_accuracy: 0.9064\n","\n","Epoch 00258: val_accuracy did not improve from 0.94581\n","Epoch 259/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9187\n","\n","Epoch 00259: val_accuracy did not improve from 0.94581\n","Epoch 260/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.4277 - val_accuracy: 0.9286\n","\n","Epoch 00260: val_accuracy did not improve from 0.94581\n","Epoch 261/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4856 - val_accuracy: 0.9039\n","\n","Epoch 00261: val_accuracy did not improve from 0.94581\n","Epoch 262/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 1.0003 - val_accuracy: 0.8498\n","\n","Epoch 00262: val_accuracy did not improve from 0.94581\n","Epoch 263/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0486 - accuracy: 0.9866 - val_loss: 0.4810 - val_accuracy: 0.9163\n","\n","Epoch 00263: val_accuracy did not improve from 0.94581\n","Epoch 264/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.5749 - val_accuracy: 0.8916\n","\n","Epoch 00264: val_accuracy did not improve from 0.94581\n","Epoch 265/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.8802 - val_accuracy: 0.8621\n","\n","Epoch 00265: val_accuracy did not improve from 0.94581\n","Epoch 266/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.5379 - val_accuracy: 0.9039\n","\n","Epoch 00266: val_accuracy did not improve from 0.94581\n","Epoch 267/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.4649 - val_accuracy: 0.9138\n","\n","Epoch 00267: val_accuracy did not improve from 0.94581\n","Epoch 268/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4525 - val_accuracy: 0.9286\n","\n","Epoch 00268: val_accuracy did not improve from 0.94581\n","Epoch 269/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.5286 - val_accuracy: 0.9138\n","\n","Epoch 00269: val_accuracy did not improve from 0.94581\n","Epoch 270/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.5513 - val_accuracy: 0.9089\n","\n","Epoch 00270: val_accuracy did not improve from 0.94581\n","Epoch 271/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0278 - accuracy: 0.9951 - val_loss: 0.8290 - val_accuracy: 0.8916\n","\n","Epoch 00271: val_accuracy did not improve from 0.94581\n","Epoch 272/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.6582 - val_accuracy: 0.8966\n","\n","Epoch 00272: val_accuracy did not improve from 0.94581\n","Epoch 273/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.5986 - val_accuracy: 0.8941\n","\n","Epoch 00273: val_accuracy did not improve from 0.94581\n","Epoch 274/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.7477 - val_accuracy: 0.8892\n","\n","Epoch 00274: val_accuracy did not improve from 0.94581\n","Epoch 275/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.7407 - val_accuracy: 0.8744\n","\n","Epoch 00275: val_accuracy did not improve from 0.94581\n","Epoch 276/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.5725 - val_accuracy: 0.9039\n","\n","Epoch 00276: val_accuracy did not improve from 0.94581\n","Epoch 277/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.6120 - val_accuracy: 0.8916\n","\n","Epoch 00277: val_accuracy did not improve from 0.94581\n","Epoch 278/500\n","52/52 [==============================] - 11s 211ms/step - loss: 0.0580 - accuracy: 0.9848 - val_loss: 0.6591 - val_accuracy: 0.8966\n","\n","Epoch 00278: val_accuracy did not improve from 0.94581\n","Epoch 279/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.4831 - val_accuracy: 0.8990\n","\n","Epoch 00279: val_accuracy did not improve from 0.94581\n","Epoch 280/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.4904 - val_accuracy: 0.9212\n","\n","Epoch 00280: val_accuracy did not improve from 0.94581\n","Epoch 281/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4128 - val_accuracy: 0.9261\n","\n","Epoch 00281: val_accuracy did not improve from 0.94581\n","Epoch 282/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4249 - val_accuracy: 0.9113\n","\n","Epoch 00282: val_accuracy did not improve from 0.94581\n","Epoch 283/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9360\n","\n","Epoch 00283: val_accuracy did not improve from 0.94581\n","Epoch 284/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4555 - val_accuracy: 0.9236\n","\n","Epoch 00284: val_accuracy did not improve from 0.94581\n","Epoch 285/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.4475 - val_accuracy: 0.9236\n","\n","Epoch 00285: val_accuracy did not improve from 0.94581\n","Epoch 286/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9187\n","\n","Epoch 00286: val_accuracy did not improve from 0.94581\n","Epoch 287/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4785 - val_accuracy: 0.9089\n","\n","Epoch 00287: val_accuracy did not improve from 0.94581\n","Epoch 288/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4545 - val_accuracy: 0.8990\n","\n","Epoch 00288: val_accuracy did not improve from 0.94581\n","Epoch 289/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4762 - val_accuracy: 0.9187\n","\n","Epoch 00289: val_accuracy did not improve from 0.94581\n","Epoch 290/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4533 - val_accuracy: 0.9089\n","\n","Epoch 00290: val_accuracy did not improve from 0.94581\n","Epoch 291/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4592 - val_accuracy: 0.9138\n","\n","Epoch 00291: val_accuracy did not improve from 0.94581\n","Epoch 292/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4719 - val_accuracy: 0.9163\n","\n","Epoch 00292: val_accuracy did not improve from 0.94581\n","Epoch 293/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4062 - val_accuracy: 0.9163\n","\n","Epoch 00293: val_accuracy did not improve from 0.94581\n","Epoch 294/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.6040 - val_accuracy: 0.8867\n","\n","Epoch 00294: val_accuracy did not improve from 0.94581\n","Epoch 295/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0112 - accuracy: 0.9951 - val_loss: 0.5410 - val_accuracy: 0.9015\n","\n","Epoch 00295: val_accuracy did not improve from 0.94581\n","Epoch 296/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4820 - val_accuracy: 0.9236\n","\n","Epoch 00296: val_accuracy did not improve from 0.94581\n","Epoch 297/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 1.0015 - val_accuracy: 0.8473\n","\n","Epoch 00297: val_accuracy did not improve from 0.94581\n","Epoch 298/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.6081 - val_accuracy: 0.8842\n","\n","Epoch 00298: val_accuracy did not improve from 0.94581\n","Epoch 299/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.6826 - val_accuracy: 0.8793\n","\n","Epoch 00299: val_accuracy did not improve from 0.94581\n","Epoch 300/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.5986 - val_accuracy: 0.8892\n","\n","Epoch 00300: val_accuracy did not improve from 0.94581\n","Epoch 301/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4855 - val_accuracy: 0.9138\n","\n","Epoch 00301: val_accuracy did not improve from 0.94581\n","Epoch 302/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5003 - val_accuracy: 0.9089\n","\n","Epoch 00302: val_accuracy did not improve from 0.94581\n","Epoch 303/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4868 - val_accuracy: 0.9236\n","\n","Epoch 00303: val_accuracy did not improve from 0.94581\n","Epoch 304/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9335\n","\n","Epoch 00304: val_accuracy did not improve from 0.94581\n","Epoch 305/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.6816e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9286\n","\n","Epoch 00305: val_accuracy did not improve from 0.94581\n","Epoch 306/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9138\n","\n","Epoch 00306: val_accuracy did not improve from 0.94581\n","Epoch 307/500\n","52/52 [==============================] - 11s 204ms/step - loss: 6.7018e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9138\n","\n","Epoch 00307: val_accuracy did not improve from 0.94581\n","Epoch 308/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4659 - val_accuracy: 0.9261\n","\n","Epoch 00308: val_accuracy did not improve from 0.94581\n","Epoch 309/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.4031 - val_accuracy: 0.9212\n","\n","Epoch 00309: val_accuracy did not improve from 0.94581\n","Epoch 310/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.4960 - val_accuracy: 0.9064\n","\n","Epoch 00310: val_accuracy did not improve from 0.94581\n","Epoch 311/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.4006 - val_accuracy: 0.9236\n","\n","Epoch 00311: val_accuracy did not improve from 0.94581\n","Epoch 312/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 0.8799 - val_accuracy: 0.8645\n","\n","Epoch 00312: val_accuracy did not improve from 0.94581\n","Epoch 313/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0602 - accuracy: 0.9829 - val_loss: 0.7982 - val_accuracy: 0.8719\n","\n","Epoch 00313: val_accuracy did not improve from 0.94581\n","Epoch 314/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.5725 - val_accuracy: 0.8916\n","\n","Epoch 00314: val_accuracy did not improve from 0.94581\n","Epoch 315/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.5138 - val_accuracy: 0.9039\n","\n","Epoch 00315: val_accuracy did not improve from 0.94581\n","Epoch 316/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.7488 - val_accuracy: 0.8596\n","\n","Epoch 00316: val_accuracy did not improve from 0.94581\n","Epoch 317/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.6898 - val_accuracy: 0.8768\n","\n","Epoch 00317: val_accuracy did not improve from 0.94581\n","Epoch 318/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.6512 - val_accuracy: 0.8842\n","\n","Epoch 00318: val_accuracy did not improve from 0.94581\n","Epoch 319/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.6837 - val_accuracy: 0.8695\n","\n","Epoch 00319: val_accuracy did not improve from 0.94581\n","Epoch 320/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.5474 - val_accuracy: 0.8892\n","\n","Epoch 00320: val_accuracy did not improve from 0.94581\n","Epoch 321/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3960 - val_accuracy: 0.9064\n","\n","Epoch 00321: val_accuracy did not improve from 0.94581\n","Epoch 322/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9261\n","\n","Epoch 00322: val_accuracy did not improve from 0.94581\n","Epoch 323/500\n","52/52 [==============================] - 11s 209ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.4259 - val_accuracy: 0.9138\n","\n","Epoch 00323: val_accuracy did not improve from 0.94581\n","Epoch 324/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.4045 - val_accuracy: 0.9138\n","\n","Epoch 00324: val_accuracy did not improve from 0.94581\n","Epoch 325/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5383 - val_accuracy: 0.8941\n","\n","Epoch 00325: val_accuracy did not improve from 0.94581\n","Epoch 326/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4464 - val_accuracy: 0.9236\n","\n","Epoch 00326: val_accuracy did not improve from 0.94581\n","Epoch 327/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4371 - val_accuracy: 0.9138\n","\n","Epoch 00327: val_accuracy did not improve from 0.94581\n","Epoch 328/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9286\n","\n","Epoch 00328: val_accuracy did not improve from 0.94581\n","Epoch 329/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.4702e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9310\n","\n","Epoch 00329: val_accuracy did not improve from 0.94581\n","Epoch 330/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0038 - accuracy: 0.9970 - val_loss: 0.4950 - val_accuracy: 0.9212\n","\n","Epoch 00330: val_accuracy did not improve from 0.94581\n","Epoch 331/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.4101 - val_accuracy: 0.9310\n","\n","Epoch 00331: val_accuracy did not improve from 0.94581\n","Epoch 332/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0144 - accuracy: 0.9939 - val_loss: 1.1946 - val_accuracy: 0.8473\n","\n","Epoch 00332: val_accuracy did not improve from 0.94581\n","Epoch 333/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9927 - val_loss: 0.5100 - val_accuracy: 0.9064\n","\n","Epoch 00333: val_accuracy did not improve from 0.94581\n","Epoch 334/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5313 - val_accuracy: 0.8941\n","\n","Epoch 00334: val_accuracy did not improve from 0.94581\n","Epoch 335/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5144 - val_accuracy: 0.9015\n","\n","Epoch 00335: val_accuracy did not improve from 0.94581\n","Epoch 336/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5139 - val_accuracy: 0.9039\n","\n","Epoch 00336: val_accuracy did not improve from 0.94581\n","Epoch 337/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.0133e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9089\n","\n","Epoch 00337: val_accuracy did not improve from 0.94581\n","Epoch 338/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.8626e-04 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9163\n","\n","Epoch 00338: val_accuracy did not improve from 0.94581\n","Epoch 339/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.5459 - val_accuracy: 0.8892\n","\n","Epoch 00339: val_accuracy did not improve from 0.94581\n","Epoch 340/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9212\n","\n","Epoch 00340: val_accuracy did not improve from 0.94581\n","Epoch 341/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.4246 - val_accuracy: 0.9163\n","\n","Epoch 00341: val_accuracy did not improve from 0.94581\n","Epoch 342/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4725 - val_accuracy: 0.9163\n","\n","Epoch 00342: val_accuracy did not improve from 0.94581\n","Epoch 343/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9212\n","\n","Epoch 00343: val_accuracy did not improve from 0.94581\n","Epoch 344/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9236\n","\n","Epoch 00344: val_accuracy did not improve from 0.94581\n","Epoch 345/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.3452e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9335\n","\n","Epoch 00345: val_accuracy did not improve from 0.94581\n","Epoch 346/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.0052e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9236\n","\n","Epoch 00346: val_accuracy did not improve from 0.94581\n","Epoch 347/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.8446e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9360\n","\n","Epoch 00347: val_accuracy did not improve from 0.94581\n","Epoch 348/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.1464e-04 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9187\n","\n","Epoch 00348: val_accuracy did not improve from 0.94581\n","Epoch 349/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3878 - val_accuracy: 0.9310\n","\n","Epoch 00349: val_accuracy did not improve from 0.94581\n","Epoch 350/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0097 - accuracy: 0.9951 - val_loss: 0.6448 - val_accuracy: 0.8842\n","\n","Epoch 00350: val_accuracy did not improve from 0.94581\n","Epoch 351/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.6857 - val_accuracy: 0.8966\n","\n","Epoch 00351: val_accuracy did not improve from 0.94581\n","Epoch 352/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.7948 - val_accuracy: 0.8695\n","\n","Epoch 00352: val_accuracy did not improve from 0.94581\n","Epoch 353/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 1.1178 - val_accuracy: 0.8498\n","\n","Epoch 00353: val_accuracy did not improve from 0.94581\n","Epoch 354/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 1.1826 - val_accuracy: 0.8424\n","\n","Epoch 00354: val_accuracy did not improve from 0.94581\n","Epoch 355/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 2.0700 - val_accuracy: 0.7217\n","\n","Epoch 00355: val_accuracy did not improve from 0.94581\n","Epoch 356/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.6084 - val_accuracy: 0.8793\n","\n","Epoch 00356: val_accuracy did not improve from 0.94581\n","Epoch 357/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.5028 - val_accuracy: 0.9113\n","\n","Epoch 00357: val_accuracy did not improve from 0.94581\n","Epoch 358/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4716 - val_accuracy: 0.9089\n","\n","Epoch 00358: val_accuracy did not improve from 0.94581\n","Epoch 359/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9236\n","\n","Epoch 00359: val_accuracy did not improve from 0.94581\n","Epoch 360/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4735 - val_accuracy: 0.9261\n","\n","Epoch 00360: val_accuracy did not improve from 0.94581\n","Epoch 361/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9286\n","\n","Epoch 00361: val_accuracy did not improve from 0.94581\n","Epoch 362/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4055 - val_accuracy: 0.9384\n","\n","Epoch 00362: val_accuracy did not improve from 0.94581\n","Epoch 363/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.4536 - val_accuracy: 0.9261\n","\n","Epoch 00363: val_accuracy did not improve from 0.94581\n","Epoch 364/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6240 - val_accuracy: 0.9039\n","\n","Epoch 00364: val_accuracy did not improve from 0.94581\n","Epoch 365/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5519 - val_accuracy: 0.9212\n","\n","Epoch 00365: val_accuracy did not improve from 0.94581\n","Epoch 366/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5431 - val_accuracy: 0.9138\n","\n","Epoch 00366: val_accuracy did not improve from 0.94581\n","Epoch 367/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3778 - val_accuracy: 0.9163\n","\n","Epoch 00367: val_accuracy did not improve from 0.94581\n","Epoch 368/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5674 - val_accuracy: 0.9138\n","\n","Epoch 00368: val_accuracy did not improve from 0.94581\n","Epoch 369/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.5666 - val_accuracy: 0.9138\n","\n","Epoch 00369: val_accuracy did not improve from 0.94581\n","Epoch 370/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5952 - val_accuracy: 0.8990\n","\n","Epoch 00370: val_accuracy did not improve from 0.94581\n","Epoch 371/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4997 - val_accuracy: 0.9039\n","\n","Epoch 00371: val_accuracy did not improve from 0.94581\n","Epoch 372/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5486 - val_accuracy: 0.9212\n","\n","Epoch 00372: val_accuracy did not improve from 0.94581\n","Epoch 373/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.7480 - val_accuracy: 0.8645\n","\n","Epoch 00373: val_accuracy did not improve from 0.94581\n","Epoch 374/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.4868 - val_accuracy: 0.8892\n","\n","Epoch 00374: val_accuracy did not improve from 0.94581\n","Epoch 375/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4936 - val_accuracy: 0.9163\n","\n","Epoch 00375: val_accuracy did not improve from 0.94581\n","Epoch 376/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9187\n","\n","Epoch 00376: val_accuracy did not improve from 0.94581\n","Epoch 377/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.9714 - val_accuracy: 0.8424\n","\n","Epoch 00377: val_accuracy did not improve from 0.94581\n","Epoch 378/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 1.0327 - val_accuracy: 0.8251\n","\n","Epoch 00378: val_accuracy did not improve from 0.94581\n","Epoch 379/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.9783 - val_accuracy: 0.8128\n","\n","Epoch 00379: val_accuracy did not improve from 0.94581\n","Epoch 380/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.5311 - val_accuracy: 0.8916\n","\n","Epoch 00380: val_accuracy did not improve from 0.94581\n","Epoch 381/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.4545 - val_accuracy: 0.9236\n","\n","Epoch 00381: val_accuracy did not improve from 0.94581\n","Epoch 382/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.8040 - val_accuracy: 0.8621\n","\n","Epoch 00382: val_accuracy did not improve from 0.94581\n","Epoch 383/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4671 - val_accuracy: 0.9113\n","\n","Epoch 00383: val_accuracy did not improve from 0.94581\n","Epoch 384/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9236\n","\n","Epoch 00384: val_accuracy did not improve from 0.94581\n","Epoch 385/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9212\n","\n","Epoch 00385: val_accuracy did not improve from 0.94581\n","Epoch 386/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4004 - val_accuracy: 0.9163\n","\n","Epoch 00386: val_accuracy did not improve from 0.94581\n","Epoch 387/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4617 - val_accuracy: 0.9113\n","\n","Epoch 00387: val_accuracy did not improve from 0.94581\n","Epoch 388/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9335\n","\n","Epoch 00388: val_accuracy did not improve from 0.94581\n","Epoch 389/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5476 - val_accuracy: 0.8941\n","\n","Epoch 00389: val_accuracy did not improve from 0.94581\n","Epoch 390/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.7405 - val_accuracy: 0.8892\n","\n","Epoch 00390: val_accuracy did not improve from 0.94581\n","Epoch 391/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.4704 - val_accuracy: 0.9138\n","\n","Epoch 00391: val_accuracy did not improve from 0.94581\n","Epoch 392/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5223 - val_accuracy: 0.9138\n","\n","Epoch 00392: val_accuracy did not improve from 0.94581\n","Epoch 393/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4386 - val_accuracy: 0.9138\n","\n","Epoch 00393: val_accuracy did not improve from 0.94581\n","Epoch 394/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.8198e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9310\n","\n","Epoch 00394: val_accuracy did not improve from 0.94581\n","Epoch 395/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.3659e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9236\n","\n","Epoch 00395: val_accuracy did not improve from 0.94581\n","Epoch 396/500\n","52/52 [==============================] - 11s 208ms/step - loss: 5.2298e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9409\n","\n","Epoch 00396: val_accuracy did not improve from 0.94581\n","Epoch 397/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.6375e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9335\n","\n","Epoch 00397: val_accuracy did not improve from 0.94581\n","Epoch 398/500\n","52/52 [==============================] - 11s 207ms/step - loss: 4.4797e-04 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9212\n","\n","Epoch 00398: val_accuracy did not improve from 0.94581\n","Epoch 399/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.5363e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9286\n","\n","Epoch 00399: val_accuracy did not improve from 0.94581\n","Epoch 400/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9286\n","\n","Epoch 00400: val_accuracy did not improve from 0.94581\n","Epoch 401/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.5351 - val_accuracy: 0.9163\n","\n","Epoch 00401: val_accuracy did not improve from 0.94581\n","Epoch 402/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4837 - val_accuracy: 0.9212\n","\n","Epoch 00402: val_accuracy did not improve from 0.94581\n","Epoch 403/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4188 - val_accuracy: 0.9138\n","\n","Epoch 00403: val_accuracy did not improve from 0.94581\n","Epoch 404/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4769 - val_accuracy: 0.9089\n","\n","Epoch 00404: val_accuracy did not improve from 0.94581\n","Epoch 405/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0369 - accuracy: 0.9915 - val_loss: 1.1973 - val_accuracy: 0.8177\n","\n","Epoch 00405: val_accuracy did not improve from 0.94581\n","Epoch 406/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.6428 - val_accuracy: 0.8966\n","\n","Epoch 00406: val_accuracy did not improve from 0.94581\n","Epoch 407/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0099 - accuracy: 0.9951 - val_loss: 0.4188 - val_accuracy: 0.9113\n","\n","Epoch 00407: val_accuracy did not improve from 0.94581\n","Epoch 408/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9113\n","\n","Epoch 00408: val_accuracy did not improve from 0.94581\n","Epoch 409/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.9129e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9236\n","\n","Epoch 00409: val_accuracy did not improve from 0.94581\n","Epoch 410/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.7094e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9310\n","\n","Epoch 00410: val_accuracy did not improve from 0.94581\n","Epoch 411/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.1190e-04 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9286\n","\n","Epoch 00411: val_accuracy did not improve from 0.94581\n","Epoch 412/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.0267e-04 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9187\n","\n","Epoch 00412: val_accuracy did not improve from 0.94581\n","Epoch 413/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4742 - val_accuracy: 0.9163\n","\n","Epoch 00413: val_accuracy did not improve from 0.94581\n","Epoch 414/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5982 - val_accuracy: 0.8867\n","\n","Epoch 00414: val_accuracy did not improve from 0.94581\n","Epoch 415/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 1.1023 - val_accuracy: 0.8276\n","\n","Epoch 00415: val_accuracy did not improve from 0.94581\n","Epoch 416/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.8194 - val_accuracy: 0.8719\n","\n","Epoch 00416: val_accuracy did not improve from 0.94581\n","Epoch 417/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.6817 - val_accuracy: 0.8892\n","\n","Epoch 00417: val_accuracy did not improve from 0.94581\n","Epoch 418/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 1.1706 - val_accuracy: 0.8251\n","\n","Epoch 00418: val_accuracy did not improve from 0.94581\n","Epoch 419/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.6982 - val_accuracy: 0.8916\n","\n","Epoch 00419: val_accuracy did not improve from 0.94581\n","Epoch 420/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4754 - val_accuracy: 0.8990\n","\n","Epoch 00420: val_accuracy did not improve from 0.94581\n","Epoch 421/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.4432 - val_accuracy: 0.9360\n","\n","Epoch 00421: val_accuracy did not improve from 0.94581\n","Epoch 422/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.5109 - val_accuracy: 0.9089\n","\n","Epoch 00422: val_accuracy did not improve from 0.94581\n","Epoch 423/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.4684 - val_accuracy: 0.9138\n","\n","Epoch 00423: val_accuracy did not improve from 0.94581\n","Epoch 424/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.6017 - val_accuracy: 0.8966\n","\n","Epoch 00424: val_accuracy did not improve from 0.94581\n","Epoch 425/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5016 - val_accuracy: 0.9039\n","\n","Epoch 00425: val_accuracy did not improve from 0.94581\n","Epoch 426/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5035 - val_accuracy: 0.9236\n","\n","Epoch 00426: val_accuracy did not improve from 0.94581\n","Epoch 427/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4569 - val_accuracy: 0.9163\n","\n","Epoch 00427: val_accuracy did not improve from 0.94581\n","Epoch 428/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 0.6452 - val_accuracy: 0.8892\n","\n","Epoch 00428: val_accuracy did not improve from 0.94581\n","Epoch 429/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6989 - val_accuracy: 0.8966\n","\n","Epoch 00429: val_accuracy did not improve from 0.94581\n","Epoch 430/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.5882 - val_accuracy: 0.8941\n","\n","Epoch 00430: val_accuracy did not improve from 0.94581\n","Epoch 431/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.7831 - val_accuracy: 0.8498\n","\n","Epoch 00431: val_accuracy did not improve from 0.94581\n","Epoch 432/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5059 - val_accuracy: 0.8990\n","\n","Epoch 00432: val_accuracy did not improve from 0.94581\n","Epoch 433/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4324 - val_accuracy: 0.9089\n","\n","Epoch 00433: val_accuracy did not improve from 0.94581\n","Epoch 434/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4906 - val_accuracy: 0.9187\n","\n","Epoch 00434: val_accuracy did not improve from 0.94581\n","Epoch 435/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4300 - val_accuracy: 0.9261\n","\n","Epoch 00435: val_accuracy did not improve from 0.94581\n","Epoch 436/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.3951 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.94581\n","Epoch 437/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.4652 - val_accuracy: 0.9113\n","\n","Epoch 00437: val_accuracy did not improve from 0.94581\n","Epoch 438/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.4890 - val_accuracy: 0.9064\n","\n","Epoch 00438: val_accuracy did not improve from 0.94581\n","Epoch 439/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4720 - val_accuracy: 0.9015\n","\n","Epoch 00439: val_accuracy did not improve from 0.94581\n","Epoch 440/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4183 - val_accuracy: 0.9187\n","\n","Epoch 00440: val_accuracy did not improve from 0.94581\n","Epoch 441/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.3533 - val_accuracy: 0.9261\n","\n","Epoch 00441: val_accuracy did not improve from 0.94581\n","Epoch 442/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.9758e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9212\n","\n","Epoch 00442: val_accuracy did not improve from 0.94581\n","Epoch 443/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4080 - val_accuracy: 0.9138\n","\n","Epoch 00443: val_accuracy did not improve from 0.94581\n","Epoch 444/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.6867e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9163\n","\n","Epoch 00444: val_accuracy did not improve from 0.94581\n","Epoch 445/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.4977e-04 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9261\n","\n","Epoch 00445: val_accuracy did not improve from 0.94581\n","Epoch 446/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.9097e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9286\n","\n","Epoch 00446: val_accuracy did not improve from 0.94581\n","Epoch 447/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.0199e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9187\n","\n","Epoch 00447: val_accuracy did not improve from 0.94581\n","Epoch 448/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.4782e-04 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9310\n","\n","Epoch 00448: val_accuracy did not improve from 0.94581\n","Epoch 449/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.6639 - val_accuracy: 0.8744\n","\n","Epoch 00449: val_accuracy did not improve from 0.94581\n","Epoch 450/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.6043 - val_accuracy: 0.8818\n","\n","Epoch 00450: val_accuracy did not improve from 0.94581\n","Epoch 451/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.5457 - val_accuracy: 0.8966\n","\n","Epoch 00451: val_accuracy did not improve from 0.94581\n","Epoch 452/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9113\n","\n","Epoch 00452: val_accuracy did not improve from 0.94581\n","Epoch 453/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9212\n","\n","Epoch 00453: val_accuracy did not improve from 0.94581\n","Epoch 454/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9187\n","\n","Epoch 00454: val_accuracy did not improve from 0.94581\n","Epoch 455/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9409\n","\n","Epoch 00455: val_accuracy did not improve from 0.94581\n","Epoch 456/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.1041e-04 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9335\n","\n","Epoch 00456: val_accuracy did not improve from 0.94581\n","Epoch 457/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4067 - val_accuracy: 0.9187\n","\n","Epoch 00457: val_accuracy did not improve from 0.94581\n","Epoch 458/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.5686 - val_accuracy: 0.9138\n","\n","Epoch 00458: val_accuracy did not improve from 0.94581\n","Epoch 459/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5826 - val_accuracy: 0.8966\n","\n","Epoch 00459: val_accuracy did not improve from 0.94581\n","Epoch 460/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5932 - val_accuracy: 0.9089\n","\n","Epoch 00460: val_accuracy did not improve from 0.94581\n","Epoch 461/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4636 - val_accuracy: 0.9138\n","\n","Epoch 00461: val_accuracy did not improve from 0.94581\n","Epoch 462/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.5028 - val_accuracy: 0.9015\n","\n","Epoch 00462: val_accuracy did not improve from 0.94581\n","Epoch 463/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.6307 - val_accuracy: 0.8695\n","\n","Epoch 00463: val_accuracy did not improve from 0.94581\n","Epoch 464/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5788 - val_accuracy: 0.8941\n","\n","Epoch 00464: val_accuracy did not improve from 0.94581\n","Epoch 465/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4459 - val_accuracy: 0.9113\n","\n","Epoch 00465: val_accuracy did not improve from 0.94581\n","Epoch 466/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4279 - val_accuracy: 0.9286\n","\n","Epoch 00466: val_accuracy did not improve from 0.94581\n","Epoch 467/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.4336e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9236\n","\n","Epoch 00467: val_accuracy did not improve from 0.94581\n","Epoch 468/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.9187\n","\n","Epoch 00468: val_accuracy did not improve from 0.94581\n","Epoch 469/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4125 - val_accuracy: 0.9261\n","\n","Epoch 00469: val_accuracy did not improve from 0.94581\n","Epoch 470/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.4292 - val_accuracy: 0.9163\n","\n","Epoch 00470: val_accuracy did not improve from 0.94581\n","Epoch 471/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.4795e-04 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9064\n","\n","Epoch 00471: val_accuracy did not improve from 0.94581\n","Epoch 472/500\n","52/52 [==============================] - 11s 207ms/step - loss: 3.0306e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9187\n","\n","Epoch 00472: val_accuracy did not improve from 0.94581\n","Epoch 473/500\n","52/52 [==============================] - 11s 207ms/step - loss: 3.3433e-04 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9113\n","\n","Epoch 00473: val_accuracy did not improve from 0.94581\n","Epoch 474/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4958 - val_accuracy: 0.9187\n","\n","Epoch 00474: val_accuracy did not improve from 0.94581\n","Epoch 475/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 1.0267 - val_accuracy: 0.8276\n","\n","Epoch 00475: val_accuracy did not improve from 0.94581\n","Epoch 476/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.7273 - val_accuracy: 0.8768\n","\n","Epoch 00476: val_accuracy did not improve from 0.94581\n","Epoch 477/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.9184 - val_accuracy: 0.8695\n","\n","Epoch 00477: val_accuracy did not improve from 0.94581\n","Epoch 478/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.6835 - val_accuracy: 0.8768\n","\n","Epoch 00478: val_accuracy did not improve from 0.94581\n","Epoch 479/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.6432 - val_accuracy: 0.9015\n","\n","Epoch 00479: val_accuracy did not improve from 0.94581\n","Epoch 480/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.4166 - val_accuracy: 0.9236\n","\n","Epoch 00480: val_accuracy did not improve from 0.94581\n","Epoch 481/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4485 - val_accuracy: 0.9187\n","\n","Epoch 00481: val_accuracy did not improve from 0.94581\n","Epoch 482/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.8339 - val_accuracy: 0.8719\n","\n","Epoch 00482: val_accuracy did not improve from 0.94581\n","Epoch 483/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0193 - accuracy: 0.9927 - val_loss: 0.6747 - val_accuracy: 0.8867\n","\n","Epoch 00483: val_accuracy did not improve from 0.94581\n","Epoch 484/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.5758 - val_accuracy: 0.9015\n","\n","Epoch 00484: val_accuracy did not improve from 0.94581\n","Epoch 485/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.9053e-04 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9113\n","\n","Epoch 00485: val_accuracy did not improve from 0.94581\n","Epoch 486/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.2632e-04 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9335\n","\n","Epoch 00486: val_accuracy did not improve from 0.94581\n","Epoch 487/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.9058e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9089\n","\n","Epoch 00487: val_accuracy did not improve from 0.94581\n","Epoch 488/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.7749e-04 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9187\n","\n","Epoch 00488: val_accuracy did not improve from 0.94581\n","Epoch 489/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.0134e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9236\n","\n","Epoch 00489: val_accuracy did not improve from 0.94581\n","Epoch 490/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.9801e-04 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9187\n","\n","Epoch 00490: val_accuracy did not improve from 0.94581\n","Epoch 491/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.2951e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9138\n","\n","Epoch 00491: val_accuracy did not improve from 0.94581\n","Epoch 492/500\n","52/52 [==============================] - 11s 208ms/step - loss: 7.5922e-04 - accuracy: 0.9994 - val_loss: 0.4384 - val_accuracy: 0.9212\n","\n","Epoch 00492: val_accuracy did not improve from 0.94581\n","Epoch 493/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.1662e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9187\n","\n","Epoch 00493: val_accuracy did not improve from 0.94581\n","Epoch 494/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.4939e-04 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.94581\n","Epoch 495/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.1153e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9261\n","\n","Epoch 00495: val_accuracy did not improve from 0.94581\n","Epoch 496/500\n","52/52 [==============================] - 11s 208ms/step - loss: 3.1023e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9212\n","\n","Epoch 00496: val_accuracy did not improve from 0.94581\n","Epoch 497/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.0557e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9236\n","\n","Epoch 00497: val_accuracy did not improve from 0.94581\n","Epoch 498/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.7882e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9261\n","\n","Epoch 00498: val_accuracy did not improve from 0.94581\n","Epoch 499/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.9140e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9089\n","\n","Epoch 00499: val_accuracy did not improve from 0.94581\n","Epoch 500/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.7071e-04 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9286\n","\n","Epoch 00500: val_accuracy did not improve from 0.94581\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f431a1c4410>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630507986068,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0f32232b-0f32-49f4-a854-33b168b931b4"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3hUVfrHP2dSSYEQCDX0IoaOAUEsIFVF7ArqWtYV6+ruurq6+nOtu3Zdy9rWvvaOK4oNlLUCSg29hxoCCell5vz+OPfO3JnMJBNIcSbv53nmmbn9nDv3fu973vc95yqtNYIgCELk42ruAgiCIAgNgwi6IAhClCCCLgiCECWIoAuCIEQJIuiCIAhRQmxzHbh9+/a6Z8+ezXV4QRCEiGTx4sV7tdYZwZY1m6D37NmTRYsWNdfhBUEQIhKl1JZQy8TlIgiCECWIoAuCIEQJIuiCIAhRggi6IAhClCCCLgiCECXUKehKqeeVUnuUUitCLFdKqUeVUuuVUsuUUiMavpiCIAhCXYRjob8ITK1l+QlAP+szC3jy0IslCIIg1Jc689C11t8opXrWssopwMvajMP7g1IqTSnVWWu9s4HKKNRBtdtDbEzDec+q3R52HSgns21SyHUqqz3EuBQxLgVAldvDez/nMqpXO3q1Tw66TUW1m+37y+idkRJ2Wcoq3Xy+ajfb9pWSEOvi+AEdvNt7PJofNuaTlhRPu5R4Pl2xi+KKapSCwV3b0C45gd4ZySTGxYTc/67CcpITYkhNjPPWY87ynRSWVXHCoM5syCumfUoC/1uXR3bPdHq1TyY5IdZbtuKKajJSE4Lu2+3RfJ6ziy35paQmxlFR7aZfh1TiYhT7SyuJj3VxTL8M9pdW0iE1EYBt+0r53/q97CwoA+DofhmM6pUesvwLN++jqLyKfh1SWbKtgB0FZSTFxzBzVHdiY1xsyS9hza4iVu44QGpiLEnxsZRVuSksrfTuo2vbVpw+IpM4xzW0t7iC2Ut24NGaI3u1Iz0lnh825ONywYjubUlNjMOlTB0/WbGLPhkpjOnTDoCt+aXk7Cxkza5iOrROIMalOGNEJku2FbA8t4B9Jb5jx7hcDO3WhtTEOLI6tybGpXjtxy3edfp0SOH4AR28/0+124NHQ3ysiz1F5STExtCmlVlWWlnNt+vzyerSmvSkePKKKsjdX8quA+XsKaqgvMqNx2OGCx83oAOd2yTyzqJcqtweAHplJHP8gI7sL6mkZ/tkKqrdLFi7l5ydB0iKj6FVfAy7C8tJTYzj7JHdaNMqjvIqN6t2HiAhNoYe7ZJ49cctFJdXe+uXlBBLWaWbwGHKJxzekaHd0kL+rweLCmc8dEvQ/6u1HhRk2X+Be7TW/7OmvwT+orWu0WtIKTULY8XTvXv3I7ZsCZkfH3XsKixnxjPfc9v0gYw7rEO9tvV4NCt3HOA/P2zhphMHkJYUDxjxeeOnrdz58SpeuGgkY/u2927zw8Z8qt2axVv2M7x7Gsf2Nx3LDpRX8dBnazm6b3smZnX0rr9ieyF9MlJIjHNxwfM/sWDdXl64aCTDu6eRlhTPW4u28dJ3m3n2gmzW7C7iiv8s5vQRmfz9tMForbniPz/z6cpdxMUojh/QgcFd23Dq8K7eh0J5lZtTn/iW1buK6J6eRHaPtjx49lA8Gl75fjMvfLeZh88Zxojubbnjoxx2FJTx5Pkj+OObS/hgyQ5vOdu0iuOb68ezcmcht3ywgo15JbWeu06tE5l1bG8mD+zoLcuHS7bz9Zo8Nu4tIWfHAXq1T+au0wZxzyerWbxlf637m3h4R/59YTb7SyqZ9PDX7C2uZOrATlx9fF+yOrdGKVi54wDtUxK46IWfWL2rKKz/eP6fx/HIF2v5ePlOqty+e9KloE9GCm1axfH8xSNpnRiHx6N5a9E2vt2Qz0dLdwTd34QBHRjRoy33z10TdLkyz2Gct/8/ZwzjlGFd2ZhXzDnP/EBeUUWtZY5xKWKUotLtITUxlh//OoFv1uZx+X9+rrHuoK6tWbnjgPd4wY4/sEtrThzcmfvnrkEp37L2KfG8MWsMB8qrmPXyYg6UV9EqLobCsipaJ8bSLiUBl4IN1rUQF6NIToiloLQqaL3t/ca6FNUe7TfPpme7JPaXVlFYVnMfAEMy2zB9aBee+noje4srSIh10aZVHHuKKrx1c9bPOQ/gzlMGcf7oHkH3XRdKqcVa6+ygy5pS0J1kZ2fraOkpumlvCbd+uIKJh3fkwqN61lheXuXm0pcXsWDdXkb2bMvblx8VdD8ej2Z3UTmdWifi9mj2FlfSqU0iT8xb770x/31BNsf2z+D+uat57cetlFS6Abjm+L78afJhANz76WqenL/Bu9/EOBcfX3MMK7YXcu8nq9lRWA7AJ9cew8a8Er5avYd3f85lYJfWPH7uCMY/MN+7bXpyPPecPphZrywGYFJWR9buLmJLfikAD58zlPziSu76eBWnDOvChw7x7ZORzKd/OJaSimru/ngVby/O5Zh+7XF7NN9tyOe2k7P4fNVuvl2fD0DH1glcM6EfN79vwjUPnDWUm99fzrQhXZg5qhub80v589tL+cvUAbz/Sy5rdxfzu6N70T41AbdHM6pXOp3bJJKaGMfSbQWs21PMnf/NAaBVXAyXHdebS47uxeDbPvOWsUe7JG9dUhNiOapvO9KT40lLiufZbzYyrFsag7q2YVSvdK581QhVUnwMpdZ5t0mOj6FdSgJb95l9tU6Mpbiimn/OGM6YPu1YlltA34xUcgtK2VdSSUZKAs98s5EvV+/x28+Mkd249Nje9G6fTEmlmwc/W8MPG/exaucBrpnQj+webflp0z4en7ee1IRYJhzegXYpCaQnxzOsWxpJ8TH8vLWAB+auoazKTff0JO49YwiDM9uwbV8pbo+mQ2oCHVqbFoHWmls+WMGrP24lLkbx8TXHcM3rv7CnqIKXLh5FSmIsHy/bQUJsDEf3a0+sS/HGwm28uXAbndokcnTf9hzWKZWb3lvOyUO7sHrnAdbtKeaSo3tx7cR+HCir4tMVu5i9dAeJsTHcf9YQuqcnoSyF23OgnMVb9vPz1v08u2ATAMcP6MDzF43E49HMX7uHq1/7xXu+42NdnDioE5v2lrDrQDmd27RiybYC7/nr2DqBCYd3JHd/GcXlVUwZ2InRvdtxoLyKLmmt6JORQn5xBX95dzllVdXcecogemek4PFovlq9h6W5BWgNj89bD8A9pw/mlGFdKa6oZk9ROVmdW3P7Rzm8+N1mADJSEzjvyO488sU6AG6fPtBPAwpKK0mKjyU+tuFa0I0t6E8D87XWr1vTa4BxdblcoknQz376e37atI/2KfEsumVSjeU3vLOUtxfnEh/jQgNPn38E4wfUtNLvn7uaJ+ZtYFDX1uQVVbD7QAW3nHS41woAI6DlVR5uem8504Z05tj+GTwxbz1b8ksZktmG46zp5IRYiqymX2pCLId3bs2KHYWkJsZy16mDuf6dpUEtmJOHduGjpTt49oJs5izfyfu/bA9a5z9M7Oe9iMEI2pK/TWbBujx2Fpbz9Zo8PsvZzXtXHsVN7y5nze4ijh/QgecuzKbKrZn22ALW7i4G4HdH92LC4R2Z+ewPAAzvnsbmvSXst8r36u+O9LY+jrnvK2JdLjbtLeG+M4Zw9shutf43P2/dz9b8Uu6fu4btBWWcMSKTd3/OBeBf543gxMGd+e+yHXzwyw6uGt+H4d3berf1eDQul8+02l9SyfA7PwcgIdbFzFHdGdAplc35pTz19QYCGXdYBi9ePKrW8lW7PcxZsYtXf9jC2dndOOOIzKDrnfzY/1i+vdA7fcKgTvzrvBFeYQxkz4Fy3l6cy/jDOpDVpXWtZdBas6eogqmPfOM950+cO4KThnSudTsnj3yxNqSohUNFtZvDbvkUgGcvyGaSo/V4zyerved3WLc0PrhqrN+2K3cUMnfFLh79aj2nDOvCP2cMr9exg/H3OatYv6eY5y7MrnGO95VU8tqPW5g+tCud0xKJi3GxIa+YBWvzuGBMT79rpjGoTdAbYiyX2cDVSqk3gCOBwpbkP/d4tNdCyC+ppLSymoTYGCqq3STFx7KvpJK3F+dy0VE9uWJcH85+6nsufnEhpw7rwh2nDsLt1jz1zQZ+3LiPXZblvG53MRXVxq9318erSE+O5/mLsvnti4soKK3igyU7yOrcmsdmDkcpxROWNbEst5Blueamf/vyMdz64UquGNeHpdsKvDfbG7NGMyQzjZd/O4qb31/B5vwSvrpuHOnJ8Rz/4Hw+WrqDGJfi2P7tmZTVkWW5BWzIK+GPE/tTXFHFsws2cfHYnvxhYn/Oyu7GcffNw6M1j587grgYF8cPMDfikb3S+SxnN/d+spo1u4v48+T+XDW+L0op4mMVr1xyJHOW72T8YR3oafncj+2fwTdr83h0xnC+35jP/XPXcMf0gX6upN7tU/h6bR5gBLMuRnRvy4jubZk+tAsn/HMB7/6ci0sZwZo6qBMA04Z0YdqQLjW2Dbwx2ybHc/2Uw1i7u8hPNMqr3MS4YHJWJw7rlMrtH+Xw+k9buW7SYXWWLzbGxfShXZg+tObxnZw9spufoF94VM+QYg7QoXUiV43vW+fxAZRSdGydyJ+nHMbN76+gb4cUTrDOTbhcNb4vn67YRYxL1VmXYCTExvDO5WN4+fstHNff/3/98+T+pCbGcv/cNXRt26rGtgO7tKGovJpHv1rPCMcD+VD464mHh1yWnhzP1cf385vXJyOFPvWIDTUWdVroSqnXgXFAe2A38DcgDkBr/ZQyV9XjmEyYUuDiutwt8Ou20JduK+CtRdu485RBNW7qareHf83fwMie6Yzp046dhWWM+cdXDOxifIQ2XdNaseCG8byxcBt/fX85H1w1lmHd0iivcvPIF+u8FkdqQixFFb4gyt9OzuLMIzJ5+PN1nD6iK9v2lTK2X3uS4mLoe/MnXDuhH8/9bxNnjOjK7aeYBtNTX2/gnk9W86/zRnDlqz/To10SX18/3rvPrfmlHHv/PNqnJLDolone+VpriiuqvQGnnB0HuPmD5Qzs0pq7Th0MwLPfbOTuOav47I/Hkhgbw80fLOfhc4bRPsUEAovKq0hJiK0hLuVVbgb836fe6W+uH0/3dqGDrAAlFdXsKCijX8dUb/kC93v7Ryt54dvNdE9P4psbxgfbTUjW7ynittk5nHdkd04YHL71WV9KKqrZXlBGf6seDUFZpZu7Ps7hsmP7UFBWyZDMhg+oVbk9vPbjVk4Y3MkbpP214PFoXvhuM6cM6+K99gJZsb2QrM6tG91Cbm4O2eXSGPxaBX3xlv2c8eR3AHz+x2Pp1zGVkopqXv1xCwvW7eWCMT259GVT7jdnjWbXgXKufWMJF4/tyQvfbvbb14NnDeWm95bTJS2Rr64b573QtNa8uXAbP27ax97iCn47thcXv7gQMMGxniGyRAb/ba5X/G+dlsVvj+7l3V+VWxPjUvzzy3WcOSKzhnh+vGwnw7qn0TWtpoVTG1prcveX0S29djEORs8bPwbgsmN7c1MtFk99eOHbTdz+UQ5/mtSfayb0q3sDQYgyGtvlEvFs3ltCtcdD3w6p/H3OKu/85dsLKSyr4txnf6TSSm2ysyoSYl2c88wP3nWP7JXuFfQvrzuOKQ9/w3VvLyUh1sVrl472sxqUUswY1Z0Zo7rXKEsoMQe8bhiznk9gbTcGwJ8m9Q+6bX38oU6UUgcl5mAyNDyaBhNzgHNGdqNLWismHd6x7pUFoYXR4gV9/Z5iTnx0AdVuD6/+bjRLtxVw2XG9efm7LSzLLWT+mjwq3Sbn2u3RbC8o45rj+7Jsu1lmM6yb8d3FuhR9MlI4cXBnZi/dwcVje9ElDKv46d8cQUIdkXD7oQLQ/SBFtin531+Ox+1p2BZgUnwsUwbWz78rCC2FFifoWmuqPdrbiWL+mj1UWpbv3XNyqPZojumbwfLcQl78bjOt4mKYMbIb/zh9MPPX5DF/zR4uH9fHm1qXHB/Du1ceRYfUBM4Ykcm5R5qsi9unD+TI3umcnV17FoZNfUTq9OFd6d2++QMwdRHOg0wQhIajxQ3OdcsHK+h38yfenlurdxWRkZpA9/QkVmw/QIfUBI7snc4Eq0nvUvD7Cf1QSjF+QAduP2UQSfGxXHhUT+JiFJ9ceywDOplAzINnD+WIHqZXX9vkeM47sodf77uG4sGzh0Z94EcQhPrT4iz0V3/cCsCK7Qdo3SqW1bsOMKBTKvExLrbuK+Xs7G7EWalk363fy00nDggaSBzWLY11d5/YpGV/Y9ZotuSX1JquJghCy6XFWei2OL/w7SaOu38+K7YfIKtLawZ0TkUpE3QD0wPsuYtG0rdDw6WeHSqje7fjnJE1A6ktgspSmH0NFOfVva4gtFBajIVeXuUmIdblzRT5ZMUu77ITB3WmZzszMM/BZnQIjUzOh/DzS4CG6Y813nGqKyE2vvH2H4lUlUNcA+al71wKG+fD2Gsbbp+Hwo5fYPP/4KjfN3dJDpmot9AXbd5n3Cr/9yn3frqG/BLThb6syowNcUy/9gzJbEObpDiO6NEwvcyERsB2M5Xua7xj7M6BuzJgzad1rxsuhbmw8N81R3+qi6boH1K0C354qvZjbZwPd3eE7Ysb7rjv/BY+vxV2r6z/tlVl8O0/wR180KyDK88l8NktsGd1w+2zmYh6QT/zqe+Z+sgCwPSo1Nr0zgSTS/7yb0eJT/rXztI3IdfqhFZZXPu6y96G29PDF/5N38Aeq+/BVtOhjNX/PbhyBuODK+Hj6yB/ffjbfHYLPHnUwYlW4XZY9hb8/IpxU4Xi4+vgwcPg07/A5/9nrPBgLHnNfK/7ov5lAfjlVbitDZRbwxZsW+g7F8veDL3dqo9g77qa87973DwMfnnl4MoDsOU72LXcNx1ntcqXv3Xw+7R5/wp4cEDt6zTkwyiAqBb0ovLgJ27C4WZgrIpqz69fzCuK4e7OsPrj5i5J81BWAO/PgoXPmunS/NrXX/AAaDc8PhKem1L3/l86Gf412vy2b7SYuJrrLX4JHjsCPI5RFr+5H/5dczA2L3lrYbMxJshdWHdZwFjL3z0Ge3KM4K38AKprGcY2f4NxGYAp28NZ8N6lMPtqWPRc6GMs/Ldv+rvH/KdtCrYZVwTA7uU1l4fD1/eY7wPW8E7P+Yae4Nt/wt1dYN3n/tvsXQ9vng+PZ9d8MNsP9JJaroPdObDL8YK1Vf8119Gu5fDEaHjhBHjqaN/yKuvBF6wV8u7v4NObYP2X4cVvlr4GRTv9Wz1aQ85sKNptDI67OsKiF+re10EQ1T50e1jUQG6ZloXLpZq2c05FMTw3GaY9DN2PDL3e7pXQugu0stw/u1eYC+6b+2HASU1T1qoy2P4z9Bxb97qNTWGu//QBx/jfO5cCCuKTzU3z6hmwf7NZVrrXfNxVxrrPHAkxAZd7pWMs9W0/wac3mt+LnofULjDqd2Z/laXw0TVmWfFu8/8AfHWX+S4/AIkBIxpWV8ATI33TH1wBnYdCx4H+6y15HX75D1xsPbCdboh5f4cD2yG9D8TEw6Vfmro6ecx64+Of18EjQ/yXxQf0VSjMNXXJD2L5ugLPTSk8P8Vct2ndYcv3xrru5qjTlu9rntev7obCbaacygWl1vjyFUXg8VCDqhL4+j7oOAhaW72Zl73hW77+Cxhytm86xopvuCvMQ+KNmXDa05BhDYTm8cCTY8zv2wqNSL95HvQYa7bN8/UEB2DfJthnjZS5c5m5jmwjz+MxhlRVKfzwL+h1LFz4kf/2+Rvg3Uvg9H9De8dgaG9fBB2y4LAToLwA3vqN/3Yp9XsnQrhEraBrrdm013fD9mqf7J1un5LAQ2cPa9oC7fgZ9qw0zdtLPgu93pNHmYv7im/NtC1QKSG6uhftNhdgQ14gb10A6z6DqxdB+3qMl7JvoylnoOjUl5J8cFeaG/xAwPC9lSXm8+RY2L8p+PaxraDavPGHxS/CnD/DlL/DmKv8j+G0yBY86L+PeXfB94/5XAU2u1aYmz7VMZTC7hXQI2CM+w3zapZr7l+h59EQnwq9jzNi+cHlZpnHAy6Xr0xte/nqZwvO3nXQJcR1+/NLvjoHY/8WY1AUW8kAHQdD1immnmBaNU52LjXn/uyXjdAteMBY16c+ZQR20zfwyqkw8Tbji09uD8deD9/cF/z4Zfuh0KQMk9YDxv8V3r/MTOf+BC9Ng99bdd/0DXTNNtf+ktdg4Om+h0a15RoqPwAbvjStk//+ES6eY+Zv/d53zPJCWGo9HLZ8G7xctqWeMQDyVptznt7bzDuQ67Pe7XK9croR6OP+Av2nwIavTBnevQR+96Vv3ZwPzGf+34Mf1z5GAxO1gn7209+zcLPv7TN9O6Rw/ugeIV8X1mhs+c5YGR2yzHRCLWmQdtN6t6O5mGcFalqFeA3Zg9bYLbcV1lxWtAuS2te0TGujutKIOZjvVm1NmWPrOG8le+HR4ZCcAX9cGXr93TmmqT35ztAPofuti/22wpoWenU55K0JLeY374Yfn4Iv/maml75uvgNdNQ/08xexdkGGmg0Uc4DXzjLf1/zim7f955qC7ixfx8GmdfX1vSbIGIzqcuNm+ega80A6/GT47lH/dXSAhev0xdqtBTDn/+GBPvGrLIV/Oqz32EQ460VjUbbuAh9eaQTSexztiyNkjvQ/Dx9cbh5+aVb67KIXoGALqBgj6KFY9gbsXWt+n/4MdB9tzsl3jxu3TP56I+CuONj2o8k4yTrFGEBr5kDWdLNtmeWC+elpsxx8MRAw69qsnWtaXu36+VolJz9qznHbXlaLxXLhTHsEXp4O/3sYktpBlxEQZ/U/OfZ6WPGeebBusER7zvVG0O3rqnQfFAV/e5SXGzbBfWZAPdr2qn3dgyRqfehOMQfzeqtLju51UGM1h0VZiFeXvXCCuQHsAM/6L2Dj18HXDSYg+zaa78oi02x1UuWwyOyg1u4c4/N74SQT9Hrp5OBNXY/bBJcKAyzgct/bX1j6Otzfx/gR62L52+a7JM88hIIF5DZ9A89PNTd3qIBYYFkPbDfugL9shnF/teZZN46y3hV63I3mpjvnPya97oiLoM8Es8y2eFt39e1z36aaFmmo/y8Um74x36448wCprvRfXrDV97vn0dB/MlBLNkl1uRETMJb2kLOhz/Ew6jLfOk4XERirO5BjbzCCBKZOHjesmu1b3utYuHapzz0w/DzTYnBeexu+gu8fN79TO/vEG6DTECOOtrDZZUoNMnTFRY64z4p3jXsi61TjegJjKBz7Z7h0nnnIzL8HXjnNLOsxFkZYbgrnuSx1/E85H5rv8kJfbGP9F9B9DHQYaPot5K2GvhNhwt/gpAdhxAUw4kJz79j34RXfQ48x5iH688vmf3jrAp8xNfpK+M17/nXrZr24pGCb+a4qNTETJzNeg6Ou8U0nOYyyhkwDdRCVgu4cEKpbeiuum9Sfy4/rU/8dbV8My9+pe71NC+DenibwEQpnk+9ly9rImW38kDb2TaUcLzWusCyIVR/BPzKNHxPM93uX+tazA2MvTzf+vi1WMGvrd1Cw2b8sWpu6fftPX5PfpswS9L6TfJkAq2YbH37JXt/27mr/wI+zqfvSdPh7wOiOaz41zdXWXaBtTxMIC5YuF+jjLNhm/Nmt2kKyJVS21d7eap206QrH32JuSIBWaXD+uz5/KxjL7uv7zY2/c0nN4y551VjpM16DITNqLgd/n/TSN025TnvK+Iz3WL7vDV8Zv+v+LZBxOPz+Z5h0B3Qe7hNaMBayk6oyX6vm1Keg02D4zfsw6XbfOpUlRnDs/8XOFpl4m2+d42+GGGs/X98Lr55pvm06D60pvoltoMJhoduti9FXGneeLejxqXD5AujtGIe+1LomXLHmmrBRLiPKVzuGyO48DM5+yWf5gglAdx0Bh51o3FT568zDuN8USEwzdSne7ThekGCodptrs2CbEeEB0+DcNwFtHpQZ/eGYP8HI35n6xKcYy3znEvM7w8pKsVvRdvl3rzQtzqR0c806cVmBc9uNVHHA/PeuOHMdXvSxaYFMvhMm3QlT/mHWm/awebg0ElEp6DsKfJZrQmwMv5/Qr9Y3v4fk2eONb6w2tIYfnjS/599Tc7mdEmVnOzh56zfwwlTftC3osYkm66Bsv6/ZbGNfQPP/AWs/Mzcj+JqUTivumOvMt23l29yeZqwX8LfywWehDzvXf/5Xd8FXd8J/zoB7upum42e3+JbvXW98/859OMuy+EUjJL/91Nysm7425SjdZ5r7Pz1rzuX3//Jt4/EY91MHa/hdW1APWILe3cpOaR2k1aWUv4B+dZfxF2+c73swBZKYZm7C056queyaX/xdRFu/M1ZaJ/MiEK919spp8Ma55pyndYd2fUxHJZfL12q4dB70Os5//1VlprXU8xgYNtM3P64VnGllRBTvgtm/hxenmWlb0PsFZPO4XL6H2YavjIWbbJU9OchbnhJb+1vodgbJpDvMd5vuprznvGymg53vqjKfOwSMsCllYjCJ1ss42nStuZ1NQoqpn/aYFpbLZcWGOkKx472rZfuMq6X3OF/ZwLg71luplf0mQVo3GHO1mXYKtX2symITJ+g4yBwLfIFVMA+JFe/5xB7gmiXGndWun+++tC10d6Vx9/Qca1qKPR1ZNGOvgTFXmt/ZvzUPl0YiKgXdGQxtl9zIvf5WvAtrrKZlWZDcZ6fPXIV4qOR8CLelGV8kmMj/x9cZ0Q0UXFesuUk3fAkjLzEXGPgsaxxpmEMtYdjn8OfaVpRtCWtt/IwPZRmr2d5PmyCjRKoYc9NUHDAfu1nu8Rj/Yo+ArJji3SZou3ausaza9THWs93kBuP/XPq6CVzuyfE1o8Fsk7fGJ5r2w9G20CffBTPf8AllIMHiDj8+bY4FJjh3giOIZ6crBqayxiWZIFZg1khSui+49f4s+P4J37K8VTX96sPPM66AjMN8WUw21WXGvdQ6iOjZDy7b/26XL3+92Y/9wHPi9LePvtK4b8BnADiJTzE+8x+fNtMle8x+7fMREwsXzvbtY9i5vtaRt/zlxt1m43Jc63YGUJvg70sFjBFj08nx6uKUDk4fcBoAACAASURBVD4LvSTfXMtte/ke1kf/wXw/M864vhLTfGU77gYjrt0Cssrs/3Hbj75rC4xQg+8/cFf4i3x6L1OH2EQT7/J4zH9m72//pprHamKiTtA9Hk3OTtN8PO/I7jx0Th3ZLM9OMFbhP7oboawveWvM98hL/SPiNk4RcD7tnT7XT/4CaNODzsmq2SY7xklVOcy1LOOsU83+XbG+h4ly/KXpfSAu2fguwVimd7ajBv972FyYa+b4rOtAwQFzgTtJTIN/HQWLXzA3dKCwFO+B18+B1842LQhbYDs7AnT5601QEUw5K4ugvXUTbf3OWEr2+vG2oG839UpIMWlhofoSBKvDurm+339YBkdeBmc+b6adgUGb37wPV1rupISA1MTENP+c9bl/9f1O616za3vvcXDld1ZKX0CZK4pNbCCYFWtnDdmZM7bw5K83biKljIgNdVj2Hof7I/u3vrTEwMAq+DJf5t5svkvyfBZ9MHoeDVcvNA9Em6pSf0F3Gi/2eQv2f9g4g+jOY9sW+r6NJoPGU2XiC1PvNS2Xw07wrZu32hzDPrexCcb9EXiunVlYzmuxwwCTfnje2755wYLlsfHWA2yPscydqaidhtRcvwmJOkG/7u2l3PPJauJjXdx16iDfSIm7c2pauwXbYPsimHsTVBSavN9gOMW3YCusnuPLSKksMb7FhBTf/rcv9vmHnRb6zNd9VqzTDVJUj3dqV5eZG3D4b0w+u1JGKMv2m4yBSkfg1OWCtj18lv+mEMFYu0m7b6PPQm+VBsPO81+vaJfPPwtG/PesNO4fqHnxF+/2+fbL9vuCQs4HW/4630Nr51LzbT8Y3rrAfHezLNQ460YszK1dHGzC7TRmC5PTj3zhf03OcZ/jff7ThAAL3S7D+e/B2a/gbR2ldIJLPg//+GBcUtpd01cLvnrbD1vtMed1zyrfOb96YXBX0WnPGMtykBVsDGZB2kFH21denBfcNROI89r2VPsHll0OaZny99DHtnFa6E4fe2pHc70/OtxY4DHxRkBTMmDQ6TXTeQP7A9RVbqeFDjDkLGMI2QRrqdoWuu1u6ehoUQTur4mJKkHP3V/K+7+YrI1KZy/QimLT2cAZRATT5PLDWt9d5R9Zt6PdYLpyvzHTBKfA+OLik02z3F1pukg/e7yv553TQm/bA462/GfPTQ6/Yj2P8UXLK0uM39npx2zV1txMn91cc9uUDsZy8niCd6UGX6Apb61PNBLbwClPwBlWb8PULqYjh+1imOxIk7P9r+36GmE7ycrp3vaT/3HsZnJMHPxfvhH27b/4ymULemDnm1TrprUt9KId4Qm6x133OhD8pu11jMkIcRLocmll+Yb7TjBpdXZTfdLtwbM+Ajn3LTjGcv/YnWl6j6u5Xkysv+BtX2RcDKV7jRurNmxrtO9EuHVfzXMLJs8bfC6tkjyTV14X9r7ta8Ip6E4LvfdxcEuez3UUDK+hoALcNWn+/n27jDauGPi/vb46BLaigpbb8T8G+tfBPwMlWIspNsG0VgttQc/yldWZEdQMRJWgz1kewtK1relNAYFJ23q0sR8An/0fPOJ40j59DLw2w1gutrW77jPj06ssNpabbVXYXaR3LTPfdhO3u+VPta28iiApik56HmNygMFcdOOsXowHdgDa34KyBT0YyR2MBf71vT5L2g/tE/SiHWb/8SlGdJWCQWeY/NnDTjDL3ZVm3vDzTfpXYhszLy7ZiFjWdDjiYnNDf/+4v8/W6dOOiTUBsy3/w5vOt/5zX31tZrzu++28EZOC+MdrVC1MQU/pYIR15uu1rxfYYcoO9tnYD56kIG6tYPSfYs6lk1CCEChkNsFcAk6crQpXiBjO6c/A4LN9edSl+eHVwf4/7DL4WegBx6prBEvb5aICJCk+2d99FOw8xMT5Hq5hCbpjH3X1r2gdxO8fm2iGcrBz/20LvdPg+rXKGoGoEvSvVu/h8M6tueb4vrz0WytPtLLU18kkME0usBeifTEFc02s/cRkddhjUqz7zHSA2fK9z0IHX5qhjbvCSkGz8lhD3ZiBxCf7BCQu0XQ2AV/LwWlBtWrrn5/rJDnD+M5XvBt8eXWlcTXYVuqW7/xvZqWMeKZ1Nzds8R5zQbdqC9Mf9QWg2vXxXcyuGNPMB5MC2N3qih0owrYvOBC7d2pMPAxwvETEee6CBQIDqc1Cn+noXq4UTPi/upvLMQGi1CpA0G1/bjjuChune+HaZaHXc1cGL0Ndgh7YqghGTJw556X5xvhxV/q3CEJhPyxsF4Vz3JVQCQChsI8XKIiBHfHiQ9w/tuFQW8e9wHWPvaHudYO1VOyHwL4NxuVjB3ub2X8OUSbo63YXM6RrG/40+TCO62/dVN8/4RuZLTAgVLTLf9p2uYRqbhbtMEEZ541fZFm03gwMqxn2y39MkK+60qRW2TduqG7xvY6DyXf7N3/tfca28qWi2ft3Bo5atfXlA9vYY4anZJisGWfqlxM7BdAW4L1rTBAtENvvXVnkb9XYro9AYbG7xnca7HNFBA4y5RRum4vm+Cz5/lP913fezOHcPCc9aNwmgdkuk+/yD6aFS6DVGWihH30dzPo6dPf8YDgFvbbmut2jMTDdsa4u5OEOw2C7iIp2Gos4lDXvt2/bQrcE3ZtpRXjbO4l1uFz8jhFQ/lAGkS3SgWPSBKPLcJg13ww/UBfBLG7nwy7rFBMzOexE49NvZqJG0PeVVJJfUknfDgEWiV9mRqCFHtBV1/7zQlk1dq/KnoG+1WTfjWmPvaI98MZ5JhrubG6GuiBPuBeOutp3Yccn+W4K26cXm+jbv9MKTEr3D6xe+JHpEedcL5SLx24mOwNBvY+ruZ4zfSvWIUK2WAYK+tR/GNE97ATTizOtu/HjOrG7Pw85xzev51jzELr4E+MKcBLnzE4YSp10GWbORaC4OLMz6kOgOyDQGnS56ifm4C/o4TTX7ZbJmKvhki/qFuxwBd0Oxu7bZGJIwUacDKRVW/Of2PGcskaw0GsIeogXj3tdLWGOI99leO3n+485cNVPwZfZ92hqF9NpKCbWuOsys8M7diMSFWO5aK0Zcafxv9YQdOcT32mha20s9IQ2DrGz1nVaGk7s/Odex8APjpxjp3vEmfMN5oHizAwJdUF6A4aW+Mcl+7r62wIaE28s8aR2/jm9XUf4fp/5vH8wz2nJn/GclV8cbwZDcmJb6BA8fzutuxXdLw/PQu802PQqBNPi+UOQ4Ve7jzZlGjANRl/h7yIJzOEGc+N0GmICe8GCe6EIHH/ajk3UF1vQOw02vTVDDZhWH2JDXA+BXLbACJDdG7nrCP+RD0MRjssFfA/0fRtM7CEcS3fMVeaBbbuDnD7044ME6GsjpIVey/3sxH4ABUvLPBhq6wRlP3wOP7nRuvAfLFEh6AWlvhs2q0tAUESFEPSy/UZsM0f6usnb6wbrIAQ+a7/LcP/5Tgu9xOHaiImDvK3+XaVDWUy2iHot9GSflWPv206LPPZ6f/eDc/+Bwaz2/czNmdbDBOBCWSXOjiLBAmKuGDPQ14Fc/yZnKEEPB6Vg8Jnmd7gCffmCutcJJFDQW3cOvl5d2Odu0Blw+f8Obh+BhGMJgy9fOr2PsYizTgtvu7BdLp3N/2pnHLnCKFfrLuaz9QczXbbfGEg3ba19u2B4g6J1WOihLHD7YdsUb3qyja5wUiSbmKhwueTuN0L3zxnD6Ng68IkZQtBt10XmEY7l1sVQ60sUlBG2U5wWeoq/K2XY+ebbznRxWrTOG/hKR9qkPSKifWHGJ/msJPsCqrJ6wAaOUpiUbjJOoOYobum94KZc03x03ixtAvy1TkEPJQK268hZn4z+5iauzzC7TY3HEvTRV8G5b9e+bm3YLp9wrNdwqW9WRHwSZF/sn+ddG4FB1FC4XMYfvyfHmq6Hy8R+wJfuO3iLtbYsFyehBNsuQ11ZKw2BrSPhBGCbmKgQ9O0FpodmnwxH86yi2LhOnBeI9piu69/c7xuitq/jjTPVZeaCqe31ZUntjPgOP993EQUK+rSHoYdjLIdQN1V8kvHxnvSQb56dohWX7LupApuRSUGCttMfNcLdNoh/OK5VzSF0r/nF6gxj4RzfO5TIxCb6f4PprfrnNb9Ka8WLbaEPONEa9fAgOer3xnc9MozRJ+uLnQnUUNjd9OvzwOg+xjeKZLgtB/C1IMv2hZcdEwyvDz1Q0MN0GR0+3fw/E287uOPXBzu4H667rAmJCpeLbaF3a+sQ1YezTIeE8Q5fnvaYwaXAdNWPT/XvvVZZavzqteUvO4ORsQnGp+x0uYCxZJ1P71AXeVyy8Xc7fd62oMcm+FwuzjxcCJ2FUx+LISbWv1NKKN++3zZBLHSlwtu2WbGsunDFIRQJKTDl7kMvTiB/2dLw53DmG8GHoqiNIWf7XlsXjsvFxraiPdUHX4+wfeihto/37+zWmHhTSOtxjpqIiLfQy6vcfLhkB2lJcbRu5Xg+eYeidbpcHM213IVmECBnBkpVKWy0xsvoGiJineIQdDuIl5Bas2kYTueFYK4NW7xj4nzN6sAHTLgdV+rCmSYXjiXnFfRfVyAobA5V0BuLVmkN7yqITQivN60TZyutPi6X1M4+a/WQLfS6fOi/AmxBbwr3Tj2JeEGfu3IXy7cX8reTs0K88Nk5zyHoO5fU7NptD3qfnOEbwH7wWf7rOC10Oze44yDfhWc/CJwZG27HWDBOgl0Q9miIrlhf5kHgQEkNJei2RZ8QZAS+YNjl/RVeyGHxaxSHXxNO12B9rE9XjO+FGQdtodsPgiAjXfrRBEHPurBdLuHGJ5qQiHe5fLpiFx1SEzhlaIg0o9osTzsveui55m3dVaWma3/7w3wXUmBvxmCj0HUZZi7kC//ry0ZwZlYEvmmmtrLZFrorzvgEMwaYLuJOGrKpd+lXpmMEmNS4YMOr2oigRzdOgapv4DdjgEnlPGgL3Q6KBswPDP42RRZLXaTUc4iHJiTiBX359kLG9GmHyxVKuAPmu+J8WQ92j8/TnjTpVwseNMMBdDvS96cFipfTTTF0phkPxrZKeh3jW+a0yisDhgOoDa+gx5jPYY7eksPPNy+1aEi6OrJ8OtfR+9LOpw/06UcKIui14zQU6uNDB1+Hp8AXsoR9bPthEuQ+Pv89Ezd6+ljTX6G5mfg30w+g97jmLkkNIlrQq9wedhSUcdrwAOvcOUxuoLsjIcXXAcLZPGyTCWgzVkrWKab7u6fKZDTYY8GAf1frYMOV2njCsNCDYbcMgvUodaZKNgd2vCEwrztSqG939JaGn4Vez3OVabkod688uGPbLYJgfv++1gtMgr0IvTmIa2UCyL9CIlrQdxaU49HQLT1A/Jw9PQNfrByfGnxkQmfX9tQuJgtkzFU116truFKbAdN8b5hxdvwBM16J8z2JTqbcbVIP+00Kvrw5sYOKkWahX7ag5siaQk2cFnp93Xp2b+WKIC8JCYekdDOW0YCTDm57AQhT0JVSU4F/AjHAv7XW9wQs7w68BKRZ69yotZ7TwGWtwdZ9Ji2rew1Bdwh2ecBTPfAlBTbOly7UNpZ1uOOAjPydL6Aa6JfuObbm+jZJ6b6hcn9tTLrD+EizTm3uktSPzkPqdicJ/lZ5fX3o8ckmbTCcMXZCcdTVB7+tAIQh6EqpGOAJYBKQCyxUSs3WWuc4VrsFeEtr/aRSKguYA/RshPL6sW2/EfTMtgGR9fKC4L/B58oIzHBJSjcXsae6ZuecE+43aY5tutY9rrONUjWHV410ktLhpAeauxRCU1BfHzqYIL7QrITzGB4FrNdabwRQSr0BnAI4BV0DdlfBNkDAMIaNw74S4x9vnxIQuHRa5YEWunab7vHO8bBtrvjOjFrYZYT//CNnmY8gtBQk3hCRhCPoXYFtjulcIPDlgLcBnymlfg8kAwHjpBqUUrOAWQDdux/6q5oKy6pIjHORGBdw8TmDdoGC7q4yb8QJlvGQcZi/L10QWiq/wl6QQt00VMeimcCLWutM4ETgFaUCB2UArfUzWutsrXV2RkY93uoSgoLSStJaBXGBOMc+qSHolTXHNREEwZ+DcbkIzU44gr4dcL5FN9Oa5+QS4C0ArfX3QCIQxltmD42C0irSkoJceM6u8oGCXlkqF6sg1EVDjigpNBnhCPpCoJ9SqpdSKh6YAcwOWGcrMAFAKXU4RtDzGrKgwSgoraJNqwBxriyBfRt90zUEvUiak4JQF9KKjUjq/Ne01tVKqauBuZiUxOe11iuVUncAi7TWs4HrgGeVUn/EBEgv0rrx++gWlFXSu31AGuIrp8E2xzjjgUPPVpaK9SEIdSH3SEQS1r9m5ZTPCZh3q+N3DlBLcnXjENTl4hTzYHiqfpWD6gjCrwpxS0YkEfsY1lpTUFZFG1vQS/fB4hfC21hcLoJQO2KhRyQR+6+VV3morPb4fOif3gTLguSWB0MuVkGoHfGhRyQROx56QZnpVNQ2yXKfeOoxYJRY6IJQO2L0RCQRK+iFZUbAvRZ6fd5GI/5BQagduUcikogV9IJSI+hptqDX632aEhQVhFqRVmxEErGCblvorQ/GQhf/oCDUjozlEpFErqDbFrqd5RL0XYYh3mIkzUlBqB25RyKSiBV0Oyjq9aEHdiAC3+vjOg2Gs1/2zZfmpCDUjgRFI5KIFfTCsipiXIqUBOvC87hrrmS/AzMxzfeOUJCLVRDqQu6RiCRiBb2gtIq0VnEoZblVgr0WzX4ZhSvGvwkpQVFBqB1XxEpDiyZi/7XCsoCBuew8dD/htix0V6x/kEdcLoIQnIQ2da8j/GqJbEF3juPiqTbvuzzxft88r4Ue6y/i0pwUhOBcvgBmvNbcpRAOkohVtsKyKtKTHa4Tj9tY5873avhZ6IfwRnNBaCm07VHznbpCxBCxFrrtQ/firrJ85Q7Xip+F7nh2SUqWIAhRSAQLeiVpSU4LvdoIt5+F7hB0p4jHSlBUEIToIyIF3e3RFFVU+3qJgjXOeRwoh4Vui3igDz0uyAuiBUEQIpyIFPSi8iq0xt/l4nEHsdAtN0tcor+FHrRXqSAIQmQTkYJeY6RFsFwuMf75s7aIxyX7+9BF0AVBiEIiUtALAsdxASsoGpDlYqcnxrUSC10QhKgnIgW9pNL0Ck2Kd1jd3qCow4duj+8Sn+Sfex6X1ASlFARBaFoiUtArqo1QJ8Y5im/70J1pi24zgBdxSQFBUbHQBUGIPiJT0KuMoCfEOsTbU2X85E6Xi9saDiCuFSjHULqxIuiCIEQfkSno1WZkxQQ/Cz2Iy8Ue3yUwTVEGHhIEIQqJSGWzXS4JsQHWeGDaotflIha5IAjRT4QLutMat33oQVwu8RIEFQQh+olMQa+qzeUSzEIXQRcEIfqJTEEP5nLxVNX0oTuDooIgCFFORAp6pSXo8TEBFnpMXIgsFxm7RRCE6CciBb2i2kN8rMv3+jmwfOgxIfLQxUIXBCH6iVBBd/u7W8DR9T9Y2qIIuiAI0U9EvrGootrjn+ECwYOi3UbDurk+QR93E6R0bLqCCoIgNCGRKehVnpoWui3ozrTFM5+H/Zsdgn5jk5VREAShqYlcl0tcEEEP7PqfkAKdBjVt4QRBEJqJCBX02lwuMcE3EgRBiHLCEnSl1FSl1Bql1HqlVFC/hVLqbKVUjlJqpVLqtYYtpj9G0IMFRQMsdEEQhBZEnT50pVQM8AQwCcgFFiqlZmutcxzr9ANuAsZqrfcrpTo0VoHB9BSt6UN3mywXl1jogiC0TMIxZ0cB67XWG7XWlcAbwCkB61wKPKG13g+gtd7TsMX0p6LaQ0JcMJdLjFjogiC0WMJRv67ANsd0rjXPSX+gv1LqW6XUD0qpqcF2pJSapZRapJRalJeXd3AlJojLRWuoLofYRBF0QRBaLA2lfrFAP2AcMBN4VimVFriS1voZrXW21jo7IyPjoA9WUe0m3inolSWANlktIuiCILRQwlG/7UA3x3SmNc9JLjBba12ltd4ErMUIfKPg9mhiXY5u/5Ul5js+WXzogiC0WMIR9IVAP6VUL6VUPDADmB2wzgcY6xylVHuMC2ZjA5bTD7dHE+Mcx6Wy2HzHp0raoiAILZY6BV1rXQ1cDcwFVgFvaa1XKqXuUEpNt1abC+QrpXKAecD1Wuv8xiq026NxOS30iiLzHZ8sLhdBEFosYXX911rPAeYEzLvV8VsDf7I+jU5Il0tCirhcBEFosUSkOevRARa6n8slIqskCIJwyESk+tXwoYvLRRAEIYIFPZTLRQRdEIQWSkSqn0eDK2iWi/jQBUFouUSkoBsL3TGjwiHoYqELgtBCiUj1cwcLisYmWuOhi4UuCELLJCIF3RMYFK0qhbgk81tcLoIgtFAiUtDdOiAo6q6EmHjzW1wugiC0UCJO/bTW6MCgqMdtXm4BIuiCILRYIk793B4NEGChVxn/OYBT6AVBEFoQkSfoOoige6rM24oEQRBaMBEn6B6P+fZzubirIEYEXRCElk3ECbrPQnfM9FT7fOiCIAgtlMgTdMuH7h8UFUEXBEGIOEH3hAyKistFEISWTcQJevCgaLUERQVBaPFEnKB7grlcnGmLNh0GNmGpBEEQmp+IczxXB3O5BKYt/mkVJLRu4pIJgiA0LxEn6ME7FgUERVt3aeJSCYIgND+R53KxfeiBWS6BLhdBEIQWRsQJelALXXqKCoIgRJ6g2xa6S9IWBUEQ/Ig4QXdbXf9ruFzEQhcEoYUTgYIepOt/sLRFQRCEFkbECbrX5SJd/wVBEPyIOEEPHhQVl4sgCELkCXrIoKhY6IIgtGwiTtC9g3MpSVsUBEFwEnGCXsPlorXVsUgEXRCElk3kCXpgUNRTbb4lKCoIQgsn4gTdfgWd10IXQRcEQQAiUNBrvILOXWW+xeUiCEILJ+IEvcZ46F4LXQRdEISWTcQJeo2gqNdCF5eLIAgtm8gT9BpBUUvQxYcuCEILJyxBV0pNVUqtUUqtV0rdWMt6ZyiltFIqu+GK6E+Nl0SLy0UQBAEIQ9CVUjHAE8AJQBYwUymVFWS9VOBa4MeGLqSTGq+gc1uCLkFRQRBaOOFY6KOA9VrrjVrrSuAN4JQg690J3AuUN2D5auB9Y5FLXC6CIAhOwhH0rsA2x3SuNc+LUmoE0E1r/XFtO1JKzVJKLVJKLcrLy6t3YcERFFWBQVGx0AVBaNkcclBUKeUCHgKuq2tdrfUzWutsrXV2RkbGQR2vRpaL10IXQRcEoWUTjqBvB7o5pjOteTapwCBgvlJqMzAamN1YgdEar6BzS09RQRAECE/QFwL9lFK9lFLxwAxgtr1Qa12otW6vte6pte4J/ABM11ovaowC13gFnZ3lInnogiC0cOoUdK11NXA1MBdYBbyltV6plLpDKTW9sQsYiG88dGuGuFwEQRAACMus1VrPAeYEzLs1xLrjDr1YoakxHrqkLQqCIACR2FM0ZFBUXC6CILRsIk7QawZFRdAFQRAgAgW9Rh66R1wugiAIEIGCPqpXOtdPOYz4WKvoMpaLIAgCEGZQ9NfE8O5tGd69rW+GDJ8rCIIARKCFXgNJWxQEQQCiQdBlLBdBEAQgGgTd4zbfkuUiCEILJwoEXdIWBUEQIBoEXVwugiAIQDQIuqQtCoIgANEg6N6eojHNWw5BEIRmJvIF3VNl/Od2z1FBEIQWShQIerW4WwRBEIgGQXdXS0BUEASBaBB02+UiCILQwol8QXdXiYUuCIJANAi6p1osdEEQBETQBUEQoobIF3RxuQiCIADRIOieKklbFARBIBoE3V0tL7cQBEEgGgRdLHRBEAQgGgTdLXnogiAIEA2C7nFLUFQQBIGoEHSx0AVBECAaBF3SFgVBEIBoEPTyAkhIbe5SCIIgNDuRLejuKijYCum9m7skgiAIzU5kC3rBVtP1P71Pc5dEEASh2YlsQd+3yXyLhS4IgkBkp4cUbjXfbXs0bzkEoZGpqqoiNzeX8vLy5i6K0EQkJiaSmZlJXFz4SR+RLeiVJeY7PqV5yyEIjUxubi6pqan07NkTJe/PjXq01uTn55Obm0uvXr3C3i6yXS5VlrUS16p5yyEIjUx5eTnt2rUTMW8hKKVo165dvVtkYQm6UmqqUmqNUmq9UurGIMv/pJTKUUotU0p9qZRqGh9IdRmoGMlDF1oEIuYti4P5v+sUdKVUDPAEcAKQBcxUSmUFrPYLkK21HgK8A9xX75IcDFXlYp0LgiBYhGOhjwLWa603aq0rgTeAU5wraK3naa1LrckfgMyGLWYIqssgNrFJDiUIgvBrJxxB7wpsc0znWvNCcQnwSbAFSqlZSqlFSqlFeXl54ZcyFFXlEJd06PsRBKFWYmJiGDZsGAMHDmTo0KE8+OCDeDyeJjn2iy++iMvlYtmyZd55gwYNYvPmzbVu98gjj1BaWuqdvvnmm+nWrRspKf5JFA899BBZWVkMGTKECRMmsGXLFu+yqVOnkpaWxrRp0xqmMo1Mg2a5KKXOB7KB44It11o/AzwDkJ2drQ/5gNVlECcWutCyuP2jleTsONCg+8zq0pq/nTww5PJWrVqxZMkSAPbs2cO5557LgQMHuP322xu0HKHIzMzk7rvv5s033wx7m0ceeYTzzz+fpCRj9J188slcffXV9OvXz2+94cOHs2jRIpKSknjyySe54YYbvMe5/vrrKS0t5emnn264yjQi4Vjo24FujulMa54fSqmJwM3AdK11RcMUrw6qysXlIghNTIcOHXjmmWd4/PHH0Vrjdru5/vrrGTlyJEOGDPGK3/z58xk3bhxnnnkmAwYM4LzzzkNrY8fdeOONXqv4z3/+MwB5eXmcccYZjBw5kpEjR/Ltt996jzlt2jRWrlzJmjVrapTns88+Y8yYMYwYMYKzzjqL4uJiHn30UXbs2MH48eMZP348AKNHj6Zz5841th8/frxX9EePHk1ubq532YQJE0hNDW+sqDvuuIORI0cyaNAgZs2a5a3rGnWktAAADBxJREFU+vXrmThxIkOHDmXEiBFs2LABgHvvvZfBgwczdOhQbryxRq7JwaG1rvWDseI3Ar2AeGApMDBgneHABqBfXfuzP0cccYQ+ZF48Wet/Tzr0/QjCr5ycnJxmPX5ycnKNeW3atNG7du3STz/9tL7zzju11lqXl5frI444Qm/cuFHPmzdPt27dWm/btk273W49evRovWDBAr13717dv39/7fF4tNZa79+/X2ut9cyZM/WCBQu01lpv2bJFDxgwQGut9QsvvKCvuuoq/dJLL+kLLrhAa631wIED9aZNm3ReXp4+5phjdHFxsdZa63vuuUfffvvtWmute/ToofPy8sKqi81VV13lrYvNvHnz9EknnVTnOcrPz/f+Pv/88/Xs2bO11lqPGjVKv/fee1prrcvKynRJSYmeM2eOHjNmjC4pKamxrZNg/zuwSIfQ1TpdLlrraqXU1cBcIAZ4Xmu9Uil1h7Xj2cD9QArwtpVqs1VrPb1hHjm1UC0WuiA0N5999hnLli3jnXfeAaCwsJB169YRHx/PqFGjyMw0ORLDhg1j8+bNjB49msTERC655BKmTZvm9U9/8cUX5OTkePd74MABiouLvdPnnnsud999N5s2bfLO++GHH8jJyWHs2LEAVFZWMmbMmIOqx3/+8x8WLVrE119/fVDbz5s3j/vuu4/S0lL27dvHwIEDGTduHNu3b+e0004DTO9PMHW9+OKLvS2D9PT0gzpmIGH50LXWc4A5AfNudfye2CClqS9VZdCqbbMcWhBaMhs3biQmJoYOHTqgteaxxx5jypQpfuvMnz+fhIQE73RMTAzV1dXExsby008/8eWXX/LOO+/w+OOP89VXX+HxePjhhx+8ohdIbGws1113Hffee693ntaaSZMm8frrrx9Sfb744gvuvvtuvv76a78yh0t5eTlXXnklixYtolu3btx2223NMkxDZPcUFQtdEJqcvLw8Lr/8cq6++mqUUkyZMoUnn3ySqqoqANauXUtJSUnI7YuLiyksLOTEE0/k4YcfZunSpQBMnjyZxx57zLueHYR1ctFFF/HFF19gZ8mNHj2ab7/9lvXr1wNQUlLC2rVrAUhNTaWoqKjO+vzyyy9cdtllzJ49mw4dOoR5Fvyxxbt9+/YUFxd7WyupqalkZmbywQcfAFBRUUFpaSmTJk3ihRde8Gbh7Nu376COG0hkC7p0LBKEJqGsrMybtjhx4kQmT57M3/72NwB+97vfkZWVxYgRIxg0aBCXXXYZ1dXVIfdVVFTEtGnTGDJkCEcffTQPPfQQAI8++iiLFi1iyJAhZGVl8dRTT9XYNj4+nmuuuYY9e/YAkJGRwYsvvsjMmTMZMmQIY8aMYfXq1QDMmjWLqVOneoOiN9xwA5mZmZSWlpKZmcltt90GmEyW4uJizjrrLIYNG8b06T5v8THHHMNZZ53Fl19+SWZmJnPnzg1ap7S0NC699FIGDRrElClTGDlypHfZK6+8wqOPPsqQIUM46qij2LVrF1OnTmX69OlkZ2czbNgwHnjggXD/ilpRWh969uDBkJ2drRctWnRoO7m/Lxx+Mkx7uGEKJQi/UlatWsXhhx/e3MUQmphg/7tSarHWOjvY+pFvoceKhS4IggCRPnyudCwSBKGJOe200/wybcDklAcGhZuDyBV0d5V5/ZxY6IIgNCHvv/9+cxchJJHrcqmwotcJ4fXiEgRBiHYiWNCtsSxE0AVBEIBIFvRyS9ATWzdvOQRBEH4lRK6ge10uIuiCIAgQ0YIuLhdBaCpkPPSGHw993LhxHHJfnAAiN8vFttAT2zRvOQShqfnkRti1vGH32WkwnHBPyMUyHnr0jIf+66S80HyLhS4ITYqMh16TTz/9lLPOOss7PX/+fK9Vf8UVV5Cdnc3AgQO9wyU0FpFpoVcUwefWiREfutDSqMWSbip69+6N2+1mz549fPjhh7Rp04aFCxdSUVHB2LFjmTx5MmAGvlq5ciVdunRh7NixfPvttxx++OG8//77rF69GqUUBQUFAFx77bX88Y9/5Oijj2br1q1MmTKFVatWAeByubjhhhv4+9//zksvveQtx969e7nrrrv44osvSE5O5t577+Whhx7i1ltv5aGHHmLevHm0b98+7Ho999xznHDCCfU+HxMnTmTWrFmUlJSQnJzMm2++yYwZMwC4++67SU9Px+12M2HCBJYtW8aQIUPqfYxwiExB//RGqLJGc4ut/1CXgiA0HDIeuhnad+rUqXz00UeceeaZfPzxx9x3330AvPXWWzzzzDNUV1ezc+dOcnJyRNC9eDyw+mPftHmhhiAITYiMh16TGTNm8Pjjj5Oenk52djapqals2rSJBx54gIULF9K2bVsuuuiiRh0nPfJ86PnroWy/+d22Z7MWRRBaIjIeenCOO+44fv75Z5599lmvu+XAgQMkJyfTpk0bdu/ezSeffHLQ+w+HyBP0bT+a76t+gmuXNm9ZBKGFIOOh1z4eOpgWyLRp0/jkk0+8bqShQ4cyfPhwBgwYwLnnnut1DTUWkTce+uqP4ZdX4Zz/gCvynkeCcDDIeOgtk/qOhx55PvQBJ5mPIAiC4EfkCbogCEIzIuOhC4JwyGitUZLV1ew01XjoB+MOFye0IEQAiYmJ5OfnH9RNLkQeWmvy8/NDpnCGQix0QYgAMjMzyc3N9abrCdFPYmKit1NWuIigC0IEEBcXR69evZq7GMKvHHG5CIIgRAki6IIgCFGCCLogCEKU0Gw9RZVSecCWOlcMTntgbwMWJxKQOrcMpM4tg0Opcw+tdUawBc0m6IeCUmpRqK6v0YrUuWUgdW4ZNFadxeUiCIIQJYigC4IgRAmRKujPNHcBmgGpc8tA6twyaJQ6R6QPXRAEQahJpFrogiAIQgAi6IIgCFFCxAm6UmqqUmqNUmq9UurG5i5PQ6GUel4ptUcptcIxL10p9blSap313daar5RSj1rnYJlSakTzlfzgUUp1U0rNU0rlKKVWKqWuteZHbb2VUolKqZ+UUkutOt9uze+llPrRqtubSql4a36CNb3eWt6zOct/sCilYpRSvyil/mtNR3V9AZRSm5VSy5VSS5RSi6x5jXptR5SgK6VigCeAE4AsYKZSKqt5S9VgvAhMDZh3I/Cl1rof8KU1Dab+/azPLODJJipjQ1MNXKe1zgJGA1dZ/2c017sCOF5rPRQYBkxVSo0G7gUe1lr3BfYDl1jrXwLst+Y/bK0XiVwLrHJMR3t9bcZrrYc5cs4b99rWWkfMBxgDzHVM3wTc1NzlasD69QRWOKbXAJ2t352BNdbvp4GZwdaL5A/wITCppdQbSAJ+Bo7E9BqMteZ7r3NgLjDG+h1rraeau+z1rGemJV7HA/8FVDTX11HvzUD7gHmNem1HlIUOdAW2OaZzrXnRSket9U7r9y6go/U76s6D1bQeDvxIlNfbcj8sAfYAnwMbgAKtdbW1irNe3jpbywuBdk1b4kPmEeAGwGNNtyO662ujgc+UUouVUrOseY16bct46BGC1lorpaIyx1QplQK8C/xBa33A+Zq1aKy31toNDFNKpQHvAwOauUiNhlJqGrBHa71YKTWuucvTxByttd6ulOoAfK6UWu1c2BjXdqRZ6NuBbo7pTGtetLJbKdUZwPreY82PmvOglIrDiPmrWuv3rNlRX28ArXUBMA/jckhTStkGlrNe3jpby9sA+U1c1ENhLDBdKbUZeAPjdvkn0VtfL1rr7db3HsyDexSNfG1HmqAvBPpZEfJ4YAYwu5nL1JjMBi60fl+I8THb8y+wIuOjgUJHMy5iUMYUfw5YpbV+yLEoauutlMqwLHOUUq0wMYNVGGE/01otsM72uTgT+EpbTtZIQGt9k9Y6U2vdE3O/fqW1Po8ora+NUipZKZVq/wYmAyto7Gu7uQMHBxFoOBFYi/E73tzc5WnAer0O7ASqMP6zSzC+wy+BdcAXQLq1rsJk+2wAlgPZzV3+g6zz0Rg/4zJgifU5MZrrDQwBfrHqvAK41ZrfG/gJWA+8DSRY8xOt6fXW8t7NXYdDqPs44L8tob5W/ZZan5W2VjX2tS1d/wVBEKKESHO5CIIgCCEQQRcEQYgSRNAFQRCiBBF0QRCEKEEEXRAEIUoQQRcEQYgSRNAFQRCihP8HbO6KuU6bgEgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630508006418,"user_tz":-540,"elapsed":20365,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_005_5_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630508007215,"user_tz":-540,"elapsed":808,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630508007634,"user_tz":-540,"elapsed":423,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5d120cc3-b837-4404-ddf0-5341c3c790df"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630508037526,"user_tz":-540,"elapsed":29897,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"aab306e6-e7ea-4397-b20e-27e0578646bd"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630508037527,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630508037528,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630508038768,"user_tz":-540,"elapsed":1247,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630508038769,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630508049599,"user_tz":-540,"elapsed":10835,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630508049600,"user_tz":-540,"elapsed":30,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a7ef4cd8-5957-4f22-bf74-dd6d42bb3fe7"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630508049601,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"23d16859-3cbf-4cee-c81b-dea6d51b3237"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_005_5_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_005_5_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ad4e5ba3-c33e-4a4e-9f9b-9d25d38af9a9\", \"HeightShiftRange_005_5_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}