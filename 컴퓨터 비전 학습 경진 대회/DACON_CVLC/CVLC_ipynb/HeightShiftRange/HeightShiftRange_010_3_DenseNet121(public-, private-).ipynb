{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_010_3_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyM/9xSwrn8W43Ix2eoLD5mN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630512955902,"user_tz":-540,"elapsed":374,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"37dde722-d12b-4f68-e046-8af146bb0f34"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 16:15:55 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630512977885,"user_tz":-540,"elapsed":21987,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"603602dd-cccd-4c6a-e24f-fa6a0d4b3e88"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630512980540,"user_tz":-540,"elapsed":2663,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630512982117,"user_tz":-540,"elapsed":1585,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630512984115,"user_tz":-540,"elapsed":2002,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630513000992,"user_tz":-540,"elapsed":16880,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630513007908,"user_tz":-540,"elapsed":6919,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630513007909,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ee35a1e0-815c-4bbe-877a-237081b71eb9"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630513007909,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7b13b171-bb5b-478b-b3fb-aa2bdb45f5bc"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630513007910,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630523217458,"user_tz":-540,"elapsed":290229,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6413b15a-46d6-4d44-f88d-00a7b0156eb6"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 53s 469ms/step - loss: 1.9608 - accuracy: 0.3015 - val_loss: 5.2686 - val_accuracy: 0.1108\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 367ms/step - loss: 1.2961 - accuracy: 0.5542 - val_loss: 7.1953 - val_accuracy: 0.1108\n","\n","Epoch 00002: val_accuracy did not improve from 0.11084\n","Epoch 3/500\n","52/52 [==============================] - 19s 372ms/step - loss: 0.9917 - accuracy: 0.6730 - val_loss: 5.8725 - val_accuracy: 0.0665\n","\n","Epoch 00003: val_accuracy did not improve from 0.11084\n","Epoch 4/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.8280 - accuracy: 0.7199 - val_loss: 9.0176 - val_accuracy: 0.0911\n","\n","Epoch 00004: val_accuracy did not improve from 0.11084\n","Epoch 5/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.7120 - accuracy: 0.7594 - val_loss: 7.4523 - val_accuracy: 0.1478\n","\n","Epoch 00005: val_accuracy improved from 0.11084 to 0.14778, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6565 - accuracy: 0.7826 - val_loss: 2.8147 - val_accuracy: 0.3103\n","\n","Epoch 00006: val_accuracy improved from 0.14778 to 0.31034, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.6057 - accuracy: 0.7893 - val_loss: 5.5061 - val_accuracy: 0.1921\n","\n","Epoch 00007: val_accuracy did not improve from 0.31034\n","Epoch 8/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.5339 - accuracy: 0.8276 - val_loss: 4.1175 - val_accuracy: 0.2808\n","\n","Epoch 00008: val_accuracy did not improve from 0.31034\n","Epoch 9/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.5407 - accuracy: 0.8063 - val_loss: 2.4200 - val_accuracy: 0.5271\n","\n","Epoch 00009: val_accuracy improved from 0.31034 to 0.52709, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.5064 - accuracy: 0.8240 - val_loss: 1.5408 - val_accuracy: 0.5542\n","\n","Epoch 00010: val_accuracy improved from 0.52709 to 0.55419, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.4356 - accuracy: 0.8465 - val_loss: 0.7679 - val_accuracy: 0.7463\n","\n","Epoch 00011: val_accuracy improved from 0.55419 to 0.74631, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.4068 - accuracy: 0.8654 - val_loss: 0.6374 - val_accuracy: 0.8300\n","\n","Epoch 00012: val_accuracy improved from 0.74631 to 0.83005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3845 - accuracy: 0.8727 - val_loss: 0.7846 - val_accuracy: 0.7512\n","\n","Epoch 00013: val_accuracy did not improve from 0.83005\n","Epoch 14/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3160 - accuracy: 0.8855 - val_loss: 0.7639 - val_accuracy: 0.7611\n","\n","Epoch 00014: val_accuracy did not improve from 0.83005\n","Epoch 15/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3506 - accuracy: 0.8812 - val_loss: 1.0801 - val_accuracy: 0.7217\n","\n","Epoch 00015: val_accuracy did not improve from 0.83005\n","Epoch 16/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3473 - accuracy: 0.8855 - val_loss: 0.9747 - val_accuracy: 0.6921\n","\n","Epoch 00016: val_accuracy did not improve from 0.83005\n","Epoch 17/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3046 - accuracy: 0.8940 - val_loss: 1.0869 - val_accuracy: 0.7389\n","\n","Epoch 00017: val_accuracy did not improve from 0.83005\n","Epoch 18/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3075 - accuracy: 0.9007 - val_loss: 1.9372 - val_accuracy: 0.5911\n","\n","Epoch 00018: val_accuracy did not improve from 0.83005\n","Epoch 19/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2604 - accuracy: 0.9117 - val_loss: 0.4219 - val_accuracy: 0.8645\n","\n","Epoch 00019: val_accuracy improved from 0.83005 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2304 - accuracy: 0.9233 - val_loss: 0.8196 - val_accuracy: 0.7562\n","\n","Epoch 00020: val_accuracy did not improve from 0.86453\n","Epoch 21/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2682 - accuracy: 0.9056 - val_loss: 2.2119 - val_accuracy: 0.5468\n","\n","Epoch 00021: val_accuracy did not improve from 0.86453\n","Epoch 22/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2608 - accuracy: 0.9123 - val_loss: 0.6128 - val_accuracy: 0.8300\n","\n","Epoch 00022: val_accuracy did not improve from 0.86453\n","Epoch 23/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2530 - accuracy: 0.9135 - val_loss: 0.9347 - val_accuracy: 0.7537\n","\n","Epoch 00023: val_accuracy did not improve from 0.86453\n","Epoch 24/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2095 - accuracy: 0.9318 - val_loss: 0.6593 - val_accuracy: 0.7906\n","\n","Epoch 00024: val_accuracy did not improve from 0.86453\n","Epoch 25/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1745 - accuracy: 0.9440 - val_loss: 0.4931 - val_accuracy: 0.8498\n","\n","Epoch 00025: val_accuracy did not improve from 0.86453\n","Epoch 26/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2281 - accuracy: 0.9190 - val_loss: 0.5191 - val_accuracy: 0.8473\n","\n","Epoch 00026: val_accuracy did not improve from 0.86453\n","Epoch 27/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1974 - accuracy: 0.9312 - val_loss: 0.4736 - val_accuracy: 0.8621\n","\n","Epoch 00027: val_accuracy did not improve from 0.86453\n","Epoch 28/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1553 - accuracy: 0.9513 - val_loss: 1.2530 - val_accuracy: 0.7635\n","\n","Epoch 00028: val_accuracy did not improve from 0.86453\n","Epoch 29/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1545 - accuracy: 0.9470 - val_loss: 0.5994 - val_accuracy: 0.8424\n","\n","Epoch 00029: val_accuracy did not improve from 0.86453\n","Epoch 30/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1817 - accuracy: 0.9403 - val_loss: 0.7739 - val_accuracy: 0.8202\n","\n","Epoch 00030: val_accuracy did not improve from 0.86453\n","Epoch 31/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1567 - accuracy: 0.9458 - val_loss: 0.5505 - val_accuracy: 0.8571\n","\n","Epoch 00031: val_accuracy did not improve from 0.86453\n","Epoch 32/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1565 - accuracy: 0.9501 - val_loss: 0.7153 - val_accuracy: 0.7980\n","\n","Epoch 00032: val_accuracy did not improve from 0.86453\n","Epoch 33/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1322 - accuracy: 0.9549 - val_loss: 0.8933 - val_accuracy: 0.7660\n","\n","Epoch 00033: val_accuracy did not improve from 0.86453\n","Epoch 34/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1333 - accuracy: 0.9549 - val_loss: 0.4685 - val_accuracy: 0.8744\n","\n","Epoch 00034: val_accuracy improved from 0.86453 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 35/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1471 - accuracy: 0.9488 - val_loss: 1.7493 - val_accuracy: 0.6650\n","\n","Epoch 00035: val_accuracy did not improve from 0.87438\n","Epoch 36/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1217 - accuracy: 0.9598 - val_loss: 1.1626 - val_accuracy: 0.7389\n","\n","Epoch 00036: val_accuracy did not improve from 0.87438\n","Epoch 37/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1480 - accuracy: 0.9495 - val_loss: 0.5755 - val_accuracy: 0.8473\n","\n","Epoch 00037: val_accuracy did not improve from 0.87438\n","Epoch 38/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3199 - accuracy: 0.9068 - val_loss: 1.6319 - val_accuracy: 0.6576\n","\n","Epoch 00038: val_accuracy did not improve from 0.87438\n","Epoch 39/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1792 - accuracy: 0.9385 - val_loss: 0.6813 - val_accuracy: 0.8276\n","\n","Epoch 00039: val_accuracy did not improve from 0.87438\n","Epoch 40/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1266 - accuracy: 0.9555 - val_loss: 0.6172 - val_accuracy: 0.8522\n","\n","Epoch 00040: val_accuracy did not improve from 0.87438\n","Epoch 41/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0930 - accuracy: 0.9720 - val_loss: 0.4780 - val_accuracy: 0.8867\n","\n","Epoch 00041: val_accuracy improved from 0.87438 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 42/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1009 - accuracy: 0.9702 - val_loss: 0.4411 - val_accuracy: 0.8818\n","\n","Epoch 00042: val_accuracy did not improve from 0.88670\n","Epoch 43/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1412 - accuracy: 0.9501 - val_loss: 0.3268 - val_accuracy: 0.9015\n","\n","Epoch 00043: val_accuracy improved from 0.88670 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 44/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1293 - accuracy: 0.9531 - val_loss: 0.6779 - val_accuracy: 0.8325\n","\n","Epoch 00044: val_accuracy did not improve from 0.90148\n","Epoch 45/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.6403 - val_accuracy: 0.8276\n","\n","Epoch 00045: val_accuracy did not improve from 0.90148\n","Epoch 46/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0797 - accuracy: 0.9775 - val_loss: 0.3956 - val_accuracy: 0.8719\n","\n","Epoch 00046: val_accuracy did not improve from 0.90148\n","Epoch 47/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1118 - accuracy: 0.9659 - val_loss: 0.6580 - val_accuracy: 0.8399\n","\n","Epoch 00047: val_accuracy did not improve from 0.90148\n","Epoch 48/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0798 - accuracy: 0.9744 - val_loss: 0.5220 - val_accuracy: 0.8596\n","\n","Epoch 00048: val_accuracy did not improve from 0.90148\n","Epoch 49/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1318 - accuracy: 0.9501 - val_loss: 0.6350 - val_accuracy: 0.8399\n","\n","Epoch 00049: val_accuracy did not improve from 0.90148\n","Epoch 50/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1162 - accuracy: 0.9592 - val_loss: 0.8123 - val_accuracy: 0.8350\n","\n","Epoch 00050: val_accuracy did not improve from 0.90148\n","Epoch 51/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.3835 - val_accuracy: 0.8842\n","\n","Epoch 00051: val_accuracy did not improve from 0.90148\n","Epoch 52/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0716 - accuracy: 0.9732 - val_loss: 0.6405 - val_accuracy: 0.8325\n","\n","Epoch 00052: val_accuracy did not improve from 0.90148\n","Epoch 53/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0688 - accuracy: 0.9769 - val_loss: 0.5334 - val_accuracy: 0.8645\n","\n","Epoch 00053: val_accuracy did not improve from 0.90148\n","Epoch 54/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 0.6148 - val_accuracy: 0.8276\n","\n","Epoch 00054: val_accuracy did not improve from 0.90148\n","Epoch 55/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1305 - accuracy: 0.9647 - val_loss: 0.7310 - val_accuracy: 0.8300\n","\n","Epoch 00055: val_accuracy did not improve from 0.90148\n","Epoch 56/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.6537 - val_accuracy: 0.8448\n","\n","Epoch 00056: val_accuracy did not improve from 0.90148\n","Epoch 57/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0620 - accuracy: 0.9805 - val_loss: 0.3401 - val_accuracy: 0.8941\n","\n","Epoch 00057: val_accuracy did not improve from 0.90148\n","Epoch 58/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.4441 - val_accuracy: 0.8842\n","\n","Epoch 00058: val_accuracy did not improve from 0.90148\n","Epoch 59/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0485 - accuracy: 0.9848 - val_loss: 0.3889 - val_accuracy: 0.8892\n","\n","Epoch 00059: val_accuracy did not improve from 0.90148\n","Epoch 60/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.6506 - val_accuracy: 0.8571\n","\n","Epoch 00060: val_accuracy did not improve from 0.90148\n","Epoch 61/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 0.5514 - val_accuracy: 0.8892\n","\n","Epoch 00061: val_accuracy did not improve from 0.90148\n","Epoch 62/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0825 - accuracy: 0.9781 - val_loss: 0.5696 - val_accuracy: 0.8596\n","\n","Epoch 00062: val_accuracy did not improve from 0.90148\n","Epoch 63/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0887 - accuracy: 0.9750 - val_loss: 0.8327 - val_accuracy: 0.8227\n","\n","Epoch 00063: val_accuracy did not improve from 0.90148\n","Epoch 64/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0483 - accuracy: 0.9872 - val_loss: 0.4692 - val_accuracy: 0.8695\n","\n","Epoch 00064: val_accuracy did not improve from 0.90148\n","Epoch 65/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.3743 - val_accuracy: 0.9015\n","\n","Epoch 00065: val_accuracy did not improve from 0.90148\n","Epoch 66/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.3686 - val_accuracy: 0.8916\n","\n","Epoch 00066: val_accuracy did not improve from 0.90148\n","Epoch 67/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.4951 - val_accuracy: 0.8941\n","\n","Epoch 00067: val_accuracy did not improve from 0.90148\n","Epoch 68/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0959 - accuracy: 0.9683 - val_loss: 1.9431 - val_accuracy: 0.6724\n","\n","Epoch 00068: val_accuracy did not improve from 0.90148\n","Epoch 69/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0796 - accuracy: 0.9732 - val_loss: 1.3581 - val_accuracy: 0.7611\n","\n","Epoch 00069: val_accuracy did not improve from 0.90148\n","Epoch 70/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1621 - accuracy: 0.9476 - val_loss: 1.5161 - val_accuracy: 0.7562\n","\n","Epoch 00070: val_accuracy did not improve from 0.90148\n","Epoch 71/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1859 - accuracy: 0.9367 - val_loss: 1.6257 - val_accuracy: 0.6897\n","\n","Epoch 00071: val_accuracy did not improve from 0.90148\n","Epoch 72/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1063 - accuracy: 0.9604 - val_loss: 0.6921 - val_accuracy: 0.8399\n","\n","Epoch 00072: val_accuracy did not improve from 0.90148\n","Epoch 73/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.3830 - val_accuracy: 0.8990\n","\n","Epoch 00073: val_accuracy did not improve from 0.90148\n","Epoch 74/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.3483 - val_accuracy: 0.9113\n","\n","Epoch 00074: val_accuracy improved from 0.90148 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.3320 - val_accuracy: 0.9163\n","\n","Epoch 00075: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 76/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.5036 - val_accuracy: 0.8768\n","\n","Epoch 00076: val_accuracy did not improve from 0.91626\n","Epoch 77/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0691 - accuracy: 0.9799 - val_loss: 0.7931 - val_accuracy: 0.8325\n","\n","Epoch 00077: val_accuracy did not improve from 0.91626\n","Epoch 78/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.4955 - val_accuracy: 0.8867\n","\n","Epoch 00078: val_accuracy did not improve from 0.91626\n","Epoch 79/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0946 - accuracy: 0.9665 - val_loss: 0.7583 - val_accuracy: 0.8103\n","\n","Epoch 00079: val_accuracy did not improve from 0.91626\n","Epoch 80/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0666 - accuracy: 0.9781 - val_loss: 0.4348 - val_accuracy: 0.8621\n","\n","Epoch 00080: val_accuracy did not improve from 0.91626\n","Epoch 81/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0322 - accuracy: 0.9860 - val_loss: 0.2964 - val_accuracy: 0.9286\n","\n","Epoch 00081: val_accuracy improved from 0.91626 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 82/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.3418 - val_accuracy: 0.9089\n","\n","Epoch 00082: val_accuracy did not improve from 0.92857\n","Epoch 83/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.3667 - val_accuracy: 0.9064\n","\n","Epoch 00083: val_accuracy did not improve from 0.92857\n","Epoch 84/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.3292 - val_accuracy: 0.9212\n","\n","Epoch 00084: val_accuracy did not improve from 0.92857\n","Epoch 85/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.3296 - val_accuracy: 0.9113\n","\n","Epoch 00085: val_accuracy did not improve from 0.92857\n","Epoch 86/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.4413 - val_accuracy: 0.8818\n","\n","Epoch 00086: val_accuracy did not improve from 0.92857\n","Epoch 87/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.3443 - val_accuracy: 0.9163\n","\n","Epoch 00087: val_accuracy did not improve from 0.92857\n","Epoch 88/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.6325 - val_accuracy: 0.8695\n","\n","Epoch 00088: val_accuracy did not improve from 0.92857\n","Epoch 89/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 0.7378 - val_accuracy: 0.8571\n","\n","Epoch 00089: val_accuracy did not improve from 0.92857\n","Epoch 90/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.5353 - val_accuracy: 0.8941\n","\n","Epoch 00090: val_accuracy did not improve from 0.92857\n","Epoch 91/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1061 - accuracy: 0.9659 - val_loss: 1.8547 - val_accuracy: 0.7266\n","\n","Epoch 00091: val_accuracy did not improve from 0.92857\n","Epoch 92/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0858 - accuracy: 0.9702 - val_loss: 0.7100 - val_accuracy: 0.8842\n","\n","Epoch 00092: val_accuracy did not improve from 0.92857\n","Epoch 93/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 0.8887 - val_accuracy: 0.8227\n","\n","Epoch 00093: val_accuracy did not improve from 0.92857\n","Epoch 94/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1070 - accuracy: 0.9635 - val_loss: 1.1828 - val_accuracy: 0.7537\n","\n","Epoch 00094: val_accuracy did not improve from 0.92857\n","Epoch 95/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0724 - accuracy: 0.9702 - val_loss: 0.3954 - val_accuracy: 0.9015\n","\n","Epoch 00095: val_accuracy did not improve from 0.92857\n","Epoch 96/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 0.6417 - val_accuracy: 0.8670\n","\n","Epoch 00096: val_accuracy did not improve from 0.92857\n","Epoch 97/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0762 - accuracy: 0.9781 - val_loss: 0.7407 - val_accuracy: 0.8424\n","\n","Epoch 00097: val_accuracy did not improve from 0.92857\n","Epoch 98/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0427 - accuracy: 0.9866 - val_loss: 0.4937 - val_accuracy: 0.8941\n","\n","Epoch 00098: val_accuracy did not improve from 0.92857\n","Epoch 99/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.4242 - val_accuracy: 0.8966\n","\n","Epoch 00099: val_accuracy did not improve from 0.92857\n","Epoch 100/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.4011 - val_accuracy: 0.8941\n","\n","Epoch 00100: val_accuracy did not improve from 0.92857\n","Epoch 101/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0744 - accuracy: 0.9799 - val_loss: 0.7825 - val_accuracy: 0.8571\n","\n","Epoch 00101: val_accuracy did not improve from 0.92857\n","Epoch 102/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0475 - accuracy: 0.9872 - val_loss: 0.6946 - val_accuracy: 0.8695\n","\n","Epoch 00102: val_accuracy did not improve from 0.92857\n","Epoch 103/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.4687 - val_accuracy: 0.8793\n","\n","Epoch 00103: val_accuracy did not improve from 0.92857\n","Epoch 104/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0307 - accuracy: 0.9915 - val_loss: 0.4328 - val_accuracy: 0.8892\n","\n","Epoch 00104: val_accuracy did not improve from 0.92857\n","Epoch 105/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.3951 - val_accuracy: 0.9064\n","\n","Epoch 00105: val_accuracy did not improve from 0.92857\n","Epoch 106/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5086 - val_accuracy: 0.9015\n","\n","Epoch 00106: val_accuracy did not improve from 0.92857\n","Epoch 107/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.5455 - val_accuracy: 0.8768\n","\n","Epoch 00107: val_accuracy did not improve from 0.92857\n","Epoch 108/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.4584 - val_accuracy: 0.9064\n","\n","Epoch 00108: val_accuracy did not improve from 0.92857\n","Epoch 109/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.6686 - val_accuracy: 0.8867\n","\n","Epoch 00109: val_accuracy did not improve from 0.92857\n","Epoch 110/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.5558 - val_accuracy: 0.8744\n","\n","Epoch 00110: val_accuracy did not improve from 0.92857\n","Epoch 111/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.5188 - val_accuracy: 0.8842\n","\n","Epoch 00111: val_accuracy did not improve from 0.92857\n","Epoch 112/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0767 - accuracy: 0.9756 - val_loss: 0.9177 - val_accuracy: 0.8300\n","\n","Epoch 00112: val_accuracy did not improve from 0.92857\n","Epoch 113/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1226 - accuracy: 0.9604 - val_loss: 0.8639 - val_accuracy: 0.8547\n","\n","Epoch 00113: val_accuracy did not improve from 0.92857\n","Epoch 114/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.4896 - val_accuracy: 0.8744\n","\n","Epoch 00114: val_accuracy did not improve from 0.92857\n","Epoch 115/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.5778 - val_accuracy: 0.8818\n","\n","Epoch 00115: val_accuracy did not improve from 0.92857\n","Epoch 116/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0339 - accuracy: 0.9872 - val_loss: 0.7076 - val_accuracy: 0.8350\n","\n","Epoch 00116: val_accuracy did not improve from 0.92857\n","Epoch 117/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 0.6306 - val_accuracy: 0.8793\n","\n","Epoch 00117: val_accuracy did not improve from 0.92857\n","Epoch 118/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0241 - accuracy: 0.9903 - val_loss: 0.7185 - val_accuracy: 0.8350\n","\n","Epoch 00118: val_accuracy did not improve from 0.92857\n","Epoch 119/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0166 - accuracy: 0.9970 - val_loss: 0.4900 - val_accuracy: 0.9039\n","\n","Epoch 00119: val_accuracy did not improve from 0.92857\n","Epoch 120/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.5328 - val_accuracy: 0.8892\n","\n","Epoch 00120: val_accuracy did not improve from 0.92857\n","Epoch 121/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.3771 - val_accuracy: 0.9113\n","\n","Epoch 00121: val_accuracy did not improve from 0.92857\n","Epoch 122/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4674 - val_accuracy: 0.8916\n","\n","Epoch 00122: val_accuracy did not improve from 0.92857\n","Epoch 123/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3790 - val_accuracy: 0.8990\n","\n","Epoch 00123: val_accuracy did not improve from 0.92857\n","Epoch 124/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3983 - val_accuracy: 0.9113\n","\n","Epoch 00124: val_accuracy did not improve from 0.92857\n","Epoch 125/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4073 - val_accuracy: 0.9113\n","\n","Epoch 00125: val_accuracy did not improve from 0.92857\n","Epoch 126/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.3432 - val_accuracy: 0.9113\n","\n","Epoch 00126: val_accuracy did not improve from 0.92857\n","Epoch 127/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9138\n","\n","Epoch 00127: val_accuracy did not improve from 0.92857\n","Epoch 128/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.6787 - val_accuracy: 0.8916\n","\n","Epoch 00128: val_accuracy did not improve from 0.92857\n","Epoch 129/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.6731 - val_accuracy: 0.8547\n","\n","Epoch 00129: val_accuracy did not improve from 0.92857\n","Epoch 130/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.8873 - val_accuracy: 0.8227\n","\n","Epoch 00130: val_accuracy did not improve from 0.92857\n","Epoch 131/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 0.5054 - val_accuracy: 0.8842\n","\n","Epoch 00131: val_accuracy did not improve from 0.92857\n","Epoch 132/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0810 - accuracy: 0.9689 - val_loss: 0.9777 - val_accuracy: 0.8054\n","\n","Epoch 00132: val_accuracy did not improve from 0.92857\n","Epoch 133/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0835 - accuracy: 0.9738 - val_loss: 0.6796 - val_accuracy: 0.8547\n","\n","Epoch 00133: val_accuracy did not improve from 0.92857\n","Epoch 134/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1012 - accuracy: 0.9683 - val_loss: 2.5225 - val_accuracy: 0.6995\n","\n","Epoch 00134: val_accuracy did not improve from 0.92857\n","Epoch 135/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0915 - accuracy: 0.9695 - val_loss: 0.6991 - val_accuracy: 0.8818\n","\n","Epoch 00135: val_accuracy did not improve from 0.92857\n","Epoch 136/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.5449 - val_accuracy: 0.8990\n","\n","Epoch 00136: val_accuracy did not improve from 0.92857\n","Epoch 137/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.4262 - val_accuracy: 0.8990\n","\n","Epoch 00137: val_accuracy did not improve from 0.92857\n","Epoch 138/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.3695 - val_accuracy: 0.9212\n","\n","Epoch 00138: val_accuracy did not improve from 0.92857\n","Epoch 139/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.4611 - val_accuracy: 0.8768\n","\n","Epoch 00139: val_accuracy did not improve from 0.92857\n","Epoch 140/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 0.5219 - val_accuracy: 0.8645\n","\n","Epoch 00140: val_accuracy did not improve from 0.92857\n","Epoch 141/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.4158 - val_accuracy: 0.9089\n","\n","Epoch 00141: val_accuracy did not improve from 0.92857\n","Epoch 142/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.4110 - val_accuracy: 0.9187\n","\n","Epoch 00142: val_accuracy did not improve from 0.92857\n","Epoch 143/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0385 - accuracy: 0.9915 - val_loss: 1.3568 - val_accuracy: 0.7488\n","\n","Epoch 00143: val_accuracy did not improve from 0.92857\n","Epoch 144/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.6869 - val_accuracy: 0.8744\n","\n","Epoch 00144: val_accuracy did not improve from 0.92857\n","Epoch 145/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.4832 - val_accuracy: 0.8768\n","\n","Epoch 00145: val_accuracy did not improve from 0.92857\n","Epoch 146/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0180 - accuracy: 0.9915 - val_loss: 0.6661 - val_accuracy: 0.8571\n","\n","Epoch 00146: val_accuracy did not improve from 0.92857\n","Epoch 147/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.6141 - val_accuracy: 0.8695\n","\n","Epoch 00147: val_accuracy did not improve from 0.92857\n","Epoch 148/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.4755 - val_accuracy: 0.8941\n","\n","Epoch 00148: val_accuracy did not improve from 0.92857\n","Epoch 149/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.4914 - val_accuracy: 0.8768\n","\n","Epoch 00149: val_accuracy did not improve from 0.92857\n","Epoch 150/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.4715 - val_accuracy: 0.8990\n","\n","Epoch 00150: val_accuracy did not improve from 0.92857\n","Epoch 151/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.4854 - val_accuracy: 0.8719\n","\n","Epoch 00151: val_accuracy did not improve from 0.92857\n","Epoch 152/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.6935 - val_accuracy: 0.8522\n","\n","Epoch 00152: val_accuracy did not improve from 0.92857\n","Epoch 153/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0380 - accuracy: 0.9854 - val_loss: 0.3645 - val_accuracy: 0.9113\n","\n","Epoch 00153: val_accuracy did not improve from 0.92857\n","Epoch 154/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6896 - val_accuracy: 0.8719\n","\n","Epoch 00154: val_accuracy did not improve from 0.92857\n","Epoch 155/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0411 - accuracy: 0.9903 - val_loss: 0.5145 - val_accuracy: 0.8892\n","\n","Epoch 00155: val_accuracy did not improve from 0.92857\n","Epoch 156/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.4764 - val_accuracy: 0.9064\n","\n","Epoch 00156: val_accuracy did not improve from 0.92857\n","Epoch 157/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.5511 - val_accuracy: 0.8941\n","\n","Epoch 00157: val_accuracy did not improve from 0.92857\n","Epoch 158/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.5081 - val_accuracy: 0.8941\n","\n","Epoch 00158: val_accuracy did not improve from 0.92857\n","Epoch 159/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4824 - val_accuracy: 0.9138\n","\n","Epoch 00159: val_accuracy did not improve from 0.92857\n","Epoch 160/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4988 - val_accuracy: 0.8966\n","\n","Epoch 00160: val_accuracy did not improve from 0.92857\n","Epoch 161/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5353 - val_accuracy: 0.8793\n","\n","Epoch 00161: val_accuracy did not improve from 0.92857\n","Epoch 162/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.4458 - val_accuracy: 0.8916\n","\n","Epoch 00162: val_accuracy did not improve from 0.92857\n","Epoch 163/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 0.4742 - val_accuracy: 0.9015\n","\n","Epoch 00163: val_accuracy did not improve from 0.92857\n","Epoch 164/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.5270 - val_accuracy: 0.9064\n","\n","Epoch 00164: val_accuracy did not improve from 0.92857\n","Epoch 165/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4406 - val_accuracy: 0.9113\n","\n","Epoch 00165: val_accuracy did not improve from 0.92857\n","Epoch 166/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.4325 - val_accuracy: 0.9113\n","\n","Epoch 00166: val_accuracy did not improve from 0.92857\n","Epoch 167/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4553 - val_accuracy: 0.9039\n","\n","Epoch 00167: val_accuracy did not improve from 0.92857\n","Epoch 168/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4486 - val_accuracy: 0.8990\n","\n","Epoch 00168: val_accuracy did not improve from 0.92857\n","Epoch 169/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5297 - val_accuracy: 0.9039\n","\n","Epoch 00169: val_accuracy did not improve from 0.92857\n","Epoch 170/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.5353 - val_accuracy: 0.8966\n","\n","Epoch 00170: val_accuracy did not improve from 0.92857\n","Epoch 171/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 1.1293 - val_accuracy: 0.8054\n","\n","Epoch 00171: val_accuracy did not improve from 0.92857\n","Epoch 172/500\n","52/52 [==============================] - 21s 399ms/step - loss: 0.0983 - accuracy: 0.9702 - val_loss: 0.8670 - val_accuracy: 0.8571\n","\n","Epoch 00172: val_accuracy did not improve from 0.92857\n","Epoch 173/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.7515 - val_accuracy: 0.8695\n","\n","Epoch 00173: val_accuracy did not improve from 0.92857\n","Epoch 174/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 0.5605 - val_accuracy: 0.8990\n","\n","Epoch 00174: val_accuracy did not improve from 0.92857\n","Epoch 175/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.7537 - val_accuracy: 0.8645\n","\n","Epoch 00175: val_accuracy did not improve from 0.92857\n","Epoch 176/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.5414 - val_accuracy: 0.8892\n","\n","Epoch 00176: val_accuracy did not improve from 0.92857\n","Epoch 177/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5343 - val_accuracy: 0.8892\n","\n","Epoch 00177: val_accuracy did not improve from 0.92857\n","Epoch 178/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0130 - accuracy: 0.9939 - val_loss: 0.3831 - val_accuracy: 0.9138\n","\n","Epoch 00178: val_accuracy did not improve from 0.92857\n","Epoch 179/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.3780 - val_accuracy: 0.9163\n","\n","Epoch 00179: val_accuracy did not improve from 0.92857\n","Epoch 180/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.3134 - val_accuracy: 0.9236\n","\n","Epoch 00180: val_accuracy did not improve from 0.92857\n","Epoch 181/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3477 - val_accuracy: 0.9163\n","\n","Epoch 00181: val_accuracy did not improve from 0.92857\n","Epoch 182/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9138\n","\n","Epoch 00182: val_accuracy did not improve from 0.92857\n","Epoch 183/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.3754 - val_accuracy: 0.9212\n","\n","Epoch 00183: val_accuracy did not improve from 0.92857\n","Epoch 184/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.6178 - val_accuracy: 0.8818\n","\n","Epoch 00184: val_accuracy did not improve from 0.92857\n","Epoch 185/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4868 - val_accuracy: 0.9064\n","\n","Epoch 00185: val_accuracy did not improve from 0.92857\n","Epoch 186/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9261\n","\n","Epoch 00186: val_accuracy did not improve from 0.92857\n","Epoch 187/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.7909 - val_accuracy: 0.8571\n","\n","Epoch 00187: val_accuracy did not improve from 0.92857\n","Epoch 188/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.6471 - val_accuracy: 0.8892\n","\n","Epoch 00188: val_accuracy did not improve from 0.92857\n","Epoch 189/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.8857 - val_accuracy: 0.8374\n","\n","Epoch 00189: val_accuracy did not improve from 0.92857\n","Epoch 190/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 1.0647 - val_accuracy: 0.8079\n","\n","Epoch 00190: val_accuracy did not improve from 0.92857\n","Epoch 191/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.8574 - val_accuracy: 0.8645\n","\n","Epoch 00191: val_accuracy did not improve from 0.92857\n","Epoch 192/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.8274 - val_accuracy: 0.8498\n","\n","Epoch 00192: val_accuracy did not improve from 0.92857\n","Epoch 193/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 0.7784 - val_accuracy: 0.8424\n","\n","Epoch 00193: val_accuracy did not improve from 0.92857\n","Epoch 194/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.4689 - val_accuracy: 0.9039\n","\n","Epoch 00194: val_accuracy did not improve from 0.92857\n","Epoch 195/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.5029 - val_accuracy: 0.8842\n","\n","Epoch 00195: val_accuracy did not improve from 0.92857\n","Epoch 196/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.4744 - val_accuracy: 0.9039\n","\n","Epoch 00196: val_accuracy did not improve from 0.92857\n","Epoch 197/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6124 - val_accuracy: 0.8744\n","\n","Epoch 00197: val_accuracy did not improve from 0.92857\n","Epoch 198/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.5351 - val_accuracy: 0.8916\n","\n","Epoch 00198: val_accuracy did not improve from 0.92857\n","Epoch 199/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.4416 - val_accuracy: 0.9187\n","\n","Epoch 00199: val_accuracy did not improve from 0.92857\n","Epoch 200/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.4710 - val_accuracy: 0.8990\n","\n","Epoch 00200: val_accuracy did not improve from 0.92857\n","Epoch 201/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3460 - val_accuracy: 0.9138\n","\n","Epoch 00201: val_accuracy did not improve from 0.92857\n","Epoch 202/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4025 - val_accuracy: 0.9089\n","\n","Epoch 00202: val_accuracy did not improve from 0.92857\n","Epoch 203/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5203 - val_accuracy: 0.8990\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.4455 - val_accuracy: 0.8867\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4720 - val_accuracy: 0.9089\n","\n","Epoch 00205: val_accuracy did not improve from 0.92857\n","Epoch 206/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.6097 - val_accuracy: 0.8818\n","\n","Epoch 00206: val_accuracy did not improve from 0.92857\n","Epoch 207/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6703 - val_accuracy: 0.8498\n","\n","Epoch 00207: val_accuracy did not improve from 0.92857\n","Epoch 208/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0129 - accuracy: 0.9939 - val_loss: 0.5054 - val_accuracy: 0.9089\n","\n","Epoch 00208: val_accuracy did not improve from 0.92857\n","Epoch 209/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0552 - accuracy: 0.9872 - val_loss: 0.8985 - val_accuracy: 0.8522\n","\n","Epoch 00209: val_accuracy did not improve from 0.92857\n","Epoch 210/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.6625 - val_accuracy: 0.8818\n","\n","Epoch 00210: val_accuracy did not improve from 0.92857\n","Epoch 211/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.5078 - val_accuracy: 0.8966\n","\n","Epoch 00211: val_accuracy did not improve from 0.92857\n","Epoch 212/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.6666 - val_accuracy: 0.8941\n","\n","Epoch 00212: val_accuracy did not improve from 0.92857\n","Epoch 213/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0467 - accuracy: 0.9829 - val_loss: 1.1038 - val_accuracy: 0.8596\n","\n","Epoch 00213: val_accuracy did not improve from 0.92857\n","Epoch 214/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.4027 - val_accuracy: 0.9212\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.6071 - val_accuracy: 0.8867\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.4608 - val_accuracy: 0.9187\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4744 - val_accuracy: 0.9089\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4556 - val_accuracy: 0.9113\n","\n","Epoch 00218: val_accuracy did not improve from 0.92857\n","Epoch 219/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.3887 - val_accuracy: 0.9187\n","\n","Epoch 00219: val_accuracy did not improve from 0.92857\n","Epoch 220/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9163\n","\n","Epoch 00220: val_accuracy did not improve from 0.92857\n","Epoch 221/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9335\n","\n","Epoch 00221: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 222/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9064\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9310\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4021 - val_accuracy: 0.9138\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9163\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 20s 383ms/step - loss: 5.1745e-04 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9261\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5068 - val_accuracy: 0.9089\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5363 - val_accuracy: 0.8916\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5310 - val_accuracy: 0.9039\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4486 - val_accuracy: 0.9113\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9236\n","\n","Epoch 00231: val_accuracy did not improve from 0.93350\n","Epoch 232/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9163\n","\n","Epoch 00232: val_accuracy did not improve from 0.93350\n","Epoch 233/500\n","52/52 [==============================] - 20s 383ms/step - loss: 4.7965e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9187\n","\n","Epoch 00233: val_accuracy did not improve from 0.93350\n","Epoch 234/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.7122 - val_accuracy: 0.8916\n","\n","Epoch 00234: val_accuracy did not improve from 0.93350\n","Epoch 235/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0220 - accuracy: 0.9896 - val_loss: 0.6423 - val_accuracy: 0.8916\n","\n","Epoch 00235: val_accuracy did not improve from 0.93350\n","Epoch 236/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 1.0817 - val_accuracy: 0.8522\n","\n","Epoch 00236: val_accuracy did not improve from 0.93350\n","Epoch 237/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0698 - accuracy: 0.9823 - val_loss: 0.7871 - val_accuracy: 0.8719\n","\n","Epoch 00237: val_accuracy did not improve from 0.93350\n","Epoch 238/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0792 - accuracy: 0.9769 - val_loss: 0.8442 - val_accuracy: 0.8793\n","\n","Epoch 00238: val_accuracy did not improve from 0.93350\n","Epoch 239/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 0.6972 - val_accuracy: 0.8719\n","\n","Epoch 00239: val_accuracy did not improve from 0.93350\n","Epoch 240/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.5691 - val_accuracy: 0.9064\n","\n","Epoch 00240: val_accuracy did not improve from 0.93350\n","Epoch 241/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.3423 - val_accuracy: 0.9261\n","\n","Epoch 00241: val_accuracy did not improve from 0.93350\n","Epoch 242/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.5350 - val_accuracy: 0.8768\n","\n","Epoch 00242: val_accuracy did not improve from 0.93350\n","Epoch 243/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.5535 - val_accuracy: 0.9039\n","\n","Epoch 00243: val_accuracy did not improve from 0.93350\n","Epoch 244/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.3529 - val_accuracy: 0.9236\n","\n","Epoch 00244: val_accuracy did not improve from 0.93350\n","Epoch 245/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.6701 - val_accuracy: 0.8744\n","\n","Epoch 00245: val_accuracy did not improve from 0.93350\n","Epoch 246/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.5747 - val_accuracy: 0.9039\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.4730 - val_accuracy: 0.9187\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4297 - val_accuracy: 0.9138\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.3919 - val_accuracy: 0.9187\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.3688 - val_accuracy: 0.9261\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.5529 - val_accuracy: 0.9039\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.4288 - val_accuracy: 0.9163\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.4956 - val_accuracy: 0.8892\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.4790 - val_accuracy: 0.9039\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4334 - val_accuracy: 0.9163\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.3408 - val_accuracy: 0.9261\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9360\n","\n","Epoch 00257: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 258/500\n","52/52 [==============================] - 20s 381ms/step - loss: 5.5964e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9360\n","\n","Epoch 00258: val_accuracy did not improve from 0.93596\n","Epoch 259/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.0972e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9360\n","\n","Epoch 00259: val_accuracy did not improve from 0.93596\n","Epoch 260/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6404 - val_accuracy: 0.8966\n","\n","Epoch 00260: val_accuracy did not improve from 0.93596\n","Epoch 261/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.4071 - val_accuracy: 0.9113\n","\n","Epoch 00261: val_accuracy did not improve from 0.93596\n","Epoch 262/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.8635 - val_accuracy: 0.8719\n","\n","Epoch 00262: val_accuracy did not improve from 0.93596\n","Epoch 263/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.6906 - val_accuracy: 0.8596\n","\n","Epoch 00263: val_accuracy did not improve from 0.93596\n","Epoch 264/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 2.2158 - val_accuracy: 0.6798\n","\n","Epoch 00264: val_accuracy did not improve from 0.93596\n","Epoch 265/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.6339 - val_accuracy: 0.8670\n","\n","Epoch 00265: val_accuracy did not improve from 0.93596\n","Epoch 266/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.4871 - val_accuracy: 0.9064\n","\n","Epoch 00266: val_accuracy did not improve from 0.93596\n","Epoch 267/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4678 - val_accuracy: 0.9261\n","\n","Epoch 00267: val_accuracy did not improve from 0.93596\n","Epoch 268/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5232 - val_accuracy: 0.9015\n","\n","Epoch 00268: val_accuracy did not improve from 0.93596\n","Epoch 269/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.4932 - val_accuracy: 0.8990\n","\n","Epoch 00269: val_accuracy did not improve from 0.93596\n","Epoch 270/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0093 - accuracy: 0.9957 - val_loss: 0.5261 - val_accuracy: 0.8966\n","\n","Epoch 00270: val_accuracy did not improve from 0.93596\n","Epoch 271/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.5099 - val_accuracy: 0.9015\n","\n","Epoch 00271: val_accuracy did not improve from 0.93596\n","Epoch 272/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5418 - val_accuracy: 0.8990\n","\n","Epoch 00272: val_accuracy did not improve from 0.93596\n","Epoch 273/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4795 - val_accuracy: 0.9039\n","\n","Epoch 00273: val_accuracy did not improve from 0.93596\n","Epoch 274/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.4958 - val_accuracy: 0.9113\n","\n","Epoch 00274: val_accuracy did not improve from 0.93596\n","Epoch 275/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4569 - val_accuracy: 0.9089\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5219 - val_accuracy: 0.8941\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5446 - val_accuracy: 0.8966\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.6247 - val_accuracy: 0.8916\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.6273 - val_accuracy: 0.9015\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0186 - accuracy: 0.9921 - val_loss: 0.6780 - val_accuracy: 0.8793\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5652 - val_accuracy: 0.8941\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8966\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","52/52 [==============================] - 20s 383ms/step - loss: 8.2905e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9163\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9089\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.8414 - val_accuracy: 0.8768\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 1.0459 - val_accuracy: 0.8571\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.7138 - val_accuracy: 0.8818\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.5870 - val_accuracy: 0.8842\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.5237 - val_accuracy: 0.8990\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 0.5722 - val_accuracy: 0.9015\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.7815 - val_accuracy: 0.8596\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.5635 - val_accuracy: 0.8867\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.5416 - val_accuracy: 0.8966\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4231 - val_accuracy: 0.9187\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9236\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.4247 - val_accuracy: 0.9113\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.5549 - val_accuracy: 0.8966\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4073 - val_accuracy: 0.9212\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9138\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4372 - val_accuracy: 0.9310\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9089\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3281 - val_accuracy: 0.9261\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4171 - val_accuracy: 0.9039\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.5008 - val_accuracy: 0.9039\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.6618 - val_accuracy: 0.8842\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.6928 - val_accuracy: 0.8350\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6187 - val_accuracy: 0.9089\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.8776 - val_accuracy: 0.8571\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.7890 - val_accuracy: 0.8670\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.6325 - val_accuracy: 0.8966\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.6038 - val_accuracy: 0.9113\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5262 - val_accuracy: 0.9187\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.4769 - val_accuracy: 0.8941\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.6479 - val_accuracy: 0.8596\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.4522 - val_accuracy: 0.9089\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.4013 - val_accuracy: 0.9163\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9212\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","52/52 [==============================] - 20s 383ms/step - loss: 4.8539e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9310\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3737 - val_accuracy: 0.9335\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.4089 - val_accuracy: 0.9015\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4346 - val_accuracy: 0.9187\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5032 - val_accuracy: 0.8892\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4163 - val_accuracy: 0.8916\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5110 - val_accuracy: 0.8916\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5071 - val_accuracy: 0.9039\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.9481e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9138\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5213 - val_accuracy: 0.8941\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.9017e-04 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9015\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5424 - val_accuracy: 0.9064\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4844 - val_accuracy: 0.9163\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3847 - val_accuracy: 0.9212\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 20s 383ms/step - loss: 6.2699e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9163\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.4878 - val_accuracy: 0.9187\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4012 - val_accuracy: 0.9286\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.6841 - val_accuracy: 0.8916\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0427 - accuracy: 0.9848 - val_loss: 0.8350 - val_accuracy: 0.8522\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 1.0075 - val_accuracy: 0.8522\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.5889 - val_accuracy: 0.8990\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 1.3912 - val_accuracy: 0.8350\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0635 - accuracy: 0.9811 - val_loss: 0.7748 - val_accuracy: 0.8793\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.5812 - val_accuracy: 0.8867\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0550 - accuracy: 0.9848 - val_loss: 0.6042 - val_accuracy: 0.8916\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.6027 - val_accuracy: 0.8892\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5712 - val_accuracy: 0.9089\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.3823 - val_accuracy: 0.9236\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.8363e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9360\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3810 - val_accuracy: 0.9236\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.5762e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9335\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.3534 - val_accuracy: 0.9286\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9384\n","\n","Epoch 00350: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 351/500\n","52/52 [==============================] - 20s 384ms/step - loss: 6.5693e-04 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9409\n","\n","Epoch 00351: val_accuracy improved from 0.93842 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 352/500\n","52/52 [==============================] - 20s 386ms/step - loss: 4.8394e-04 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9409\n","\n","Epoch 00352: val_accuracy did not improve from 0.94089\n","Epoch 353/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4110 - val_accuracy: 0.9360\n","\n","Epoch 00353: val_accuracy did not improve from 0.94089\n","Epoch 354/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.6845 - val_accuracy: 0.8719\n","\n","Epoch 00354: val_accuracy did not improve from 0.94089\n","Epoch 355/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5089 - val_accuracy: 0.9039\n","\n","Epoch 00355: val_accuracy did not improve from 0.94089\n","Epoch 356/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.6098 - val_accuracy: 0.8867\n","\n","Epoch 00356: val_accuracy did not improve from 0.94089\n","Epoch 357/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.5970 - val_accuracy: 0.8892\n","\n","Epoch 00357: val_accuracy did not improve from 0.94089\n","Epoch 358/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.7082 - val_accuracy: 0.8867\n","\n","Epoch 00358: val_accuracy did not improve from 0.94089\n","Epoch 359/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5494 - val_accuracy: 0.8768\n","\n","Epoch 00359: val_accuracy did not improve from 0.94089\n","Epoch 360/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4968 - val_accuracy: 0.8916\n","\n","Epoch 00360: val_accuracy did not improve from 0.94089\n","Epoch 361/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.4582 - val_accuracy: 0.9138\n","\n","Epoch 00361: val_accuracy did not improve from 0.94089\n","Epoch 362/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5297 - val_accuracy: 0.8916\n","\n","Epoch 00362: val_accuracy did not improve from 0.94089\n","Epoch 363/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9163\n","\n","Epoch 00363: val_accuracy did not improve from 0.94089\n","Epoch 364/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4660 - val_accuracy: 0.8941\n","\n","Epoch 00364: val_accuracy did not improve from 0.94089\n","Epoch 365/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.8611e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9286\n","\n","Epoch 00365: val_accuracy did not improve from 0.94089\n","Epoch 366/500\n","52/52 [==============================] - 20s 384ms/step - loss: 4.6055e-04 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9286\n","\n","Epoch 00366: val_accuracy did not improve from 0.94089\n","Epoch 367/500\n","52/52 [==============================] - 20s 383ms/step - loss: 3.2324e-04 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9384\n","\n","Epoch 00367: val_accuracy did not improve from 0.94089\n","Epoch 368/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3326 - val_accuracy: 0.9483\n","\n","Epoch 00368: val_accuracy improved from 0.94089 to 0.94828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5\n","Epoch 369/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.5282 - val_accuracy: 0.8892\n","\n","Epoch 00369: val_accuracy did not improve from 0.94828\n","Epoch 370/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.3656 - val_accuracy: 0.9286\n","\n","Epoch 00370: val_accuracy did not improve from 0.94828\n","Epoch 371/500\n","52/52 [==============================] - 21s 398ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.4467 - val_accuracy: 0.9039\n","\n","Epoch 00371: val_accuracy did not improve from 0.94828\n","Epoch 372/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5113 - val_accuracy: 0.8892\n","\n","Epoch 00372: val_accuracy did not improve from 0.94828\n","Epoch 373/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0328 - accuracy: 0.9927 - val_loss: 0.7093 - val_accuracy: 0.8744\n","\n","Epoch 00373: val_accuracy did not improve from 0.94828\n","Epoch 374/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0127 - accuracy: 0.9939 - val_loss: 0.6714 - val_accuracy: 0.8916\n","\n","Epoch 00374: val_accuracy did not improve from 0.94828\n","Epoch 375/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5212 - val_accuracy: 0.9039\n","\n","Epoch 00375: val_accuracy did not improve from 0.94828\n","Epoch 376/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.5617 - val_accuracy: 0.8990\n","\n","Epoch 00376: val_accuracy did not improve from 0.94828\n","Epoch 377/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.6223 - val_accuracy: 0.9089\n","\n","Epoch 00377: val_accuracy did not improve from 0.94828\n","Epoch 378/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.4608 - val_accuracy: 0.9064\n","\n","Epoch 00378: val_accuracy did not improve from 0.94828\n","Epoch 379/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.4747 - val_accuracy: 0.9138\n","\n","Epoch 00379: val_accuracy did not improve from 0.94828\n","Epoch 380/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4650 - val_accuracy: 0.9261\n","\n","Epoch 00380: val_accuracy did not improve from 0.94828\n","Epoch 381/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4374 - val_accuracy: 0.9163\n","\n","Epoch 00381: val_accuracy did not improve from 0.94828\n","Epoch 382/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9261\n","\n","Epoch 00382: val_accuracy did not improve from 0.94828\n","Epoch 383/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4669 - val_accuracy: 0.9212\n","\n","Epoch 00383: val_accuracy did not improve from 0.94828\n","Epoch 384/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4308 - val_accuracy: 0.9187\n","\n","Epoch 00384: val_accuracy did not improve from 0.94828\n","Epoch 385/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3642 - val_accuracy: 0.9286\n","\n","Epoch 00385: val_accuracy did not improve from 0.94828\n","Epoch 386/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.0402e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9310\n","\n","Epoch 00386: val_accuracy did not improve from 0.94828\n","Epoch 387/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.9966e-04 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.9212\n","\n","Epoch 00387: val_accuracy did not improve from 0.94828\n","Epoch 388/500\n","52/52 [==============================] - 20s 384ms/step - loss: 4.1095e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9433\n","\n","Epoch 00388: val_accuracy did not improve from 0.94828\n","Epoch 389/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.3496e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9310\n","\n","Epoch 00389: val_accuracy did not improve from 0.94828\n","Epoch 390/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.7805e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9113\n","\n","Epoch 00390: val_accuracy did not improve from 0.94828\n","Epoch 391/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4086 - val_accuracy: 0.9236\n","\n","Epoch 00391: val_accuracy did not improve from 0.94828\n","Epoch 392/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4864 - val_accuracy: 0.9212\n","\n","Epoch 00392: val_accuracy did not improve from 0.94828\n","Epoch 393/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5863 - val_accuracy: 0.9064\n","\n","Epoch 00393: val_accuracy did not improve from 0.94828\n","Epoch 394/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 1.2881 - val_accuracy: 0.8276\n","\n","Epoch 00394: val_accuracy did not improve from 0.94828\n","Epoch 395/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.5960 - val_accuracy: 0.8842\n","\n","Epoch 00395: val_accuracy did not improve from 0.94828\n","Epoch 396/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4923 - val_accuracy: 0.8990\n","\n","Epoch 00396: val_accuracy did not improve from 0.94828\n","Epoch 397/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4955 - val_accuracy: 0.9187\n","\n","Epoch 00397: val_accuracy did not improve from 0.94828\n","Epoch 398/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0144 - accuracy: 0.9982 - val_loss: 0.6917 - val_accuracy: 0.8916\n","\n","Epoch 00398: val_accuracy did not improve from 0.94828\n","Epoch 399/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5036 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.94828\n","Epoch 400/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.5346 - val_accuracy: 0.9138\n","\n","Epoch 00400: val_accuracy did not improve from 0.94828\n","Epoch 401/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9113\n","\n","Epoch 00401: val_accuracy did not improve from 0.94828\n","Epoch 402/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.3057e-04 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9138\n","\n","Epoch 00402: val_accuracy did not improve from 0.94828\n","Epoch 403/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.9249e-04 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.9064\n","\n","Epoch 00403: val_accuracy did not improve from 0.94828\n","Epoch 404/500\n","52/52 [==============================] - 20s 383ms/step - loss: 5.6170e-04 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9236\n","\n","Epoch 00404: val_accuracy did not improve from 0.94828\n","Epoch 405/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.2510e-04 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9163\n","\n","Epoch 00405: val_accuracy did not improve from 0.94828\n","Epoch 406/500\n","52/52 [==============================] - 20s 383ms/step - loss: 3.7800e-04 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9163\n","\n","Epoch 00406: val_accuracy did not improve from 0.94828\n","Epoch 407/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.2174e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9286\n","\n","Epoch 00407: val_accuracy did not improve from 0.94828\n","Epoch 408/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.5300e-04 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9138\n","\n","Epoch 00408: val_accuracy did not improve from 0.94828\n","Epoch 409/500\n","52/52 [==============================] - 20s 382ms/step - loss: 1.5956e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9236\n","\n","Epoch 00409: val_accuracy did not improve from 0.94828\n","Epoch 410/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.0344e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9236\n","\n","Epoch 00410: val_accuracy did not improve from 0.94828\n","Epoch 411/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6805 - val_accuracy: 0.8941\n","\n","Epoch 00411: val_accuracy did not improve from 0.94828\n","Epoch 412/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.6913 - val_accuracy: 0.8719\n","\n","Epoch 00412: val_accuracy did not improve from 0.94828\n","Epoch 413/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.7880 - val_accuracy: 0.8842\n","\n","Epoch 00413: val_accuracy did not improve from 0.94828\n","Epoch 414/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.7061 - val_accuracy: 0.8670\n","\n","Epoch 00414: val_accuracy did not improve from 0.94828\n","Epoch 415/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 1.1542 - val_accuracy: 0.8399\n","\n","Epoch 00415: val_accuracy did not improve from 0.94828\n","Epoch 416/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.6394 - val_accuracy: 0.9064\n","\n","Epoch 00416: val_accuracy did not improve from 0.94828\n","Epoch 417/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0185 - accuracy: 0.9921 - val_loss: 0.6245 - val_accuracy: 0.8941\n","\n","Epoch 00417: val_accuracy did not improve from 0.94828\n","Epoch 418/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.5277 - val_accuracy: 0.8966\n","\n","Epoch 00418: val_accuracy did not improve from 0.94828\n","Epoch 419/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.6689 - val_accuracy: 0.8818\n","\n","Epoch 00419: val_accuracy did not improve from 0.94828\n","Epoch 420/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 0.7133 - val_accuracy: 0.8916\n","\n","Epoch 00420: val_accuracy did not improve from 0.94828\n","Epoch 421/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.5595 - val_accuracy: 0.8941\n","\n","Epoch 00421: val_accuracy did not improve from 0.94828\n","Epoch 422/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.4394 - val_accuracy: 0.9113\n","\n","Epoch 00422: val_accuracy did not improve from 0.94828\n","Epoch 423/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.5410 - val_accuracy: 0.8990\n","\n","Epoch 00423: val_accuracy did not improve from 0.94828\n","Epoch 424/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5303 - val_accuracy: 0.8916\n","\n","Epoch 00424: val_accuracy did not improve from 0.94828\n","Epoch 425/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0119 - accuracy: 0.9945 - val_loss: 0.5499 - val_accuracy: 0.8768\n","\n","Epoch 00425: val_accuracy did not improve from 0.94828\n","Epoch 426/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4350 - val_accuracy: 0.9015\n","\n","Epoch 00426: val_accuracy did not improve from 0.94828\n","Epoch 427/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3886 - val_accuracy: 0.8990\n","\n","Epoch 00427: val_accuracy did not improve from 0.94828\n","Epoch 428/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4160 - val_accuracy: 0.9138\n","\n","Epoch 00428: val_accuracy did not improve from 0.94828\n","Epoch 429/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5862 - val_accuracy: 0.8916\n","\n","Epoch 00429: val_accuracy did not improve from 0.94828\n","Epoch 430/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4393 - val_accuracy: 0.9236\n","\n","Epoch 00430: val_accuracy did not improve from 0.94828\n","Epoch 431/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5336 - val_accuracy: 0.9089\n","\n","Epoch 00431: val_accuracy did not improve from 0.94828\n","Epoch 432/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4606 - val_accuracy: 0.9163\n","\n","Epoch 00432: val_accuracy did not improve from 0.94828\n","Epoch 433/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5135 - val_accuracy: 0.9064\n","\n","Epoch 00433: val_accuracy did not improve from 0.94828\n","Epoch 434/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5959 - val_accuracy: 0.8990\n","\n","Epoch 00434: val_accuracy did not improve from 0.94828\n","Epoch 435/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.4802 - val_accuracy: 0.9212\n","\n","Epoch 00435: val_accuracy did not improve from 0.94828\n","Epoch 436/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.7768 - val_accuracy: 0.8916\n","\n","Epoch 00436: val_accuracy did not improve from 0.94828\n","Epoch 437/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.7049 - val_accuracy: 0.8916\n","\n","Epoch 00437: val_accuracy did not improve from 0.94828\n","Epoch 438/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4911 - val_accuracy: 0.9015\n","\n","Epoch 00438: val_accuracy did not improve from 0.94828\n","Epoch 439/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9089\n","\n","Epoch 00439: val_accuracy did not improve from 0.94828\n","Epoch 440/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4092 - val_accuracy: 0.9138\n","\n","Epoch 00440: val_accuracy did not improve from 0.94828\n","Epoch 441/500\n","52/52 [==============================] - 20s 383ms/step - loss: 6.0870e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9187\n","\n","Epoch 00441: val_accuracy did not improve from 0.94828\n","Epoch 442/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5617 - val_accuracy: 0.9039\n","\n","Epoch 00442: val_accuracy did not improve from 0.94828\n","Epoch 443/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9360\n","\n","Epoch 00443: val_accuracy did not improve from 0.94828\n","Epoch 444/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.3807e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9212\n","\n","Epoch 00444: val_accuracy did not improve from 0.94828\n","Epoch 445/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5860 - val_accuracy: 0.9163\n","\n","Epoch 00445: val_accuracy did not improve from 0.94828\n","Epoch 446/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4465 - val_accuracy: 0.9236\n","\n","Epoch 00446: val_accuracy did not improve from 0.94828\n","Epoch 447/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6365 - val_accuracy: 0.8867\n","\n","Epoch 00447: val_accuracy did not improve from 0.94828\n","Epoch 448/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.9276 - val_accuracy: 0.8645\n","\n","Epoch 00448: val_accuracy did not improve from 0.94828\n","Epoch 449/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 0.6305 - val_accuracy: 0.9015\n","\n","Epoch 00449: val_accuracy did not improve from 0.94828\n","Epoch 450/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5466 - val_accuracy: 0.8892\n","\n","Epoch 00450: val_accuracy did not improve from 0.94828\n","Epoch 451/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.6158 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.94828\n","Epoch 452/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5276 - val_accuracy: 0.9113\n","\n","Epoch 00452: val_accuracy did not improve from 0.94828\n","Epoch 453/500\n","52/52 [==============================] - 20s 381ms/step - loss: 8.4546e-04 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.94828\n","Epoch 454/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5912 - val_accuracy: 0.9064\n","\n","Epoch 00454: val_accuracy did not improve from 0.94828\n","Epoch 455/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5023 - val_accuracy: 0.9089\n","\n","Epoch 00455: val_accuracy did not improve from 0.94828\n","Epoch 456/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4546 - val_accuracy: 0.9286\n","\n","Epoch 00456: val_accuracy did not improve from 0.94828\n","Epoch 457/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4166 - val_accuracy: 0.9261\n","\n","Epoch 00457: val_accuracy did not improve from 0.94828\n","Epoch 458/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4931 - val_accuracy: 0.9335\n","\n","Epoch 00458: val_accuracy did not improve from 0.94828\n","Epoch 459/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4504 - val_accuracy: 0.9212\n","\n","Epoch 00459: val_accuracy did not improve from 0.94828\n","Epoch 460/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.7096 - val_accuracy: 0.8966\n","\n","Epoch 00460: val_accuracy did not improve from 0.94828\n","Epoch 461/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5079 - val_accuracy: 0.9113\n","\n","Epoch 00461: val_accuracy did not improve from 0.94828\n","Epoch 462/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.5909 - val_accuracy: 0.9064\n","\n","Epoch 00462: val_accuracy did not improve from 0.94828\n","Epoch 463/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.9512 - val_accuracy: 0.8473\n","\n","Epoch 00463: val_accuracy did not improve from 0.94828\n","Epoch 464/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.6089 - val_accuracy: 0.9064\n","\n","Epoch 00464: val_accuracy did not improve from 0.94828\n","Epoch 465/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.3924 - val_accuracy: 0.9212\n","\n","Epoch 00465: val_accuracy did not improve from 0.94828\n","Epoch 466/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4175 - val_accuracy: 0.9310\n","\n","Epoch 00466: val_accuracy did not improve from 0.94828\n","Epoch 467/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.2919e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9286\n","\n","Epoch 00467: val_accuracy did not improve from 0.94828\n","Epoch 468/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4028 - val_accuracy: 0.9261\n","\n","Epoch 00468: val_accuracy did not improve from 0.94828\n","Epoch 469/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.5141 - val_accuracy: 0.9138\n","\n","Epoch 00469: val_accuracy did not improve from 0.94828\n","Epoch 470/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6530 - val_accuracy: 0.8867\n","\n","Epoch 00470: val_accuracy did not improve from 0.94828\n","Epoch 471/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.7924 - val_accuracy: 0.7241\n","\n","Epoch 00471: val_accuracy did not improve from 0.94828\n","Epoch 472/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.6894 - val_accuracy: 0.8966\n","\n","Epoch 00472: val_accuracy did not improve from 0.94828\n","Epoch 473/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0239 - accuracy: 0.9951 - val_loss: 0.7501 - val_accuracy: 0.9039\n","\n","Epoch 00473: val_accuracy did not improve from 0.94828\n","Epoch 474/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.7045 - val_accuracy: 0.8842\n","\n","Epoch 00474: val_accuracy did not improve from 0.94828\n","Epoch 475/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4571 - val_accuracy: 0.9187\n","\n","Epoch 00475: val_accuracy did not improve from 0.94828\n","Epoch 476/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 1.3286 - val_accuracy: 0.8522\n","\n","Epoch 00476: val_accuracy did not improve from 0.94828\n","Epoch 477/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.6158 - val_accuracy: 0.9039\n","\n","Epoch 00477: val_accuracy did not improve from 0.94828\n","Epoch 478/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5410 - val_accuracy: 0.9089\n","\n","Epoch 00478: val_accuracy did not improve from 0.94828\n","Epoch 479/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5368 - val_accuracy: 0.9261\n","\n","Epoch 00479: val_accuracy did not improve from 0.94828\n","Epoch 480/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5382 - val_accuracy: 0.9089\n","\n","Epoch 00480: val_accuracy did not improve from 0.94828\n","Epoch 481/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4703 - val_accuracy: 0.9064\n","\n","Epoch 00481: val_accuracy did not improve from 0.94828\n","Epoch 482/500\n","52/52 [==============================] - 20s 382ms/step - loss: 5.7221e-04 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9286\n","\n","Epoch 00482: val_accuracy did not improve from 0.94828\n","Epoch 483/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9163\n","\n","Epoch 00483: val_accuracy did not improve from 0.94828\n","Epoch 484/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5136 - val_accuracy: 0.9138\n","\n","Epoch 00484: val_accuracy did not improve from 0.94828\n","Epoch 485/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5326 - val_accuracy: 0.9015\n","\n","Epoch 00485: val_accuracy did not improve from 0.94828\n","Epoch 486/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5309 - val_accuracy: 0.9113\n","\n","Epoch 00486: val_accuracy did not improve from 0.94828\n","Epoch 487/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.6860 - val_accuracy: 0.8867\n","\n","Epoch 00487: val_accuracy did not improve from 0.94828\n","Epoch 488/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.7045 - val_accuracy: 0.9064\n","\n","Epoch 00488: val_accuracy did not improve from 0.94828\n","Epoch 489/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5938 - val_accuracy: 0.9113\n","\n","Epoch 00489: val_accuracy did not improve from 0.94828\n","Epoch 490/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9138\n","\n","Epoch 00490: val_accuracy did not improve from 0.94828\n","Epoch 491/500\n","52/52 [==============================] - 20s 382ms/step - loss: 4.9056e-04 - accuracy: 1.0000 - val_loss: 0.5754 - val_accuracy: 0.9138\n","\n","Epoch 00491: val_accuracy did not improve from 0.94828\n","Epoch 492/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.6226e-04 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.9089\n","\n","Epoch 00492: val_accuracy did not improve from 0.94828\n","Epoch 493/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5860 - val_accuracy: 0.9089\n","\n","Epoch 00493: val_accuracy did not improve from 0.94828\n","Epoch 494/500\n","52/52 [==============================] - 20s 383ms/step - loss: 8.8498e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.94828\n","Epoch 495/500\n","52/52 [==============================] - 20s 382ms/step - loss: 6.6701e-04 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.9089\n","\n","Epoch 00495: val_accuracy did not improve from 0.94828\n","Epoch 496/500\n","52/52 [==============================] - 20s 383ms/step - loss: 4.0286e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9064\n","\n","Epoch 00496: val_accuracy did not improve from 0.94828\n","Epoch 497/500\n","52/52 [==============================] - 20s 382ms/step - loss: 2.9407e-04 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9089\n","\n","Epoch 00497: val_accuracy did not improve from 0.94828\n","Epoch 498/500\n","52/52 [==============================] - 20s 385ms/step - loss: 7.7084e-05 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8966\n","\n","Epoch 00498: val_accuracy did not improve from 0.94828\n","Epoch 499/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.0687e-04 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.9138\n","\n","Epoch 00499: val_accuracy did not improve from 0.94828\n","Epoch 500/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5811 - val_accuracy: 0.9187\n","\n","Epoch 00500: val_accuracy did not improve from 0.94828\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb685ee0950>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630523217460,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b9d95a70-32fe-4478-e71b-0a8aadb82907"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630523230946,"user_tz":-540,"elapsed":13177,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_3_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-"},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630523288201,"user_tz":-540,"elapsed":56001,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"63ac40f6-2c22-43fe-ab50-5293f343329a"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK"},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630523289410,"user_tz":-540,"elapsed":2,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630523301844,"user_tz":-540,"elapsed":12435,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630523304931,"user_tz":-540,"elapsed":191,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7a02953c-de8b-4b72-f913-9f8f46b8a1e2"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_3_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_3_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_c019bd31-bdc2-4357-aa46-a7c300c3479a\", \"HeightShiftRange_010_3_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}]}]}