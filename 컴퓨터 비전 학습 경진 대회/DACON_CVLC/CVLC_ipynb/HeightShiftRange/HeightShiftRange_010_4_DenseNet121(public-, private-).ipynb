{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HeightShiftRange_010_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPfZrZhhT22dvbfLLTrOcty"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630516233344,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f9d8d71b-9e80-4b45-fe0b-48062062ac91"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep  1 17:10:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630516252533,"user_tz":-540,"elapsed":19193,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b19bf886-49b1-463d-9008-656e12f3fb95"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630516255430,"user_tz":-540,"elapsed":2903,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630516256721,"user_tz":-540,"elapsed":1305,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630516258977,"user_tz":-540,"elapsed":2260,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630516275767,"user_tz":-540,"elapsed":16792,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630516282719,"user_tz":-540,"elapsed":6955,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630516282720,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ffd53190-3166-4d1a-d01d-a448c719c340"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630516282720,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"420b7cdc-6fbc-4a0a-b82f-b45048858add"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630516282721,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630521850480,"user_tz":-540,"elapsed":5567769,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"aa71e6c9-0bec-4bc6-ee51-65227e556a58"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 38s 257ms/step - loss: 2.0171 - accuracy: 0.2759 - val_loss: 3.9697 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.2639 - accuracy: 0.5639 - val_loss: 8.7484 - val_accuracy: 0.0517\n","\n","Epoch 00002: val_accuracy did not improve from 0.09852\n","Epoch 3/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.0048 - accuracy: 0.6577 - val_loss: 5.8508 - val_accuracy: 0.0862\n","\n","Epoch 00003: val_accuracy did not improve from 0.09852\n","Epoch 4/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.8832 - accuracy: 0.6985 - val_loss: 6.2202 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.09852\n","Epoch 5/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.7518 - accuracy: 0.7448 - val_loss: 3.2753 - val_accuracy: 0.1502\n","\n","Epoch 00005: val_accuracy improved from 0.09852 to 0.15025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.6681 - accuracy: 0.7631 - val_loss: 6.6374 - val_accuracy: 0.2069\n","\n","Epoch 00006: val_accuracy improved from 0.15025 to 0.20690, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.6054 - accuracy: 0.8015 - val_loss: 4.6035 - val_accuracy: 0.1749\n","\n","Epoch 00007: val_accuracy did not improve from 0.20690\n","Epoch 8/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.5975 - accuracy: 0.7923 - val_loss: 2.1014 - val_accuracy: 0.4335\n","\n","Epoch 00008: val_accuracy improved from 0.20690 to 0.43350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.5078 - accuracy: 0.8167 - val_loss: 2.8358 - val_accuracy: 0.3596\n","\n","Epoch 00009: val_accuracy did not improve from 0.43350\n","Epoch 10/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.5070 - accuracy: 0.8289 - val_loss: 1.1220 - val_accuracy: 0.6847\n","\n","Epoch 00010: val_accuracy improved from 0.43350 to 0.68473, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4344 - accuracy: 0.8551 - val_loss: 0.7926 - val_accuracy: 0.7537\n","\n","Epoch 00011: val_accuracy improved from 0.68473 to 0.75369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3774 - accuracy: 0.8660 - val_loss: 0.9142 - val_accuracy: 0.7586\n","\n","Epoch 00012: val_accuracy improved from 0.75369 to 0.75862, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.3746 - accuracy: 0.8721 - val_loss: 1.0458 - val_accuracy: 0.7241\n","\n","Epoch 00013: val_accuracy did not improve from 0.75862\n","Epoch 14/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3342 - accuracy: 0.8849 - val_loss: 0.6967 - val_accuracy: 0.7956\n","\n","Epoch 00014: val_accuracy improved from 0.75862 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.3433 - accuracy: 0.8819 - val_loss: 3.8242 - val_accuracy: 0.3621\n","\n","Epoch 00015: val_accuracy did not improve from 0.79557\n","Epoch 16/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.3299 - accuracy: 0.8922 - val_loss: 1.1345 - val_accuracy: 0.6897\n","\n","Epoch 00016: val_accuracy did not improve from 0.79557\n","Epoch 17/500\n","52/52 [==============================] - 11s 203ms/step - loss: 0.3481 - accuracy: 0.8770 - val_loss: 0.9928 - val_accuracy: 0.7512\n","\n","Epoch 00017: val_accuracy did not improve from 0.79557\n","Epoch 18/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3143 - accuracy: 0.8916 - val_loss: 1.2394 - val_accuracy: 0.6995\n","\n","Epoch 00018: val_accuracy did not improve from 0.79557\n","Epoch 19/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2486 - accuracy: 0.9135 - val_loss: 0.6434 - val_accuracy: 0.8227\n","\n","Epoch 00019: val_accuracy improved from 0.79557 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2852 - accuracy: 0.9044 - val_loss: 0.8005 - val_accuracy: 0.7956\n","\n","Epoch 00020: val_accuracy did not improve from 0.82266\n","Epoch 21/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2380 - accuracy: 0.9202 - val_loss: 0.8414 - val_accuracy: 0.7906\n","\n","Epoch 00021: val_accuracy did not improve from 0.82266\n","Epoch 22/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1983 - accuracy: 0.9318 - val_loss: 0.8002 - val_accuracy: 0.8079\n","\n","Epoch 00022: val_accuracy did not improve from 0.82266\n","Epoch 23/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2224 - accuracy: 0.9190 - val_loss: 0.4966 - val_accuracy: 0.8621\n","\n","Epoch 00023: val_accuracy improved from 0.82266 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2194 - accuracy: 0.9220 - val_loss: 0.7348 - val_accuracy: 0.8054\n","\n","Epoch 00024: val_accuracy did not improve from 0.86207\n","Epoch 25/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1632 - accuracy: 0.9391 - val_loss: 0.5070 - val_accuracy: 0.8645\n","\n","Epoch 00025: val_accuracy improved from 0.86207 to 0.86453, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1744 - accuracy: 0.9440 - val_loss: 0.5675 - val_accuracy: 0.8473\n","\n","Epoch 00026: val_accuracy did not improve from 0.86453\n","Epoch 27/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1942 - accuracy: 0.9312 - val_loss: 0.9039 - val_accuracy: 0.7734\n","\n","Epoch 00027: val_accuracy did not improve from 0.86453\n","Epoch 28/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2318 - accuracy: 0.9153 - val_loss: 0.6530 - val_accuracy: 0.8276\n","\n","Epoch 00028: val_accuracy did not improve from 0.86453\n","Epoch 29/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1704 - accuracy: 0.9409 - val_loss: 1.0609 - val_accuracy: 0.7611\n","\n","Epoch 00029: val_accuracy did not improve from 0.86453\n","Epoch 30/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1554 - accuracy: 0.9476 - val_loss: 0.6938 - val_accuracy: 0.7980\n","\n","Epoch 00030: val_accuracy did not improve from 0.86453\n","Epoch 31/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2033 - accuracy: 0.9379 - val_loss: 0.8501 - val_accuracy: 0.7956\n","\n","Epoch 00031: val_accuracy did not improve from 0.86453\n","Epoch 32/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.2464 - accuracy: 0.9184 - val_loss: 0.9488 - val_accuracy: 0.7685\n","\n","Epoch 00032: val_accuracy did not improve from 0.86453\n","Epoch 33/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1754 - accuracy: 0.9403 - val_loss: 0.4478 - val_accuracy: 0.8744\n","\n","Epoch 00033: val_accuracy improved from 0.86453 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 34/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1943 - accuracy: 0.9361 - val_loss: 1.1433 - val_accuracy: 0.7537\n","\n","Epoch 00034: val_accuracy did not improve from 0.87438\n","Epoch 35/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1667 - accuracy: 0.9495 - val_loss: 0.5113 - val_accuracy: 0.8621\n","\n","Epoch 00035: val_accuracy did not improve from 0.87438\n","Epoch 36/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1417 - accuracy: 0.9568 - val_loss: 0.6140 - val_accuracy: 0.8399\n","\n","Epoch 00036: val_accuracy did not improve from 0.87438\n","Epoch 37/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1172 - accuracy: 0.9622 - val_loss: 0.8335 - val_accuracy: 0.7980\n","\n","Epoch 00037: val_accuracy did not improve from 0.87438\n","Epoch 38/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1499 - accuracy: 0.9488 - val_loss: 0.6337 - val_accuracy: 0.8399\n","\n","Epoch 00038: val_accuracy did not improve from 0.87438\n","Epoch 39/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1512 - accuracy: 0.9458 - val_loss: 0.6269 - val_accuracy: 0.8399\n","\n","Epoch 00039: val_accuracy did not improve from 0.87438\n","Epoch 40/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1045 - accuracy: 0.9659 - val_loss: 0.4520 - val_accuracy: 0.8719\n","\n","Epoch 00040: val_accuracy did not improve from 0.87438\n","Epoch 41/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1088 - accuracy: 0.9665 - val_loss: 0.4336 - val_accuracy: 0.8818\n","\n","Epoch 00041: val_accuracy improved from 0.87438 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 42/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0819 - accuracy: 0.9732 - val_loss: 0.4452 - val_accuracy: 0.8793\n","\n","Epoch 00042: val_accuracy did not improve from 0.88177\n","Epoch 43/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0829 - accuracy: 0.9720 - val_loss: 0.4431 - val_accuracy: 0.8842\n","\n","Epoch 00043: val_accuracy improved from 0.88177 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 44/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 0.4785 - val_accuracy: 0.8719\n","\n","Epoch 00044: val_accuracy did not improve from 0.88424\n","Epoch 45/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0767 - accuracy: 0.9775 - val_loss: 0.6531 - val_accuracy: 0.8325\n","\n","Epoch 00045: val_accuracy did not improve from 0.88424\n","Epoch 46/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0918 - accuracy: 0.9714 - val_loss: 0.5024 - val_accuracy: 0.8768\n","\n","Epoch 00046: val_accuracy did not improve from 0.88424\n","Epoch 47/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1461 - accuracy: 0.9495 - val_loss: 0.4846 - val_accuracy: 0.8670\n","\n","Epoch 00047: val_accuracy did not improve from 0.88424\n","Epoch 48/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0932 - accuracy: 0.9689 - val_loss: 1.0929 - val_accuracy: 0.8030\n","\n","Epoch 00048: val_accuracy did not improve from 0.88424\n","Epoch 49/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1515 - accuracy: 0.9458 - val_loss: 0.7955 - val_accuracy: 0.7956\n","\n","Epoch 00049: val_accuracy did not improve from 0.88424\n","Epoch 50/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1470 - accuracy: 0.9531 - val_loss: 0.5699 - val_accuracy: 0.8350\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.4239 - val_accuracy: 0.8842\n","\n","Epoch 00051: val_accuracy did not improve from 0.88424\n","Epoch 52/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.5584 - val_accuracy: 0.8744\n","\n","Epoch 00052: val_accuracy did not improve from 0.88424\n","Epoch 53/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0764 - accuracy: 0.9750 - val_loss: 1.0776 - val_accuracy: 0.7931\n","\n","Epoch 00053: val_accuracy did not improve from 0.88424\n","Epoch 54/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1067 - accuracy: 0.9641 - val_loss: 0.9593 - val_accuracy: 0.8054\n","\n","Epoch 00054: val_accuracy did not improve from 0.88424\n","Epoch 55/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1252 - accuracy: 0.9531 - val_loss: 0.7695 - val_accuracy: 0.8374\n","\n","Epoch 00055: val_accuracy did not improve from 0.88424\n","Epoch 56/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.7758 - val_accuracy: 0.8177\n","\n","Epoch 00056: val_accuracy did not improve from 0.88424\n","Epoch 57/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.4996 - val_accuracy: 0.8719\n","\n","Epoch 00057: val_accuracy did not improve from 0.88424\n","Epoch 58/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0480 - accuracy: 0.9817 - val_loss: 0.3933 - val_accuracy: 0.9015\n","\n","Epoch 00058: val_accuracy improved from 0.88424 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 59/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0603 - accuracy: 0.9799 - val_loss: 0.5444 - val_accuracy: 0.8547\n","\n","Epoch 00059: val_accuracy did not improve from 0.90148\n","Epoch 60/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0768 - accuracy: 0.9714 - val_loss: 0.5641 - val_accuracy: 0.8768\n","\n","Epoch 00060: val_accuracy did not improve from 0.90148\n","Epoch 61/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1094 - accuracy: 0.9641 - val_loss: 0.8960 - val_accuracy: 0.7980\n","\n","Epoch 00061: val_accuracy did not improve from 0.90148\n","Epoch 62/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0908 - accuracy: 0.9689 - val_loss: 0.7188 - val_accuracy: 0.8350\n","\n","Epoch 00062: val_accuracy did not improve from 0.90148\n","Epoch 63/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.4482 - val_accuracy: 0.8892\n","\n","Epoch 00063: val_accuracy did not improve from 0.90148\n","Epoch 64/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0651 - accuracy: 0.9811 - val_loss: 0.5868 - val_accuracy: 0.8571\n","\n","Epoch 00064: val_accuracy did not improve from 0.90148\n","Epoch 65/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0847 - accuracy: 0.9720 - val_loss: 0.7314 - val_accuracy: 0.8399\n","\n","Epoch 00065: val_accuracy did not improve from 0.90148\n","Epoch 66/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1245 - accuracy: 0.9586 - val_loss: 0.6216 - val_accuracy: 0.8498\n","\n","Epoch 00066: val_accuracy did not improve from 0.90148\n","Epoch 67/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0950 - accuracy: 0.9641 - val_loss: 0.4956 - val_accuracy: 0.8966\n","\n","Epoch 00067: val_accuracy did not improve from 0.90148\n","Epoch 68/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.5628 - val_accuracy: 0.8695\n","\n","Epoch 00068: val_accuracy did not improve from 0.90148\n","Epoch 69/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.3919 - val_accuracy: 0.9039\n","\n","Epoch 00069: val_accuracy improved from 0.90148 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 70/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.4765 - val_accuracy: 0.8695\n","\n","Epoch 00070: val_accuracy did not improve from 0.90394\n","Epoch 71/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.4163 - val_accuracy: 0.9015\n","\n","Epoch 00071: val_accuracy did not improve from 0.90394\n","Epoch 72/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1057 - accuracy: 0.9616 - val_loss: 0.8240 - val_accuracy: 0.8325\n","\n","Epoch 00072: val_accuracy did not improve from 0.90394\n","Epoch 73/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0993 - accuracy: 0.9702 - val_loss: 0.7840 - val_accuracy: 0.8300\n","\n","Epoch 00073: val_accuracy did not improve from 0.90394\n","Epoch 74/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 0.5146 - val_accuracy: 0.8547\n","\n","Epoch 00074: val_accuracy did not improve from 0.90394\n","Epoch 75/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0577 - accuracy: 0.9787 - val_loss: 0.7398 - val_accuracy: 0.8498\n","\n","Epoch 00075: val_accuracy did not improve from 0.90394\n","Epoch 76/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0537 - accuracy: 0.9817 - val_loss: 0.5601 - val_accuracy: 0.8645\n","\n","Epoch 00076: val_accuracy did not improve from 0.90394\n","Epoch 77/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0494 - accuracy: 0.9805 - val_loss: 0.5571 - val_accuracy: 0.8842\n","\n","Epoch 00077: val_accuracy did not improve from 0.90394\n","Epoch 78/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0559 - accuracy: 0.9817 - val_loss: 0.5717 - val_accuracy: 0.8645\n","\n","Epoch 00078: val_accuracy did not improve from 0.90394\n","Epoch 79/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.7438 - val_accuracy: 0.8596\n","\n","Epoch 00079: val_accuracy did not improve from 0.90394\n","Epoch 80/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1075 - accuracy: 0.9647 - val_loss: 0.7840 - val_accuracy: 0.8350\n","\n","Epoch 00080: val_accuracy did not improve from 0.90394\n","Epoch 81/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0796 - accuracy: 0.9708 - val_loss: 0.7175 - val_accuracy: 0.8621\n","\n","Epoch 00081: val_accuracy did not improve from 0.90394\n","Epoch 82/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0786 - accuracy: 0.9732 - val_loss: 0.5587 - val_accuracy: 0.8768\n","\n","Epoch 00082: val_accuracy did not improve from 0.90394\n","Epoch 83/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0452 - accuracy: 0.9799 - val_loss: 0.6780 - val_accuracy: 0.8448\n","\n","Epoch 00083: val_accuracy did not improve from 0.90394\n","Epoch 84/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.5435 - val_accuracy: 0.9015\n","\n","Epoch 00084: val_accuracy did not improve from 0.90394\n","Epoch 85/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0457 - accuracy: 0.9817 - val_loss: 0.5283 - val_accuracy: 0.8916\n","\n","Epoch 00085: val_accuracy did not improve from 0.90394\n","Epoch 86/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.4451 - val_accuracy: 0.9163\n","\n","Epoch 00086: val_accuracy improved from 0.90394 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 87/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.5515 - val_accuracy: 0.8793\n","\n","Epoch 00087: val_accuracy did not improve from 0.91626\n","Epoch 88/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1043 - accuracy: 0.9622 - val_loss: 0.8205 - val_accuracy: 0.8448\n","\n","Epoch 00088: val_accuracy did not improve from 0.91626\n","Epoch 89/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.7330 - val_accuracy: 0.8350\n","\n","Epoch 00089: val_accuracy did not improve from 0.91626\n","Epoch 90/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.3829 - val_accuracy: 0.9286\n","\n","Epoch 00090: val_accuracy improved from 0.91626 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 91/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.4993 - val_accuracy: 0.8892\n","\n","Epoch 00091: val_accuracy did not improve from 0.92857\n","Epoch 92/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.4057 - val_accuracy: 0.9163\n","\n","Epoch 00092: val_accuracy did not improve from 0.92857\n","Epoch 93/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.5107 - val_accuracy: 0.8768\n","\n","Epoch 00093: val_accuracy did not improve from 0.92857\n","Epoch 94/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.8049 - val_accuracy: 0.8547\n","\n","Epoch 00094: val_accuracy did not improve from 0.92857\n","Epoch 95/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0522 - accuracy: 0.9781 - val_loss: 0.5857 - val_accuracy: 0.8892\n","\n","Epoch 00095: val_accuracy did not improve from 0.92857\n","Epoch 96/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.4687 - val_accuracy: 0.8768\n","\n","Epoch 00096: val_accuracy did not improve from 0.92857\n","Epoch 97/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.7046 - val_accuracy: 0.8645\n","\n","Epoch 00097: val_accuracy did not improve from 0.92857\n","Epoch 98/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1290 - accuracy: 0.9610 - val_loss: 1.7976 - val_accuracy: 0.6970\n","\n","Epoch 00098: val_accuracy did not improve from 0.92857\n","Epoch 99/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0683 - accuracy: 0.9762 - val_loss: 0.6702 - val_accuracy: 0.8522\n","\n","Epoch 00099: val_accuracy did not improve from 0.92857\n","Epoch 100/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0505 - accuracy: 0.9884 - val_loss: 0.5881 - val_accuracy: 0.8719\n","\n","Epoch 00100: val_accuracy did not improve from 0.92857\n","Epoch 101/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.4774 - val_accuracy: 0.8793\n","\n","Epoch 00101: val_accuracy did not improve from 0.92857\n","Epoch 102/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.5563 - val_accuracy: 0.8695\n","\n","Epoch 00102: val_accuracy did not improve from 0.92857\n","Epoch 103/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0271 - accuracy: 0.9927 - val_loss: 0.4514 - val_accuracy: 0.8842\n","\n","Epoch 00103: val_accuracy did not improve from 0.92857\n","Epoch 104/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.4874 - val_accuracy: 0.8892\n","\n","Epoch 00104: val_accuracy did not improve from 0.92857\n","Epoch 105/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.3454 - val_accuracy: 0.9039\n","\n","Epoch 00105: val_accuracy did not improve from 0.92857\n","Epoch 106/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.4434 - val_accuracy: 0.8916\n","\n","Epoch 00106: val_accuracy did not improve from 0.92857\n","Epoch 107/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.9034 - val_accuracy: 0.8103\n","\n","Epoch 00107: val_accuracy did not improve from 0.92857\n","Epoch 108/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0712 - accuracy: 0.9708 - val_loss: 1.2766 - val_accuracy: 0.7537\n","\n","Epoch 00108: val_accuracy did not improve from 0.92857\n","Epoch 109/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0877 - accuracy: 0.9653 - val_loss: 0.6545 - val_accuracy: 0.8547\n","\n","Epoch 00109: val_accuracy did not improve from 0.92857\n","Epoch 110/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9884 - val_loss: 0.4804 - val_accuracy: 0.8941\n","\n","Epoch 00110: val_accuracy did not improve from 0.92857\n","Epoch 111/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.4462 - val_accuracy: 0.8941\n","\n","Epoch 00111: val_accuracy did not improve from 0.92857\n","Epoch 112/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.6200 - val_accuracy: 0.8621\n","\n","Epoch 00112: val_accuracy did not improve from 0.92857\n","Epoch 113/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0559 - accuracy: 0.9842 - val_loss: 0.5749 - val_accuracy: 0.9015\n","\n","Epoch 00113: val_accuracy did not improve from 0.92857\n","Epoch 114/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0245 - accuracy: 0.9903 - val_loss: 0.7439 - val_accuracy: 0.8596\n","\n","Epoch 00114: val_accuracy did not improve from 0.92857\n","Epoch 115/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 1.1363 - val_accuracy: 0.7882\n","\n","Epoch 00115: val_accuracy did not improve from 0.92857\n","Epoch 116/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0561 - accuracy: 0.9836 - val_loss: 1.0283 - val_accuracy: 0.8498\n","\n","Epoch 00116: val_accuracy did not improve from 0.92857\n","Epoch 117/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1206 - accuracy: 0.9647 - val_loss: 0.7497 - val_accuracy: 0.8719\n","\n","Epoch 00117: val_accuracy did not improve from 0.92857\n","Epoch 118/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0581 - accuracy: 0.9787 - val_loss: 0.4594 - val_accuracy: 0.9089\n","\n","Epoch 00118: val_accuracy did not improve from 0.92857\n","Epoch 119/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.4251 - val_accuracy: 0.9113\n","\n","Epoch 00119: val_accuracy did not improve from 0.92857\n","Epoch 120/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.6721 - val_accuracy: 0.8744\n","\n","Epoch 00120: val_accuracy did not improve from 0.92857\n","Epoch 121/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.6683 - val_accuracy: 0.8768\n","\n","Epoch 00121: val_accuracy did not improve from 0.92857\n","Epoch 122/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.5088 - val_accuracy: 0.9064\n","\n","Epoch 00122: val_accuracy did not improve from 0.92857\n","Epoch 123/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4485 - val_accuracy: 0.9113\n","\n","Epoch 00123: val_accuracy did not improve from 0.92857\n","Epoch 124/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4208 - val_accuracy: 0.9163\n","\n","Epoch 00124: val_accuracy did not improve from 0.92857\n","Epoch 125/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4618 - val_accuracy: 0.9310\n","\n","Epoch 00125: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 126/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.6619 - val_accuracy: 0.8793\n","\n","Epoch 00126: val_accuracy did not improve from 0.93103\n","Epoch 127/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.4952 - val_accuracy: 0.8916\n","\n","Epoch 00127: val_accuracy did not improve from 0.93103\n","Epoch 128/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.5282 - val_accuracy: 0.8867\n","\n","Epoch 00128: val_accuracy did not improve from 0.93103\n","Epoch 129/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.6792 - val_accuracy: 0.8621\n","\n","Epoch 00129: val_accuracy did not improve from 0.93103\n","Epoch 130/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.6037 - val_accuracy: 0.8892\n","\n","Epoch 00130: val_accuracy did not improve from 0.93103\n","Epoch 131/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.6472 - val_accuracy: 0.8793\n","\n","Epoch 00131: val_accuracy did not improve from 0.93103\n","Epoch 132/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.5352 - val_accuracy: 0.8744\n","\n","Epoch 00132: val_accuracy did not improve from 0.93103\n","Epoch 133/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 1.1861 - val_accuracy: 0.7488\n","\n","Epoch 00133: val_accuracy did not improve from 0.93103\n","Epoch 134/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.6130 - val_accuracy: 0.8818\n","\n","Epoch 00134: val_accuracy did not improve from 0.93103\n","Epoch 135/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.5257 - val_accuracy: 0.8990\n","\n","Epoch 00135: val_accuracy did not improve from 0.93103\n","Epoch 136/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0603 - accuracy: 0.9732 - val_loss: 0.8044 - val_accuracy: 0.8645\n","\n","Epoch 00136: val_accuracy did not improve from 0.93103\n","Epoch 137/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0404 - accuracy: 0.9848 - val_loss: 0.7483 - val_accuracy: 0.8202\n","\n","Epoch 00137: val_accuracy did not improve from 0.93103\n","Epoch 138/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0335 - accuracy: 0.9927 - val_loss: 2.5121 - val_accuracy: 0.6749\n","\n","Epoch 00138: val_accuracy did not improve from 0.93103\n","Epoch 139/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.5910 - val_accuracy: 0.8892\n","\n","Epoch 00139: val_accuracy did not improve from 0.93103\n","Epoch 140/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.6081 - val_accuracy: 0.8818\n","\n","Epoch 00140: val_accuracy did not improve from 0.93103\n","Epoch 141/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.6192 - val_accuracy: 0.8695\n","\n","Epoch 00141: val_accuracy did not improve from 0.93103\n","Epoch 142/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.6185 - val_accuracy: 0.8547\n","\n","Epoch 00142: val_accuracy did not improve from 0.93103\n","Epoch 143/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0207 - accuracy: 0.9909 - val_loss: 0.5407 - val_accuracy: 0.8966\n","\n","Epoch 00143: val_accuracy did not improve from 0.93103\n","Epoch 144/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4878 - val_accuracy: 0.9138\n","\n","Epoch 00144: val_accuracy did not improve from 0.93103\n","Epoch 145/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.4985 - val_accuracy: 0.8990\n","\n","Epoch 00145: val_accuracy did not improve from 0.93103\n","Epoch 146/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.5331 - val_accuracy: 0.9089\n","\n","Epoch 00146: val_accuracy did not improve from 0.93103\n","Epoch 147/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4141 - val_accuracy: 0.9187\n","\n","Epoch 00147: val_accuracy did not improve from 0.93103\n","Epoch 148/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5916 - val_accuracy: 0.9015\n","\n","Epoch 00148: val_accuracy did not improve from 0.93103\n","Epoch 149/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.6353 - val_accuracy: 0.8670\n","\n","Epoch 00149: val_accuracy did not improve from 0.93103\n","Epoch 150/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.7064 - val_accuracy: 0.8571\n","\n","Epoch 00150: val_accuracy did not improve from 0.93103\n","Epoch 151/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.6396 - val_accuracy: 0.8719\n","\n","Epoch 00151: val_accuracy did not improve from 0.93103\n","Epoch 152/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0169 - accuracy: 0.9927 - val_loss: 0.5851 - val_accuracy: 0.8596\n","\n","Epoch 00152: val_accuracy did not improve from 0.93103\n","Epoch 153/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0292 - accuracy: 0.9890 - val_loss: 0.9916 - val_accuracy: 0.8473\n","\n","Epoch 00153: val_accuracy did not improve from 0.93103\n","Epoch 154/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0401 - accuracy: 0.9860 - val_loss: 0.5982 - val_accuracy: 0.8793\n","\n","Epoch 00154: val_accuracy did not improve from 0.93103\n","Epoch 155/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.7048 - val_accuracy: 0.8522\n","\n","Epoch 00155: val_accuracy did not improve from 0.93103\n","Epoch 156/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0550 - accuracy: 0.9842 - val_loss: 1.0180 - val_accuracy: 0.8596\n","\n","Epoch 00156: val_accuracy did not improve from 0.93103\n","Epoch 157/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.4624 - val_accuracy: 0.8941\n","\n","Epoch 00157: val_accuracy did not improve from 0.93103\n","Epoch 158/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.6331 - val_accuracy: 0.8498\n","\n","Epoch 00158: val_accuracy did not improve from 0.93103\n","Epoch 159/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.9809 - val_accuracy: 0.7980\n","\n","Epoch 00159: val_accuracy did not improve from 0.93103\n","Epoch 160/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 1.0984 - val_accuracy: 0.8054\n","\n","Epoch 00160: val_accuracy did not improve from 0.93103\n","Epoch 161/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.8132 - val_accuracy: 0.8621\n","\n","Epoch 00161: val_accuracy did not improve from 0.93103\n","Epoch 162/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5280 - val_accuracy: 0.9064\n","\n","Epoch 00162: val_accuracy did not improve from 0.93103\n","Epoch 163/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.7061 - val_accuracy: 0.8571\n","\n","Epoch 00163: val_accuracy did not improve from 0.93103\n","Epoch 164/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 1.0065 - val_accuracy: 0.7980\n","\n","Epoch 00164: val_accuracy did not improve from 0.93103\n","Epoch 165/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1207 - accuracy: 0.9629 - val_loss: 1.3902 - val_accuracy: 0.8177\n","\n","Epoch 00165: val_accuracy did not improve from 0.93103\n","Epoch 166/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.5679 - val_accuracy: 0.8916\n","\n","Epoch 00166: val_accuracy did not improve from 0.93103\n","Epoch 167/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0378 - accuracy: 0.9903 - val_loss: 0.6226 - val_accuracy: 0.8867\n","\n","Epoch 00167: val_accuracy did not improve from 0.93103\n","Epoch 168/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.5610 - val_accuracy: 0.8818\n","\n","Epoch 00168: val_accuracy did not improve from 0.93103\n","Epoch 169/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0094 - accuracy: 0.9951 - val_loss: 0.4616 - val_accuracy: 0.8966\n","\n","Epoch 00169: val_accuracy did not improve from 0.93103\n","Epoch 170/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5596 - val_accuracy: 0.8842\n","\n","Epoch 00170: val_accuracy did not improve from 0.93103\n","Epoch 171/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5871 - val_accuracy: 0.8695\n","\n","Epoch 00171: val_accuracy did not improve from 0.93103\n","Epoch 172/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5125 - val_accuracy: 0.8966\n","\n","Epoch 00172: val_accuracy did not improve from 0.93103\n","Epoch 173/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.6533 - val_accuracy: 0.8842\n","\n","Epoch 00173: val_accuracy did not improve from 0.93103\n","Epoch 174/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.4761 - val_accuracy: 0.8867\n","\n","Epoch 00174: val_accuracy did not improve from 0.93103\n","Epoch 175/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.8433 - val_accuracy: 0.8670\n","\n","Epoch 00175: val_accuracy did not improve from 0.93103\n","Epoch 176/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.4192 - val_accuracy: 0.9113\n","\n","Epoch 00176: val_accuracy did not improve from 0.93103\n","Epoch 177/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.4805 - val_accuracy: 0.9138\n","\n","Epoch 00177: val_accuracy did not improve from 0.93103\n","Epoch 178/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.5456 - val_accuracy: 0.8793\n","\n","Epoch 00178: val_accuracy did not improve from 0.93103\n","Epoch 179/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5301 - val_accuracy: 0.8498\n","\n","Epoch 00179: val_accuracy did not improve from 0.93103\n","Epoch 180/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.6125 - val_accuracy: 0.8842\n","\n","Epoch 00180: val_accuracy did not improve from 0.93103\n","Epoch 181/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.6247 - val_accuracy: 0.8990\n","\n","Epoch 00181: val_accuracy did not improve from 0.93103\n","Epoch 182/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0702 - accuracy: 0.9738 - val_loss: 1.4407 - val_accuracy: 0.8079\n","\n","Epoch 00182: val_accuracy did not improve from 0.93103\n","Epoch 183/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1568 - accuracy: 0.9586 - val_loss: 1.0859 - val_accuracy: 0.8448\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0454 - accuracy: 0.9823 - val_loss: 0.7567 - val_accuracy: 0.8350\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.5154 - val_accuracy: 0.9039\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.6424 - val_accuracy: 0.8818\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.4757 - val_accuracy: 0.9015\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5136 - val_accuracy: 0.8941\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.6028 - val_accuracy: 0.8793\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.4445 - val_accuracy: 0.9113\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.3623 - val_accuracy: 0.9187\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4675 - val_accuracy: 0.9187\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9163\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4142 - val_accuracy: 0.9089\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4863 - val_accuracy: 0.9089\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3036 - val_accuracy: 0.9409\n","\n","Epoch 00196: val_accuracy improved from 0.93103 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5\n","Epoch 197/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.4665 - val_accuracy: 0.9015\n","\n","Epoch 00197: val_accuracy did not improve from 0.94089\n","Epoch 198/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5888 - val_accuracy: 0.8744\n","\n","Epoch 00198: val_accuracy did not improve from 0.94089\n","Epoch 199/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5281 - val_accuracy: 0.9089\n","\n","Epoch 00199: val_accuracy did not improve from 0.94089\n","Epoch 200/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.7279 - val_accuracy: 0.8571\n","\n","Epoch 00200: val_accuracy did not improve from 0.94089\n","Epoch 201/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 0.8191 - val_accuracy: 0.8695\n","\n","Epoch 00201: val_accuracy did not improve from 0.94089\n","Epoch 202/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.7086 - val_accuracy: 0.8719\n","\n","Epoch 00202: val_accuracy did not improve from 0.94089\n","Epoch 203/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.7561 - val_accuracy: 0.8399\n","\n","Epoch 00203: val_accuracy did not improve from 0.94089\n","Epoch 204/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 0.4597 - val_accuracy: 0.8966\n","\n","Epoch 00204: val_accuracy did not improve from 0.94089\n","Epoch 205/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5865 - val_accuracy: 0.8892\n","\n","Epoch 00205: val_accuracy did not improve from 0.94089\n","Epoch 206/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.5773 - val_accuracy: 0.8719\n","\n","Epoch 00206: val_accuracy did not improve from 0.94089\n","Epoch 207/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 0.5465 - val_accuracy: 0.8916\n","\n","Epoch 00207: val_accuracy did not improve from 0.94089\n","Epoch 208/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4859 - val_accuracy: 0.9039\n","\n","Epoch 00208: val_accuracy did not improve from 0.94089\n","Epoch 209/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.4060 - val_accuracy: 0.9310\n","\n","Epoch 00209: val_accuracy did not improve from 0.94089\n","Epoch 210/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3703 - val_accuracy: 0.9360\n","\n","Epoch 00210: val_accuracy did not improve from 0.94089\n","Epoch 211/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3429 - val_accuracy: 0.9409\n","\n","Epoch 00211: val_accuracy did not improve from 0.94089\n","Epoch 212/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4025 - val_accuracy: 0.9163\n","\n","Epoch 00212: val_accuracy did not improve from 0.94089\n","Epoch 213/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.1348e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9212\n","\n","Epoch 00213: val_accuracy did not improve from 0.94089\n","Epoch 214/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9236\n","\n","Epoch 00214: val_accuracy did not improve from 0.94089\n","Epoch 215/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4022 - val_accuracy: 0.9261\n","\n","Epoch 00215: val_accuracy did not improve from 0.94089\n","Epoch 216/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.9099e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9261\n","\n","Epoch 00216: val_accuracy did not improve from 0.94089\n","Epoch 217/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.9251e-04 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9335\n","\n","Epoch 00217: val_accuracy did not improve from 0.94089\n","Epoch 218/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.8856 - val_accuracy: 0.8645\n","\n","Epoch 00218: val_accuracy did not improve from 0.94089\n","Epoch 219/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.6329 - val_accuracy: 0.8695\n","\n","Epoch 00219: val_accuracy did not improve from 0.94089\n","Epoch 220/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6132 - val_accuracy: 0.8941\n","\n","Epoch 00220: val_accuracy did not improve from 0.94089\n","Epoch 221/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0628 - accuracy: 0.9762 - val_loss: 0.9342 - val_accuracy: 0.8621\n","\n","Epoch 00221: val_accuracy did not improve from 0.94089\n","Epoch 222/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0900 - accuracy: 0.9708 - val_loss: 1.8130 - val_accuracy: 0.6576\n","\n","Epoch 00222: val_accuracy did not improve from 0.94089\n","Epoch 223/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0858 - accuracy: 0.9738 - val_loss: 1.0721 - val_accuracy: 0.7857\n","\n","Epoch 00223: val_accuracy did not improve from 0.94089\n","Epoch 224/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.6576 - val_accuracy: 0.8621\n","\n","Epoch 00224: val_accuracy did not improve from 0.94089\n","Epoch 225/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.6411 - val_accuracy: 0.8768\n","\n","Epoch 00225: val_accuracy did not improve from 0.94089\n","Epoch 226/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.6398 - val_accuracy: 0.8473\n","\n","Epoch 00226: val_accuracy did not improve from 0.94089\n","Epoch 227/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0136 - accuracy: 0.9927 - val_loss: 0.5282 - val_accuracy: 0.8892\n","\n","Epoch 00227: val_accuracy did not improve from 0.94089\n","Epoch 228/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.4765 - val_accuracy: 0.9089\n","\n","Epoch 00228: val_accuracy did not improve from 0.94089\n","Epoch 229/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4659 - val_accuracy: 0.9039\n","\n","Epoch 00229: val_accuracy did not improve from 0.94089\n","Epoch 230/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.3901 - val_accuracy: 0.9212\n","\n","Epoch 00230: val_accuracy did not improve from 0.94089\n","Epoch 231/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9212\n","\n","Epoch 00231: val_accuracy did not improve from 0.94089\n","Epoch 232/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.6646 - val_accuracy: 0.8473\n","\n","Epoch 00232: val_accuracy did not improve from 0.94089\n","Epoch 233/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5673 - val_accuracy: 0.8695\n","\n","Epoch 00233: val_accuracy did not improve from 0.94089\n","Epoch 234/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4515 - val_accuracy: 0.9113\n","\n","Epoch 00234: val_accuracy did not improve from 0.94089\n","Epoch 235/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9163\n","\n","Epoch 00235: val_accuracy did not improve from 0.94089\n","Epoch 236/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.8957 - val_accuracy: 0.8325\n","\n","Epoch 00236: val_accuracy did not improve from 0.94089\n","Epoch 237/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.6260 - val_accuracy: 0.8695\n","\n","Epoch 00237: val_accuracy did not improve from 0.94089\n","Epoch 238/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.3914 - val_accuracy: 0.9089\n","\n","Epoch 00238: val_accuracy did not improve from 0.94089\n","Epoch 239/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4645 - val_accuracy: 0.9163\n","\n","Epoch 00239: val_accuracy did not improve from 0.94089\n","Epoch 240/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5669 - val_accuracy: 0.8966\n","\n","Epoch 00240: val_accuracy did not improve from 0.94089\n","Epoch 241/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9212\n","\n","Epoch 00241: val_accuracy did not improve from 0.94089\n","Epoch 242/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9236\n","\n","Epoch 00242: val_accuracy did not improve from 0.94089\n","Epoch 243/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0054 - accuracy: 0.9970 - val_loss: 0.5575 - val_accuracy: 0.9039\n","\n","Epoch 00243: val_accuracy did not improve from 0.94089\n","Epoch 244/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.4765 - val_accuracy: 0.9064\n","\n","Epoch 00244: val_accuracy did not improve from 0.94089\n","Epoch 245/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.4451 - val_accuracy: 0.8941\n","\n","Epoch 00245: val_accuracy did not improve from 0.94089\n","Epoch 246/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0128 - accuracy: 0.9939 - val_loss: 0.7250 - val_accuracy: 0.8916\n","\n","Epoch 00246: val_accuracy did not improve from 0.94089\n","Epoch 247/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.7756 - val_accuracy: 0.8719\n","\n","Epoch 00247: val_accuracy did not improve from 0.94089\n","Epoch 248/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0252 - accuracy: 0.9951 - val_loss: 0.6842 - val_accuracy: 0.8621\n","\n","Epoch 00248: val_accuracy did not improve from 0.94089\n","Epoch 249/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.6318 - val_accuracy: 0.8744\n","\n","Epoch 00249: val_accuracy did not improve from 0.94089\n","Epoch 250/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.6118 - val_accuracy: 0.9163\n","\n","Epoch 00250: val_accuracy did not improve from 0.94089\n","Epoch 251/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5819 - val_accuracy: 0.8842\n","\n","Epoch 00251: val_accuracy did not improve from 0.94089\n","Epoch 252/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5933 - val_accuracy: 0.8966\n","\n","Epoch 00252: val_accuracy did not improve from 0.94089\n","Epoch 253/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9138\n","\n","Epoch 00253: val_accuracy did not improve from 0.94089\n","Epoch 254/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.9273e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9360\n","\n","Epoch 00254: val_accuracy did not improve from 0.94089\n","Epoch 255/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.0756e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9236\n","\n","Epoch 00255: val_accuracy did not improve from 0.94089\n","Epoch 256/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.3199e-04 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9360\n","\n","Epoch 00256: val_accuracy did not improve from 0.94089\n","Epoch 257/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.7280e-04 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9138\n","\n","Epoch 00257: val_accuracy did not improve from 0.94089\n","Epoch 258/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.7035 - val_accuracy: 0.8892\n","\n","Epoch 00258: val_accuracy did not improve from 0.94089\n","Epoch 259/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0671 - accuracy: 0.9823 - val_loss: 1.1576 - val_accuracy: 0.8054\n","\n","Epoch 00259: val_accuracy did not improve from 0.94089\n","Epoch 260/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0993 - accuracy: 0.9708 - val_loss: 0.8249 - val_accuracy: 0.8793\n","\n","Epoch 00260: val_accuracy did not improve from 0.94089\n","Epoch 261/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.5530 - val_accuracy: 0.9187\n","\n","Epoch 00261: val_accuracy did not improve from 0.94089\n","Epoch 262/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.6745 - val_accuracy: 0.8941\n","\n","Epoch 00262: val_accuracy did not improve from 0.94089\n","Epoch 263/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4767 - val_accuracy: 0.9138\n","\n","Epoch 00263: val_accuracy did not improve from 0.94089\n","Epoch 264/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4541 - val_accuracy: 0.9113\n","\n","Epoch 00264: val_accuracy did not improve from 0.94089\n","Epoch 265/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4276 - val_accuracy: 0.9236\n","\n","Epoch 00265: val_accuracy did not improve from 0.94089\n","Epoch 266/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4732 - val_accuracy: 0.9113\n","\n","Epoch 00266: val_accuracy did not improve from 0.94089\n","Epoch 267/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5099 - val_accuracy: 0.9113\n","\n","Epoch 00267: val_accuracy did not improve from 0.94089\n","Epoch 268/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8867\n","\n","Epoch 00268: val_accuracy did not improve from 0.94089\n","Epoch 269/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5489 - val_accuracy: 0.8892\n","\n","Epoch 00269: val_accuracy did not improve from 0.94089\n","Epoch 270/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.6990 - val_accuracy: 0.8867\n","\n","Epoch 00270: val_accuracy did not improve from 0.94089\n","Epoch 271/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5651 - val_accuracy: 0.9015\n","\n","Epoch 00271: val_accuracy did not improve from 0.94089\n","Epoch 272/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5423 - val_accuracy: 0.9064\n","\n","Epoch 00272: val_accuracy did not improve from 0.94089\n","Epoch 273/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.9089\n","\n","Epoch 00273: val_accuracy did not improve from 0.94089\n","Epoch 274/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.9470 - val_accuracy: 0.8276\n","\n","Epoch 00274: val_accuracy did not improve from 0.94089\n","Epoch 275/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.7593 - val_accuracy: 0.8177\n","\n","Epoch 00275: val_accuracy did not improve from 0.94089\n","Epoch 276/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5305 - val_accuracy: 0.8768\n","\n","Epoch 00276: val_accuracy did not improve from 0.94089\n","Epoch 277/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.8793\n","\n","Epoch 00277: val_accuracy did not improve from 0.94089\n","Epoch 278/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9015\n","\n","Epoch 00278: val_accuracy did not improve from 0.94089\n","Epoch 279/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.8737 - val_accuracy: 0.8571\n","\n","Epoch 00279: val_accuracy did not improve from 0.94089\n","Epoch 280/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.6964 - val_accuracy: 0.8571\n","\n","Epoch 00280: val_accuracy did not improve from 0.94089\n","Epoch 281/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.4627 - val_accuracy: 0.8916\n","\n","Epoch 00281: val_accuracy did not improve from 0.94089\n","Epoch 282/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4274 - val_accuracy: 0.8966\n","\n","Epoch 00282: val_accuracy did not improve from 0.94089\n","Epoch 283/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9064\n","\n","Epoch 00283: val_accuracy did not improve from 0.94089\n","Epoch 284/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5179 - val_accuracy: 0.8966\n","\n","Epoch 00284: val_accuracy did not improve from 0.94089\n","Epoch 285/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4117 - val_accuracy: 0.9113\n","\n","Epoch 00285: val_accuracy did not improve from 0.94089\n","Epoch 286/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5562 - val_accuracy: 0.9089\n","\n","Epoch 00286: val_accuracy did not improve from 0.94089\n","Epoch 287/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.5813 - val_accuracy: 0.9212\n","\n","Epoch 00287: val_accuracy did not improve from 0.94089\n","Epoch 288/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.4800 - val_accuracy: 0.8867\n","\n","Epoch 00288: val_accuracy did not improve from 0.94089\n","Epoch 289/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0712 - accuracy: 0.9836 - val_loss: 1.1138 - val_accuracy: 0.8300\n","\n","Epoch 00289: val_accuracy did not improve from 0.94089\n","Epoch 290/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0874 - accuracy: 0.9738 - val_loss: 0.9636 - val_accuracy: 0.8645\n","\n","Epoch 00290: val_accuracy did not improve from 0.94089\n","Epoch 291/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.6825 - val_accuracy: 0.8744\n","\n","Epoch 00291: val_accuracy did not improve from 0.94089\n","Epoch 292/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 1.0464 - val_accuracy: 0.7709\n","\n","Epoch 00292: val_accuracy did not improve from 0.94089\n","Epoch 293/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.6558 - val_accuracy: 0.8645\n","\n","Epoch 00293: val_accuracy did not improve from 0.94089\n","Epoch 294/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.5492 - val_accuracy: 0.8768\n","\n","Epoch 00294: val_accuracy did not improve from 0.94089\n","Epoch 295/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.4426 - val_accuracy: 0.9187\n","\n","Epoch 00295: val_accuracy did not improve from 0.94089\n","Epoch 296/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5645 - val_accuracy: 0.8744\n","\n","Epoch 00296: val_accuracy did not improve from 0.94089\n","Epoch 297/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4801 - val_accuracy: 0.8990\n","\n","Epoch 00297: val_accuracy did not improve from 0.94089\n","Epoch 298/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5595 - val_accuracy: 0.9089\n","\n","Epoch 00298: val_accuracy did not improve from 0.94089\n","Epoch 299/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4697 - val_accuracy: 0.9039\n","\n","Epoch 00299: val_accuracy did not improve from 0.94089\n","Epoch 300/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.4400 - val_accuracy: 0.9015\n","\n","Epoch 00300: val_accuracy did not improve from 0.94089\n","Epoch 301/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4339 - val_accuracy: 0.9310\n","\n","Epoch 00301: val_accuracy did not improve from 0.94089\n","Epoch 302/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.6165e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9212\n","\n","Epoch 00302: val_accuracy did not improve from 0.94089\n","Epoch 303/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.1215e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9261\n","\n","Epoch 00303: val_accuracy did not improve from 0.94089\n","Epoch 304/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3853e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9138\n","\n","Epoch 00304: val_accuracy did not improve from 0.94089\n","Epoch 305/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.2642e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9187\n","\n","Epoch 00305: val_accuracy did not improve from 0.94089\n","Epoch 306/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.2327e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9310\n","\n","Epoch 00306: val_accuracy did not improve from 0.94089\n","Epoch 307/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.1756e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9310\n","\n","Epoch 00307: val_accuracy did not improve from 0.94089\n","Epoch 308/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.4496e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9236\n","\n","Epoch 00308: val_accuracy did not improve from 0.94089\n","Epoch 309/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0347 - accuracy: 0.9872 - val_loss: 0.8862 - val_accuracy: 0.8227\n","\n","Epoch 00309: val_accuracy did not improve from 0.94089\n","Epoch 310/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.6383 - val_accuracy: 0.8793\n","\n","Epoch 00310: val_accuracy did not improve from 0.94089\n","Epoch 311/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.8417 - val_accuracy: 0.8818\n","\n","Epoch 00311: val_accuracy did not improve from 0.94089\n","Epoch 312/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.9673 - val_accuracy: 0.8522\n","\n","Epoch 00312: val_accuracy did not improve from 0.94089\n","Epoch 313/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.4025 - val_accuracy: 0.8941\n","\n","Epoch 00313: val_accuracy did not improve from 0.94089\n","Epoch 314/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 1.5491 - val_accuracy: 0.7685\n","\n","Epoch 00314: val_accuracy did not improve from 0.94089\n","Epoch 315/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0258 - accuracy: 0.9884 - val_loss: 0.6261 - val_accuracy: 0.8793\n","\n","Epoch 00315: val_accuracy did not improve from 0.94089\n","Epoch 316/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.5050 - val_accuracy: 0.8596\n","\n","Epoch 00316: val_accuracy did not improve from 0.94089\n","Epoch 317/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.8932 - val_accuracy: 0.8350\n","\n","Epoch 00317: val_accuracy did not improve from 0.94089\n","Epoch 318/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.4699 - val_accuracy: 0.9138\n","\n","Epoch 00318: val_accuracy did not improve from 0.94089\n","Epoch 319/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4181 - val_accuracy: 0.9163\n","\n","Epoch 00319: val_accuracy did not improve from 0.94089\n","Epoch 320/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4047 - val_accuracy: 0.9187\n","\n","Epoch 00320: val_accuracy did not improve from 0.94089\n","Epoch 321/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.7310 - val_accuracy: 0.8768\n","\n","Epoch 00321: val_accuracy did not improve from 0.94089\n","Epoch 322/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.5478 - val_accuracy: 0.9039\n","\n","Epoch 00322: val_accuracy did not improve from 0.94089\n","Epoch 323/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5385 - val_accuracy: 0.9064\n","\n","Epoch 00323: val_accuracy did not improve from 0.94089\n","Epoch 324/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9113\n","\n","Epoch 00324: val_accuracy did not improve from 0.94089\n","Epoch 325/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.9685e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9163\n","\n","Epoch 00325: val_accuracy did not improve from 0.94089\n","Epoch 326/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.2673e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9163\n","\n","Epoch 00326: val_accuracy did not improve from 0.94089\n","Epoch 327/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.9215e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9163\n","\n","Epoch 00327: val_accuracy did not improve from 0.94089\n","Epoch 328/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4294 - val_accuracy: 0.9089\n","\n","Epoch 00328: val_accuracy did not improve from 0.94089\n","Epoch 329/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.6279e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9039\n","\n","Epoch 00329: val_accuracy did not improve from 0.94089\n","Epoch 330/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.6258e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9335\n","\n","Epoch 00330: val_accuracy did not improve from 0.94089\n","Epoch 331/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9261\n","\n","Epoch 00331: val_accuracy did not improve from 0.94089\n","Epoch 332/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.6392e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9163\n","\n","Epoch 00332: val_accuracy did not improve from 0.94089\n","Epoch 333/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.4049e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9261\n","\n","Epoch 00333: val_accuracy did not improve from 0.94089\n","Epoch 334/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.0816e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9360\n","\n","Epoch 00334: val_accuracy did not improve from 0.94089\n","Epoch 335/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.0310e-04 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9261\n","\n","Epoch 00335: val_accuracy did not improve from 0.94089\n","Epoch 336/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.8459e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9310\n","\n","Epoch 00336: val_accuracy did not improve from 0.94089\n","Epoch 337/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4209 - val_accuracy: 0.9286\n","\n","Epoch 00337: val_accuracy did not improve from 0.94089\n","Epoch 338/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4566 - val_accuracy: 0.9163\n","\n","Epoch 00338: val_accuracy did not improve from 0.94089\n","Epoch 339/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9163\n","\n","Epoch 00339: val_accuracy did not improve from 0.94089\n","Epoch 340/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4498 - val_accuracy: 0.9113\n","\n","Epoch 00340: val_accuracy did not improve from 0.94089\n","Epoch 341/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9261\n","\n","Epoch 00341: val_accuracy did not improve from 0.94089\n","Epoch 342/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.1288e-04 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9236\n","\n","Epoch 00342: val_accuracy did not improve from 0.94089\n","Epoch 343/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.4009e-04 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9409\n","\n","Epoch 00343: val_accuracy did not improve from 0.94089\n","Epoch 344/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.1300 - val_accuracy: 0.8448\n","\n","Epoch 00344: val_accuracy did not improve from 0.94089\n","Epoch 345/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0612 - accuracy: 0.9836 - val_loss: 0.8601 - val_accuracy: 0.8374\n","\n","Epoch 00345: val_accuracy did not improve from 0.94089\n","Epoch 346/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0384 - accuracy: 0.9915 - val_loss: 1.0917 - val_accuracy: 0.8374\n","\n","Epoch 00346: val_accuracy did not improve from 0.94089\n","Epoch 347/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0740 - accuracy: 0.9829 - val_loss: 1.0168 - val_accuracy: 0.8498\n","\n","Epoch 00347: val_accuracy did not improve from 0.94089\n","Epoch 348/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.7776 - val_accuracy: 0.8498\n","\n","Epoch 00348: val_accuracy did not improve from 0.94089\n","Epoch 349/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 0.8153 - val_accuracy: 0.8473\n","\n","Epoch 00349: val_accuracy did not improve from 0.94089\n","Epoch 350/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.6745 - val_accuracy: 0.8990\n","\n","Epoch 00350: val_accuracy did not improve from 0.94089\n","Epoch 351/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5762 - val_accuracy: 0.9113\n","\n","Epoch 00351: val_accuracy did not improve from 0.94089\n","Epoch 352/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9212\n","\n","Epoch 00352: val_accuracy did not improve from 0.94089\n","Epoch 353/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4473 - val_accuracy: 0.9015\n","\n","Epoch 00353: val_accuracy did not improve from 0.94089\n","Epoch 354/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9089\n","\n","Epoch 00354: val_accuracy did not improve from 0.94089\n","Epoch 355/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9138\n","\n","Epoch 00355: val_accuracy did not improve from 0.94089\n","Epoch 356/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.5296e-04 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9187\n","\n","Epoch 00356: val_accuracy did not improve from 0.94089\n","Epoch 357/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5669 - val_accuracy: 0.9039\n","\n","Epoch 00357: val_accuracy did not improve from 0.94089\n","Epoch 358/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.6461 - val_accuracy: 0.8695\n","\n","Epoch 00358: val_accuracy did not improve from 0.94089\n","Epoch 359/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4216 - val_accuracy: 0.9138\n","\n","Epoch 00359: val_accuracy did not improve from 0.94089\n","Epoch 360/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4275 - val_accuracy: 0.9236\n","\n","Epoch 00360: val_accuracy did not improve from 0.94089\n","Epoch 361/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4338 - val_accuracy: 0.9089\n","\n","Epoch 00361: val_accuracy did not improve from 0.94089\n","Epoch 362/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4901 - val_accuracy: 0.8892\n","\n","Epoch 00362: val_accuracy did not improve from 0.94089\n","Epoch 363/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5442 - val_accuracy: 0.8867\n","\n","Epoch 00363: val_accuracy did not improve from 0.94089\n","Epoch 364/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9064\n","\n","Epoch 00364: val_accuracy did not improve from 0.94089\n","Epoch 365/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.1129e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9039\n","\n","Epoch 00365: val_accuracy did not improve from 0.94089\n","Epoch 366/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.3763 - val_accuracy: 0.9064\n","\n","Epoch 00366: val_accuracy did not improve from 0.94089\n","Epoch 367/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4593 - val_accuracy: 0.9113\n","\n","Epoch 00367: val_accuracy did not improve from 0.94089\n","Epoch 368/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4879 - val_accuracy: 0.9163\n","\n","Epoch 00368: val_accuracy did not improve from 0.94089\n","Epoch 369/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.6733 - val_accuracy: 0.8842\n","\n","Epoch 00369: val_accuracy did not improve from 0.94089\n","Epoch 370/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0605 - accuracy: 0.9872 - val_loss: 0.9141 - val_accuracy: 0.8645\n","\n","Epoch 00370: val_accuracy did not improve from 0.94089\n","Epoch 371/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.8366 - val_accuracy: 0.8670\n","\n","Epoch 00371: val_accuracy did not improve from 0.94089\n","Epoch 372/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0338 - accuracy: 0.9933 - val_loss: 0.7545 - val_accuracy: 0.8399\n","\n","Epoch 00372: val_accuracy did not improve from 0.94089\n","Epoch 373/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.6098 - val_accuracy: 0.8645\n","\n","Epoch 00373: val_accuracy did not improve from 0.94089\n","Epoch 374/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.5449 - val_accuracy: 0.8941\n","\n","Epoch 00374: val_accuracy did not improve from 0.94089\n","Epoch 375/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4966 - val_accuracy: 0.8966\n","\n","Epoch 00375: val_accuracy did not improve from 0.94089\n","Epoch 376/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4784 - val_accuracy: 0.8990\n","\n","Epoch 00376: val_accuracy did not improve from 0.94089\n","Epoch 377/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.4676 - val_accuracy: 0.9187\n","\n","Epoch 00377: val_accuracy did not improve from 0.94089\n","Epoch 378/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.6053 - val_accuracy: 0.8867\n","\n","Epoch 00378: val_accuracy did not improve from 0.94089\n","Epoch 379/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.6508 - val_accuracy: 0.8744\n","\n","Epoch 00379: val_accuracy did not improve from 0.94089\n","Epoch 380/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5512 - val_accuracy: 0.9187\n","\n","Epoch 00380: val_accuracy did not improve from 0.94089\n","Epoch 381/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5601 - val_accuracy: 0.9039\n","\n","Epoch 00381: val_accuracy did not improve from 0.94089\n","Epoch 382/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5015 - val_accuracy: 0.9089\n","\n","Epoch 00382: val_accuracy did not improve from 0.94089\n","Epoch 383/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.5707 - val_accuracy: 0.9015\n","\n","Epoch 00383: val_accuracy did not improve from 0.94089\n","Epoch 384/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5468 - val_accuracy: 0.9113\n","\n","Epoch 00384: val_accuracy did not improve from 0.94089\n","Epoch 385/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4634 - val_accuracy: 0.9113\n","\n","Epoch 00385: val_accuracy did not improve from 0.94089\n","Epoch 386/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.5212 - val_accuracy: 0.9089\n","\n","Epoch 00386: val_accuracy did not improve from 0.94089\n","Epoch 387/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4803 - val_accuracy: 0.9163\n","\n","Epoch 00387: val_accuracy did not improve from 0.94089\n","Epoch 388/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5632 - val_accuracy: 0.9064\n","\n","Epoch 00388: val_accuracy did not improve from 0.94089\n","Epoch 389/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5182 - val_accuracy: 0.8818\n","\n","Epoch 00389: val_accuracy did not improve from 0.94089\n","Epoch 390/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6450 - val_accuracy: 0.8793\n","\n","Epoch 00390: val_accuracy did not improve from 0.94089\n","Epoch 391/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6230 - val_accuracy: 0.8867\n","\n","Epoch 00391: val_accuracy did not improve from 0.94089\n","Epoch 392/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4653 - val_accuracy: 0.9163\n","\n","Epoch 00392: val_accuracy did not improve from 0.94089\n","Epoch 393/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9089\n","\n","Epoch 00393: val_accuracy did not improve from 0.94089\n","Epoch 394/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.4547 - val_accuracy: 0.9138\n","\n","Epoch 00394: val_accuracy did not improve from 0.94089\n","Epoch 395/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9236\n","\n","Epoch 00395: val_accuracy did not improve from 0.94089\n","Epoch 396/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.5188e-04 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9335\n","\n","Epoch 00396: val_accuracy did not improve from 0.94089\n","Epoch 397/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.9861e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9409\n","\n","Epoch 00397: val_accuracy did not improve from 0.94089\n","Epoch 398/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.3552e-04 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9310\n","\n","Epoch 00398: val_accuracy did not improve from 0.94089\n","Epoch 399/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.1505e-04 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9212\n","\n","Epoch 00399: val_accuracy did not improve from 0.94089\n","Epoch 400/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.0087e-04 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9212\n","\n","Epoch 00400: val_accuracy did not improve from 0.94089\n","Epoch 401/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4486 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.94089\n","Epoch 402/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5828 - val_accuracy: 0.9015\n","\n","Epoch 00402: val_accuracy did not improve from 0.94089\n","Epoch 403/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0728 - accuracy: 0.9842 - val_loss: 0.9136 - val_accuracy: 0.8473\n","\n","Epoch 00403: val_accuracy did not improve from 0.94089\n","Epoch 404/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.8055 - val_accuracy: 0.8719\n","\n","Epoch 00404: val_accuracy did not improve from 0.94089\n","Epoch 405/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.6722 - val_accuracy: 0.8892\n","\n","Epoch 00405: val_accuracy did not improve from 0.94089\n","Epoch 406/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.5543 - val_accuracy: 0.9064\n","\n","Epoch 00406: val_accuracy did not improve from 0.94089\n","Epoch 407/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4676 - val_accuracy: 0.9163\n","\n","Epoch 00407: val_accuracy did not improve from 0.94089\n","Epoch 408/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5323 - val_accuracy: 0.9113\n","\n","Epoch 00408: val_accuracy did not improve from 0.94089\n","Epoch 409/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.9089\n","\n","Epoch 00409: val_accuracy did not improve from 0.94089\n","Epoch 410/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9212\n","\n","Epoch 00410: val_accuracy did not improve from 0.94089\n","Epoch 411/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.4379 - val_accuracy: 0.9212\n","\n","Epoch 00411: val_accuracy did not improve from 0.94089\n","Epoch 412/500\n","52/52 [==============================] - 11s 207ms/step - loss: 8.5674e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9286\n","\n","Epoch 00412: val_accuracy did not improve from 0.94089\n","Epoch 413/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.6023e-04 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9286\n","\n","Epoch 00413: val_accuracy did not improve from 0.94089\n","Epoch 414/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.1276e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9310\n","\n","Epoch 00414: val_accuracy did not improve from 0.94089\n","Epoch 415/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.1149e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9335\n","\n","Epoch 00415: val_accuracy did not improve from 0.94089\n","Epoch 416/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4241 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.94089\n","Epoch 417/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5223 - val_accuracy: 0.9163\n","\n","Epoch 00417: val_accuracy did not improve from 0.94089\n","Epoch 418/500\n","52/52 [==============================] - 11s 207ms/step - loss: 9.2042e-04 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9187\n","\n","Epoch 00418: val_accuracy did not improve from 0.94089\n","Epoch 419/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.7098 - val_accuracy: 0.8966\n","\n","Epoch 00419: val_accuracy did not improve from 0.94089\n","Epoch 420/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4656 - val_accuracy: 0.9138\n","\n","Epoch 00420: val_accuracy did not improve from 0.94089\n","Epoch 421/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5525 - val_accuracy: 0.8941\n","\n","Epoch 00421: val_accuracy did not improve from 0.94089\n","Epoch 422/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5439 - val_accuracy: 0.9113\n","\n","Epoch 00422: val_accuracy did not improve from 0.94089\n","Epoch 423/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.6264 - val_accuracy: 0.8793\n","\n","Epoch 00423: val_accuracy did not improve from 0.94089\n","Epoch 424/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.6973 - val_accuracy: 0.8719\n","\n","Epoch 00424: val_accuracy did not improve from 0.94089\n","Epoch 425/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0855 - accuracy: 0.9799 - val_loss: 0.9238 - val_accuracy: 0.8448\n","\n","Epoch 00425: val_accuracy did not improve from 0.94089\n","Epoch 426/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 1.6835 - val_accuracy: 0.7833\n","\n","Epoch 00426: val_accuracy did not improve from 0.94089\n","Epoch 427/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.6919 - val_accuracy: 0.8448\n","\n","Epoch 00427: val_accuracy did not improve from 0.94089\n","Epoch 428/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.5082 - val_accuracy: 0.9089\n","\n","Epoch 00428: val_accuracy did not improve from 0.94089\n","Epoch 429/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4449 - val_accuracy: 0.8892\n","\n","Epoch 00429: val_accuracy did not improve from 0.94089\n","Epoch 430/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.3987 - val_accuracy: 0.9261\n","\n","Epoch 00430: val_accuracy did not improve from 0.94089\n","Epoch 431/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4598 - val_accuracy: 0.9163\n","\n","Epoch 00431: val_accuracy did not improve from 0.94089\n","Epoch 432/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5132 - val_accuracy: 0.8867\n","\n","Epoch 00432: val_accuracy did not improve from 0.94089\n","Epoch 433/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9064\n","\n","Epoch 00433: val_accuracy did not improve from 0.94089\n","Epoch 434/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3676 - val_accuracy: 0.9310\n","\n","Epoch 00434: val_accuracy did not improve from 0.94089\n","Epoch 435/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.8945e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9261\n","\n","Epoch 00435: val_accuracy did not improve from 0.94089\n","Epoch 436/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.8576e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.94089\n","Epoch 437/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4055 - val_accuracy: 0.9212\n","\n","Epoch 00437: val_accuracy did not improve from 0.94089\n","Epoch 438/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4606 - val_accuracy: 0.9212\n","\n","Epoch 00438: val_accuracy did not improve from 0.94089\n","Epoch 439/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.5252 - val_accuracy: 0.9015\n","\n","Epoch 00439: val_accuracy did not improve from 0.94089\n","Epoch 440/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 0.6234 - val_accuracy: 0.9064\n","\n","Epoch 00440: val_accuracy did not improve from 0.94089\n","Epoch 441/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 1.2856 - val_accuracy: 0.8547\n","\n","Epoch 00441: val_accuracy did not improve from 0.94089\n","Epoch 442/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.4900 - val_accuracy: 0.9089\n","\n","Epoch 00442: val_accuracy did not improve from 0.94089\n","Epoch 443/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4705 - val_accuracy: 0.8990\n","\n","Epoch 00443: val_accuracy did not improve from 0.94089\n","Epoch 444/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.4619 - val_accuracy: 0.9113\n","\n","Epoch 00444: val_accuracy did not improve from 0.94089\n","Epoch 445/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.6067 - val_accuracy: 0.8818\n","\n","Epoch 00445: val_accuracy did not improve from 0.94089\n","Epoch 446/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5014 - val_accuracy: 0.9064\n","\n","Epoch 00446: val_accuracy did not improve from 0.94089\n","Epoch 447/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4371 - val_accuracy: 0.9138\n","\n","Epoch 00447: val_accuracy did not improve from 0.94089\n","Epoch 448/500\n","52/52 [==============================] - 11s 207ms/step - loss: 8.5579e-04 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9113\n","\n","Epoch 00448: val_accuracy did not improve from 0.94089\n","Epoch 449/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5528 - val_accuracy: 0.8966\n","\n","Epoch 00449: val_accuracy did not improve from 0.94089\n","Epoch 450/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4123 - val_accuracy: 0.9187\n","\n","Epoch 00450: val_accuracy did not improve from 0.94089\n","Epoch 451/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.1789e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9187\n","\n","Epoch 00451: val_accuracy did not improve from 0.94089\n","Epoch 452/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4829 - val_accuracy: 0.9039\n","\n","Epoch 00452: val_accuracy did not improve from 0.94089\n","Epoch 453/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.4476 - val_accuracy: 0.9286\n","\n","Epoch 00453: val_accuracy did not improve from 0.94089\n","Epoch 454/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.1748e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9089\n","\n","Epoch 00454: val_accuracy did not improve from 0.94089\n","Epoch 455/500\n","52/52 [==============================] - 11s 207ms/step - loss: 5.3602e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9212\n","\n","Epoch 00455: val_accuracy did not improve from 0.94089\n","Epoch 456/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.1764e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9236\n","\n","Epoch 00456: val_accuracy did not improve from 0.94089\n","Epoch 457/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.4702e-04 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9261\n","\n","Epoch 00457: val_accuracy did not improve from 0.94089\n","Epoch 458/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.9228e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9138\n","\n","Epoch 00458: val_accuracy did not improve from 0.94089\n","Epoch 459/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9089\n","\n","Epoch 00459: val_accuracy did not improve from 0.94089\n","Epoch 460/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4468 - val_accuracy: 0.9163\n","\n","Epoch 00460: val_accuracy did not improve from 0.94089\n","Epoch 461/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9236\n","\n","Epoch 00461: val_accuracy did not improve from 0.94089\n","Epoch 462/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.0293e-04 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9113\n","\n","Epoch 00462: val_accuracy did not improve from 0.94089\n","Epoch 463/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4926 - val_accuracy: 0.9039\n","\n","Epoch 00463: val_accuracy did not improve from 0.94089\n","Epoch 464/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.6605 - val_accuracy: 0.8793\n","\n","Epoch 00464: val_accuracy did not improve from 0.94089\n","Epoch 465/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.9995 - val_accuracy: 0.8424\n","\n","Epoch 00465: val_accuracy did not improve from 0.94089\n","Epoch 466/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 1.0784 - val_accuracy: 0.7660\n","\n","Epoch 00466: val_accuracy did not improve from 0.94089\n","Epoch 467/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0187 - accuracy: 0.9896 - val_loss: 1.0184 - val_accuracy: 0.8498\n","\n","Epoch 00467: val_accuracy did not improve from 0.94089\n","Epoch 468/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0601 - accuracy: 0.9836 - val_loss: 1.2599 - val_accuracy: 0.7882\n","\n","Epoch 00468: val_accuracy did not improve from 0.94089\n","Epoch 469/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.7369 - val_accuracy: 0.8793\n","\n","Epoch 00469: val_accuracy did not improve from 0.94089\n","Epoch 470/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 1.0903 - val_accuracy: 0.8547\n","\n","Epoch 00470: val_accuracy did not improve from 0.94089\n","Epoch 471/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4694 - val_accuracy: 0.9015\n","\n","Epoch 00471: val_accuracy did not improve from 0.94089\n","Epoch 472/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.5603 - val_accuracy: 0.8990\n","\n","Epoch 00472: val_accuracy did not improve from 0.94089\n","Epoch 473/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6022 - val_accuracy: 0.8744\n","\n","Epoch 00473: val_accuracy did not improve from 0.94089\n","Epoch 474/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4662 - val_accuracy: 0.9039\n","\n","Epoch 00474: val_accuracy did not improve from 0.94089\n","Epoch 475/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4196 - val_accuracy: 0.9163\n","\n","Epoch 00475: val_accuracy did not improve from 0.94089\n","Epoch 476/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.7316 - val_accuracy: 0.8768\n","\n","Epoch 00476: val_accuracy did not improve from 0.94089\n","Epoch 477/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5089 - val_accuracy: 0.9039\n","\n","Epoch 00477: val_accuracy did not improve from 0.94089\n","Epoch 478/500\n","52/52 [==============================] - 11s 207ms/step - loss: 4.1285e-04 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9064\n","\n","Epoch 00478: val_accuracy did not improve from 0.94089\n","Epoch 479/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.9140 - val_accuracy: 0.8719\n","\n","Epoch 00479: val_accuracy did not improve from 0.94089\n","Epoch 480/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6302 - val_accuracy: 0.8818\n","\n","Epoch 00480: val_accuracy did not improve from 0.94089\n","Epoch 481/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5499 - val_accuracy: 0.9015\n","\n","Epoch 00481: val_accuracy did not improve from 0.94089\n","Epoch 482/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.5281 - val_accuracy: 0.9089\n","\n","Epoch 00482: val_accuracy did not improve from 0.94089\n","Epoch 483/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5455 - val_accuracy: 0.9212\n","\n","Epoch 00483: val_accuracy did not improve from 0.94089\n","Epoch 484/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6225 - val_accuracy: 0.9039\n","\n","Epoch 00484: val_accuracy did not improve from 0.94089\n","Epoch 485/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.1269e-04 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9138\n","\n","Epoch 00485: val_accuracy did not improve from 0.94089\n","Epoch 486/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.5409e-04 - accuracy: 1.0000 - val_loss: 0.5441 - val_accuracy: 0.9212\n","\n","Epoch 00486: val_accuracy did not improve from 0.94089\n","Epoch 487/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.2693e-04 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.9163\n","\n","Epoch 00487: val_accuracy did not improve from 0.94089\n","Epoch 488/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.2834e-04 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.9163\n","\n","Epoch 00488: val_accuracy did not improve from 0.94089\n","Epoch 489/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5538 - val_accuracy: 0.9236\n","\n","Epoch 00489: val_accuracy did not improve from 0.94089\n","Epoch 490/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5923 - val_accuracy: 0.9310\n","\n","Epoch 00490: val_accuracy did not improve from 0.94089\n","Epoch 491/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9113\n","\n","Epoch 00491: val_accuracy did not improve from 0.94089\n","Epoch 492/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.2110e-04 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9212\n","\n","Epoch 00492: val_accuracy did not improve from 0.94089\n","Epoch 493/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5124 - val_accuracy: 0.9187\n","\n","Epoch 00493: val_accuracy did not improve from 0.94089\n","Epoch 494/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5203 - val_accuracy: 0.9212\n","\n","Epoch 00494: val_accuracy did not improve from 0.94089\n","Epoch 495/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.8451e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9163\n","\n","Epoch 00495: val_accuracy did not improve from 0.94089\n","Epoch 496/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.1149e-04 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9212\n","\n","Epoch 00496: val_accuracy did not improve from 0.94089\n","Epoch 497/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.8087e-04 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.9187\n","\n","Epoch 00497: val_accuracy did not improve from 0.94089\n","Epoch 498/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5898 - val_accuracy: 0.9089\n","\n","Epoch 00498: val_accuracy did not improve from 0.94089\n","Epoch 499/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5441 - val_accuracy: 0.9261\n","\n","Epoch 00499: val_accuracy did not improve from 0.94089\n","Epoch 500/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.9187\n","\n","Epoch 00500: val_accuracy did not improve from 0.94089\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7cabc615d0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630521850483,"user_tz":-540,"elapsed":30,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0227b9a8-5962-45dd-e019-247c82833327"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630521866300,"user_tz":-540,"elapsed":15834,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_010_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630521866960,"user_tz":-540,"elapsed":669,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630521867393,"user_tz":-540,"elapsed":438,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"15605cbf-51f9-4d35-bc5f-1d8b0b52427f"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630521898135,"user_tz":-540,"elapsed":30748,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3c300c04-c391-4174-9662-230ff745ab76"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630521898139,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630521898141,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630521899594,"user_tz":-540,"elapsed":1460,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630521899600,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630521910449,"user_tz":-540,"elapsed":10862,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630521910451,"user_tz":-540,"elapsed":32,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b7d22775-0b77-4cb8-d0d9-c483c787234a"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630521910451,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5803fe44-2692-4e51-d55b-ce24468f429d"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_010_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_aa818717-e742-4cc2-ab71-f904a37f60c0\", \"HeightShiftRange_010_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}