{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageSize_256_5_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1c2MWKPmFEryc2NI5jyKAAWVmxqH1VUCz","timestamp":1631216398169},{"file_id":"1_XM5eXz-mRq_8btoHAcEP8vfGSYFw1LC","timestamp":1631216374547},{"file_id":"1WF9YyXyX0BHUcSI4EfvLCmpIZnkjfht_","timestamp":1631199517663},{"file_id":"1DhKkeZKVN6SnskBHR9I9JhnmnnAvvYsM","timestamp":1631199484204},{"file_id":"1Sb1zx-9JnMoqZN44rSFWtUmopGi9YObV","timestamp":1631049773986},{"file_id":"1Ukz7x6x60p-yX7qFtl681RI02Xq38gil","timestamp":1631047282593},{"file_id":"1a65ZxKUM-ebeKKlnVVwnVW-zuq6YjgE5","timestamp":1631047194111},{"file_id":"1zeTuwcXoX2nrULVuhoDyze5Ppfttrv0w","timestamp":1631045991075},{"file_id":"1Q_w97zg4VwPEfNBX52yhb8QqQexMpqf_","timestamp":1631044605223},{"file_id":"1pqowzoSTmQGAh-N1th_R0C3TI9Gyl4Hc","timestamp":1631043183868},{"file_id":"1fedN2kXOFJ_DCXWKCH9EXVlgwLeCYz7u","timestamp":1631039069646},{"file_id":"1ZXAcHyuCWCyRAdv1K2fjSI7EYUZUzgd-","timestamp":1631037094537},{"file_id":"1QwQAud74jt30tPFhBZB4ST8jpL6yfXId","timestamp":1631035798955},{"file_id":"1HK4HDd8d-ydp1hpjE542SlZzhcebS04s","timestamp":1631035758423},{"file_id":"1BDI3hcYWj0EQ36ajZDAXvOF7hl4SSZLK","timestamp":1631030590142},{"file_id":"1wkcCzuHh8bbAgm3A6BK30Yutz6_lW7Wz","timestamp":1630968808808},{"file_id":"1NBaJvfE-mNYLwaRSb3DmI2VgGlo-L64e","timestamp":1630968784020},{"file_id":"1tuxKDEpXqS10eUFd1BhXSulkLRHwm5Ls","timestamp":1630968742688},{"file_id":"1tT8KjKA8d3WPDIBeqi3Pl2OBSYM0j1vs","timestamp":1630968318011},{"file_id":"1zXLjChcCNAAwvHd2Cpnq9eXPmx2Hxv7v","timestamp":1630968226179},{"file_id":"1my69WIg_k7Dsobadf8IPYHpbt46UeiOr","timestamp":1630961678442},{"file_id":"1FBIwhXm4-AXNBfg_zN4PCqYB4fBkJis9","timestamp":1630961652892},{"file_id":"1aKbh7xPYx3QmxXPNnL4Ibm-oAutHqQmP","timestamp":1630961578285},{"file_id":"1oOSCmJ_elzy5wWrlNC00MqwUHJayiHDY","timestamp":1630961542590},{"file_id":"1t7sTp3m7RRztyvU4tfL8W8lGrMk2FQjn","timestamp":1630951440213},{"file_id":"1fazDZeCuGnik7RX86NUluX6WpNk8nyHy","timestamp":1630949981703},{"file_id":"1hFR9zdRHLq9CD3Qx-qnlkZJvce1OlPUu","timestamp":1630949783061},{"file_id":"1zC6movFvQGJ4fr54cjU-Pu08xt53vVjF","timestamp":1630949772598},{"file_id":"1JjM9eMHh_iT2pY6BNfy6y5ztoX5BznNb","timestamp":1630866486107},{"file_id":"1RJHw6qRW-G23IN47ZOMM1nOcrOv-Lq_k","timestamp":1630866451790},{"file_id":"1--_lXPMfaPxWLicd9uWOpl48GRqT9x9K","timestamp":1630847367248},{"file_id":"1PGeXA-Nb00rJuv1I3ZBF6rpNR4qDErXE","timestamp":1630836207896},{"file_id":"19f4sGczygDy6VCFM6Dc6mfSNNAdh6QMI","timestamp":1630836183988},{"file_id":"1dSlKlnhNkaJD6rX0PnYAwTzru54zKEmb","timestamp":1630836149378},{"file_id":"1GxaesOzgv99NpOY71Qn2A4_a_nbiGScP","timestamp":1630836075710},{"file_id":"1pAOyg2ba1nqW5-60Tb4uA63Qfb9UVr1l","timestamp":1630835987308},{"file_id":"10TnEQPLI8MHQRmh84M8HicSibJfewY9a","timestamp":1630835956891},{"file_id":"1fiIBRDmLIPxB3JYTePwN6q-04wPwAWWN","timestamp":1630778953404},{"file_id":"1vco_0hIBI4evIfDmQDH07Nq5lQJx4Kod","timestamp":1630778923697},{"file_id":"1r3BflNbSZB370f8W3h8PQ5C7NEdbXsJj","timestamp":1630766001155},{"file_id":"1fyedjHIW6-8SHp9ow65apBeykbHxS7oi","timestamp":1630760236494},{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyPFRzOm7xOmxVgcPr4CPCFX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269181749,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"daa27788-6497-4fe4-8cae-022d4473fd52"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep 10 10:19:41 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269207794,"user_tz":-540,"elapsed":26050,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3fa2265b-7b26-418a-b088-01649d7c8b79"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1631269215205,"user_tz":-540,"elapsed":7415,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1631269216229,"user_tz":-540,"elapsed":1040,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1631269218620,"user_tz":-540,"elapsed":2395,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1631269239354,"user_tz":-540,"elapsed":20737,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1631269247221,"user_tz":-540,"elapsed":7873,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(256, 256, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269247221,"user_tz":-540,"elapsed":28,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9d81342d-6e7a-4c24-bb28-da26d9ef6c7b"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631269247222,"user_tz":-540,"elapsed":24,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a91a3976-8a97-466d-9842-03b826624a65"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(256,256), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(256,256), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1631269247223,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631295956324,"user_tz":-540,"elapsed":26709119,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dd5c581b-8aea-40ac-bb79-fe6ce275870b"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 89s 1s/step - loss: 2.0341 - accuracy: 0.2759 - val_loss: 29.3041 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 50s 957ms/step - loss: 1.3000 - accuracy: 0.5688 - val_loss: 7.0138 - val_accuracy: 0.1429\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.14286, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 50s 955ms/step - loss: 1.0186 - accuracy: 0.6474 - val_loss: 55.6187 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.14286\n","Epoch 4/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.8476 - accuracy: 0.7144 - val_loss: 11.9148 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.14286\n","Epoch 5/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.7374 - accuracy: 0.7448 - val_loss: 8.6950 - val_accuracy: 0.1133\n","\n","Epoch 00005: val_accuracy did not improve from 0.14286\n","Epoch 6/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.6999 - accuracy: 0.7637 - val_loss: 8.5917 - val_accuracy: 0.2094\n","\n","Epoch 00006: val_accuracy improved from 0.14286 to 0.20936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.6099 - accuracy: 0.8027 - val_loss: 3.9050 - val_accuracy: 0.3547\n","\n","Epoch 00007: val_accuracy improved from 0.20936 to 0.35468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.5263 - accuracy: 0.8325 - val_loss: 4.2951 - val_accuracy: 0.3227\n","\n","Epoch 00008: val_accuracy did not improve from 0.35468\n","Epoch 9/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.4501 - accuracy: 0.8538 - val_loss: 3.9733 - val_accuracy: 0.3030\n","\n","Epoch 00009: val_accuracy did not improve from 0.35468\n","Epoch 10/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.5055 - accuracy: 0.8264 - val_loss: 3.5010 - val_accuracy: 0.4433\n","\n","Epoch 00010: val_accuracy improved from 0.35468 to 0.44335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.4969 - accuracy: 0.8368 - val_loss: 2.3469 - val_accuracy: 0.5271\n","\n","Epoch 00011: val_accuracy improved from 0.44335 to 0.52709, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.4065 - accuracy: 0.8672 - val_loss: 1.4661 - val_accuracy: 0.6453\n","\n","Epoch 00012: val_accuracy improved from 0.52709 to 0.64532, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.4028 - accuracy: 0.8618 - val_loss: 2.8949 - val_accuracy: 0.5197\n","\n","Epoch 00013: val_accuracy did not improve from 0.64532\n","Epoch 14/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.4301 - accuracy: 0.8477 - val_loss: 0.9305 - val_accuracy: 0.7660\n","\n","Epoch 00014: val_accuracy improved from 0.64532 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.3281 - accuracy: 0.8904 - val_loss: 1.2514 - val_accuracy: 0.6724\n","\n","Epoch 00015: val_accuracy did not improve from 0.76601\n","Epoch 16/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.3124 - accuracy: 0.8977 - val_loss: 0.7594 - val_accuracy: 0.8153\n","\n","Epoch 00016: val_accuracy improved from 0.76601 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.3143 - accuracy: 0.8922 - val_loss: 0.7957 - val_accuracy: 0.8005\n","\n","Epoch 00017: val_accuracy did not improve from 0.81527\n","Epoch 18/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.2682 - accuracy: 0.9111 - val_loss: 1.3931 - val_accuracy: 0.6626\n","\n","Epoch 00018: val_accuracy did not improve from 0.81527\n","Epoch 19/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.3151 - accuracy: 0.8916 - val_loss: 1.3625 - val_accuracy: 0.6576\n","\n","Epoch 00019: val_accuracy did not improve from 0.81527\n","Epoch 20/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.2787 - accuracy: 0.9062 - val_loss: 0.7077 - val_accuracy: 0.8227\n","\n","Epoch 00020: val_accuracy improved from 0.81527 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 21/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.2254 - accuracy: 0.9178 - val_loss: 0.7756 - val_accuracy: 0.7931\n","\n","Epoch 00021: val_accuracy did not improve from 0.82266\n","Epoch 22/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1905 - accuracy: 0.9391 - val_loss: 0.6404 - val_accuracy: 0.8227\n","\n","Epoch 00022: val_accuracy did not improve from 0.82266\n","Epoch 23/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.2107 - accuracy: 0.9294 - val_loss: 0.6856 - val_accuracy: 0.8128\n","\n","Epoch 00023: val_accuracy did not improve from 0.82266\n","Epoch 24/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.2345 - accuracy: 0.9178 - val_loss: 1.3661 - val_accuracy: 0.6970\n","\n","Epoch 00024: val_accuracy did not improve from 0.82266\n","Epoch 25/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.2020 - accuracy: 0.9391 - val_loss: 0.6002 - val_accuracy: 0.8473\n","\n","Epoch 00025: val_accuracy improved from 0.82266 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.2047 - accuracy: 0.9306 - val_loss: 0.6171 - val_accuracy: 0.8128\n","\n","Epoch 00026: val_accuracy did not improve from 0.84729\n","Epoch 27/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1870 - accuracy: 0.9342 - val_loss: 0.5128 - val_accuracy: 0.8300\n","\n","Epoch 00027: val_accuracy did not improve from 0.84729\n","Epoch 28/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.2341 - accuracy: 0.9178 - val_loss: 1.0545 - val_accuracy: 0.7783\n","\n","Epoch 00028: val_accuracy did not improve from 0.84729\n","Epoch 29/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.1791 - accuracy: 0.9452 - val_loss: 0.4970 - val_accuracy: 0.8522\n","\n","Epoch 00029: val_accuracy improved from 0.84729 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 30/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.1579 - accuracy: 0.9507 - val_loss: 1.4026 - val_accuracy: 0.6823\n","\n","Epoch 00030: val_accuracy did not improve from 0.85222\n","Epoch 31/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1972 - accuracy: 0.9324 - val_loss: 0.8366 - val_accuracy: 0.7882\n","\n","Epoch 00031: val_accuracy did not improve from 0.85222\n","Epoch 32/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1548 - accuracy: 0.9379 - val_loss: 1.1153 - val_accuracy: 0.7365\n","\n","Epoch 00032: val_accuracy did not improve from 0.85222\n","Epoch 33/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1305 - accuracy: 0.9488 - val_loss: 1.1334 - val_accuracy: 0.7143\n","\n","Epoch 00033: val_accuracy did not improve from 0.85222\n","Epoch 34/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1161 - accuracy: 0.9568 - val_loss: 0.6782 - val_accuracy: 0.8251\n","\n","Epoch 00034: val_accuracy did not improve from 0.85222\n","Epoch 35/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.1199 - accuracy: 0.9592 - val_loss: 0.4491 - val_accuracy: 0.8695\n","\n","Epoch 00035: val_accuracy improved from 0.85222 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1420 - accuracy: 0.9501 - val_loss: 0.6226 - val_accuracy: 0.8350\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1447 - accuracy: 0.9562 - val_loss: 0.7422 - val_accuracy: 0.8251\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1238 - accuracy: 0.9592 - val_loss: 0.6731 - val_accuracy: 0.8399\n","\n","Epoch 00038: val_accuracy did not improve from 0.86946\n","Epoch 39/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1421 - accuracy: 0.9501 - val_loss: 0.5203 - val_accuracy: 0.8719\n","\n","Epoch 00039: val_accuracy improved from 0.86946 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 40/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0828 - accuracy: 0.9720 - val_loss: 0.5933 - val_accuracy: 0.8498\n","\n","Epoch 00040: val_accuracy did not improve from 0.87192\n","Epoch 41/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0961 - accuracy: 0.9677 - val_loss: 0.6120 - val_accuracy: 0.8350\n","\n","Epoch 00041: val_accuracy did not improve from 0.87192\n","Epoch 42/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1048 - accuracy: 0.9695 - val_loss: 0.5474 - val_accuracy: 0.8695\n","\n","Epoch 00042: val_accuracy did not improve from 0.87192\n","Epoch 43/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1080 - accuracy: 0.9635 - val_loss: 0.7698 - val_accuracy: 0.8473\n","\n","Epoch 00043: val_accuracy did not improve from 0.87192\n","Epoch 44/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.1016 - accuracy: 0.9629 - val_loss: 0.5753 - val_accuracy: 0.8522\n","\n","Epoch 00044: val_accuracy did not improve from 0.87192\n","Epoch 45/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1343 - accuracy: 0.9562 - val_loss: 1.5018 - val_accuracy: 0.6995\n","\n","Epoch 00045: val_accuracy did not improve from 0.87192\n","Epoch 46/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1437 - accuracy: 0.9482 - val_loss: 0.5863 - val_accuracy: 0.8621\n","\n","Epoch 00046: val_accuracy did not improve from 0.87192\n","Epoch 47/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1004 - accuracy: 0.9671 - val_loss: 0.6335 - val_accuracy: 0.8744\n","\n","Epoch 00047: val_accuracy improved from 0.87192 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 48/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.1100 - accuracy: 0.9604 - val_loss: 0.5110 - val_accuracy: 0.8842\n","\n","Epoch 00048: val_accuracy improved from 0.87438 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 49/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0826 - accuracy: 0.9762 - val_loss: 0.5591 - val_accuracy: 0.8522\n","\n","Epoch 00049: val_accuracy did not improve from 0.88424\n","Epoch 50/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1179 - accuracy: 0.9592 - val_loss: 1.8346 - val_accuracy: 0.6576\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1137 - accuracy: 0.9635 - val_loss: 0.9262 - val_accuracy: 0.8030\n","\n","Epoch 00051: val_accuracy did not improve from 0.88424\n","Epoch 52/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0768 - accuracy: 0.9775 - val_loss: 0.3427 - val_accuracy: 0.9113\n","\n","Epoch 00052: val_accuracy improved from 0.88424 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 53/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 0.3205 - val_accuracy: 0.9015\n","\n","Epoch 00053: val_accuracy did not improve from 0.91133\n","Epoch 54/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.6522 - val_accuracy: 0.8596\n","\n","Epoch 00054: val_accuracy did not improve from 0.91133\n","Epoch 55/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1333 - accuracy: 0.9476 - val_loss: 1.4619 - val_accuracy: 0.7069\n","\n","Epoch 00055: val_accuracy did not improve from 0.91133\n","Epoch 56/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.1223 - accuracy: 0.9598 - val_loss: 0.8103 - val_accuracy: 0.8350\n","\n","Epoch 00056: val_accuracy did not improve from 0.91133\n","Epoch 57/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1019 - accuracy: 0.9641 - val_loss: 0.4188 - val_accuracy: 0.8842\n","\n","Epoch 00057: val_accuracy did not improve from 0.91133\n","Epoch 58/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.3994 - val_accuracy: 0.8818\n","\n","Epoch 00058: val_accuracy did not improve from 0.91133\n","Epoch 59/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.3735 - val_accuracy: 0.8916\n","\n","Epoch 00059: val_accuracy did not improve from 0.91133\n","Epoch 60/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0713 - accuracy: 0.9762 - val_loss: 0.4601 - val_accuracy: 0.8916\n","\n","Epoch 00060: val_accuracy did not improve from 0.91133\n","Epoch 61/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 0.4930 - val_accuracy: 0.8768\n","\n","Epoch 00061: val_accuracy did not improve from 0.91133\n","Epoch 62/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0699 - accuracy: 0.9775 - val_loss: 0.7120 - val_accuracy: 0.8596\n","\n","Epoch 00062: val_accuracy did not improve from 0.91133\n","Epoch 63/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0769 - accuracy: 0.9750 - val_loss: 0.5676 - val_accuracy: 0.8719\n","\n","Epoch 00063: val_accuracy did not improve from 0.91133\n","Epoch 64/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.4199 - val_accuracy: 0.8941\n","\n","Epoch 00064: val_accuracy did not improve from 0.91133\n","Epoch 65/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0708 - accuracy: 0.9762 - val_loss: 0.4499 - val_accuracy: 0.8818\n","\n","Epoch 00065: val_accuracy did not improve from 0.91133\n","Epoch 66/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0670 - accuracy: 0.9787 - val_loss: 0.4665 - val_accuracy: 0.8892\n","\n","Epoch 00066: val_accuracy did not improve from 0.91133\n","Epoch 67/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.9355 - val_accuracy: 0.7931\n","\n","Epoch 00067: val_accuracy did not improve from 0.91133\n","Epoch 68/500\n","52/52 [==============================] - 50s 952ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.4180 - val_accuracy: 0.8941\n","\n","Epoch 00068: val_accuracy did not improve from 0.91133\n","Epoch 69/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0670 - accuracy: 0.9726 - val_loss: 0.9720 - val_accuracy: 0.8399\n","\n","Epoch 00069: val_accuracy did not improve from 0.91133\n","Epoch 70/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0601 - accuracy: 0.9762 - val_loss: 0.6439 - val_accuracy: 0.8424\n","\n","Epoch 00070: val_accuracy did not improve from 0.91133\n","Epoch 71/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0656 - accuracy: 0.9787 - val_loss: 0.8865 - val_accuracy: 0.8103\n","\n","Epoch 00071: val_accuracy did not improve from 0.91133\n","Epoch 72/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.0742 - accuracy: 0.9738 - val_loss: 0.4862 - val_accuracy: 0.8818\n","\n","Epoch 00072: val_accuracy did not improve from 0.91133\n","Epoch 73/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0856 - accuracy: 0.9714 - val_loss: 0.6049 - val_accuracy: 0.8695\n","\n","Epoch 00073: val_accuracy did not improve from 0.91133\n","Epoch 74/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1207 - accuracy: 0.9665 - val_loss: 1.0409 - val_accuracy: 0.8202\n","\n","Epoch 00074: val_accuracy did not improve from 0.91133\n","Epoch 75/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0895 - accuracy: 0.9695 - val_loss: 0.7566 - val_accuracy: 0.8522\n","\n","Epoch 00075: val_accuracy did not improve from 0.91133\n","Epoch 76/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.0497 - accuracy: 0.9854 - val_loss: 0.5539 - val_accuracy: 0.8793\n","\n","Epoch 00076: val_accuracy did not improve from 0.91133\n","Epoch 77/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.3259 - val_accuracy: 0.9236\n","\n","Epoch 00077: val_accuracy improved from 0.91133 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 78/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.4158 - val_accuracy: 0.9113\n","\n","Epoch 00078: val_accuracy did not improve from 0.92365\n","Epoch 79/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.5809 - val_accuracy: 0.8867\n","\n","Epoch 00079: val_accuracy did not improve from 0.92365\n","Epoch 80/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.4822 - val_accuracy: 0.8818\n","\n","Epoch 00080: val_accuracy did not improve from 0.92365\n","Epoch 81/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.4513 - val_accuracy: 0.8966\n","\n","Epoch 00081: val_accuracy did not improve from 0.92365\n","Epoch 82/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.3956 - val_accuracy: 0.8842\n","\n","Epoch 00082: val_accuracy did not improve from 0.92365\n","Epoch 83/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.5713 - val_accuracy: 0.8793\n","\n","Epoch 00083: val_accuracy did not improve from 0.92365\n","Epoch 84/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0929 - accuracy: 0.9677 - val_loss: 0.6821 - val_accuracy: 0.8670\n","\n","Epoch 00084: val_accuracy did not improve from 0.92365\n","Epoch 85/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0519 - accuracy: 0.9805 - val_loss: 0.4499 - val_accuracy: 0.8867\n","\n","Epoch 00085: val_accuracy did not improve from 0.92365\n","Epoch 86/500\n","52/52 [==============================] - 50s 953ms/step - loss: 0.0527 - accuracy: 0.9842 - val_loss: 0.4155 - val_accuracy: 0.8793\n","\n","Epoch 00086: val_accuracy did not improve from 0.92365\n","Epoch 87/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.4094 - val_accuracy: 0.8916\n","\n","Epoch 00087: val_accuracy did not improve from 0.92365\n","Epoch 88/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.4252 - val_accuracy: 0.8990\n","\n","Epoch 00088: val_accuracy did not improve from 0.92365\n","Epoch 89/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.3651 - val_accuracy: 0.9064\n","\n","Epoch 00089: val_accuracy did not improve from 0.92365\n","Epoch 90/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.5199 - val_accuracy: 0.8842\n","\n","Epoch 00090: val_accuracy did not improve from 0.92365\n","Epoch 91/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0727 - accuracy: 0.9781 - val_loss: 1.8202 - val_accuracy: 0.7340\n","\n","Epoch 00091: val_accuracy did not improve from 0.92365\n","Epoch 92/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 1.2494 - val_accuracy: 0.7931\n","\n","Epoch 00092: val_accuracy did not improve from 0.92365\n","Epoch 93/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.1148 - accuracy: 0.9653 - val_loss: 0.8834 - val_accuracy: 0.8300\n","\n","Epoch 00093: val_accuracy did not improve from 0.92365\n","Epoch 94/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0589 - accuracy: 0.9793 - val_loss: 0.8126 - val_accuracy: 0.8448\n","\n","Epoch 00094: val_accuracy did not improve from 0.92365\n","Epoch 95/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0464 - accuracy: 0.9884 - val_loss: 0.6489 - val_accuracy: 0.8793\n","\n","Epoch 00095: val_accuracy did not improve from 0.92365\n","Epoch 96/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0433 - accuracy: 0.9872 - val_loss: 0.7699 - val_accuracy: 0.8498\n","\n","Epoch 00096: val_accuracy did not improve from 0.92365\n","Epoch 97/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0599 - accuracy: 0.9781 - val_loss: 0.6682 - val_accuracy: 0.8768\n","\n","Epoch 00097: val_accuracy did not improve from 0.92365\n","Epoch 98/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.5312 - val_accuracy: 0.8670\n","\n","Epoch 00098: val_accuracy did not improve from 0.92365\n","Epoch 99/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0700 - accuracy: 0.9823 - val_loss: 0.7491 - val_accuracy: 0.8522\n","\n","Epoch 00099: val_accuracy did not improve from 0.92365\n","Epoch 100/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.6696 - val_accuracy: 0.8645\n","\n","Epoch 00100: val_accuracy did not improve from 0.92365\n","Epoch 101/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.4208 - val_accuracy: 0.9113\n","\n","Epoch 00101: val_accuracy did not improve from 0.92365\n","Epoch 102/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0316 - accuracy: 0.9866 - val_loss: 0.4423 - val_accuracy: 0.9015\n","\n","Epoch 00102: val_accuracy did not improve from 0.92365\n","Epoch 103/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.5785 - val_accuracy: 0.8892\n","\n","Epoch 00103: val_accuracy did not improve from 0.92365\n","Epoch 104/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.3551 - val_accuracy: 0.9212\n","\n","Epoch 00104: val_accuracy did not improve from 0.92365\n","Epoch 105/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.3808 - val_accuracy: 0.9163\n","\n","Epoch 00105: val_accuracy did not improve from 0.92365\n","Epoch 106/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.4784 - val_accuracy: 0.8966\n","\n","Epoch 00106: val_accuracy did not improve from 0.92365\n","Epoch 107/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.7314 - val_accuracy: 0.8498\n","\n","Epoch 00107: val_accuracy did not improve from 0.92365\n","Epoch 108/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1107 - accuracy: 0.9683 - val_loss: 1.0203 - val_accuracy: 0.8177\n","\n","Epoch 00108: val_accuracy did not improve from 0.92365\n","Epoch 109/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.5508 - val_accuracy: 0.8793\n","\n","Epoch 00109: val_accuracy did not improve from 0.92365\n","Epoch 110/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 0.4849 - val_accuracy: 0.8916\n","\n","Epoch 00110: val_accuracy did not improve from 0.92365\n","Epoch 111/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.4034 - val_accuracy: 0.9089\n","\n","Epoch 00111: val_accuracy did not improve from 0.92365\n","Epoch 112/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.4075 - val_accuracy: 0.9187\n","\n","Epoch 00112: val_accuracy did not improve from 0.92365\n","Epoch 113/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.4554 - val_accuracy: 0.8916\n","\n","Epoch 00113: val_accuracy did not improve from 0.92365\n","Epoch 114/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.5779 - val_accuracy: 0.8867\n","\n","Epoch 00114: val_accuracy did not improve from 0.92365\n","Epoch 115/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.8928 - val_accuracy: 0.8202\n","\n","Epoch 00115: val_accuracy did not improve from 0.92365\n","Epoch 116/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 0.5673 - val_accuracy: 0.8867\n","\n","Epoch 00116: val_accuracy did not improve from 0.92365\n","Epoch 117/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.4867 - val_accuracy: 0.8744\n","\n","Epoch 00117: val_accuracy did not improve from 0.92365\n","Epoch 118/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.5035 - val_accuracy: 0.8916\n","\n","Epoch 00118: val_accuracy did not improve from 0.92365\n","Epoch 119/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.5215 - val_accuracy: 0.8941\n","\n","Epoch 00119: val_accuracy did not improve from 0.92365\n","Epoch 120/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0190 - accuracy: 0.9903 - val_loss: 0.6584 - val_accuracy: 0.8867\n","\n","Epoch 00120: val_accuracy did not improve from 0.92365\n","Epoch 121/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.4131 - val_accuracy: 0.9113\n","\n","Epoch 00121: val_accuracy did not improve from 0.92365\n","Epoch 122/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0325 - accuracy: 0.9872 - val_loss: 0.7182 - val_accuracy: 0.8498\n","\n","Epoch 00122: val_accuracy did not improve from 0.92365\n","Epoch 123/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.5885 - val_accuracy: 0.8867\n","\n","Epoch 00123: val_accuracy did not improve from 0.92365\n","Epoch 124/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 1.0743 - val_accuracy: 0.8103\n","\n","Epoch 00124: val_accuracy did not improve from 0.92365\n","Epoch 125/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.4143 - val_accuracy: 0.8990\n","\n","Epoch 00125: val_accuracy did not improve from 0.92365\n","Epoch 126/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.5162 - val_accuracy: 0.8892\n","\n","Epoch 00126: val_accuracy did not improve from 0.92365\n","Epoch 127/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 0.5863 - val_accuracy: 0.8768\n","\n","Epoch 00127: val_accuracy did not improve from 0.92365\n","Epoch 128/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5036 - val_accuracy: 0.9015\n","\n","Epoch 00128: val_accuracy did not improve from 0.92365\n","Epoch 129/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0386 - accuracy: 0.9903 - val_loss: 0.7781 - val_accuracy: 0.8448\n","\n","Epoch 00129: val_accuracy did not improve from 0.92365\n","Epoch 130/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.1070 - accuracy: 0.9689 - val_loss: 1.1518 - val_accuracy: 0.8079\n","\n","Epoch 00130: val_accuracy did not improve from 0.92365\n","Epoch 131/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0883 - accuracy: 0.9738 - val_loss: 0.7709 - val_accuracy: 0.8522\n","\n","Epoch 00131: val_accuracy did not improve from 0.92365\n","Epoch 132/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0675 - accuracy: 0.9781 - val_loss: 0.7240 - val_accuracy: 0.8670\n","\n","Epoch 00132: val_accuracy did not improve from 0.92365\n","Epoch 133/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.4188 - val_accuracy: 0.9113\n","\n","Epoch 00133: val_accuracy did not improve from 0.92365\n","Epoch 134/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0217 - accuracy: 0.9915 - val_loss: 0.3768 - val_accuracy: 0.9138\n","\n","Epoch 00134: val_accuracy did not improve from 0.92365\n","Epoch 135/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.3559 - val_accuracy: 0.9163\n","\n","Epoch 00135: val_accuracy did not improve from 0.92365\n","Epoch 136/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.3582 - val_accuracy: 0.9089\n","\n","Epoch 00136: val_accuracy did not improve from 0.92365\n","Epoch 137/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.4771 - val_accuracy: 0.8966\n","\n","Epoch 00137: val_accuracy did not improve from 0.92365\n","Epoch 138/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.3110 - val_accuracy: 0.9187\n","\n","Epoch 00138: val_accuracy did not improve from 0.92365\n","Epoch 139/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4444 - val_accuracy: 0.8867\n","\n","Epoch 00139: val_accuracy did not improve from 0.92365\n","Epoch 140/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.4094 - val_accuracy: 0.9039\n","\n","Epoch 00140: val_accuracy did not improve from 0.92365\n","Epoch 141/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.4054 - val_accuracy: 0.9039\n","\n","Epoch 00141: val_accuracy did not improve from 0.92365\n","Epoch 142/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4313 - val_accuracy: 0.9039\n","\n","Epoch 00142: val_accuracy did not improve from 0.92365\n","Epoch 143/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3529 - val_accuracy: 0.9113\n","\n","Epoch 00143: val_accuracy did not improve from 0.92365\n","Epoch 144/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3964 - val_accuracy: 0.9039\n","\n","Epoch 00144: val_accuracy did not improve from 0.92365\n","Epoch 145/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3879 - val_accuracy: 0.9163\n","\n","Epoch 00145: val_accuracy did not improve from 0.92365\n","Epoch 146/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.4823 - val_accuracy: 0.9015\n","\n","Epoch 00146: val_accuracy did not improve from 0.92365\n","Epoch 147/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.8187 - val_accuracy: 0.8547\n","\n","Epoch 00147: val_accuracy did not improve from 0.92365\n","Epoch 148/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 1.3840 - val_accuracy: 0.8054\n","\n","Epoch 00148: val_accuracy did not improve from 0.92365\n","Epoch 149/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 0.6790 - val_accuracy: 0.8695\n","\n","Epoch 00149: val_accuracy did not improve from 0.92365\n","Epoch 150/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.1861 - accuracy: 0.9446 - val_loss: 1.2447 - val_accuracy: 0.8177\n","\n","Epoch 00150: val_accuracy did not improve from 0.92365\n","Epoch 151/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.1183 - accuracy: 0.9622 - val_loss: 0.7485 - val_accuracy: 0.8448\n","\n","Epoch 00151: val_accuracy did not improve from 0.92365\n","Epoch 152/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0722 - accuracy: 0.9762 - val_loss: 0.5389 - val_accuracy: 0.8842\n","\n","Epoch 00152: val_accuracy did not improve from 0.92365\n","Epoch 153/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.4213 - val_accuracy: 0.9064\n","\n","Epoch 00153: val_accuracy did not improve from 0.92365\n","Epoch 154/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.3318 - val_accuracy: 0.9212\n","\n","Epoch 00154: val_accuracy did not improve from 0.92365\n","Epoch 155/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3247 - val_accuracy: 0.9286\n","\n","Epoch 00155: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 156/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3686 - val_accuracy: 0.9212\n","\n","Epoch 00156: val_accuracy did not improve from 0.92857\n","Epoch 157/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4428 - val_accuracy: 0.9064\n","\n","Epoch 00157: val_accuracy did not improve from 0.92857\n","Epoch 158/500\n","52/52 [==============================] - 50s 955ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9113\n","\n","Epoch 00158: val_accuracy did not improve from 0.92857\n","Epoch 159/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.3921 - val_accuracy: 0.9286\n","\n","Epoch 00159: val_accuracy did not improve from 0.92857\n","Epoch 160/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.3727 - val_accuracy: 0.9163\n","\n","Epoch 00160: val_accuracy did not improve from 0.92857\n","Epoch 161/500\n","52/52 [==============================] - 50s 954ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.3296 - val_accuracy: 0.9163\n","\n","Epoch 00161: val_accuracy did not improve from 0.92857\n","Epoch 162/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.3449 - val_accuracy: 0.9236\n","\n","Epoch 00162: val_accuracy did not improve from 0.92857\n","Epoch 163/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9384\n","\n","Epoch 00163: val_accuracy improved from 0.92857 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 164/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.3878 - val_accuracy: 0.9089\n","\n","Epoch 00164: val_accuracy did not improve from 0.93842\n","Epoch 165/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.3341 - val_accuracy: 0.9039\n","\n","Epoch 00165: val_accuracy did not improve from 0.93842\n","Epoch 166/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4003 - val_accuracy: 0.9261\n","\n","Epoch 00166: val_accuracy did not improve from 0.93842\n","Epoch 167/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0269 - accuracy: 0.9939 - val_loss: 0.8660 - val_accuracy: 0.8547\n","\n","Epoch 00167: val_accuracy did not improve from 0.93842\n","Epoch 168/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.7353 - val_accuracy: 0.8670\n","\n","Epoch 00168: val_accuracy did not improve from 0.93842\n","Epoch 169/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.6816 - val_accuracy: 0.8744\n","\n","Epoch 00169: val_accuracy did not improve from 0.93842\n","Epoch 170/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.5307 - val_accuracy: 0.8966\n","\n","Epoch 00170: val_accuracy did not improve from 0.93842\n","Epoch 171/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.4616 - val_accuracy: 0.9039\n","\n","Epoch 00171: val_accuracy did not improve from 0.93842\n","Epoch 172/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.9766 - val_accuracy: 0.8374\n","\n","Epoch 00172: val_accuracy did not improve from 0.93842\n","Epoch 173/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0507 - accuracy: 0.9811 - val_loss: 0.5189 - val_accuracy: 0.9039\n","\n","Epoch 00173: val_accuracy did not improve from 0.93842\n","Epoch 174/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0747 - accuracy: 0.9762 - val_loss: 0.7428 - val_accuracy: 0.8695\n","\n","Epoch 00174: val_accuracy did not improve from 0.93842\n","Epoch 175/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.6622 - val_accuracy: 0.8768\n","\n","Epoch 00175: val_accuracy did not improve from 0.93842\n","Epoch 176/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0485 - accuracy: 0.9848 - val_loss: 0.6267 - val_accuracy: 0.8768\n","\n","Epoch 00176: val_accuracy did not improve from 0.93842\n","Epoch 177/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0209 - accuracy: 0.9915 - val_loss: 0.5267 - val_accuracy: 0.8941\n","\n","Epoch 00177: val_accuracy did not improve from 0.93842\n","Epoch 178/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0133 - accuracy: 0.9939 - val_loss: 0.5192 - val_accuracy: 0.8867\n","\n","Epoch 00178: val_accuracy did not improve from 0.93842\n","Epoch 179/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.6110 - val_accuracy: 0.8818\n","\n","Epoch 00179: val_accuracy did not improve from 0.93842\n","Epoch 180/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 0.5120 - val_accuracy: 0.8867\n","\n","Epoch 00180: val_accuracy did not improve from 0.93842\n","Epoch 181/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.5009 - val_accuracy: 0.9113\n","\n","Epoch 00181: val_accuracy did not improve from 0.93842\n","Epoch 182/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3938 - val_accuracy: 0.9163\n","\n","Epoch 00182: val_accuracy did not improve from 0.93842\n","Epoch 183/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.4575 - val_accuracy: 0.9187\n","\n","Epoch 00183: val_accuracy did not improve from 0.93842\n","Epoch 184/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.3860 - val_accuracy: 0.8966\n","\n","Epoch 00184: val_accuracy did not improve from 0.93842\n","Epoch 185/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4443 - val_accuracy: 0.9039\n","\n","Epoch 00185: val_accuracy did not improve from 0.93842\n","Epoch 186/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.4937 - val_accuracy: 0.9113\n","\n","Epoch 00186: val_accuracy did not improve from 0.93842\n","Epoch 187/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6451 - val_accuracy: 0.8842\n","\n","Epoch 00187: val_accuracy did not improve from 0.93842\n","Epoch 188/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.5000 - val_accuracy: 0.8966\n","\n","Epoch 00188: val_accuracy did not improve from 0.93842\n","Epoch 189/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.6820 - val_accuracy: 0.8867\n","\n","Epoch 00189: val_accuracy did not improve from 0.93842\n","Epoch 190/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.5945 - val_accuracy: 0.8990\n","\n","Epoch 00190: val_accuracy did not improve from 0.93842\n","Epoch 191/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.5058 - val_accuracy: 0.9236\n","\n","Epoch 00191: val_accuracy did not improve from 0.93842\n","Epoch 192/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.8471 - val_accuracy: 0.8719\n","\n","Epoch 00192: val_accuracy did not improve from 0.93842\n","Epoch 193/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.6337 - val_accuracy: 0.8916\n","\n","Epoch 00193: val_accuracy did not improve from 0.93842\n","Epoch 194/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.5860 - val_accuracy: 0.8867\n","\n","Epoch 00194: val_accuracy did not improve from 0.93842\n","Epoch 195/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0325 - accuracy: 0.9921 - val_loss: 0.7766 - val_accuracy: 0.8621\n","\n","Epoch 00195: val_accuracy did not improve from 0.93842\n","Epoch 196/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0545 - accuracy: 0.9842 - val_loss: 0.9875 - val_accuracy: 0.8276\n","\n","Epoch 00196: val_accuracy did not improve from 0.93842\n","Epoch 197/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 1.0564 - val_accuracy: 0.8103\n","\n","Epoch 00197: val_accuracy did not improve from 0.93842\n","Epoch 198/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.4151 - val_accuracy: 0.9138\n","\n","Epoch 00198: val_accuracy did not improve from 0.93842\n","Epoch 199/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0377 - accuracy: 0.9860 - val_loss: 1.2212 - val_accuracy: 0.8424\n","\n","Epoch 00199: val_accuracy did not improve from 0.93842\n","Epoch 200/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 1.0597 - val_accuracy: 0.8276\n","\n","Epoch 00200: val_accuracy did not improve from 0.93842\n","Epoch 201/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.6461 - val_accuracy: 0.8645\n","\n","Epoch 00201: val_accuracy did not improve from 0.93842\n","Epoch 202/500\n","52/52 [==============================] - 50s 970ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.7034 - val_accuracy: 0.8695\n","\n","Epoch 00202: val_accuracy did not improve from 0.93842\n","Epoch 203/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.4133 - val_accuracy: 0.9187\n","\n","Epoch 00203: val_accuracy did not improve from 0.93842\n","Epoch 204/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.6152 - val_accuracy: 0.9015\n","\n","Epoch 00204: val_accuracy did not improve from 0.93842\n","Epoch 205/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4261 - val_accuracy: 0.9039\n","\n","Epoch 00205: val_accuracy did not improve from 0.93842\n","Epoch 206/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3965 - val_accuracy: 0.9089\n","\n","Epoch 00206: val_accuracy did not improve from 0.93842\n","Epoch 207/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4132 - val_accuracy: 0.9039\n","\n","Epoch 00207: val_accuracy did not improve from 0.93842\n","Epoch 208/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.6430 - val_accuracy: 0.8892\n","\n","Epoch 00208: val_accuracy did not improve from 0.93842\n","Epoch 209/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4621 - val_accuracy: 0.9064\n","\n","Epoch 00209: val_accuracy did not improve from 0.93842\n","Epoch 210/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4369 - val_accuracy: 0.9138\n","\n","Epoch 00210: val_accuracy did not improve from 0.93842\n","Epoch 211/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3833 - val_accuracy: 0.9212\n","\n","Epoch 00211: val_accuracy did not improve from 0.93842\n","Epoch 212/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3381 - val_accuracy: 0.9286\n","\n","Epoch 00212: val_accuracy did not improve from 0.93842\n","Epoch 213/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.4096 - val_accuracy: 0.9212\n","\n","Epoch 00213: val_accuracy did not improve from 0.93842\n","Epoch 214/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4104 - val_accuracy: 0.9187\n","\n","Epoch 00214: val_accuracy did not improve from 0.93842\n","Epoch 215/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3575 - val_accuracy: 0.9286\n","\n","Epoch 00215: val_accuracy did not improve from 0.93842\n","Epoch 216/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4566 - val_accuracy: 0.8916\n","\n","Epoch 00216: val_accuracy did not improve from 0.93842\n","Epoch 217/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3607 - val_accuracy: 0.9236\n","\n","Epoch 00217: val_accuracy did not improve from 0.93842\n","Epoch 218/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4190 - val_accuracy: 0.9039\n","\n","Epoch 00218: val_accuracy did not improve from 0.93842\n","Epoch 219/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3853 - val_accuracy: 0.9261\n","\n","Epoch 00219: val_accuracy did not improve from 0.93842\n","Epoch 220/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.3761 - val_accuracy: 0.9015\n","\n","Epoch 00220: val_accuracy did not improve from 0.93842\n","Epoch 221/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9089\n","\n","Epoch 00221: val_accuracy did not improve from 0.93842\n","Epoch 222/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5021 - val_accuracy: 0.9089\n","\n","Epoch 00222: val_accuracy did not improve from 0.93842\n","Epoch 223/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5448 - val_accuracy: 0.8818\n","\n","Epoch 00223: val_accuracy did not improve from 0.93842\n","Epoch 224/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3603 - val_accuracy: 0.9113\n","\n","Epoch 00224: val_accuracy did not improve from 0.93842\n","Epoch 225/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9163\n","\n","Epoch 00225: val_accuracy did not improve from 0.93842\n","Epoch 226/500\n","52/52 [==============================] - 50s 962ms/step - loss: 8.7451e-04 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9163\n","\n","Epoch 00226: val_accuracy did not improve from 0.93842\n","Epoch 227/500\n","52/52 [==============================] - 50s 961ms/step - loss: 7.3311e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9384\n","\n","Epoch 00227: val_accuracy did not improve from 0.93842\n","Epoch 228/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4374 - val_accuracy: 0.9163\n","\n","Epoch 00228: val_accuracy did not improve from 0.93842\n","Epoch 229/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 2.7196 - val_accuracy: 0.6946\n","\n","Epoch 00229: val_accuracy did not improve from 0.93842\n","Epoch 230/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 32.6443 - val_accuracy: 0.1355\n","\n","Epoch 00230: val_accuracy did not improve from 0.93842\n","Epoch 231/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0669 - accuracy: 0.9738 - val_loss: 1.0734 - val_accuracy: 0.8374\n","\n","Epoch 00231: val_accuracy did not improve from 0.93842\n","Epoch 232/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0560 - accuracy: 0.9781 - val_loss: 0.8849 - val_accuracy: 0.8793\n","\n","Epoch 00232: val_accuracy did not improve from 0.93842\n","Epoch 233/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.9676 - val_accuracy: 0.8276\n","\n","Epoch 00233: val_accuracy did not improve from 0.93842\n","Epoch 234/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.8980 - val_accuracy: 0.8645\n","\n","Epoch 00234: val_accuracy did not improve from 0.93842\n","Epoch 235/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0344 - accuracy: 0.9872 - val_loss: 0.6230 - val_accuracy: 0.8719\n","\n","Epoch 00235: val_accuracy did not improve from 0.93842\n","Epoch 236/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.4499 - val_accuracy: 0.8990\n","\n","Epoch 00236: val_accuracy did not improve from 0.93842\n","Epoch 237/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.3652 - val_accuracy: 0.9212\n","\n","Epoch 00237: val_accuracy did not improve from 0.93842\n","Epoch 238/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4444 - val_accuracy: 0.9236\n","\n","Epoch 00238: val_accuracy did not improve from 0.93842\n","Epoch 239/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.4648 - val_accuracy: 0.9138\n","\n","Epoch 00239: val_accuracy did not improve from 0.93842\n","Epoch 240/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4358 - val_accuracy: 0.9089\n","\n","Epoch 00240: val_accuracy did not improve from 0.93842\n","Epoch 241/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4868 - val_accuracy: 0.9089\n","\n","Epoch 00241: val_accuracy did not improve from 0.93842\n","Epoch 242/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5837 - val_accuracy: 0.8867\n","\n","Epoch 00242: val_accuracy did not improve from 0.93842\n","Epoch 243/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4441 - val_accuracy: 0.9089\n","\n","Epoch 00243: val_accuracy did not improve from 0.93842\n","Epoch 244/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.4615 - val_accuracy: 0.9015\n","\n","Epoch 00244: val_accuracy did not improve from 0.93842\n","Epoch 245/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 1.4497 - val_accuracy: 0.7685\n","\n","Epoch 00245: val_accuracy did not improve from 0.93842\n","Epoch 246/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.6959 - val_accuracy: 0.8571\n","\n","Epoch 00246: val_accuracy did not improve from 0.93842\n","Epoch 247/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.5866 - val_accuracy: 0.8892\n","\n","Epoch 00247: val_accuracy did not improve from 0.93842\n","Epoch 248/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0228 - accuracy: 0.9909 - val_loss: 0.5122 - val_accuracy: 0.9089\n","\n","Epoch 00248: val_accuracy did not improve from 0.93842\n","Epoch 249/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0167 - accuracy: 0.9927 - val_loss: 0.6137 - val_accuracy: 0.8842\n","\n","Epoch 00249: val_accuracy did not improve from 0.93842\n","Epoch 250/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.4243 - val_accuracy: 0.9089\n","\n","Epoch 00250: val_accuracy did not improve from 0.93842\n","Epoch 251/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.6500 - val_accuracy: 0.8818\n","\n","Epoch 00251: val_accuracy did not improve from 0.93842\n","Epoch 252/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.6405 - val_accuracy: 0.8842\n","\n","Epoch 00252: val_accuracy did not improve from 0.93842\n","Epoch 253/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.5002 - val_accuracy: 0.9064\n","\n","Epoch 00253: val_accuracy did not improve from 0.93842\n","Epoch 254/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.6012 - val_accuracy: 0.9064\n","\n","Epoch 00254: val_accuracy did not improve from 0.93842\n","Epoch 255/500\n","52/52 [==============================] - 50s 973ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.4412 - val_accuracy: 0.9113\n","\n","Epoch 00255: val_accuracy did not improve from 0.93842\n","Epoch 256/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4282 - val_accuracy: 0.9212\n","\n","Epoch 00256: val_accuracy did not improve from 0.93842\n","Epoch 257/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.4411 - val_accuracy: 0.9089\n","\n","Epoch 00257: val_accuracy did not improve from 0.93842\n","Epoch 258/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.3946 - val_accuracy: 0.9286\n","\n","Epoch 00258: val_accuracy did not improve from 0.93842\n","Epoch 259/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4519 - val_accuracy: 0.9113\n","\n","Epoch 00259: val_accuracy did not improve from 0.93842\n","Epoch 260/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4057 - val_accuracy: 0.9015\n","\n","Epoch 00260: val_accuracy did not improve from 0.93842\n","Epoch 261/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.3930 - val_accuracy: 0.9212\n","\n","Epoch 00261: val_accuracy did not improve from 0.93842\n","Epoch 262/500\n","52/52 [==============================] - 50s 956ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4083 - val_accuracy: 0.9212\n","\n","Epoch 00262: val_accuracy did not improve from 0.93842\n","Epoch 263/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3831 - val_accuracy: 0.9261\n","\n","Epoch 00263: val_accuracy did not improve from 0.93842\n","Epoch 264/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.4480 - val_accuracy: 0.9039\n","\n","Epoch 00264: val_accuracy did not improve from 0.93842\n","Epoch 265/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4359 - val_accuracy: 0.9163\n","\n","Epoch 00265: val_accuracy did not improve from 0.93842\n","Epoch 266/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0392 - accuracy: 0.9903 - val_loss: 0.8539 - val_accuracy: 0.8571\n","\n","Epoch 00266: val_accuracy did not improve from 0.93842\n","Epoch 267/500\n","52/52 [==============================] - 50s 971ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.5454 - val_accuracy: 0.8966\n","\n","Epoch 00267: val_accuracy did not improve from 0.93842\n","Epoch 268/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.5171 - val_accuracy: 0.9113\n","\n","Epoch 00268: val_accuracy did not improve from 0.93842\n","Epoch 269/500\n","52/52 [==============================] - 50s 957ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.4649 - val_accuracy: 0.9113\n","\n","Epoch 00269: val_accuracy did not improve from 0.93842\n","Epoch 270/500\n","52/52 [==============================] - 50s 958ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5139 - val_accuracy: 0.9089\n","\n","Epoch 00270: val_accuracy did not improve from 0.93842\n","Epoch 271/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9212\n","\n","Epoch 00271: val_accuracy did not improve from 0.93842\n","Epoch 272/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4252 - val_accuracy: 0.9236\n","\n","Epoch 00272: val_accuracy did not improve from 0.93842\n","Epoch 273/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6146 - val_accuracy: 0.8941\n","\n","Epoch 00273: val_accuracy did not improve from 0.93842\n","Epoch 274/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.6292 - val_accuracy: 0.8916\n","\n","Epoch 00274: val_accuracy did not improve from 0.93842\n","Epoch 275/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.4835 - val_accuracy: 0.9064\n","\n","Epoch 00275: val_accuracy did not improve from 0.93842\n","Epoch 276/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5491 - val_accuracy: 0.9039\n","\n","Epoch 00276: val_accuracy did not improve from 0.93842\n","Epoch 277/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.5329 - val_accuracy: 0.8990\n","\n","Epoch 00277: val_accuracy did not improve from 0.93842\n","Epoch 278/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0952 - accuracy: 0.9738 - val_loss: 2.8564 - val_accuracy: 0.7044\n","\n","Epoch 00278: val_accuracy did not improve from 0.93842\n","Epoch 279/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0730 - accuracy: 0.9805 - val_loss: 1.2463 - val_accuracy: 0.8498\n","\n","Epoch 00279: val_accuracy did not improve from 0.93842\n","Epoch 280/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.8982 - val_accuracy: 0.8621\n","\n","Epoch 00280: val_accuracy did not improve from 0.93842\n","Epoch 281/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5067 - val_accuracy: 0.9163\n","\n","Epoch 00281: val_accuracy did not improve from 0.93842\n","Epoch 282/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.6606 - val_accuracy: 0.8941\n","\n","Epoch 00282: val_accuracy did not improve from 0.93842\n","Epoch 283/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5095 - val_accuracy: 0.9138\n","\n","Epoch 00283: val_accuracy did not improve from 0.93842\n","Epoch 284/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.6390 - val_accuracy: 0.8916\n","\n","Epoch 00284: val_accuracy did not improve from 0.93842\n","Epoch 285/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5342 - val_accuracy: 0.9039\n","\n","Epoch 00285: val_accuracy did not improve from 0.93842\n","Epoch 286/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4566 - val_accuracy: 0.9212\n","\n","Epoch 00286: val_accuracy did not improve from 0.93842\n","Epoch 287/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9138\n","\n","Epoch 00287: val_accuracy did not improve from 0.93842\n","Epoch 288/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9163\n","\n","Epoch 00288: val_accuracy did not improve from 0.93842\n","Epoch 289/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4555 - val_accuracy: 0.9163\n","\n","Epoch 00289: val_accuracy did not improve from 0.93842\n","Epoch 290/500\n","52/52 [==============================] - 50s 961ms/step - loss: 8.1120e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9187\n","\n","Epoch 00290: val_accuracy did not improve from 0.93842\n","Epoch 291/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0092 - accuracy: 0.9951 - val_loss: 0.7052 - val_accuracy: 0.8867\n","\n","Epoch 00291: val_accuracy did not improve from 0.93842\n","Epoch 292/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 1.5583 - val_accuracy: 0.7562\n","\n","Epoch 00292: val_accuracy did not improve from 0.93842\n","Epoch 293/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.6940 - val_accuracy: 0.8867\n","\n","Epoch 00293: val_accuracy did not improve from 0.93842\n","Epoch 294/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.6644 - val_accuracy: 0.8916\n","\n","Epoch 00294: val_accuracy did not improve from 0.93842\n","Epoch 295/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.5803 - val_accuracy: 0.8990\n","\n","Epoch 00295: val_accuracy did not improve from 0.93842\n","Epoch 296/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5455 - val_accuracy: 0.8941\n","\n","Epoch 00296: val_accuracy did not improve from 0.93842\n","Epoch 297/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5260 - val_accuracy: 0.9015\n","\n","Epoch 00297: val_accuracy did not improve from 0.93842\n","Epoch 298/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5589 - val_accuracy: 0.8990\n","\n","Epoch 00298: val_accuracy did not improve from 0.93842\n","Epoch 299/500\n","52/52 [==============================] - 50s 961ms/step - loss: 8.9436e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9064\n","\n","Epoch 00299: val_accuracy did not improve from 0.93842\n","Epoch 300/500\n","52/52 [==============================] - 50s 961ms/step - loss: 8.9362e-04 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9212\n","\n","Epoch 00300: val_accuracy did not improve from 0.93842\n","Epoch 301/500\n","52/52 [==============================] - 50s 962ms/step - loss: 9.2083e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9138\n","\n","Epoch 00301: val_accuracy did not improve from 0.93842\n","Epoch 302/500\n","52/52 [==============================] - 50s 963ms/step - loss: 5.7394e-04 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9113\n","\n","Epoch 00302: val_accuracy did not improve from 0.93842\n","Epoch 303/500\n","52/52 [==============================] - 50s 966ms/step - loss: 8.3201e-04 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9163\n","\n","Epoch 00303: val_accuracy did not improve from 0.93842\n","Epoch 304/500\n","52/52 [==============================] - 50s 968ms/step - loss: 6.6826e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9163\n","\n","Epoch 00304: val_accuracy did not improve from 0.93842\n","Epoch 305/500\n","52/52 [==============================] - 50s 967ms/step - loss: 4.2477e-04 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9187\n","\n","Epoch 00305: val_accuracy did not improve from 0.93842\n","Epoch 306/500\n","52/52 [==============================] - 50s 966ms/step - loss: 6.4276e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9212\n","\n","Epoch 00306: val_accuracy did not improve from 0.93842\n","Epoch 307/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9089\n","\n","Epoch 00307: val_accuracy did not improve from 0.93842\n","Epoch 308/500\n","52/52 [==============================] - 51s 969ms/step - loss: 6.8513e-04 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9163\n","\n","Epoch 00308: val_accuracy did not improve from 0.93842\n","Epoch 309/500\n","52/52 [==============================] - 50s 966ms/step - loss: 7.7250e-04 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9089\n","\n","Epoch 00309: val_accuracy did not improve from 0.93842\n","Epoch 310/500\n","52/52 [==============================] - 50s 966ms/step - loss: 3.1734e-04 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9089\n","\n","Epoch 00310: val_accuracy did not improve from 0.93842\n","Epoch 311/500\n","52/52 [==============================] - 50s 968ms/step - loss: 3.8575e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9187\n","\n","Epoch 00311: val_accuracy did not improve from 0.93842\n","Epoch 312/500\n","52/52 [==============================] - 50s 966ms/step - loss: 5.0055e-04 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9113\n","\n","Epoch 00312: val_accuracy did not improve from 0.93842\n","Epoch 313/500\n","52/52 [==============================] - 50s 966ms/step - loss: 3.2251e-04 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9064\n","\n","Epoch 00313: val_accuracy did not improve from 0.93842\n","Epoch 314/500\n","52/52 [==============================] - 50s 967ms/step - loss: 2.8934e-04 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9335\n","\n","Epoch 00314: val_accuracy did not improve from 0.93842\n","Epoch 315/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5841 - val_accuracy: 0.9064\n","\n","Epoch 00315: val_accuracy did not improve from 0.93842\n","Epoch 316/500\n","52/52 [==============================] - 50s 968ms/step - loss: 5.8076e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9089\n","\n","Epoch 00316: val_accuracy did not improve from 0.93842\n","Epoch 317/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.8900 - val_accuracy: 0.8744\n","\n","Epoch 00317: val_accuracy did not improve from 0.93842\n","Epoch 318/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 1.7820 - val_accuracy: 0.7808\n","\n","Epoch 00318: val_accuracy did not improve from 0.93842\n","Epoch 319/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0897 - accuracy: 0.9744 - val_loss: 1.9166 - val_accuracy: 0.7660\n","\n","Epoch 00319: val_accuracy did not improve from 0.93842\n","Epoch 320/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0801 - accuracy: 0.9793 - val_loss: 1.7659 - val_accuracy: 0.7488\n","\n","Epoch 00320: val_accuracy did not improve from 0.93842\n","Epoch 321/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.9072 - val_accuracy: 0.8645\n","\n","Epoch 00321: val_accuracy did not improve from 0.93842\n","Epoch 322/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.7224 - val_accuracy: 0.8941\n","\n","Epoch 00322: val_accuracy did not improve from 0.93842\n","Epoch 323/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.5652 - val_accuracy: 0.8990\n","\n","Epoch 00323: val_accuracy did not improve from 0.93842\n","Epoch 324/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.6016 - val_accuracy: 0.8793\n","\n","Epoch 00324: val_accuracy did not improve from 0.93842\n","Epoch 325/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4846 - val_accuracy: 0.9089\n","\n","Epoch 00325: val_accuracy did not improve from 0.93842\n","Epoch 326/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4573 - val_accuracy: 0.9089\n","\n","Epoch 00326: val_accuracy did not improve from 0.93842\n","Epoch 327/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.5389 - val_accuracy: 0.8941\n","\n","Epoch 00327: val_accuracy did not improve from 0.93842\n","Epoch 328/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4082 - val_accuracy: 0.9236\n","\n","Epoch 00328: val_accuracy did not improve from 0.93842\n","Epoch 329/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4895 - val_accuracy: 0.9039\n","\n","Epoch 00329: val_accuracy did not improve from 0.93842\n","Epoch 330/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4919 - val_accuracy: 0.8916\n","\n","Epoch 00330: val_accuracy did not improve from 0.93842\n","Epoch 331/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5217 - val_accuracy: 0.9039\n","\n","Epoch 00331: val_accuracy did not improve from 0.93842\n","Epoch 332/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0764 - accuracy: 0.9769 - val_loss: 0.8240 - val_accuracy: 0.8621\n","\n","Epoch 00332: val_accuracy did not improve from 0.93842\n","Epoch 333/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.4893 - val_accuracy: 0.8990\n","\n","Epoch 00333: val_accuracy did not improve from 0.93842\n","Epoch 334/500\n","52/52 [==============================] - 50s 960ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.5855 - val_accuracy: 0.9015\n","\n","Epoch 00334: val_accuracy did not improve from 0.93842\n","Epoch 335/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0120 - accuracy: 0.9933 - val_loss: 0.5145 - val_accuracy: 0.8916\n","\n","Epoch 00335: val_accuracy did not improve from 0.93842\n","Epoch 336/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.5534 - val_accuracy: 0.8916\n","\n","Epoch 00336: val_accuracy did not improve from 0.93842\n","Epoch 337/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4886 - val_accuracy: 0.9113\n","\n","Epoch 00337: val_accuracy did not improve from 0.93842\n","Epoch 338/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9064\n","\n","Epoch 00338: val_accuracy did not improve from 0.93842\n","Epoch 339/500\n","52/52 [==============================] - 50s 977ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4197 - val_accuracy: 0.9212\n","\n","Epoch 00339: val_accuracy did not improve from 0.93842\n","Epoch 340/500\n","52/52 [==============================] - 50s 966ms/step - loss: 6.7117e-04 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9236\n","\n","Epoch 00340: val_accuracy did not improve from 0.93842\n","Epoch 341/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4247 - val_accuracy: 0.9236\n","\n","Epoch 00341: val_accuracy did not improve from 0.93842\n","Epoch 342/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9113\n","\n","Epoch 00342: val_accuracy did not improve from 0.93842\n","Epoch 343/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.6809 - val_accuracy: 0.8695\n","\n","Epoch 00343: val_accuracy did not improve from 0.93842\n","Epoch 344/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 1.4409 - val_accuracy: 0.8325\n","\n","Epoch 00344: val_accuracy did not improve from 0.93842\n","Epoch 345/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0500 - accuracy: 0.9860 - val_loss: 0.7507 - val_accuracy: 0.8768\n","\n","Epoch 00345: val_accuracy did not improve from 0.93842\n","Epoch 346/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.6076 - val_accuracy: 0.8867\n","\n","Epoch 00346: val_accuracy did not improve from 0.93842\n","Epoch 347/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5507 - val_accuracy: 0.9113\n","\n","Epoch 00347: val_accuracy did not improve from 0.93842\n","Epoch 348/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5354 - val_accuracy: 0.8990\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0090 - accuracy: 0.9957 - val_loss: 0.5490 - val_accuracy: 0.9089\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5226 - val_accuracy: 0.8990\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4141 - val_accuracy: 0.9163\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4060 - val_accuracy: 0.9236\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 50s 966ms/step - loss: 6.0146e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9187\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.4417 - val_accuracy: 0.9236\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6383 - val_accuracy: 0.8695\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.5217 - val_accuracy: 0.9039\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5101 - val_accuracy: 0.9064\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.6762 - val_accuracy: 0.8842\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4235 - val_accuracy: 0.9138\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9236\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4661 - val_accuracy: 0.9187\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.4322 - val_accuracy: 0.9163\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4980 - val_accuracy: 0.9064\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4645 - val_accuracy: 0.9261\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5179 - val_accuracy: 0.9236\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5034 - val_accuracy: 0.9138\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9384\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4919 - val_accuracy: 0.9286\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5583 - val_accuracy: 0.8867\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.9748 - val_accuracy: 0.8522\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.3675 - val_accuracy: 0.9163\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.6474 - val_accuracy: 0.8990\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0676 - accuracy: 0.9836 - val_loss: 0.7908 - val_accuracy: 0.8793\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.6203 - val_accuracy: 0.8867\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.6813 - val_accuracy: 0.8941\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.6259 - val_accuracy: 0.8867\n","\n","Epoch 00376: val_accuracy did not improve from 0.93842\n","Epoch 377/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4994 - val_accuracy: 0.9212\n","\n","Epoch 00377: val_accuracy did not improve from 0.93842\n","Epoch 378/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5010 - val_accuracy: 0.9039\n","\n","Epoch 00378: val_accuracy did not improve from 0.93842\n","Epoch 379/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4168 - val_accuracy: 0.9163\n","\n","Epoch 00379: val_accuracy did not improve from 0.93842\n","Epoch 380/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.4850 - val_accuracy: 0.9015\n","\n","Epoch 00380: val_accuracy did not improve from 0.93842\n","Epoch 381/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.4818 - val_accuracy: 0.8916\n","\n","Epoch 00381: val_accuracy did not improve from 0.93842\n","Epoch 382/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5675 - val_accuracy: 0.8990\n","\n","Epoch 00382: val_accuracy did not improve from 0.93842\n","Epoch 383/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.5987 - val_accuracy: 0.8867\n","\n","Epoch 00383: val_accuracy did not improve from 0.93842\n","Epoch 384/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5884 - val_accuracy: 0.8990\n","\n","Epoch 00384: val_accuracy did not improve from 0.93842\n","Epoch 385/500\n","52/52 [==============================] - 50s 959ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4563 - val_accuracy: 0.9212\n","\n","Epoch 00385: val_accuracy did not improve from 0.93842\n","Epoch 386/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5962 - val_accuracy: 0.8768\n","\n","Epoch 00386: val_accuracy did not improve from 0.93842\n","Epoch 387/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.6611 - val_accuracy: 0.8793\n","\n","Epoch 00387: val_accuracy did not improve from 0.93842\n","Epoch 388/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5793 - val_accuracy: 0.9015\n","\n","Epoch 00388: val_accuracy did not improve from 0.93842\n","Epoch 389/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6445 - val_accuracy: 0.8990\n","\n","Epoch 00389: val_accuracy did not improve from 0.93842\n","Epoch 390/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.6397 - val_accuracy: 0.8892\n","\n","Epoch 00390: val_accuracy did not improve from 0.93842\n","Epoch 391/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4722 - val_accuracy: 0.9163\n","\n","Epoch 00391: val_accuracy did not improve from 0.93842\n","Epoch 392/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4738 - val_accuracy: 0.9163\n","\n","Epoch 00392: val_accuracy did not improve from 0.93842\n","Epoch 393/500\n","52/52 [==============================] - 52s 997ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.5032 - val_accuracy: 0.9039\n","\n","Epoch 00393: val_accuracy did not improve from 0.93842\n","Epoch 394/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.6218 - val_accuracy: 0.9015\n","\n","Epoch 00394: val_accuracy did not improve from 0.93842\n","Epoch 395/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4354 - val_accuracy: 0.9286\n","\n","Epoch 00395: val_accuracy did not improve from 0.93842\n","Epoch 396/500\n","52/52 [==============================] - 50s 963ms/step - loss: 7.3619e-04 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9236\n","\n","Epoch 00396: val_accuracy did not improve from 0.93842\n","Epoch 397/500\n","52/52 [==============================] - 50s 965ms/step - loss: 3.3506e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9163\n","\n","Epoch 00397: val_accuracy did not improve from 0.93842\n","Epoch 398/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.5342 - val_accuracy: 0.9163\n","\n","Epoch 00398: val_accuracy did not improve from 0.93842\n","Epoch 399/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5306 - val_accuracy: 0.9187\n","\n","Epoch 00399: val_accuracy did not improve from 0.93842\n","Epoch 400/500\n","52/52 [==============================] - 50s 965ms/step - loss: 8.5909e-04 - accuracy: 0.9994 - val_loss: 0.4835 - val_accuracy: 0.9187\n","\n","Epoch 00400: val_accuracy did not improve from 0.93842\n","Epoch 401/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.93842\n","Epoch 402/500\n","52/52 [==============================] - 50s 965ms/step - loss: 6.7477e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9261\n","\n","Epoch 00402: val_accuracy did not improve from 0.93842\n","Epoch 403/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.7280 - val_accuracy: 0.8744\n","\n","Epoch 00403: val_accuracy did not improve from 0.93842\n","Epoch 404/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 0.6680 - val_accuracy: 0.8892\n","\n","Epoch 00404: val_accuracy did not improve from 0.93842\n","Epoch 405/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.5638 - val_accuracy: 0.8867\n","\n","Epoch 00405: val_accuracy did not improve from 0.93842\n","Epoch 406/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0431 - accuracy: 0.9878 - val_loss: 1.0364 - val_accuracy: 0.8547\n","\n","Epoch 00406: val_accuracy did not improve from 0.93842\n","Epoch 407/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.6842 - val_accuracy: 0.8670\n","\n","Epoch 00407: val_accuracy did not improve from 0.93842\n","Epoch 408/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6568 - val_accuracy: 0.8892\n","\n","Epoch 00408: val_accuracy did not improve from 0.93842\n","Epoch 409/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4851 - val_accuracy: 0.9236\n","\n","Epoch 00409: val_accuracy did not improve from 0.93842\n","Epoch 410/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0383 - accuracy: 0.9890 - val_loss: 0.7316 - val_accuracy: 0.8448\n","\n","Epoch 00410: val_accuracy did not improve from 0.93842\n","Epoch 411/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0417 - accuracy: 0.9854 - val_loss: 0.8688 - val_accuracy: 0.8670\n","\n","Epoch 00411: val_accuracy did not improve from 0.93842\n","Epoch 412/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.4560 - val_accuracy: 0.9187\n","\n","Epoch 00412: val_accuracy did not improve from 0.93842\n","Epoch 413/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.5752 - val_accuracy: 0.9064\n","\n","Epoch 00413: val_accuracy did not improve from 0.93842\n","Epoch 414/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.5949 - val_accuracy: 0.8916\n","\n","Epoch 00414: val_accuracy did not improve from 0.93842\n","Epoch 415/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4640 - val_accuracy: 0.9113\n","\n","Epoch 00415: val_accuracy did not improve from 0.93842\n","Epoch 416/500\n","52/52 [==============================] - 51s 969ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9310\n","\n","Epoch 00416: val_accuracy did not improve from 0.93842\n","Epoch 417/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5124 - val_accuracy: 0.9138\n","\n","Epoch 00417: val_accuracy did not improve from 0.93842\n","Epoch 418/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4700 - val_accuracy: 0.9138\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4731 - val_accuracy: 0.9163\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 50s 965ms/step - loss: 9.7172e-04 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9286\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 51s 969ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.5911 - val_accuracy: 0.8966\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 51s 969ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.7105 - val_accuracy: 0.8793\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 51s 969ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5411 - val_accuracy: 0.9064\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4486 - val_accuracy: 0.9163\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4009 - val_accuracy: 0.9286\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 50s 965ms/step - loss: 8.7282e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9458\n","\n","Epoch 00426: val_accuracy improved from 0.93842 to 0.94581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5\n","Epoch 427/500\n","52/52 [==============================] - 50s 966ms/step - loss: 4.4763e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9310\n","\n","Epoch 00427: val_accuracy did not improve from 0.94581\n","Epoch 428/500\n","52/52 [==============================] - 50s 968ms/step - loss: 4.1323e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9360\n","\n","Epoch 00428: val_accuracy did not improve from 0.94581\n","Epoch 429/500\n","52/52 [==============================] - 51s 969ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.8364 - val_accuracy: 0.8621\n","\n","Epoch 00429: val_accuracy did not improve from 0.94581\n","Epoch 430/500\n","52/52 [==============================] - 51s 970ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.8857 - val_accuracy: 0.8842\n","\n","Epoch 00430: val_accuracy did not improve from 0.94581\n","Epoch 431/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 1.2031 - val_accuracy: 0.8325\n","\n","Epoch 00431: val_accuracy did not improve from 0.94581\n","Epoch 432/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0257 - accuracy: 0.9903 - val_loss: 0.6309 - val_accuracy: 0.8966\n","\n","Epoch 00432: val_accuracy did not improve from 0.94581\n","Epoch 433/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 1.2838 - val_accuracy: 0.8054\n","\n","Epoch 00433: val_accuracy did not improve from 0.94581\n","Epoch 434/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.7906 - val_accuracy: 0.8793\n","\n","Epoch 00434: val_accuracy did not improve from 0.94581\n","Epoch 435/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5015 - val_accuracy: 0.9015\n","\n","Epoch 00435: val_accuracy did not improve from 0.94581\n","Epoch 436/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0324 - accuracy: 0.9933 - val_loss: 0.7174 - val_accuracy: 0.8596\n","\n","Epoch 00436: val_accuracy did not improve from 0.94581\n","Epoch 437/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.8462 - val_accuracy: 0.8645\n","\n","Epoch 00437: val_accuracy did not improve from 0.94581\n","Epoch 438/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.8268 - val_accuracy: 0.8571\n","\n","Epoch 00438: val_accuracy did not improve from 0.94581\n","Epoch 439/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4892 - val_accuracy: 0.9089\n","\n","Epoch 00439: val_accuracy did not improve from 0.94581\n","Epoch 440/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4986 - val_accuracy: 0.9064\n","\n","Epoch 00440: val_accuracy did not improve from 0.94581\n","Epoch 441/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4962 - val_accuracy: 0.9064\n","\n","Epoch 00441: val_accuracy did not improve from 0.94581\n","Epoch 442/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5464 - val_accuracy: 0.9015\n","\n","Epoch 00442: val_accuracy did not improve from 0.94581\n","Epoch 443/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9187\n","\n","Epoch 00443: val_accuracy did not improve from 0.94581\n","Epoch 444/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5180 - val_accuracy: 0.9212\n","\n","Epoch 00444: val_accuracy did not improve from 0.94581\n","Epoch 445/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6373 - val_accuracy: 0.8941\n","\n","Epoch 00445: val_accuracy did not improve from 0.94581\n","Epoch 446/500\n","52/52 [==============================] - 50s 965ms/step - loss: 7.1109e-04 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.94581\n","Epoch 447/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4848 - val_accuracy: 0.9212\n","\n","Epoch 00447: val_accuracy did not improve from 0.94581\n","Epoch 448/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.9089\n","\n","Epoch 00448: val_accuracy did not improve from 0.94581\n","Epoch 449/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.9064\n","\n","Epoch 00449: val_accuracy did not improve from 0.94581\n","Epoch 450/500\n","52/52 [==============================] - 50s 979ms/step - loss: 8.6123e-04 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.94581\n","Epoch 451/500\n","52/52 [==============================] - 50s 966ms/step - loss: 5.5459e-04 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.9113\n","\n","Epoch 00451: val_accuracy did not improve from 0.94581\n","Epoch 452/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.5632 - val_accuracy: 0.9163\n","\n","Epoch 00452: val_accuracy did not improve from 0.94581\n","Epoch 453/500\n","52/52 [==============================] - 50s 965ms/step - loss: 5.1435e-04 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.94581\n","Epoch 454/500\n","52/52 [==============================] - 50s 965ms/step - loss: 5.4610e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9310\n","\n","Epoch 00454: val_accuracy did not improve from 0.94581\n","Epoch 455/500\n","52/52 [==============================] - 50s 964ms/step - loss: 7.0688e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9212\n","\n","Epoch 00455: val_accuracy did not improve from 0.94581\n","Epoch 456/500\n","52/52 [==============================] - 50s 963ms/step - loss: 4.9038e-04 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9138\n","\n","Epoch 00456: val_accuracy did not improve from 0.94581\n","Epoch 457/500\n","52/52 [==============================] - 50s 963ms/step - loss: 7.1180e-04 - accuracy: 0.9994 - val_loss: 0.4836 - val_accuracy: 0.9236\n","\n","Epoch 00457: val_accuracy did not improve from 0.94581\n","Epoch 458/500\n","52/52 [==============================] - 50s 967ms/step - loss: 7.2681e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9310\n","\n","Epoch 00458: val_accuracy did not improve from 0.94581\n","Epoch 459/500\n","52/52 [==============================] - 50s 962ms/step - loss: 4.6462e-04 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.9187\n","\n","Epoch 00459: val_accuracy did not improve from 0.94581\n","Epoch 460/500\n","52/52 [==============================] - 50s 964ms/step - loss: 7.7226e-04 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9261\n","\n","Epoch 00460: val_accuracy did not improve from 0.94581\n","Epoch 461/500\n","52/52 [==============================] - 51s 969ms/step - loss: 2.8590e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9236\n","\n","Epoch 00461: val_accuracy did not improve from 0.94581\n","Epoch 462/500\n","52/52 [==============================] - 50s 966ms/step - loss: 2.9305e-04 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9286\n","\n","Epoch 00462: val_accuracy did not improve from 0.94581\n","Epoch 463/500\n","52/52 [==============================] - 50s 978ms/step - loss: 8.0601e-05 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9310\n","\n","Epoch 00463: val_accuracy did not improve from 0.94581\n","Epoch 464/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5626 - val_accuracy: 0.9039\n","\n","Epoch 00464: val_accuracy did not improve from 0.94581\n","Epoch 465/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.6181 - val_accuracy: 0.8892\n","\n","Epoch 00465: val_accuracy did not improve from 0.94581\n","Epoch 466/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4441 - val_accuracy: 0.9163\n","\n","Epoch 00466: val_accuracy did not improve from 0.94581\n","Epoch 467/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5559 - val_accuracy: 0.9138\n","\n","Epoch 00467: val_accuracy did not improve from 0.94581\n","Epoch 468/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5107 - val_accuracy: 0.9039\n","\n","Epoch 00468: val_accuracy did not improve from 0.94581\n","Epoch 469/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4729 - val_accuracy: 0.9064\n","\n","Epoch 00469: val_accuracy did not improve from 0.94581\n","Epoch 470/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.5276 - val_accuracy: 0.8966\n","\n","Epoch 00470: val_accuracy did not improve from 0.94581\n","Epoch 471/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5567 - val_accuracy: 0.9089\n","\n","Epoch 00471: val_accuracy did not improve from 0.94581\n","Epoch 472/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.7825 - val_accuracy: 0.8768\n","\n","Epoch 00472: val_accuracy did not improve from 0.94581\n","Epoch 473/500\n","52/52 [==============================] - 50s 968ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6085 - val_accuracy: 0.8793\n","\n","Epoch 00473: val_accuracy did not improve from 0.94581\n","Epoch 474/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.9056 - val_accuracy: 0.8818\n","\n","Epoch 00474: val_accuracy did not improve from 0.94581\n","Epoch 475/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.8853 - val_accuracy: 0.8596\n","\n","Epoch 00475: val_accuracy did not improve from 0.94581\n","Epoch 476/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.6147 - val_accuracy: 0.9039\n","\n","Epoch 00476: val_accuracy did not improve from 0.94581\n","Epoch 477/500\n","52/52 [==============================] - 50s 979ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.6261 - val_accuracy: 0.9015\n","\n","Epoch 00477: val_accuracy did not improve from 0.94581\n","Epoch 478/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.6880 - val_accuracy: 0.9015\n","\n","Epoch 00478: val_accuracy did not improve from 0.94581\n","Epoch 479/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4908 - val_accuracy: 0.9089\n","\n","Epoch 00479: val_accuracy did not improve from 0.94581\n","Epoch 480/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5560 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.94581\n","Epoch 481/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0459 - accuracy: 0.9896 - val_loss: 3.5148 - val_accuracy: 0.5862\n","\n","Epoch 00481: val_accuracy did not improve from 0.94581\n","Epoch 482/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7589 - val_accuracy: 0.8695\n","\n","Epoch 00482: val_accuracy did not improve from 0.94581\n","Epoch 483/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.6800 - val_accuracy: 0.8990\n","\n","Epoch 00483: val_accuracy did not improve from 0.94581\n","Epoch 484/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5243 - val_accuracy: 0.9187\n","\n","Epoch 00484: val_accuracy did not improve from 0.94581\n","Epoch 485/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6174 - val_accuracy: 0.9039\n","\n","Epoch 00485: val_accuracy did not improve from 0.94581\n","Epoch 486/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.5187 - val_accuracy: 0.9261\n","\n","Epoch 00486: val_accuracy did not improve from 0.94581\n","Epoch 487/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6037 - val_accuracy: 0.9039\n","\n","Epoch 00487: val_accuracy did not improve from 0.94581\n","Epoch 488/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.6263 - val_accuracy: 0.8916\n","\n","Epoch 00488: val_accuracy did not improve from 0.94581\n","Epoch 489/500\n","52/52 [==============================] - 50s 962ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8916\n","\n","Epoch 00489: val_accuracy did not improve from 0.94581\n","Epoch 490/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.7627 - val_accuracy: 0.8892\n","\n","Epoch 00490: val_accuracy did not improve from 0.94581\n","Epoch 491/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6130 - val_accuracy: 0.8990\n","\n","Epoch 00491: val_accuracy did not improve from 0.94581\n","Epoch 492/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5631 - val_accuracy: 0.8916\n","\n","Epoch 00492: val_accuracy did not improve from 0.94581\n","Epoch 493/500\n","52/52 [==============================] - 50s 964ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5596 - val_accuracy: 0.9015\n","\n","Epoch 00493: val_accuracy did not improve from 0.94581\n","Epoch 494/500\n","52/52 [==============================] - 50s 966ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5189 - val_accuracy: 0.9015\n","\n","Epoch 00494: val_accuracy did not improve from 0.94581\n","Epoch 495/500\n","52/52 [==============================] - 50s 975ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5778 - val_accuracy: 0.8990\n","\n","Epoch 00495: val_accuracy did not improve from 0.94581\n","Epoch 496/500\n","52/52 [==============================] - 50s 961ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4967 - val_accuracy: 0.8916\n","\n","Epoch 00496: val_accuracy did not improve from 0.94581\n","Epoch 497/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5060 - val_accuracy: 0.9039\n","\n","Epoch 00497: val_accuracy did not improve from 0.94581\n","Epoch 498/500\n","52/52 [==============================] - 50s 967ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5873 - val_accuracy: 0.8966\n","\n","Epoch 00498: val_accuracy did not improve from 0.94581\n","Epoch 499/500\n","52/52 [==============================] - 50s 965ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.5747 - val_accuracy: 0.8966\n","\n","Epoch 00499: val_accuracy did not improve from 0.94581\n","Epoch 500/500\n","52/52 [==============================] - 50s 963ms/step - loss: 0.0832 - accuracy: 0.9836 - val_loss: 1.1060 - val_accuracy: 0.8276\n","\n","Epoch 00500: val_accuracy did not improve from 0.94581\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff592019950>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1631295956326,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f2f1fe1f-67f4-46e1-d0b9-c8af71a967b6"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1631295991864,"user_tz":-540,"elapsed":35548,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_256_5_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1631295992438,"user_tz":-540,"elapsed":577,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631295992937,"user_tz":-540,"elapsed":502,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"bcc2842a-cdb2-49bb-dae1-7d799492893b"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(256,256), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631296197342,"user_tz":-540,"elapsed":204408,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f038b7bd-326f-437b-fcd8-b3e8055da7b7"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1631296197879,"user_tz":-540,"elapsed":539,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1631296197880,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1631296199972,"user_tz":-540,"elapsed":2096,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1631296199973,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1631296216199,"user_tz":-540,"elapsed":16232,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1631296216205,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7f242d80-b76a-4d0d-846b-6acbcc69e265"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1631296216205,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"3ef2187c-0515-4474-842a-9a0656956845"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_256_5_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_256_5_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_c7e8082b-d6b6-4059-b320-1a53d9688f94\", \"ImageSize_256_5_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}