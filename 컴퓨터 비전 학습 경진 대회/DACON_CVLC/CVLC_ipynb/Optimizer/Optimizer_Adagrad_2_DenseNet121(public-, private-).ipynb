{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Optimizer_Adagrad_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1ZYZLb8oI5JPL7pdtUGXS2HWGvvEkG37o","timestamp":1631426405791},{"file_id":"1Ymr5heamBXdfPhZMTjn2gji6Zg6rnkY7","timestamp":1631425982689},{"file_id":"15lkBwp6eMMLJR0VRjWKMbVOR8_PwmmX7","timestamp":1631425917996},{"file_id":"1BsNUIQOH7x0jXVQiG6o8vRLy5sNMj6W6","timestamp":1631413866383},{"file_id":"1fqXDGN57IeuGUr31tyYRpN_LJYLwJBoZ","timestamp":1631413737650},{"file_id":"1Jl6kAKKtC2xTyqKEfJIFPHc9RcDKoeYn","timestamp":1631351489824},{"file_id":"1_dlcNrMAu5ukle5C6uUvtMX3g-ohV_ys","timestamp":1631298299098},{"file_id":"1p5CCsaiDThRuLsjc6qcFCsWr-IIFE-Di","timestamp":1631297060156},{"file_id":"1ocTCIWAPJ4UcO34WMEtPRebgS3d13uQQ","timestamp":1631288369165},{"file_id":"1QFJIsSAG6754fACK-TcZEGD_jQTlfenW","timestamp":1631270717433},{"file_id":"1p5Rg-oC5wgs8kljSDJf6F3i0LQrXsxVc","timestamp":1631269202490},{"file_id":"1f3nznDNfoCy2o3khbtOPBsLH6aWkikaC","timestamp":1631216445247},{"file_id":"1c2MWKPmFEryc2NI5jyKAAWVmxqH1VUCz","timestamp":1631216398169},{"file_id":"1_XM5eXz-mRq_8btoHAcEP8vfGSYFw1LC","timestamp":1631216374547},{"file_id":"1WF9YyXyX0BHUcSI4EfvLCmpIZnkjfht_","timestamp":1631199517663},{"file_id":"1DhKkeZKVN6SnskBHR9I9JhnmnnAvvYsM","timestamp":1631199484204},{"file_id":"1Sb1zx-9JnMoqZN44rSFWtUmopGi9YObV","timestamp":1631049773986},{"file_id":"1Ukz7x6x60p-yX7qFtl681RI02Xq38gil","timestamp":1631047282593},{"file_id":"1a65ZxKUM-ebeKKlnVVwnVW-zuq6YjgE5","timestamp":1631047194111},{"file_id":"1zeTuwcXoX2nrULVuhoDyze5Ppfttrv0w","timestamp":1631045991075},{"file_id":"1Q_w97zg4VwPEfNBX52yhb8QqQexMpqf_","timestamp":1631044605223},{"file_id":"1pqowzoSTmQGAh-N1th_R0C3TI9Gyl4Hc","timestamp":1631043183868},{"file_id":"1fedN2kXOFJ_DCXWKCH9EXVlgwLeCYz7u","timestamp":1631039069646},{"file_id":"1ZXAcHyuCWCyRAdv1K2fjSI7EYUZUzgd-","timestamp":1631037094537},{"file_id":"1QwQAud74jt30tPFhBZB4ST8jpL6yfXId","timestamp":1631035798955},{"file_id":"1HK4HDd8d-ydp1hpjE542SlZzhcebS04s","timestamp":1631035758423},{"file_id":"1BDI3hcYWj0EQ36ajZDAXvOF7hl4SSZLK","timestamp":1631030590142},{"file_id":"1wkcCzuHh8bbAgm3A6BK30Yutz6_lW7Wz","timestamp":1630968808808},{"file_id":"1NBaJvfE-mNYLwaRSb3DmI2VgGlo-L64e","timestamp":1630968784020},{"file_id":"1tuxKDEpXqS10eUFd1BhXSulkLRHwm5Ls","timestamp":1630968742688},{"file_id":"1tT8KjKA8d3WPDIBeqi3Pl2OBSYM0j1vs","timestamp":1630968318011},{"file_id":"1zXLjChcCNAAwvHd2Cpnq9eXPmx2Hxv7v","timestamp":1630968226179},{"file_id":"1my69WIg_k7Dsobadf8IPYHpbt46UeiOr","timestamp":1630961678442},{"file_id":"1FBIwhXm4-AXNBfg_zN4PCqYB4fBkJis9","timestamp":1630961652892},{"file_id":"1aKbh7xPYx3QmxXPNnL4Ibm-oAutHqQmP","timestamp":1630961578285},{"file_id":"1oOSCmJ_elzy5wWrlNC00MqwUHJayiHDY","timestamp":1630961542590},{"file_id":"1t7sTp3m7RRztyvU4tfL8W8lGrMk2FQjn","timestamp":1630951440213},{"file_id":"1fazDZeCuGnik7RX86NUluX6WpNk8nyHy","timestamp":1630949981703},{"file_id":"1hFR9zdRHLq9CD3Qx-qnlkZJvce1OlPUu","timestamp":1630949783061},{"file_id":"1zC6movFvQGJ4fr54cjU-Pu08xt53vVjF","timestamp":1630949772598},{"file_id":"1JjM9eMHh_iT2pY6BNfy6y5ztoX5BznNb","timestamp":1630866486107},{"file_id":"1RJHw6qRW-G23IN47ZOMM1nOcrOv-Lq_k","timestamp":1630866451790},{"file_id":"1--_lXPMfaPxWLicd9uWOpl48GRqT9x9K","timestamp":1630847367248},{"file_id":"1PGeXA-Nb00rJuv1I3ZBF6rpNR4qDErXE","timestamp":1630836207896},{"file_id":"19f4sGczygDy6VCFM6Dc6mfSNNAdh6QMI","timestamp":1630836183988},{"file_id":"1dSlKlnhNkaJD6rX0PnYAwTzru54zKEmb","timestamp":1630836149378},{"file_id":"1GxaesOzgv99NpOY71Qn2A4_a_nbiGScP","timestamp":1630836075710},{"file_id":"1pAOyg2ba1nqW5-60Tb4uA63Qfb9UVr1l","timestamp":1630835987308},{"file_id":"10TnEQPLI8MHQRmh84M8HicSibJfewY9a","timestamp":1630835956891},{"file_id":"1fiIBRDmLIPxB3JYTePwN6q-04wPwAWWN","timestamp":1630778953404},{"file_id":"1vco_0hIBI4evIfDmQDH07Nq5lQJx4Kod","timestamp":1630778923697},{"file_id":"1r3BflNbSZB370f8W3h8PQ5C7NEdbXsJj","timestamp":1630766001155},{"file_id":"1fyedjHIW6-8SHp9ow65apBeykbHxS7oi","timestamp":1630760236494},{"file_id":"1QnPclrYnKmBsAWRJ51Rre-PMBgVa9Cl3","timestamp":1630760206258},{"file_id":"1K7n8RRDie4UKR4IX4z4XcOvrqBpuzCX2","timestamp":1630760179968},{"file_id":"18NxWLqCn6GIqSPUVwANqnaPRMf5i0YEt","timestamp":1630745018066},{"file_id":"1EDWcCOn_TRgBJv_ZMCvsd_r1unwaZzE7","timestamp":1630744974962},{"file_id":"1JA5LGhrhW19laOkeoR8qPDaFWjoqSMzr","timestamp":1630744944221},{"file_id":"1PtmJdXo9AY1M6u1bHhpUHKQ0PGMoOPWZ","timestamp":1630744160988},{"file_id":"1q8viSykqnipNZ_WZtwFtIvj_ZdVFX4vC","timestamp":1630699910907},{"file_id":"1I9ElhTSO4vKs1a5lfr-r0PB1MndT08Nr","timestamp":1630699885519},{"file_id":"14FhoIy7URVKqSDzemys-qARDeDRrpK5D","timestamp":1630676044569},{"file_id":"1SyIKO_pcFSLG_l2VOhA42Qj1Sfgu9xJ5","timestamp":1630675996818},{"file_id":"1bR6CC08w6e4QxXCvbI1hPuVGX4Xr2aS6","timestamp":1630675972365},{"file_id":"1m9zTT841JY7COW8wa0uLUmdxh4mwTROg","timestamp":1630675935279},{"file_id":"1K-M0y6ngoFlaXHKpD1A2obin5bN69rOP","timestamp":1630668564612},{"file_id":"1blwd04nWkDbZIiyYRsoikGHv7D2lN1M7","timestamp":1630663027637},{"file_id":"1OWcGKJuP-Tlx2cd7fYiEF4iFQBw_jTaV","timestamp":1630663004855},{"file_id":"1iIv2T-FeMWjlLKmFmVia0cp_FsKKhP6n","timestamp":1630662692922},{"file_id":"122a3KanHz7tYxI2RkTyd5CDHFsGXxRcD","timestamp":1630652306408},{"file_id":"1rmWpSzQjpXc4LfrgWir30dbjafFqnlzh","timestamp":1630652271928},{"file_id":"1LZU500qd_mzkL28Su52XN_qaRf_yaHht","timestamp":1630646510103},{"file_id":"16JOqSkO3uC_jfclj81AzxJShlzoOMH_B","timestamp":1630613714759},{"file_id":"1eaN7vOK3RK8eeKTKP85BVew6KGSCyH_6","timestamp":1630613687181},{"file_id":"1hFz_giaup3ft5PdsqD18owTBdvEk-9En","timestamp":1630613648785},{"file_id":"15fNytZzTcRPBSdHijbaWLKC0KR8SWzhp","timestamp":1630612864615},{"file_id":"1C8ZNqu7Eb5heuVECStaVKpkxyihLmMkO","timestamp":1630602470521},{"file_id":"1DN9Efw8q90g7HCJ5VhXJYn57jItRUHnr","timestamp":1630602447501},{"file_id":"1ZYwQgfbGvCmGKmNM25goBD839_1yJrul","timestamp":1630602408672},{"file_id":"1_j6u69eFZFR-bV-7FdC_KmRhJ8AI-Ifh","timestamp":1630602370180},{"file_id":"1unjV74CiTTQsLla4T4r8Xawlb_l1_ego","timestamp":1630602293534},{"file_id":"1MSEaTlfMh47aob3-U8yPBQNcpxSO0RC6","timestamp":1630524166308},{"file_id":"1uj1q7VaxDNJ4v0Qnpewz9OO5vDawvGL1","timestamp":1630524142681},{"file_id":"1SXi4BHkyVdQzSXMkx23PhKLYG_cgy9Ne","timestamp":1630524118198},{"file_id":"1ktumtKU2gng5uaTndy4q6ORrf_vm1MB5","timestamp":1630516331014},{"file_id":"19fk2AWJq9X3zvPm2WSAtKO7ljZBPUG5l","timestamp":1630516290119},{"file_id":"1ZOrlvLwHgJ8yqXlMzsUBuNpAS1leHpTw","timestamp":1630516251869},{"file_id":"1lrAXMllo7_hAtAVIxPhE7Xno3vS6aFxT","timestamp":1630515420255},{"file_id":"17dTh7DEVFlzrmiHY5X5ldlDVaanaV9e-","timestamp":1630504418101},{"file_id":"1mqEzmVKqNVAF_0chUK1joEpZK_PYc0_4","timestamp":1630504394196},{"file_id":"1mzp8pt1OJt9CAaiKKe25s3yNAqrGew9R","timestamp":1630504147646},{"file_id":"1FMgk3jn7Q2dQ8p_Hu7bJRfcSBb13Rnvo","timestamp":1630504098889},{"file_id":"1hhBZ077MXyvhUnuxI7SD86ahYiLsCzOG","timestamp":1630500513841},{"file_id":"1EEfvNr8ZybJmpeRuKJ-r7__rhnDnaIM7","timestamp":1630495179853},{"file_id":"17e4zKJb3AvCBXA5MdPqutbvT9s1-CP6A","timestamp":1630484224103},{"file_id":"1ZyJ9--fiBCqqZIpZYXBwYIGMXZPnoPvu","timestamp":1630484173863},{"file_id":"1abkZGMd_cSctW05mIZfosyOPOLNr-LK9","timestamp":1630484131331},{"file_id":"1fKp4Svl_srbEAv_YpXTvSwqDozb4bj9H","timestamp":1630484105207},{"file_id":"1y9kcnOXGhn5ArjCk66kqJCIvgyfTRSkk","timestamp":1630483907553},{"file_id":"1o9CD4AI2tKzcdbdLJ4A6xkENgqmZG7oW","timestamp":1630475138628},{"file_id":"17KUAlMIBl9TgxSnuNYcPwx2zScEUw5W-","timestamp":1630475103015},{"file_id":"12cn5R3wN6-IWoeS68BSqi4LxqlCxJxYt","timestamp":1630464969114},{"file_id":"1KLLc8roFaz12DcPj1WHhuKt9ZBQqi76a","timestamp":1630464678834},{"file_id":"1VZIQ1plZ8Dw3dEaOdrcDkgTjXOv0OcTp","timestamp":1630464589009},{"file_id":"1HiqQpOR-bo5ZelQ96RenE8K365HqE7Lv","timestamp":1630438189228},{"file_id":"1ltViornnQGTXyCDuiYgIGfZy1m46LTW_","timestamp":1630438122242},{"file_id":"12vcTsqE7nuRUe3r9-4k5efqml3ud1k9Z","timestamp":1630438078632},{"file_id":"1EdFynNtlBeF206lf5xA2umzEqK_Pjyi5","timestamp":1630437839162},{"file_id":"1pKJK3lnnRPxX28V0U_A45uk_SI4WlDZr","timestamp":1630432659647},{"file_id":"1soBcJ0zzhkPsMINjzGMbYGcga7VX-2Be","timestamp":1630432634550},{"file_id":"12jPQ_wSDDvGyzTBUV-h-pRZ8N-lp9bkW","timestamp":1630425888718},{"file_id":"1ik1ECJq6EbWwGegXLisYoxytv0-7JQcn","timestamp":1630425853722},{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOdGzZp3+eqbfoK4suLF6s9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631458613586,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c8303bc4-9b32-4959-d484-09e7c8e8ad7c"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 12 14:56:54 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631458630077,"user_tz":-540,"elapsed":16203,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e45baac2-43de-4756-ae26-4a23cabe164c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1631458632992,"user_tz":-540,"elapsed":2531,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1631458634400,"user_tz":-540,"elapsed":1414,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1631458636438,"user_tz":-540,"elapsed":2041,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1631458652791,"user_tz":-540,"elapsed":16357,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1631458659549,"user_tz":-540,"elapsed":6760,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1631458659550,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631458659551,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dad8fac5-cbbe-4e16-8ec5-57f21af70309"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1631458659551,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631468788401,"user_tz":-540,"elapsed":10128857,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b7832555-fcbe-4e53-dc5a-bf5e496eee3a"},"source":["DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 51s 462ms/step - loss: 2.3442 - accuracy: 0.1017 - val_loss: 2.3143 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 360ms/step - loss: 2.2459 - accuracy: 0.1705 - val_loss: 2.3769 - val_accuracy: 0.0985\n","\n","Epoch 00002: val_accuracy did not improve from 0.09852\n","Epoch 3/500\n","52/52 [==============================] - 19s 364ms/step - loss: 2.2181 - accuracy: 0.1979 - val_loss: 2.5115 - val_accuracy: 0.0985\n","\n","Epoch 00003: val_accuracy did not improve from 0.09852\n","Epoch 4/500\n","52/52 [==============================] - 19s 367ms/step - loss: 2.1886 - accuracy: 0.2211 - val_loss: 2.6056 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.09852\n","Epoch 5/500\n","52/52 [==============================] - 19s 370ms/step - loss: 2.1695 - accuracy: 0.2211 - val_loss: 2.6075 - val_accuracy: 0.0985\n","\n","Epoch 00005: val_accuracy did not improve from 0.09852\n","Epoch 6/500\n","52/52 [==============================] - 19s 371ms/step - loss: 2.1447 - accuracy: 0.2418 - val_loss: 2.5682 - val_accuracy: 0.0985\n","\n","Epoch 00006: val_accuracy did not improve from 0.09852\n","Epoch 7/500\n","52/52 [==============================] - 19s 373ms/step - loss: 2.1166 - accuracy: 0.2759 - val_loss: 2.5593 - val_accuracy: 0.0985\n","\n","Epoch 00007: val_accuracy did not improve from 0.09852\n","Epoch 8/500\n","52/52 [==============================] - 20s 376ms/step - loss: 2.1018 - accuracy: 0.2649 - val_loss: 2.6056 - val_accuracy: 0.0911\n","\n","Epoch 00008: val_accuracy did not improve from 0.09852\n","Epoch 9/500\n","52/52 [==============================] - 20s 377ms/step - loss: 2.0837 - accuracy: 0.2881 - val_loss: 2.6393 - val_accuracy: 0.0961\n","\n","Epoch 00009: val_accuracy did not improve from 0.09852\n","Epoch 10/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.0578 - accuracy: 0.3045 - val_loss: 2.6344 - val_accuracy: 0.0961\n","\n","Epoch 00010: val_accuracy did not improve from 0.09852\n","Epoch 11/500\n","52/52 [==============================] - 20s 382ms/step - loss: 2.0359 - accuracy: 0.3270 - val_loss: 2.6995 - val_accuracy: 0.0985\n","\n","Epoch 00011: val_accuracy did not improve from 0.09852\n","Epoch 12/500\n","52/52 [==============================] - 20s 383ms/step - loss: 2.0135 - accuracy: 0.3222 - val_loss: 2.7027 - val_accuracy: 0.0961\n","\n","Epoch 00012: val_accuracy did not improve from 0.09852\n","Epoch 13/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.9911 - accuracy: 0.3496 - val_loss: 2.7433 - val_accuracy: 0.0788\n","\n","Epoch 00013: val_accuracy did not improve from 0.09852\n","Epoch 14/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.9674 - accuracy: 0.3703 - val_loss: 2.8339 - val_accuracy: 0.0985\n","\n","Epoch 00014: val_accuracy did not improve from 0.09852\n","Epoch 15/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.9419 - accuracy: 0.3776 - val_loss: 2.6569 - val_accuracy: 0.1010\n","\n","Epoch 00015: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.9145 - accuracy: 0.3934 - val_loss: 2.3742 - val_accuracy: 0.1207\n","\n","Epoch 00016: val_accuracy improved from 0.10099 to 0.12069, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.8931 - accuracy: 0.3946 - val_loss: 2.1164 - val_accuracy: 0.2069\n","\n","Epoch 00017: val_accuracy improved from 0.12069 to 0.20690, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.8694 - accuracy: 0.4239 - val_loss: 2.0396 - val_accuracy: 0.2488\n","\n","Epoch 00018: val_accuracy improved from 0.20690 to 0.24877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.8567 - accuracy: 0.4190 - val_loss: 2.0177 - val_accuracy: 0.2931\n","\n","Epoch 00019: val_accuracy improved from 0.24877 to 0.29310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.8228 - accuracy: 0.4421 - val_loss: 1.9385 - val_accuracy: 0.3448\n","\n","Epoch 00020: val_accuracy improved from 0.29310 to 0.34483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 21/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.8019 - accuracy: 0.4476 - val_loss: 1.8330 - val_accuracy: 0.4138\n","\n","Epoch 00021: val_accuracy improved from 0.34483 to 0.41379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 22/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.7912 - accuracy: 0.4488 - val_loss: 1.7994 - val_accuracy: 0.4039\n","\n","Epoch 00022: val_accuracy did not improve from 0.41379\n","Epoch 23/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.7638 - accuracy: 0.4525 - val_loss: 1.7933 - val_accuracy: 0.4286\n","\n","Epoch 00023: val_accuracy improved from 0.41379 to 0.42857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.7447 - accuracy: 0.4549 - val_loss: 1.7142 - val_accuracy: 0.4187\n","\n","Epoch 00024: val_accuracy did not improve from 0.42857\n","Epoch 25/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.7101 - accuracy: 0.4817 - val_loss: 1.7414 - val_accuracy: 0.4557\n","\n","Epoch 00025: val_accuracy improved from 0.42857 to 0.45567, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.6926 - accuracy: 0.4896 - val_loss: 1.6816 - val_accuracy: 0.4433\n","\n","Epoch 00026: val_accuracy did not improve from 0.45567\n","Epoch 27/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.6719 - accuracy: 0.4860 - val_loss: 1.6672 - val_accuracy: 0.4532\n","\n","Epoch 00027: val_accuracy did not improve from 0.45567\n","Epoch 28/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.6491 - accuracy: 0.5177 - val_loss: 1.6720 - val_accuracy: 0.4778\n","\n","Epoch 00028: val_accuracy improved from 0.45567 to 0.47783, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 29/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.6231 - accuracy: 0.5061 - val_loss: 1.6055 - val_accuracy: 0.4975\n","\n","Epoch 00029: val_accuracy improved from 0.47783 to 0.49754, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 30/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.6043 - accuracy: 0.5262 - val_loss: 1.6099 - val_accuracy: 0.4778\n","\n","Epoch 00030: val_accuracy did not improve from 0.49754\n","Epoch 31/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.5753 - accuracy: 0.5371 - val_loss: 1.6015 - val_accuracy: 0.4581\n","\n","Epoch 00031: val_accuracy did not improve from 0.49754\n","Epoch 32/500\n","52/52 [==============================] - 20s 387ms/step - loss: 1.5546 - accuracy: 0.5524 - val_loss: 1.5517 - val_accuracy: 0.4729\n","\n","Epoch 00032: val_accuracy did not improve from 0.49754\n","Epoch 33/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.5248 - accuracy: 0.5554 - val_loss: 1.5262 - val_accuracy: 0.5197\n","\n","Epoch 00033: val_accuracy improved from 0.49754 to 0.51970, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 34/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.5076 - accuracy: 0.5542 - val_loss: 1.5239 - val_accuracy: 0.5025\n","\n","Epoch 00034: val_accuracy did not improve from 0.51970\n","Epoch 35/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.4820 - accuracy: 0.5743 - val_loss: 1.5171 - val_accuracy: 0.4926\n","\n","Epoch 00035: val_accuracy did not improve from 0.51970\n","Epoch 36/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.4578 - accuracy: 0.5676 - val_loss: 1.5236 - val_accuracy: 0.4951\n","\n","Epoch 00036: val_accuracy did not improve from 0.51970\n","Epoch 37/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.4393 - accuracy: 0.5847 - val_loss: 1.4798 - val_accuracy: 0.5049\n","\n","Epoch 00037: val_accuracy did not improve from 0.51970\n","Epoch 38/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.4248 - accuracy: 0.5926 - val_loss: 1.4488 - val_accuracy: 0.5690\n","\n","Epoch 00038: val_accuracy improved from 0.51970 to 0.56897, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 39/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.4025 - accuracy: 0.6048 - val_loss: 1.4160 - val_accuracy: 0.5271\n","\n","Epoch 00039: val_accuracy did not improve from 0.56897\n","Epoch 40/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.3796 - accuracy: 0.5993 - val_loss: 1.3833 - val_accuracy: 0.5493\n","\n","Epoch 00040: val_accuracy did not improve from 0.56897\n","Epoch 41/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.3523 - accuracy: 0.6163 - val_loss: 1.3551 - val_accuracy: 0.5542\n","\n","Epoch 00041: val_accuracy did not improve from 0.56897\n","Epoch 42/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.3226 - accuracy: 0.6169 - val_loss: 1.3399 - val_accuracy: 0.5517\n","\n","Epoch 00042: val_accuracy did not improve from 0.56897\n","Epoch 43/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.3123 - accuracy: 0.6218 - val_loss: 1.3335 - val_accuracy: 0.5320\n","\n","Epoch 00043: val_accuracy did not improve from 0.56897\n","Epoch 44/500\n","52/52 [==============================] - 20s 382ms/step - loss: 1.2774 - accuracy: 0.6407 - val_loss: 1.3141 - val_accuracy: 0.5419\n","\n","Epoch 00044: val_accuracy did not improve from 0.56897\n","Epoch 45/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.2646 - accuracy: 0.6443 - val_loss: 1.3281 - val_accuracy: 0.5640\n","\n","Epoch 00045: val_accuracy did not improve from 0.56897\n","Epoch 46/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.2398 - accuracy: 0.6401 - val_loss: 1.2572 - val_accuracy: 0.6059\n","\n","Epoch 00046: val_accuracy improved from 0.56897 to 0.60591, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 47/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.2208 - accuracy: 0.6608 - val_loss: 1.2438 - val_accuracy: 0.6281\n","\n","Epoch 00047: val_accuracy improved from 0.60591 to 0.62808, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 48/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.2066 - accuracy: 0.6687 - val_loss: 1.3053 - val_accuracy: 0.5985\n","\n","Epoch 00048: val_accuracy did not improve from 0.62808\n","Epoch 49/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.1716 - accuracy: 0.6650 - val_loss: 1.2430 - val_accuracy: 0.6059\n","\n","Epoch 00049: val_accuracy did not improve from 0.62808\n","Epoch 50/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.1410 - accuracy: 0.6833 - val_loss: 1.2129 - val_accuracy: 0.6379\n","\n","Epoch 00050: val_accuracy improved from 0.62808 to 0.63793, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 51/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.1483 - accuracy: 0.6827 - val_loss: 1.1743 - val_accuracy: 0.6453\n","\n","Epoch 00051: val_accuracy improved from 0.63793 to 0.64532, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 52/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.1180 - accuracy: 0.6906 - val_loss: 1.1744 - val_accuracy: 0.6379\n","\n","Epoch 00052: val_accuracy did not improve from 0.64532\n","Epoch 53/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.0882 - accuracy: 0.6979 - val_loss: 1.1777 - val_accuracy: 0.6404\n","\n","Epoch 00053: val_accuracy did not improve from 0.64532\n","Epoch 54/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.0825 - accuracy: 0.7065 - val_loss: 1.2094 - val_accuracy: 0.6084\n","\n","Epoch 00054: val_accuracy did not improve from 0.64532\n","Epoch 55/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.0599 - accuracy: 0.7132 - val_loss: 1.1475 - val_accuracy: 0.6182\n","\n","Epoch 00055: val_accuracy did not improve from 0.64532\n","Epoch 56/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.0322 - accuracy: 0.7229 - val_loss: 1.1229 - val_accuracy: 0.6601\n","\n","Epoch 00056: val_accuracy improved from 0.64532 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 57/500\n","52/52 [==============================] - 20s 383ms/step - loss: 1.0157 - accuracy: 0.7272 - val_loss: 1.1640 - val_accuracy: 0.6305\n","\n","Epoch 00057: val_accuracy did not improve from 0.66010\n","Epoch 58/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.0000 - accuracy: 0.7241 - val_loss: 1.2298 - val_accuracy: 0.6010\n","\n","Epoch 00058: val_accuracy did not improve from 0.66010\n","Epoch 59/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.9870 - accuracy: 0.7211 - val_loss: 1.0880 - val_accuracy: 0.6502\n","\n","Epoch 00059: val_accuracy did not improve from 0.66010\n","Epoch 60/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.9703 - accuracy: 0.7326 - val_loss: 1.0524 - val_accuracy: 0.6576\n","\n","Epoch 00060: val_accuracy did not improve from 0.66010\n","Epoch 61/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.9554 - accuracy: 0.7467 - val_loss: 1.0890 - val_accuracy: 0.6256\n","\n","Epoch 00061: val_accuracy did not improve from 0.66010\n","Epoch 62/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.9407 - accuracy: 0.7387 - val_loss: 1.0544 - val_accuracy: 0.6478\n","\n","Epoch 00062: val_accuracy did not improve from 0.66010\n","Epoch 63/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.9205 - accuracy: 0.7454 - val_loss: 1.0260 - val_accuracy: 0.6823\n","\n","Epoch 00063: val_accuracy improved from 0.66010 to 0.68227, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 64/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.9032 - accuracy: 0.7533 - val_loss: 1.1591 - val_accuracy: 0.5887\n","\n","Epoch 00064: val_accuracy did not improve from 0.68227\n","Epoch 65/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.8755 - accuracy: 0.7661 - val_loss: 1.0138 - val_accuracy: 0.6675\n","\n","Epoch 00065: val_accuracy did not improve from 0.68227\n","Epoch 66/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.8760 - accuracy: 0.7607 - val_loss: 0.9850 - val_accuracy: 0.6995\n","\n","Epoch 00066: val_accuracy improved from 0.68227 to 0.69951, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 67/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.8609 - accuracy: 0.7625 - val_loss: 1.0037 - val_accuracy: 0.6675\n","\n","Epoch 00067: val_accuracy did not improve from 0.69951\n","Epoch 68/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.8464 - accuracy: 0.7698 - val_loss: 1.0162 - val_accuracy: 0.6897\n","\n","Epoch 00068: val_accuracy did not improve from 0.69951\n","Epoch 69/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.8173 - accuracy: 0.7826 - val_loss: 0.9702 - val_accuracy: 0.6970\n","\n","Epoch 00069: val_accuracy did not improve from 0.69951\n","Epoch 70/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.8177 - accuracy: 0.7728 - val_loss: 1.0183 - val_accuracy: 0.6576\n","\n","Epoch 00070: val_accuracy did not improve from 0.69951\n","Epoch 71/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.7907 - accuracy: 0.7783 - val_loss: 0.9929 - val_accuracy: 0.6995\n","\n","Epoch 00071: val_accuracy did not improve from 0.69951\n","Epoch 72/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.7842 - accuracy: 0.7832 - val_loss: 0.9638 - val_accuracy: 0.6970\n","\n","Epoch 00072: val_accuracy did not improve from 0.69951\n","Epoch 73/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.7707 - accuracy: 0.7808 - val_loss: 1.0120 - val_accuracy: 0.6650\n","\n","Epoch 00073: val_accuracy did not improve from 0.69951\n","Epoch 74/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.7588 - accuracy: 0.8009 - val_loss: 0.9359 - val_accuracy: 0.7020\n","\n","Epoch 00074: val_accuracy improved from 0.69951 to 0.70197, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.7440 - accuracy: 0.8057 - val_loss: 0.9085 - val_accuracy: 0.6773\n","\n","Epoch 00075: val_accuracy did not improve from 0.70197\n","Epoch 76/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.7322 - accuracy: 0.8033 - val_loss: 0.9233 - val_accuracy: 0.6970\n","\n","Epoch 00076: val_accuracy did not improve from 0.70197\n","Epoch 77/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.7137 - accuracy: 0.8100 - val_loss: 0.9500 - val_accuracy: 0.7094\n","\n","Epoch 00077: val_accuracy improved from 0.70197 to 0.70936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 78/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.7042 - accuracy: 0.8155 - val_loss: 0.9388 - val_accuracy: 0.7044\n","\n","Epoch 00078: val_accuracy did not improve from 0.70936\n","Epoch 79/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6946 - accuracy: 0.8167 - val_loss: 0.9097 - val_accuracy: 0.6946\n","\n","Epoch 00079: val_accuracy did not improve from 0.70936\n","Epoch 80/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6863 - accuracy: 0.8173 - val_loss: 0.9135 - val_accuracy: 0.6921\n","\n","Epoch 00080: val_accuracy did not improve from 0.70936\n","Epoch 81/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6816 - accuracy: 0.8069 - val_loss: 0.9101 - val_accuracy: 0.7094\n","\n","Epoch 00081: val_accuracy did not improve from 0.70936\n","Epoch 82/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.6655 - accuracy: 0.8155 - val_loss: 0.8826 - val_accuracy: 0.7241\n","\n","Epoch 00082: val_accuracy improved from 0.70936 to 0.72414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 83/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.6445 - accuracy: 0.8295 - val_loss: 0.8648 - val_accuracy: 0.7020\n","\n","Epoch 00083: val_accuracy did not improve from 0.72414\n","Epoch 84/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6366 - accuracy: 0.8264 - val_loss: 0.8608 - val_accuracy: 0.7167\n","\n","Epoch 00084: val_accuracy did not improve from 0.72414\n","Epoch 85/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6255 - accuracy: 0.8337 - val_loss: 0.8644 - val_accuracy: 0.7094\n","\n","Epoch 00085: val_accuracy did not improve from 0.72414\n","Epoch 86/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6023 - accuracy: 0.8508 - val_loss: 0.8690 - val_accuracy: 0.6897\n","\n","Epoch 00086: val_accuracy did not improve from 0.72414\n","Epoch 87/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.6142 - accuracy: 0.8343 - val_loss: 0.8460 - val_accuracy: 0.7340\n","\n","Epoch 00087: val_accuracy improved from 0.72414 to 0.73399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 88/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5870 - accuracy: 0.8465 - val_loss: 0.9115 - val_accuracy: 0.6749\n","\n","Epoch 00088: val_accuracy did not improve from 0.73399\n","Epoch 89/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.5854 - accuracy: 0.8410 - val_loss: 0.8166 - val_accuracy: 0.7389\n","\n","Epoch 00089: val_accuracy improved from 0.73399 to 0.73892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 90/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5683 - accuracy: 0.8593 - val_loss: 0.7916 - val_accuracy: 0.7463\n","\n","Epoch 00090: val_accuracy improved from 0.73892 to 0.74631, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 91/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.5665 - accuracy: 0.8605 - val_loss: 0.8377 - val_accuracy: 0.7365\n","\n","Epoch 00091: val_accuracy did not improve from 0.74631\n","Epoch 92/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.5444 - accuracy: 0.8611 - val_loss: 0.8305 - val_accuracy: 0.7094\n","\n","Epoch 00092: val_accuracy did not improve from 0.74631\n","Epoch 93/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.5473 - accuracy: 0.8648 - val_loss: 0.8225 - val_accuracy: 0.7266\n","\n","Epoch 00093: val_accuracy did not improve from 0.74631\n","Epoch 94/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5318 - accuracy: 0.8666 - val_loss: 0.8114 - val_accuracy: 0.7217\n","\n","Epoch 00094: val_accuracy did not improve from 0.74631\n","Epoch 95/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5453 - accuracy: 0.8587 - val_loss: 1.0957 - val_accuracy: 0.6207\n","\n","Epoch 00095: val_accuracy did not improve from 0.74631\n","Epoch 96/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.5073 - accuracy: 0.8678 - val_loss: 0.9367 - val_accuracy: 0.6872\n","\n","Epoch 00096: val_accuracy did not improve from 0.74631\n","Epoch 97/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.5104 - accuracy: 0.8739 - val_loss: 0.8292 - val_accuracy: 0.7217\n","\n","Epoch 00097: val_accuracy did not improve from 0.74631\n","Epoch 98/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4796 - accuracy: 0.8855 - val_loss: 0.7948 - val_accuracy: 0.7611\n","\n","Epoch 00098: val_accuracy improved from 0.74631 to 0.76108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 99/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4820 - accuracy: 0.8788 - val_loss: 0.7728 - val_accuracy: 0.7340\n","\n","Epoch 00099: val_accuracy did not improve from 0.76108\n","Epoch 100/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.4793 - accuracy: 0.8764 - val_loss: 0.7765 - val_accuracy: 0.7463\n","\n","Epoch 00100: val_accuracy did not improve from 0.76108\n","Epoch 101/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.4607 - accuracy: 0.8861 - val_loss: 0.8015 - val_accuracy: 0.7537\n","\n","Epoch 00101: val_accuracy did not improve from 0.76108\n","Epoch 102/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4557 - accuracy: 0.8934 - val_loss: 0.8025 - val_accuracy: 0.7340\n","\n","Epoch 00102: val_accuracy did not improve from 0.76108\n","Epoch 103/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.4519 - accuracy: 0.8892 - val_loss: 0.7969 - val_accuracy: 0.7438\n","\n","Epoch 00103: val_accuracy did not improve from 0.76108\n","Epoch 104/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4462 - accuracy: 0.8904 - val_loss: 0.7878 - val_accuracy: 0.7414\n","\n","Epoch 00104: val_accuracy did not improve from 0.76108\n","Epoch 105/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4326 - accuracy: 0.9044 - val_loss: 0.8867 - val_accuracy: 0.7069\n","\n","Epoch 00105: val_accuracy did not improve from 0.76108\n","Epoch 106/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4221 - accuracy: 0.9001 - val_loss: 0.7753 - val_accuracy: 0.7537\n","\n","Epoch 00106: val_accuracy did not improve from 0.76108\n","Epoch 107/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.4134 - accuracy: 0.9044 - val_loss: 0.7500 - val_accuracy: 0.7611\n","\n","Epoch 00107: val_accuracy did not improve from 0.76108\n","Epoch 108/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3945 - accuracy: 0.9032 - val_loss: 0.7644 - val_accuracy: 0.7512\n","\n","Epoch 00108: val_accuracy did not improve from 0.76108\n","Epoch 109/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3846 - accuracy: 0.9135 - val_loss: 0.7665 - val_accuracy: 0.7512\n","\n","Epoch 00109: val_accuracy did not improve from 0.76108\n","Epoch 110/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3915 - accuracy: 0.9111 - val_loss: 0.7360 - val_accuracy: 0.7660\n","\n","Epoch 00110: val_accuracy improved from 0.76108 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 111/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3898 - accuracy: 0.9050 - val_loss: 0.7538 - val_accuracy: 0.7611\n","\n","Epoch 00111: val_accuracy did not improve from 0.76601\n","Epoch 112/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3740 - accuracy: 0.9190 - val_loss: 0.7504 - val_accuracy: 0.7635\n","\n","Epoch 00112: val_accuracy did not improve from 0.76601\n","Epoch 113/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3716 - accuracy: 0.9153 - val_loss: 0.7657 - val_accuracy: 0.7488\n","\n","Epoch 00113: val_accuracy did not improve from 0.76601\n","Epoch 114/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3480 - accuracy: 0.9239 - val_loss: 0.8880 - val_accuracy: 0.6970\n","\n","Epoch 00114: val_accuracy did not improve from 0.76601\n","Epoch 115/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.3650 - accuracy: 0.9153 - val_loss: 0.7777 - val_accuracy: 0.7365\n","\n","Epoch 00115: val_accuracy did not improve from 0.76601\n","Epoch 116/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3615 - accuracy: 0.9129 - val_loss: 0.9834 - val_accuracy: 0.6897\n","\n","Epoch 00116: val_accuracy did not improve from 0.76601\n","Epoch 117/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3361 - accuracy: 0.9263 - val_loss: 0.7620 - val_accuracy: 0.7512\n","\n","Epoch 00117: val_accuracy did not improve from 0.76601\n","Epoch 118/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.3349 - accuracy: 0.9233 - val_loss: 0.7851 - val_accuracy: 0.7414\n","\n","Epoch 00118: val_accuracy did not improve from 0.76601\n","Epoch 119/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3306 - accuracy: 0.9269 - val_loss: 0.7613 - val_accuracy: 0.7463\n","\n","Epoch 00119: val_accuracy did not improve from 0.76601\n","Epoch 120/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3278 - accuracy: 0.9275 - val_loss: 0.7583 - val_accuracy: 0.7586\n","\n","Epoch 00120: val_accuracy did not improve from 0.76601\n","Epoch 121/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3240 - accuracy: 0.9220 - val_loss: 0.7732 - val_accuracy: 0.7414\n","\n","Epoch 00121: val_accuracy did not improve from 0.76601\n","Epoch 122/500\n","52/52 [==============================] - 21s 405ms/step - loss: 0.3143 - accuracy: 0.9324 - val_loss: 0.7654 - val_accuracy: 0.7586\n","\n","Epoch 00122: val_accuracy did not improve from 0.76601\n","Epoch 123/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.3010 - accuracy: 0.9409 - val_loss: 0.8263 - val_accuracy: 0.7094\n","\n","Epoch 00123: val_accuracy did not improve from 0.76601\n","Epoch 124/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3053 - accuracy: 0.9306 - val_loss: 0.7435 - val_accuracy: 0.7414\n","\n","Epoch 00124: val_accuracy did not improve from 0.76601\n","Epoch 125/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2909 - accuracy: 0.9403 - val_loss: 0.7136 - val_accuracy: 0.7808\n","\n","Epoch 00125: val_accuracy improved from 0.76601 to 0.78079, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 126/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2635 - accuracy: 0.9555 - val_loss: 0.7244 - val_accuracy: 0.7537\n","\n","Epoch 00126: val_accuracy did not improve from 0.78079\n","Epoch 127/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2702 - accuracy: 0.9501 - val_loss: 0.7566 - val_accuracy: 0.7537\n","\n","Epoch 00127: val_accuracy did not improve from 0.78079\n","Epoch 128/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2676 - accuracy: 0.9507 - val_loss: 0.7264 - val_accuracy: 0.7414\n","\n","Epoch 00128: val_accuracy did not improve from 0.78079\n","Epoch 129/500\n","52/52 [==============================] - 21s 405ms/step - loss: 0.2718 - accuracy: 0.9452 - val_loss: 0.7252 - val_accuracy: 0.7537\n","\n","Epoch 00129: val_accuracy did not improve from 0.78079\n","Epoch 130/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2679 - accuracy: 0.9488 - val_loss: 0.7393 - val_accuracy: 0.7660\n","\n","Epoch 00130: val_accuracy did not improve from 0.78079\n","Epoch 131/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2584 - accuracy: 0.9531 - val_loss: 0.9397 - val_accuracy: 0.6921\n","\n","Epoch 00131: val_accuracy did not improve from 0.78079\n","Epoch 132/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2684 - accuracy: 0.9507 - val_loss: 0.7762 - val_accuracy: 0.7414\n","\n","Epoch 00132: val_accuracy did not improve from 0.78079\n","Epoch 133/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2593 - accuracy: 0.9501 - val_loss: 0.7330 - val_accuracy: 0.7635\n","\n","Epoch 00133: val_accuracy did not improve from 0.78079\n","Epoch 134/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2455 - accuracy: 0.9549 - val_loss: 0.8168 - val_accuracy: 0.7266\n","\n","Epoch 00134: val_accuracy did not improve from 0.78079\n","Epoch 135/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2405 - accuracy: 0.9653 - val_loss: 0.8144 - val_accuracy: 0.7365\n","\n","Epoch 00135: val_accuracy did not improve from 0.78079\n","Epoch 136/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2295 - accuracy: 0.9665 - val_loss: 0.9151 - val_accuracy: 0.7044\n","\n","Epoch 00136: val_accuracy did not improve from 0.78079\n","Epoch 137/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2421 - accuracy: 0.9495 - val_loss: 0.7278 - val_accuracy: 0.7340\n","\n","Epoch 00137: val_accuracy did not improve from 0.78079\n","Epoch 138/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2249 - accuracy: 0.9677 - val_loss: 0.7232 - val_accuracy: 0.7709\n","\n","Epoch 00138: val_accuracy did not improve from 0.78079\n","Epoch 139/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2197 - accuracy: 0.9549 - val_loss: 0.7385 - val_accuracy: 0.7414\n","\n","Epoch 00139: val_accuracy did not improve from 0.78079\n","Epoch 140/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2153 - accuracy: 0.9635 - val_loss: 0.7989 - val_accuracy: 0.7438\n","\n","Epoch 00140: val_accuracy did not improve from 0.78079\n","Epoch 141/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2111 - accuracy: 0.9635 - val_loss: 0.7755 - val_accuracy: 0.7512\n","\n","Epoch 00141: val_accuracy did not improve from 0.78079\n","Epoch 142/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1935 - accuracy: 0.9744 - val_loss: 0.9501 - val_accuracy: 0.7069\n","\n","Epoch 00142: val_accuracy did not improve from 0.78079\n","Epoch 143/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2263 - accuracy: 0.9537 - val_loss: 0.7208 - val_accuracy: 0.7586\n","\n","Epoch 00143: val_accuracy did not improve from 0.78079\n","Epoch 144/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2004 - accuracy: 0.9665 - val_loss: 0.8509 - val_accuracy: 0.7143\n","\n","Epoch 00144: val_accuracy did not improve from 0.78079\n","Epoch 145/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1955 - accuracy: 0.9708 - val_loss: 0.8966 - val_accuracy: 0.7217\n","\n","Epoch 00145: val_accuracy did not improve from 0.78079\n","Epoch 146/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1990 - accuracy: 0.9689 - val_loss: 0.7309 - val_accuracy: 0.7660\n","\n","Epoch 00146: val_accuracy did not improve from 0.78079\n","Epoch 147/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1961 - accuracy: 0.9653 - val_loss: 0.7384 - val_accuracy: 0.7586\n","\n","Epoch 00147: val_accuracy did not improve from 0.78079\n","Epoch 148/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1874 - accuracy: 0.9744 - val_loss: 0.7172 - val_accuracy: 0.7537\n","\n","Epoch 00148: val_accuracy did not improve from 0.78079\n","Epoch 149/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1902 - accuracy: 0.9689 - val_loss: 0.8144 - val_accuracy: 0.7192\n","\n","Epoch 00149: val_accuracy did not improve from 0.78079\n","Epoch 150/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1750 - accuracy: 0.9762 - val_loss: 0.7125 - val_accuracy: 0.7389\n","\n","Epoch 00150: val_accuracy did not improve from 0.78079\n","Epoch 151/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1772 - accuracy: 0.9750 - val_loss: 0.9450 - val_accuracy: 0.7069\n","\n","Epoch 00151: val_accuracy did not improve from 0.78079\n","Epoch 152/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1766 - accuracy: 0.9726 - val_loss: 0.7741 - val_accuracy: 0.7241\n","\n","Epoch 00152: val_accuracy did not improve from 0.78079\n","Epoch 153/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1635 - accuracy: 0.9799 - val_loss: 0.8544 - val_accuracy: 0.7463\n","\n","Epoch 00153: val_accuracy did not improve from 0.78079\n","Epoch 154/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1595 - accuracy: 0.9781 - val_loss: 0.7680 - val_accuracy: 0.7537\n","\n","Epoch 00154: val_accuracy did not improve from 0.78079\n","Epoch 155/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1672 - accuracy: 0.9714 - val_loss: 0.7691 - val_accuracy: 0.7783\n","\n","Epoch 00155: val_accuracy did not improve from 0.78079\n","Epoch 156/500\n","52/52 [==============================] - 21s 410ms/step - loss: 0.1713 - accuracy: 0.9732 - val_loss: 0.7799 - val_accuracy: 0.7611\n","\n","Epoch 00156: val_accuracy did not improve from 0.78079\n","Epoch 157/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1481 - accuracy: 0.9787 - val_loss: 0.7996 - val_accuracy: 0.7291\n","\n","Epoch 00157: val_accuracy did not improve from 0.78079\n","Epoch 158/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1562 - accuracy: 0.9769 - val_loss: 0.7267 - val_accuracy: 0.7512\n","\n","Epoch 00158: val_accuracy did not improve from 0.78079\n","Epoch 159/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1550 - accuracy: 0.9762 - val_loss: 0.8025 - val_accuracy: 0.7488\n","\n","Epoch 00159: val_accuracy did not improve from 0.78079\n","Epoch 160/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1440 - accuracy: 0.9781 - val_loss: 0.8187 - val_accuracy: 0.7438\n","\n","Epoch 00160: val_accuracy did not improve from 0.78079\n","Epoch 161/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1423 - accuracy: 0.9823 - val_loss: 0.8040 - val_accuracy: 0.7389\n","\n","Epoch 00161: val_accuracy did not improve from 0.78079\n","Epoch 162/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1456 - accuracy: 0.9769 - val_loss: 0.7335 - val_accuracy: 0.7414\n","\n","Epoch 00162: val_accuracy did not improve from 0.78079\n","Epoch 163/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1442 - accuracy: 0.9842 - val_loss: 0.7822 - val_accuracy: 0.7783\n","\n","Epoch 00163: val_accuracy did not improve from 0.78079\n","Epoch 164/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1407 - accuracy: 0.9799 - val_loss: 0.7675 - val_accuracy: 0.7586\n","\n","Epoch 00164: val_accuracy did not improve from 0.78079\n","Epoch 165/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1385 - accuracy: 0.9817 - val_loss: 1.1940 - val_accuracy: 0.6626\n","\n","Epoch 00165: val_accuracy did not improve from 0.78079\n","Epoch 166/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1349 - accuracy: 0.9817 - val_loss: 0.7368 - val_accuracy: 0.7611\n","\n","Epoch 00166: val_accuracy did not improve from 0.78079\n","Epoch 167/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1406 - accuracy: 0.9781 - val_loss: 0.7836 - val_accuracy: 0.7365\n","\n","Epoch 00167: val_accuracy did not improve from 0.78079\n","Epoch 168/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1271 - accuracy: 0.9823 - val_loss: 0.7270 - val_accuracy: 0.7857\n","\n","Epoch 00168: val_accuracy improved from 0.78079 to 0.78571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 169/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1361 - accuracy: 0.9762 - val_loss: 0.7897 - val_accuracy: 0.7586\n","\n","Epoch 00169: val_accuracy did not improve from 0.78571\n","Epoch 170/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1311 - accuracy: 0.9811 - val_loss: 0.7668 - val_accuracy: 0.7611\n","\n","Epoch 00170: val_accuracy did not improve from 0.78571\n","Epoch 171/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1259 - accuracy: 0.9842 - val_loss: 0.7977 - val_accuracy: 0.7537\n","\n","Epoch 00171: val_accuracy did not improve from 0.78571\n","Epoch 172/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1213 - accuracy: 0.9842 - val_loss: 0.7677 - val_accuracy: 0.7635\n","\n","Epoch 00172: val_accuracy did not improve from 0.78571\n","Epoch 173/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1238 - accuracy: 0.9811 - val_loss: 0.7468 - val_accuracy: 0.7685\n","\n","Epoch 00173: val_accuracy did not improve from 0.78571\n","Epoch 174/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1143 - accuracy: 0.9872 - val_loss: 0.7360 - val_accuracy: 0.7635\n","\n","Epoch 00174: val_accuracy did not improve from 0.78571\n","Epoch 175/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1195 - accuracy: 0.9866 - val_loss: 0.8748 - val_accuracy: 0.7389\n","\n","Epoch 00175: val_accuracy did not improve from 0.78571\n","Epoch 176/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1113 - accuracy: 0.9872 - val_loss: 0.8189 - val_accuracy: 0.7512\n","\n","Epoch 00176: val_accuracy did not improve from 0.78571\n","Epoch 177/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1106 - accuracy: 0.9878 - val_loss: 0.8304 - val_accuracy: 0.7389\n","\n","Epoch 00177: val_accuracy did not improve from 0.78571\n","Epoch 178/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1243 - accuracy: 0.9836 - val_loss: 0.7778 - val_accuracy: 0.7660\n","\n","Epoch 00178: val_accuracy did not improve from 0.78571\n","Epoch 179/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1021 - accuracy: 0.9878 - val_loss: 0.8050 - val_accuracy: 0.7488\n","\n","Epoch 00179: val_accuracy did not improve from 0.78571\n","Epoch 180/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1059 - accuracy: 0.9872 - val_loss: 0.7410 - val_accuracy: 0.7709\n","\n","Epoch 00180: val_accuracy did not improve from 0.78571\n","Epoch 181/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1043 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.7414\n","\n","Epoch 00181: val_accuracy did not improve from 0.78571\n","Epoch 182/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1104 - accuracy: 0.9878 - val_loss: 0.7934 - val_accuracy: 0.7438\n","\n","Epoch 00182: val_accuracy did not improve from 0.78571\n","Epoch 183/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0990 - accuracy: 0.9915 - val_loss: 0.7243 - val_accuracy: 0.7734\n","\n","Epoch 00183: val_accuracy did not improve from 0.78571\n","Epoch 184/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1062 - accuracy: 0.9872 - val_loss: 0.9728 - val_accuracy: 0.6970\n","\n","Epoch 00184: val_accuracy did not improve from 0.78571\n","Epoch 185/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0995 - accuracy: 0.9896 - val_loss: 0.7503 - val_accuracy: 0.7586\n","\n","Epoch 00185: val_accuracy did not improve from 0.78571\n","Epoch 186/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1096 - accuracy: 0.9854 - val_loss: 0.7075 - val_accuracy: 0.7833\n","\n","Epoch 00186: val_accuracy did not improve from 0.78571\n","Epoch 187/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1019 - accuracy: 0.9860 - val_loss: 0.9020 - val_accuracy: 0.7291\n","\n","Epoch 00187: val_accuracy did not improve from 0.78571\n","Epoch 188/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0981 - accuracy: 0.9884 - val_loss: 0.7564 - val_accuracy: 0.7660\n","\n","Epoch 00188: val_accuracy did not improve from 0.78571\n","Epoch 189/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0971 - accuracy: 0.9866 - val_loss: 0.8074 - val_accuracy: 0.7340\n","\n","Epoch 00189: val_accuracy did not improve from 0.78571\n","Epoch 190/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0960 - accuracy: 0.9878 - val_loss: 0.7832 - val_accuracy: 0.7611\n","\n","Epoch 00190: val_accuracy did not improve from 0.78571\n","Epoch 191/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0972 - accuracy: 0.9884 - val_loss: 0.8102 - val_accuracy: 0.7512\n","\n","Epoch 00191: val_accuracy did not improve from 0.78571\n","Epoch 192/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0952 - accuracy: 0.9909 - val_loss: 0.7179 - val_accuracy: 0.7833\n","\n","Epoch 00192: val_accuracy did not improve from 0.78571\n","Epoch 193/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0829 - accuracy: 0.9915 - val_loss: 0.8354 - val_accuracy: 0.7389\n","\n","Epoch 00193: val_accuracy did not improve from 0.78571\n","Epoch 194/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0863 - accuracy: 0.9915 - val_loss: 0.8163 - val_accuracy: 0.7414\n","\n","Epoch 00194: val_accuracy did not improve from 0.78571\n","Epoch 195/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0849 - accuracy: 0.9927 - val_loss: 0.7586 - val_accuracy: 0.7611\n","\n","Epoch 00195: val_accuracy did not improve from 0.78571\n","Epoch 196/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0860 - accuracy: 0.9896 - val_loss: 0.7260 - val_accuracy: 0.7685\n","\n","Epoch 00196: val_accuracy did not improve from 0.78571\n","Epoch 197/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0900 - accuracy: 0.9909 - val_loss: 0.7724 - val_accuracy: 0.7734\n","\n","Epoch 00197: val_accuracy did not improve from 0.78571\n","Epoch 198/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0748 - accuracy: 0.9927 - val_loss: 0.7731 - val_accuracy: 0.7635\n","\n","Epoch 00198: val_accuracy did not improve from 0.78571\n","Epoch 199/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0879 - accuracy: 0.9872 - val_loss: 0.7940 - val_accuracy: 0.7389\n","\n","Epoch 00199: val_accuracy did not improve from 0.78571\n","Epoch 200/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0825 - accuracy: 0.9927 - val_loss: 0.7681 - val_accuracy: 0.7709\n","\n","Epoch 00200: val_accuracy did not improve from 0.78571\n","Epoch 201/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0927 - accuracy: 0.9878 - val_loss: 0.8156 - val_accuracy: 0.7586\n","\n","Epoch 00201: val_accuracy did not improve from 0.78571\n","Epoch 202/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0729 - accuracy: 0.9933 - val_loss: 0.7743 - val_accuracy: 0.7611\n","\n","Epoch 00202: val_accuracy did not improve from 0.78571\n","Epoch 203/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0810 - accuracy: 0.9915 - val_loss: 0.8153 - val_accuracy: 0.7537\n","\n","Epoch 00203: val_accuracy did not improve from 0.78571\n","Epoch 204/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0866 - accuracy: 0.9866 - val_loss: 0.7680 - val_accuracy: 0.7759\n","\n","Epoch 00204: val_accuracy did not improve from 0.78571\n","Epoch 205/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0818 - accuracy: 0.9915 - val_loss: 0.7795 - val_accuracy: 0.7488\n","\n","Epoch 00205: val_accuracy did not improve from 0.78571\n","Epoch 206/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0775 - accuracy: 0.9890 - val_loss: 0.7274 - val_accuracy: 0.7635\n","\n","Epoch 00206: val_accuracy did not improve from 0.78571\n","Epoch 207/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0736 - accuracy: 0.9909 - val_loss: 0.8129 - val_accuracy: 0.7586\n","\n","Epoch 00207: val_accuracy did not improve from 0.78571\n","Epoch 208/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0739 - accuracy: 0.9945 - val_loss: 0.7575 - val_accuracy: 0.7709\n","\n","Epoch 00208: val_accuracy did not improve from 0.78571\n","Epoch 209/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0717 - accuracy: 0.9927 - val_loss: 0.7713 - val_accuracy: 0.7635\n","\n","Epoch 00209: val_accuracy did not improve from 0.78571\n","Epoch 210/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0703 - accuracy: 0.9921 - val_loss: 0.7795 - val_accuracy: 0.7660\n","\n","Epoch 00210: val_accuracy did not improve from 0.78571\n","Epoch 211/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0683 - accuracy: 0.9927 - val_loss: 0.7898 - val_accuracy: 0.7512\n","\n","Epoch 00211: val_accuracy did not improve from 0.78571\n","Epoch 212/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0716 - accuracy: 0.9921 - val_loss: 0.7540 - val_accuracy: 0.7685\n","\n","Epoch 00212: val_accuracy did not improve from 0.78571\n","Epoch 213/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0700 - accuracy: 0.9963 - val_loss: 0.7234 - val_accuracy: 0.7783\n","\n","Epoch 00213: val_accuracy did not improve from 0.78571\n","Epoch 214/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0725 - accuracy: 0.9933 - val_loss: 0.7602 - val_accuracy: 0.7759\n","\n","Epoch 00214: val_accuracy did not improve from 0.78571\n","Epoch 215/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0599 - accuracy: 0.9963 - val_loss: 0.7185 - val_accuracy: 0.7759\n","\n","Epoch 00215: val_accuracy did not improve from 0.78571\n","Epoch 216/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0661 - accuracy: 0.9939 - val_loss: 0.7498 - val_accuracy: 0.7709\n","\n","Epoch 00216: val_accuracy did not improve from 0.78571\n","Epoch 217/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0735 - accuracy: 0.9896 - val_loss: 0.8994 - val_accuracy: 0.7414\n","\n","Epoch 00217: val_accuracy did not improve from 0.78571\n","Epoch 218/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0712 - accuracy: 0.9921 - val_loss: 0.9682 - val_accuracy: 0.7389\n","\n","Epoch 00218: val_accuracy did not improve from 0.78571\n","Epoch 219/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0759 - accuracy: 0.9915 - val_loss: 0.7988 - val_accuracy: 0.7611\n","\n","Epoch 00219: val_accuracy did not improve from 0.78571\n","Epoch 220/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0721 - accuracy: 0.9896 - val_loss: 0.7419 - val_accuracy: 0.7857\n","\n","Epoch 00220: val_accuracy did not improve from 0.78571\n","Epoch 221/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0600 - accuracy: 0.9933 - val_loss: 0.7679 - val_accuracy: 0.7759\n","\n","Epoch 00221: val_accuracy did not improve from 0.78571\n","Epoch 222/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0674 - accuracy: 0.9933 - val_loss: 0.7788 - val_accuracy: 0.7611\n","\n","Epoch 00222: val_accuracy did not improve from 0.78571\n","Epoch 223/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0675 - accuracy: 0.9915 - val_loss: 0.8987 - val_accuracy: 0.7389\n","\n","Epoch 00223: val_accuracy did not improve from 0.78571\n","Epoch 224/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0595 - accuracy: 0.9939 - val_loss: 0.7671 - val_accuracy: 0.7537\n","\n","Epoch 00224: val_accuracy did not improve from 0.78571\n","Epoch 225/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0682 - accuracy: 0.9921 - val_loss: 0.7646 - val_accuracy: 0.7635\n","\n","Epoch 00225: val_accuracy did not improve from 0.78571\n","Epoch 226/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0686 - accuracy: 0.9915 - val_loss: 0.7541 - val_accuracy: 0.7611\n","\n","Epoch 00226: val_accuracy did not improve from 0.78571\n","Epoch 227/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0713 - accuracy: 0.9890 - val_loss: 1.3948 - val_accuracy: 0.6232\n","\n","Epoch 00227: val_accuracy did not improve from 0.78571\n","Epoch 228/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0750 - accuracy: 0.9909 - val_loss: 0.8678 - val_accuracy: 0.7463\n","\n","Epoch 00228: val_accuracy did not improve from 0.78571\n","Epoch 229/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0570 - accuracy: 0.9951 - val_loss: 0.8457 - val_accuracy: 0.7586\n","\n","Epoch 00229: val_accuracy did not improve from 0.78571\n","Epoch 230/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0582 - accuracy: 0.9970 - val_loss: 0.7412 - val_accuracy: 0.7808\n","\n","Epoch 00230: val_accuracy did not improve from 0.78571\n","Epoch 231/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0669 - accuracy: 0.9957 - val_loss: 0.7449 - val_accuracy: 0.7586\n","\n","Epoch 00231: val_accuracy did not improve from 0.78571\n","Epoch 232/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0530 - accuracy: 0.9970 - val_loss: 0.8226 - val_accuracy: 0.7488\n","\n","Epoch 00232: val_accuracy did not improve from 0.78571\n","Epoch 233/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0681 - accuracy: 0.9921 - val_loss: 0.7640 - val_accuracy: 0.7709\n","\n","Epoch 00233: val_accuracy did not improve from 0.78571\n","Epoch 234/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0571 - accuracy: 0.9957 - val_loss: 0.7777 - val_accuracy: 0.7808\n","\n","Epoch 00234: val_accuracy did not improve from 0.78571\n","Epoch 235/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0519 - accuracy: 0.9951 - val_loss: 0.7243 - val_accuracy: 0.7685\n","\n","Epoch 00235: val_accuracy did not improve from 0.78571\n","Epoch 236/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0569 - accuracy: 0.9957 - val_loss: 0.7567 - val_accuracy: 0.7438\n","\n","Epoch 00236: val_accuracy did not improve from 0.78571\n","Epoch 237/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0602 - accuracy: 0.9927 - val_loss: 0.7496 - val_accuracy: 0.7709\n","\n","Epoch 00237: val_accuracy did not improve from 0.78571\n","Epoch 238/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0669 - accuracy: 0.9896 - val_loss: 0.9788 - val_accuracy: 0.7020\n","\n","Epoch 00238: val_accuracy did not improve from 0.78571\n","Epoch 239/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0494 - accuracy: 0.9945 - val_loss: 0.7810 - val_accuracy: 0.7759\n","\n","Epoch 00239: val_accuracy did not improve from 0.78571\n","Epoch 240/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0548 - accuracy: 0.9945 - val_loss: 0.7606 - val_accuracy: 0.7512\n","\n","Epoch 00240: val_accuracy did not improve from 0.78571\n","Epoch 241/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0542 - accuracy: 0.9945 - val_loss: 0.8378 - val_accuracy: 0.7537\n","\n","Epoch 00241: val_accuracy did not improve from 0.78571\n","Epoch 242/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0479 - accuracy: 0.9976 - val_loss: 0.7804 - val_accuracy: 0.7635\n","\n","Epoch 00242: val_accuracy did not improve from 0.78571\n","Epoch 243/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0430 - accuracy: 0.9957 - val_loss: 0.7875 - val_accuracy: 0.7611\n","\n","Epoch 00243: val_accuracy did not improve from 0.78571\n","Epoch 244/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0571 - accuracy: 0.9945 - val_loss: 0.7523 - val_accuracy: 0.7734\n","\n","Epoch 00244: val_accuracy did not improve from 0.78571\n","Epoch 245/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0473 - accuracy: 0.9982 - val_loss: 0.8270 - val_accuracy: 0.7611\n","\n","Epoch 00245: val_accuracy did not improve from 0.78571\n","Epoch 246/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0552 - accuracy: 0.9945 - val_loss: 0.8103 - val_accuracy: 0.7685\n","\n","Epoch 00246: val_accuracy did not improve from 0.78571\n","Epoch 247/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0465 - accuracy: 0.9970 - val_loss: 0.7441 - val_accuracy: 0.7759\n","\n","Epoch 00247: val_accuracy did not improve from 0.78571\n","Epoch 248/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0512 - accuracy: 0.9927 - val_loss: 0.8060 - val_accuracy: 0.7611\n","\n","Epoch 00248: val_accuracy did not improve from 0.78571\n","Epoch 249/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0514 - accuracy: 0.9945 - val_loss: 0.8205 - val_accuracy: 0.7488\n","\n","Epoch 00249: val_accuracy did not improve from 0.78571\n","Epoch 250/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0506 - accuracy: 0.9957 - val_loss: 0.7650 - val_accuracy: 0.7611\n","\n","Epoch 00250: val_accuracy did not improve from 0.78571\n","Epoch 251/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0468 - accuracy: 0.9963 - val_loss: 0.7986 - val_accuracy: 0.7586\n","\n","Epoch 00251: val_accuracy did not improve from 0.78571\n","Epoch 252/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0494 - accuracy: 0.9927 - val_loss: 0.7574 - val_accuracy: 0.7685\n","\n","Epoch 00252: val_accuracy did not improve from 0.78571\n","Epoch 253/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0457 - accuracy: 0.9945 - val_loss: 0.7358 - val_accuracy: 0.7660\n","\n","Epoch 00253: val_accuracy did not improve from 0.78571\n","Epoch 254/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0447 - accuracy: 0.9988 - val_loss: 0.7755 - val_accuracy: 0.7709\n","\n","Epoch 00254: val_accuracy did not improve from 0.78571\n","Epoch 255/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.7734\n","\n","Epoch 00255: val_accuracy did not improve from 0.78571\n","Epoch 256/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0408 - accuracy: 0.9970 - val_loss: 0.7779 - val_accuracy: 0.7734\n","\n","Epoch 00256: val_accuracy did not improve from 0.78571\n","Epoch 257/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0432 - accuracy: 0.9951 - val_loss: 0.6942 - val_accuracy: 0.7956\n","\n","Epoch 00257: val_accuracy improved from 0.78571 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 258/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7512\n","\n","Epoch 00258: val_accuracy did not improve from 0.79557\n","Epoch 259/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0419 - accuracy: 0.9976 - val_loss: 0.9592 - val_accuracy: 0.7143\n","\n","Epoch 00259: val_accuracy did not improve from 0.79557\n","Epoch 260/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0473 - accuracy: 0.9957 - val_loss: 0.8136 - val_accuracy: 0.7611\n","\n","Epoch 00260: val_accuracy did not improve from 0.79557\n","Epoch 261/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0457 - accuracy: 0.9976 - val_loss: 0.8100 - val_accuracy: 0.7562\n","\n","Epoch 00261: val_accuracy did not improve from 0.79557\n","Epoch 262/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0459 - accuracy: 0.9963 - val_loss: 0.9059 - val_accuracy: 0.7463\n","\n","Epoch 00262: val_accuracy did not improve from 0.79557\n","Epoch 263/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0378 - accuracy: 0.9970 - val_loss: 0.7328 - val_accuracy: 0.7833\n","\n","Epoch 00263: val_accuracy did not improve from 0.79557\n","Epoch 264/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0378 - accuracy: 0.9976 - val_loss: 0.7806 - val_accuracy: 0.7488\n","\n","Epoch 00264: val_accuracy did not improve from 0.79557\n","Epoch 265/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0447 - accuracy: 0.9976 - val_loss: 0.8074 - val_accuracy: 0.7537\n","\n","Epoch 00265: val_accuracy did not improve from 0.79557\n","Epoch 266/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0471 - accuracy: 0.9957 - val_loss: 0.8434 - val_accuracy: 0.7512\n","\n","Epoch 00266: val_accuracy did not improve from 0.79557\n","Epoch 267/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0439 - accuracy: 0.9970 - val_loss: 0.8251 - val_accuracy: 0.7783\n","\n","Epoch 00267: val_accuracy did not improve from 0.79557\n","Epoch 268/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0437 - accuracy: 0.9957 - val_loss: 0.7703 - val_accuracy: 0.7709\n","\n","Epoch 00268: val_accuracy did not improve from 0.79557\n","Epoch 269/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0409 - accuracy: 0.9939 - val_loss: 0.7517 - val_accuracy: 0.7709\n","\n","Epoch 00269: val_accuracy did not improve from 0.79557\n","Epoch 270/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0355 - accuracy: 0.9982 - val_loss: 0.8614 - val_accuracy: 0.7463\n","\n","Epoch 00270: val_accuracy did not improve from 0.79557\n","Epoch 271/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0451 - accuracy: 0.9963 - val_loss: 0.7412 - val_accuracy: 0.7931\n","\n","Epoch 00271: val_accuracy did not improve from 0.79557\n","Epoch 272/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0394 - accuracy: 0.9963 - val_loss: 0.8029 - val_accuracy: 0.7685\n","\n","Epoch 00272: val_accuracy did not improve from 0.79557\n","Epoch 273/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0376 - accuracy: 0.9970 - val_loss: 0.8441 - val_accuracy: 0.7611\n","\n","Epoch 00273: val_accuracy did not improve from 0.79557\n","Epoch 274/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0392 - accuracy: 0.9982 - val_loss: 0.8382 - val_accuracy: 0.7463\n","\n","Epoch 00274: val_accuracy did not improve from 0.79557\n","Epoch 275/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0394 - accuracy: 0.9963 - val_loss: 0.7280 - val_accuracy: 0.8079\n","\n","Epoch 00275: val_accuracy improved from 0.79557 to 0.80788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 276/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0370 - accuracy: 0.9970 - val_loss: 0.9043 - val_accuracy: 0.7340\n","\n","Epoch 00276: val_accuracy did not improve from 0.80788\n","Epoch 277/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0396 - accuracy: 0.9982 - val_loss: 0.7487 - val_accuracy: 0.7808\n","\n","Epoch 00277: val_accuracy did not improve from 0.80788\n","Epoch 278/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0340 - accuracy: 0.9982 - val_loss: 0.8741 - val_accuracy: 0.7463\n","\n","Epoch 00278: val_accuracy did not improve from 0.80788\n","Epoch 279/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0366 - accuracy: 0.9957 - val_loss: 0.7730 - val_accuracy: 0.7685\n","\n","Epoch 00279: val_accuracy did not improve from 0.80788\n","Epoch 280/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0386 - accuracy: 0.9970 - val_loss: 0.7351 - val_accuracy: 0.7709\n","\n","Epoch 00280: val_accuracy did not improve from 0.80788\n","Epoch 281/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0361 - accuracy: 0.9976 - val_loss: 0.7216 - val_accuracy: 0.7882\n","\n","Epoch 00281: val_accuracy did not improve from 0.80788\n","Epoch 282/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0364 - accuracy: 0.9963 - val_loss: 0.7682 - val_accuracy: 0.7759\n","\n","Epoch 00282: val_accuracy did not improve from 0.80788\n","Epoch 283/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0381 - accuracy: 0.9970 - val_loss: 0.8156 - val_accuracy: 0.7635\n","\n","Epoch 00283: val_accuracy did not improve from 0.80788\n","Epoch 284/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0429 - accuracy: 0.9957 - val_loss: 0.7569 - val_accuracy: 0.7833\n","\n","Epoch 00284: val_accuracy did not improve from 0.80788\n","Epoch 285/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0354 - accuracy: 0.9988 - val_loss: 0.7919 - val_accuracy: 0.7734\n","\n","Epoch 00285: val_accuracy did not improve from 0.80788\n","Epoch 286/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0379 - accuracy: 0.9963 - val_loss: 0.7423 - val_accuracy: 0.7808\n","\n","Epoch 00286: val_accuracy did not improve from 0.80788\n","Epoch 287/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0372 - accuracy: 0.9963 - val_loss: 0.7803 - val_accuracy: 0.7709\n","\n","Epoch 00287: val_accuracy did not improve from 0.80788\n","Epoch 288/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0335 - accuracy: 0.9970 - val_loss: 0.7564 - val_accuracy: 0.7808\n","\n","Epoch 00288: val_accuracy did not improve from 0.80788\n","Epoch 289/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0361 - accuracy: 0.9982 - val_loss: 0.8004 - val_accuracy: 0.7734\n","\n","Epoch 00289: val_accuracy did not improve from 0.80788\n","Epoch 290/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0328 - accuracy: 0.9976 - val_loss: 0.8166 - val_accuracy: 0.7734\n","\n","Epoch 00290: val_accuracy did not improve from 0.80788\n","Epoch 291/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0296 - accuracy: 0.9982 - val_loss: 0.8406 - val_accuracy: 0.7315\n","\n","Epoch 00291: val_accuracy did not improve from 0.80788\n","Epoch 292/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0319 - accuracy: 0.9982 - val_loss: 0.7744 - val_accuracy: 0.7759\n","\n","Epoch 00292: val_accuracy did not improve from 0.80788\n","Epoch 293/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0384 - accuracy: 0.9951 - val_loss: 0.8836 - val_accuracy: 0.7488\n","\n","Epoch 00293: val_accuracy did not improve from 0.80788\n","Epoch 294/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0428 - accuracy: 0.9957 - val_loss: 0.7713 - val_accuracy: 0.7635\n","\n","Epoch 00294: val_accuracy did not improve from 0.80788\n","Epoch 295/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0307 - accuracy: 0.9982 - val_loss: 0.8384 - val_accuracy: 0.7685\n","\n","Epoch 00295: val_accuracy did not improve from 0.80788\n","Epoch 296/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0332 - accuracy: 0.9988 - val_loss: 0.7321 - val_accuracy: 0.8054\n","\n","Epoch 00296: val_accuracy did not improve from 0.80788\n","Epoch 297/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0407 - accuracy: 0.9963 - val_loss: 0.9580 - val_accuracy: 0.7463\n","\n","Epoch 00297: val_accuracy did not improve from 0.80788\n","Epoch 298/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0360 - accuracy: 0.9957 - val_loss: 0.9804 - val_accuracy: 0.7365\n","\n","Epoch 00298: val_accuracy did not improve from 0.80788\n","Epoch 299/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0340 - accuracy: 0.9976 - val_loss: 0.7271 - val_accuracy: 0.7808\n","\n","Epoch 00299: val_accuracy did not improve from 0.80788\n","Epoch 300/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0344 - accuracy: 0.9970 - val_loss: 0.8227 - val_accuracy: 0.7537\n","\n","Epoch 00300: val_accuracy did not improve from 0.80788\n","Epoch 301/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0313 - accuracy: 0.9963 - val_loss: 0.9162 - val_accuracy: 0.7414\n","\n","Epoch 00301: val_accuracy did not improve from 0.80788\n","Epoch 302/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0326 - accuracy: 0.9976 - val_loss: 0.8063 - val_accuracy: 0.7685\n","\n","Epoch 00302: val_accuracy did not improve from 0.80788\n","Epoch 303/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0339 - accuracy: 0.9963 - val_loss: 0.9009 - val_accuracy: 0.7562\n","\n","Epoch 00303: val_accuracy did not improve from 0.80788\n","Epoch 304/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0386 - accuracy: 0.9970 - val_loss: 0.8160 - val_accuracy: 0.7635\n","\n","Epoch 00304: val_accuracy did not improve from 0.80788\n","Epoch 305/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0306 - accuracy: 0.9988 - val_loss: 0.7486 - val_accuracy: 0.7980\n","\n","Epoch 00305: val_accuracy did not improve from 0.80788\n","Epoch 306/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0307 - accuracy: 0.9976 - val_loss: 0.7203 - val_accuracy: 0.7833\n","\n","Epoch 00306: val_accuracy did not improve from 0.80788\n","Epoch 307/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0302 - accuracy: 0.9982 - val_loss: 0.7747 - val_accuracy: 0.7783\n","\n","Epoch 00307: val_accuracy did not improve from 0.80788\n","Epoch 308/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0369 - accuracy: 0.9951 - val_loss: 0.8138 - val_accuracy: 0.7635\n","\n","Epoch 00308: val_accuracy did not improve from 0.80788\n","Epoch 309/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0406 - accuracy: 0.9939 - val_loss: 0.7848 - val_accuracy: 0.7857\n","\n","Epoch 00309: val_accuracy did not improve from 0.80788\n","Epoch 310/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0391 - accuracy: 0.9963 - val_loss: 0.7730 - val_accuracy: 0.7808\n","\n","Epoch 00310: val_accuracy did not improve from 0.80788\n","Epoch 311/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0353 - accuracy: 0.9970 - val_loss: 0.9014 - val_accuracy: 0.7365\n","\n","Epoch 00311: val_accuracy did not improve from 0.80788\n","Epoch 312/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0368 - accuracy: 0.9927 - val_loss: 0.7618 - val_accuracy: 0.7734\n","\n","Epoch 00312: val_accuracy did not improve from 0.80788\n","Epoch 313/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0365 - accuracy: 0.9963 - val_loss: 0.7028 - val_accuracy: 0.7980\n","\n","Epoch 00313: val_accuracy did not improve from 0.80788\n","Epoch 314/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0293 - accuracy: 0.9970 - val_loss: 0.8303 - val_accuracy: 0.7734\n","\n","Epoch 00314: val_accuracy did not improve from 0.80788\n","Epoch 315/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0311 - accuracy: 0.9982 - val_loss: 0.7609 - val_accuracy: 0.7635\n","\n","Epoch 00315: val_accuracy did not improve from 0.80788\n","Epoch 316/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0310 - accuracy: 0.9976 - val_loss: 0.7583 - val_accuracy: 0.7685\n","\n","Epoch 00316: val_accuracy did not improve from 0.80788\n","Epoch 317/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0305 - accuracy: 0.9976 - val_loss: 0.8320 - val_accuracy: 0.7611\n","\n","Epoch 00317: val_accuracy did not improve from 0.80788\n","Epoch 318/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0281 - accuracy: 0.9988 - val_loss: 0.7556 - val_accuracy: 0.7808\n","\n","Epoch 00318: val_accuracy did not improve from 0.80788\n","Epoch 319/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0317 - accuracy: 0.9970 - val_loss: 0.7724 - val_accuracy: 0.7882\n","\n","Epoch 00319: val_accuracy did not improve from 0.80788\n","Epoch 320/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0246 - accuracy: 0.9982 - val_loss: 0.7922 - val_accuracy: 0.7857\n","\n","Epoch 00320: val_accuracy did not improve from 0.80788\n","Epoch 321/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0270 - accuracy: 0.9988 - val_loss: 0.7894 - val_accuracy: 0.7808\n","\n","Epoch 00321: val_accuracy did not improve from 0.80788\n","Epoch 322/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0270 - accuracy: 0.9988 - val_loss: 0.8001 - val_accuracy: 0.7562\n","\n","Epoch 00322: val_accuracy did not improve from 0.80788\n","Epoch 323/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0283 - accuracy: 0.9982 - val_loss: 0.7829 - val_accuracy: 0.7759\n","\n","Epoch 00323: val_accuracy did not improve from 0.80788\n","Epoch 324/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0348 - accuracy: 0.9970 - val_loss: 0.7315 - val_accuracy: 0.7783\n","\n","Epoch 00324: val_accuracy did not improve from 0.80788\n","Epoch 325/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0237 - accuracy: 0.9988 - val_loss: 0.6924 - val_accuracy: 0.7931\n","\n","Epoch 00325: val_accuracy did not improve from 0.80788\n","Epoch 326/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0301 - accuracy: 0.9963 - val_loss: 0.7640 - val_accuracy: 0.7709\n","\n","Epoch 00326: val_accuracy did not improve from 0.80788\n","Epoch 327/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0265 - accuracy: 0.9994 - val_loss: 0.8246 - val_accuracy: 0.7635\n","\n","Epoch 00327: val_accuracy did not improve from 0.80788\n","Epoch 328/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0310 - accuracy: 0.9976 - val_loss: 0.7837 - val_accuracy: 0.7562\n","\n","Epoch 00328: val_accuracy did not improve from 0.80788\n","Epoch 329/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0311 - accuracy: 0.9982 - val_loss: 0.9229 - val_accuracy: 0.7291\n","\n","Epoch 00329: val_accuracy did not improve from 0.80788\n","Epoch 330/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0286 - accuracy: 0.9970 - val_loss: 0.9206 - val_accuracy: 0.7512\n","\n","Epoch 00330: val_accuracy did not improve from 0.80788\n","Epoch 331/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0282 - accuracy: 0.9982 - val_loss: 0.8326 - val_accuracy: 0.7611\n","\n","Epoch 00331: val_accuracy did not improve from 0.80788\n","Epoch 332/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0291 - accuracy: 0.9988 - val_loss: 0.7671 - val_accuracy: 0.7709\n","\n","Epoch 00332: val_accuracy did not improve from 0.80788\n","Epoch 333/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0343 - accuracy: 0.9963 - val_loss: 0.7729 - val_accuracy: 0.7783\n","\n","Epoch 00333: val_accuracy did not improve from 0.80788\n","Epoch 334/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0373 - accuracy: 0.9957 - val_loss: 0.8178 - val_accuracy: 0.7635\n","\n","Epoch 00334: val_accuracy did not improve from 0.80788\n","Epoch 335/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0323 - accuracy: 0.9957 - val_loss: 0.7788 - val_accuracy: 0.7463\n","\n","Epoch 00335: val_accuracy did not improve from 0.80788\n","Epoch 336/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0352 - accuracy: 0.9970 - val_loss: 0.8271 - val_accuracy: 0.7734\n","\n","Epoch 00336: val_accuracy did not improve from 0.80788\n","Epoch 337/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0253 - accuracy: 0.9976 - val_loss: 0.9258 - val_accuracy: 0.7635\n","\n","Epoch 00337: val_accuracy did not improve from 0.80788\n","Epoch 338/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0284 - accuracy: 0.9970 - val_loss: 0.8003 - val_accuracy: 0.7931\n","\n","Epoch 00338: val_accuracy did not improve from 0.80788\n","Epoch 339/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 0.7880 - val_accuracy: 0.7635\n","\n","Epoch 00339: val_accuracy did not improve from 0.80788\n","Epoch 340/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0235 - accuracy: 0.9994 - val_loss: 0.7552 - val_accuracy: 0.7759\n","\n","Epoch 00340: val_accuracy did not improve from 0.80788\n","Epoch 341/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0258 - accuracy: 0.9988 - val_loss: 0.7385 - val_accuracy: 0.7906\n","\n","Epoch 00341: val_accuracy did not improve from 0.80788\n","Epoch 342/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0279 - accuracy: 0.9994 - val_loss: 0.7598 - val_accuracy: 0.7635\n","\n","Epoch 00342: val_accuracy did not improve from 0.80788\n","Epoch 343/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0274 - accuracy: 0.9970 - val_loss: 0.7490 - val_accuracy: 0.7783\n","\n","Epoch 00343: val_accuracy did not improve from 0.80788\n","Epoch 344/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0267 - accuracy: 0.9976 - val_loss: 0.7756 - val_accuracy: 0.7685\n","\n","Epoch 00344: val_accuracy did not improve from 0.80788\n","Epoch 345/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0250 - accuracy: 0.9994 - val_loss: 0.8195 - val_accuracy: 0.7660\n","\n","Epoch 00345: val_accuracy did not improve from 0.80788\n","Epoch 346/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0252 - accuracy: 0.9976 - val_loss: 0.7561 - val_accuracy: 0.7709\n","\n","Epoch 00346: val_accuracy did not improve from 0.80788\n","Epoch 347/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0284 - accuracy: 0.9963 - val_loss: 0.8073 - val_accuracy: 0.7562\n","\n","Epoch 00347: val_accuracy did not improve from 0.80788\n","Epoch 348/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0240 - accuracy: 0.9994 - val_loss: 0.8072 - val_accuracy: 0.7611\n","\n","Epoch 00348: val_accuracy did not improve from 0.80788\n","Epoch 349/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0243 - accuracy: 0.9982 - val_loss: 0.8092 - val_accuracy: 0.7660\n","\n","Epoch 00349: val_accuracy did not improve from 0.80788\n","Epoch 350/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0199 - accuracy: 0.9988 - val_loss: 0.8057 - val_accuracy: 0.7759\n","\n","Epoch 00350: val_accuracy did not improve from 0.80788\n","Epoch 351/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0222 - accuracy: 0.9988 - val_loss: 0.8027 - val_accuracy: 0.7611\n","\n","Epoch 00351: val_accuracy did not improve from 0.80788\n","Epoch 352/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0221 - accuracy: 0.9994 - val_loss: 0.7552 - val_accuracy: 0.7759\n","\n","Epoch 00352: val_accuracy did not improve from 0.80788\n","Epoch 353/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0236 - accuracy: 0.9982 - val_loss: 0.8072 - val_accuracy: 0.7734\n","\n","Epoch 00353: val_accuracy did not improve from 0.80788\n","Epoch 354/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0278 - accuracy: 0.9963 - val_loss: 0.8511 - val_accuracy: 0.7660\n","\n","Epoch 00354: val_accuracy did not improve from 0.80788\n","Epoch 355/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0192 - accuracy: 0.9994 - val_loss: 0.7398 - val_accuracy: 0.7833\n","\n","Epoch 00355: val_accuracy did not improve from 0.80788\n","Epoch 356/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0247 - accuracy: 0.9988 - val_loss: 0.7367 - val_accuracy: 0.7882\n","\n","Epoch 00356: val_accuracy did not improve from 0.80788\n","Epoch 357/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0257 - accuracy: 0.9976 - val_loss: 0.7805 - val_accuracy: 0.7759\n","\n","Epoch 00357: val_accuracy did not improve from 0.80788\n","Epoch 358/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0239 - accuracy: 0.9988 - val_loss: 0.7997 - val_accuracy: 0.7660\n","\n","Epoch 00358: val_accuracy did not improve from 0.80788\n","Epoch 359/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0256 - accuracy: 0.9976 - val_loss: 0.7671 - val_accuracy: 0.7783\n","\n","Epoch 00359: val_accuracy did not improve from 0.80788\n","Epoch 360/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.7783\n","\n","Epoch 00360: val_accuracy did not improve from 0.80788\n","Epoch 361/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0264 - accuracy: 0.9982 - val_loss: 0.9706 - val_accuracy: 0.7365\n","\n","Epoch 00361: val_accuracy did not improve from 0.80788\n","Epoch 362/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0260 - accuracy: 0.9976 - val_loss: 0.7954 - val_accuracy: 0.7783\n","\n","Epoch 00362: val_accuracy did not improve from 0.80788\n","Epoch 363/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0269 - accuracy: 0.9976 - val_loss: 1.1812 - val_accuracy: 0.6946\n","\n","Epoch 00363: val_accuracy did not improve from 0.80788\n","Epoch 364/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0282 - accuracy: 0.9951 - val_loss: 1.5116 - val_accuracy: 0.5985\n","\n","Epoch 00364: val_accuracy did not improve from 0.80788\n","Epoch 365/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0218 - accuracy: 0.9994 - val_loss: 0.7547 - val_accuracy: 0.7882\n","\n","Epoch 00365: val_accuracy did not improve from 0.80788\n","Epoch 366/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0226 - accuracy: 0.9988 - val_loss: 0.7781 - val_accuracy: 0.7808\n","\n","Epoch 00366: val_accuracy did not improve from 0.80788\n","Epoch 367/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0205 - accuracy: 0.9988 - val_loss: 0.7471 - val_accuracy: 0.7808\n","\n","Epoch 00367: val_accuracy did not improve from 0.80788\n","Epoch 368/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.7882\n","\n","Epoch 00368: val_accuracy did not improve from 0.80788\n","Epoch 369/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7956\n","\n","Epoch 00369: val_accuracy did not improve from 0.80788\n","Epoch 370/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0251 - accuracy: 0.9970 - val_loss: 0.8415 - val_accuracy: 0.7635\n","\n","Epoch 00370: val_accuracy did not improve from 0.80788\n","Epoch 371/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0250 - accuracy: 0.9976 - val_loss: 0.8291 - val_accuracy: 0.7635\n","\n","Epoch 00371: val_accuracy did not improve from 0.80788\n","Epoch 372/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0193 - accuracy: 0.9988 - val_loss: 0.7860 - val_accuracy: 0.7906\n","\n","Epoch 00372: val_accuracy did not improve from 0.80788\n","Epoch 373/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0196 - accuracy: 0.9994 - val_loss: 0.7881 - val_accuracy: 0.7734\n","\n","Epoch 00373: val_accuracy did not improve from 0.80788\n","Epoch 374/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0223 - accuracy: 0.9988 - val_loss: 0.8054 - val_accuracy: 0.7906\n","\n","Epoch 00374: val_accuracy did not improve from 0.80788\n","Epoch 375/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0215 - accuracy: 0.9982 - val_loss: 0.8198 - val_accuracy: 0.7685\n","\n","Epoch 00375: val_accuracy did not improve from 0.80788\n","Epoch 376/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0206 - accuracy: 0.9988 - val_loss: 0.7785 - val_accuracy: 0.7833\n","\n","Epoch 00376: val_accuracy did not improve from 0.80788\n","Epoch 377/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0220 - accuracy: 0.9994 - val_loss: 0.7393 - val_accuracy: 0.7857\n","\n","Epoch 00377: val_accuracy did not improve from 0.80788\n","Epoch 378/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0229 - accuracy: 0.9994 - val_loss: 0.7878 - val_accuracy: 0.7833\n","\n","Epoch 00378: val_accuracy did not improve from 0.80788\n","Epoch 379/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.7808\n","\n","Epoch 00379: val_accuracy did not improve from 0.80788\n","Epoch 380/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0206 - accuracy: 0.9988 - val_loss: 0.7556 - val_accuracy: 0.7857\n","\n","Epoch 00380: val_accuracy did not improve from 0.80788\n","Epoch 381/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0205 - accuracy: 0.9988 - val_loss: 0.7733 - val_accuracy: 0.7857\n","\n","Epoch 00381: val_accuracy did not improve from 0.80788\n","Epoch 382/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0229 - accuracy: 0.9976 - val_loss: 0.8833 - val_accuracy: 0.7562\n","\n","Epoch 00382: val_accuracy did not improve from 0.80788\n","Epoch 383/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0221 - accuracy: 0.9988 - val_loss: 0.7912 - val_accuracy: 0.7562\n","\n","Epoch 00383: val_accuracy did not improve from 0.80788\n","Epoch 384/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0264 - accuracy: 0.9976 - val_loss: 0.8672 - val_accuracy: 0.7759\n","\n","Epoch 00384: val_accuracy did not improve from 0.80788\n","Epoch 385/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0244 - accuracy: 0.9982 - val_loss: 0.7887 - val_accuracy: 0.7783\n","\n","Epoch 00385: val_accuracy did not improve from 0.80788\n","Epoch 386/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0275 - accuracy: 0.9982 - val_loss: 0.8346 - val_accuracy: 0.7611\n","\n","Epoch 00386: val_accuracy did not improve from 0.80788\n","Epoch 387/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0187 - accuracy: 0.9994 - val_loss: 0.8500 - val_accuracy: 0.7635\n","\n","Epoch 00387: val_accuracy did not improve from 0.80788\n","Epoch 388/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.7808\n","\n","Epoch 00388: val_accuracy did not improve from 0.80788\n","Epoch 389/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0191 - accuracy: 0.9982 - val_loss: 0.7198 - val_accuracy: 0.7882\n","\n","Epoch 00389: val_accuracy did not improve from 0.80788\n","Epoch 390/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0270 - accuracy: 0.9976 - val_loss: 0.7853 - val_accuracy: 0.7783\n","\n","Epoch 00390: val_accuracy did not improve from 0.80788\n","Epoch 391/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0213 - accuracy: 0.9988 - val_loss: 0.7805 - val_accuracy: 0.7635\n","\n","Epoch 00391: val_accuracy did not improve from 0.80788\n","Epoch 392/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0222 - accuracy: 0.9976 - val_loss: 0.8318 - val_accuracy: 0.7537\n","\n","Epoch 00392: val_accuracy did not improve from 0.80788\n","Epoch 393/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0227 - accuracy: 0.9970 - val_loss: 0.9503 - val_accuracy: 0.7488\n","\n","Epoch 00393: val_accuracy did not improve from 0.80788\n","Epoch 394/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0167 - accuracy: 0.9994 - val_loss: 0.8714 - val_accuracy: 0.7734\n","\n","Epoch 00394: val_accuracy did not improve from 0.80788\n","Epoch 395/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0266 - accuracy: 0.9982 - val_loss: 0.8485 - val_accuracy: 0.7709\n","\n","Epoch 00395: val_accuracy did not improve from 0.80788\n","Epoch 396/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0243 - accuracy: 0.9988 - val_loss: 0.7976 - val_accuracy: 0.7685\n","\n","Epoch 00396: val_accuracy did not improve from 0.80788\n","Epoch 397/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 0.7545 - val_accuracy: 0.7882\n","\n","Epoch 00397: val_accuracy did not improve from 0.80788\n","Epoch 398/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0190 - accuracy: 0.9988 - val_loss: 0.8181 - val_accuracy: 0.7906\n","\n","Epoch 00398: val_accuracy did not improve from 0.80788\n","Epoch 399/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0210 - accuracy: 0.9994 - val_loss: 0.7114 - val_accuracy: 0.7906\n","\n","Epoch 00399: val_accuracy did not improve from 0.80788\n","Epoch 400/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0227 - accuracy: 0.9982 - val_loss: 0.9271 - val_accuracy: 0.7365\n","\n","Epoch 00400: val_accuracy did not improve from 0.80788\n","Epoch 401/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.8224 - val_accuracy: 0.7685\n","\n","Epoch 00401: val_accuracy did not improve from 0.80788\n","Epoch 402/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0222 - accuracy: 0.9970 - val_loss: 0.7777 - val_accuracy: 0.7562\n","\n","Epoch 00402: val_accuracy did not improve from 0.80788\n","Epoch 403/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0179 - accuracy: 0.9988 - val_loss: 0.6838 - val_accuracy: 0.7956\n","\n","Epoch 00403: val_accuracy did not improve from 0.80788\n","Epoch 404/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.7980\n","\n","Epoch 00404: val_accuracy did not improve from 0.80788\n","Epoch 405/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0241 - accuracy: 0.9988 - val_loss: 0.8689 - val_accuracy: 0.7463\n","\n","Epoch 00405: val_accuracy did not improve from 0.80788\n","Epoch 406/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0181 - accuracy: 0.9994 - val_loss: 0.7894 - val_accuracy: 0.7734\n","\n","Epoch 00406: val_accuracy did not improve from 0.80788\n","Epoch 407/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0199 - accuracy: 0.9982 - val_loss: 0.7495 - val_accuracy: 0.7956\n","\n","Epoch 00407: val_accuracy did not improve from 0.80788\n","Epoch 408/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7513 - val_accuracy: 0.7734\n","\n","Epoch 00408: val_accuracy did not improve from 0.80788\n","Epoch 409/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.7741 - val_accuracy: 0.7808\n","\n","Epoch 00409: val_accuracy did not improve from 0.80788\n","Epoch 410/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0193 - accuracy: 0.9994 - val_loss: 0.9071 - val_accuracy: 0.7266\n","\n","Epoch 00410: val_accuracy did not improve from 0.80788\n","Epoch 411/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0190 - accuracy: 0.9982 - val_loss: 0.7780 - val_accuracy: 0.7660\n","\n","Epoch 00411: val_accuracy did not improve from 0.80788\n","Epoch 412/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0206 - accuracy: 0.9982 - val_loss: 0.8741 - val_accuracy: 0.7537\n","\n","Epoch 00412: val_accuracy did not improve from 0.80788\n","Epoch 413/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.8699 - val_accuracy: 0.7537\n","\n","Epoch 00413: val_accuracy did not improve from 0.80788\n","Epoch 414/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0187 - accuracy: 0.9988 - val_loss: 0.7534 - val_accuracy: 0.7833\n","\n","Epoch 00414: val_accuracy did not improve from 0.80788\n","Epoch 415/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0203 - accuracy: 0.9988 - val_loss: 0.8291 - val_accuracy: 0.7611\n","\n","Epoch 00415: val_accuracy did not improve from 0.80788\n","Epoch 416/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.7783\n","\n","Epoch 00416: val_accuracy did not improve from 0.80788\n","Epoch 417/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0192 - accuracy: 0.9988 - val_loss: 0.8030 - val_accuracy: 0.7611\n","\n","Epoch 00417: val_accuracy did not improve from 0.80788\n","Epoch 418/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0181 - accuracy: 0.9994 - val_loss: 0.8148 - val_accuracy: 0.7808\n","\n","Epoch 00418: val_accuracy did not improve from 0.80788\n","Epoch 419/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.7857\n","\n","Epoch 00419: val_accuracy did not improve from 0.80788\n","Epoch 420/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.7980\n","\n","Epoch 00420: val_accuracy did not improve from 0.80788\n","Epoch 421/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0165 - accuracy: 0.9994 - val_loss: 0.7503 - val_accuracy: 0.7808\n","\n","Epoch 00421: val_accuracy did not improve from 0.80788\n","Epoch 422/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.8304 - val_accuracy: 0.7562\n","\n","Epoch 00422: val_accuracy did not improve from 0.80788\n","Epoch 423/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.7660\n","\n","Epoch 00423: val_accuracy did not improve from 0.80788\n","Epoch 424/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.7676 - val_accuracy: 0.7685\n","\n","Epoch 00424: val_accuracy did not improve from 0.80788\n","Epoch 425/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0173 - accuracy: 0.9988 - val_loss: 0.7270 - val_accuracy: 0.7931\n","\n","Epoch 00425: val_accuracy did not improve from 0.80788\n","Epoch 426/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0157 - accuracy: 0.9994 - val_loss: 0.7238 - val_accuracy: 0.7956\n","\n","Epoch 00426: val_accuracy did not improve from 0.80788\n","Epoch 427/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0160 - accuracy: 0.9994 - val_loss: 0.8284 - val_accuracy: 0.7635\n","\n","Epoch 00427: val_accuracy did not improve from 0.80788\n","Epoch 428/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0198 - accuracy: 0.9994 - val_loss: 0.7613 - val_accuracy: 0.7709\n","\n","Epoch 00428: val_accuracy did not improve from 0.80788\n","Epoch 429/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0189 - accuracy: 0.9982 - val_loss: 0.7972 - val_accuracy: 0.7882\n","\n","Epoch 00429: val_accuracy did not improve from 0.80788\n","Epoch 430/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8103\n","\n","Epoch 00430: val_accuracy improved from 0.80788 to 0.81034, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5\n","Epoch 431/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0193 - accuracy: 0.9988 - val_loss: 0.9253 - val_accuracy: 0.7365\n","\n","Epoch 00431: val_accuracy did not improve from 0.81034\n","Epoch 432/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0205 - accuracy: 0.9982 - val_loss: 0.7497 - val_accuracy: 0.7857\n","\n","Epoch 00432: val_accuracy did not improve from 0.81034\n","Epoch 433/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0145 - accuracy: 0.9994 - val_loss: 0.7639 - val_accuracy: 0.7660\n","\n","Epoch 00433: val_accuracy did not improve from 0.81034\n","Epoch 434/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.8654 - val_accuracy: 0.7562\n","\n","Epoch 00434: val_accuracy did not improve from 0.81034\n","Epoch 435/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.8005\n","\n","Epoch 00435: val_accuracy did not improve from 0.81034\n","Epoch 436/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0161 - accuracy: 0.9988 - val_loss: 0.7748 - val_accuracy: 0.7734\n","\n","Epoch 00436: val_accuracy did not improve from 0.81034\n","Epoch 437/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7734\n","\n","Epoch 00437: val_accuracy did not improve from 0.81034\n","Epoch 438/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.7931\n","\n","Epoch 00438: val_accuracy did not improve from 0.81034\n","Epoch 439/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.8253 - val_accuracy: 0.7611\n","\n","Epoch 00439: val_accuracy did not improve from 0.81034\n","Epoch 440/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0182 - accuracy: 0.9988 - val_loss: 0.7778 - val_accuracy: 0.7906\n","\n","Epoch 00440: val_accuracy did not improve from 0.81034\n","Epoch 441/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0184 - accuracy: 0.9988 - val_loss: 0.7878 - val_accuracy: 0.7759\n","\n","Epoch 00441: val_accuracy did not improve from 0.81034\n","Epoch 442/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 0.7808 - val_accuracy: 0.7783\n","\n","Epoch 00442: val_accuracy did not improve from 0.81034\n","Epoch 443/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0193 - accuracy: 0.9976 - val_loss: 0.8580 - val_accuracy: 0.7512\n","\n","Epoch 00443: val_accuracy did not improve from 0.81034\n","Epoch 444/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.7833\n","\n","Epoch 00444: val_accuracy did not improve from 0.81034\n","Epoch 445/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.7627 - val_accuracy: 0.7709\n","\n","Epoch 00445: val_accuracy did not improve from 0.81034\n","Epoch 446/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0164 - accuracy: 0.9994 - val_loss: 0.7686 - val_accuracy: 0.7833\n","\n","Epoch 00446: val_accuracy did not improve from 0.81034\n","Epoch 447/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.7660\n","\n","Epoch 00447: val_accuracy did not improve from 0.81034\n","Epoch 448/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0162 - accuracy: 0.9988 - val_loss: 0.7713 - val_accuracy: 0.7734\n","\n","Epoch 00448: val_accuracy did not improve from 0.81034\n","Epoch 449/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0183 - accuracy: 0.9994 - val_loss: 0.8090 - val_accuracy: 0.7980\n","\n","Epoch 00449: val_accuracy did not improve from 0.81034\n","Epoch 450/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0155 - accuracy: 0.9988 - val_loss: 0.7305 - val_accuracy: 0.8005\n","\n","Epoch 00450: val_accuracy did not improve from 0.81034\n","Epoch 451/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.7783\n","\n","Epoch 00451: val_accuracy did not improve from 0.81034\n","Epoch 452/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.7690 - val_accuracy: 0.7734\n","\n","Epoch 00452: val_accuracy did not improve from 0.81034\n","Epoch 453/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0170 - accuracy: 0.9982 - val_loss: 0.8598 - val_accuracy: 0.7685\n","\n","Epoch 00453: val_accuracy did not improve from 0.81034\n","Epoch 454/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0153 - accuracy: 0.9982 - val_loss: 0.8658 - val_accuracy: 0.7660\n","\n","Epoch 00454: val_accuracy did not improve from 0.81034\n","Epoch 455/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0163 - accuracy: 0.9988 - val_loss: 0.7872 - val_accuracy: 0.7734\n","\n","Epoch 00455: val_accuracy did not improve from 0.81034\n","Epoch 456/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.8332 - val_accuracy: 0.7808\n","\n","Epoch 00456: val_accuracy did not improve from 0.81034\n","Epoch 457/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0185 - accuracy: 0.9976 - val_loss: 0.7970 - val_accuracy: 0.7931\n","\n","Epoch 00457: val_accuracy did not improve from 0.81034\n","Epoch 458/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0215 - accuracy: 0.9976 - val_loss: 0.8045 - val_accuracy: 0.7857\n","\n","Epoch 00458: val_accuracy did not improve from 0.81034\n","Epoch 459/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0148 - accuracy: 0.9994 - val_loss: 0.7419 - val_accuracy: 0.7882\n","\n","Epoch 00459: val_accuracy did not improve from 0.81034\n","Epoch 460/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0134 - accuracy: 0.9994 - val_loss: 0.8475 - val_accuracy: 0.7512\n","\n","Epoch 00460: val_accuracy did not improve from 0.81034\n","Epoch 461/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0168 - accuracy: 0.9994 - val_loss: 0.8509 - val_accuracy: 0.7611\n","\n","Epoch 00461: val_accuracy did not improve from 0.81034\n","Epoch 462/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 0.7987 - val_accuracy: 0.7956\n","\n","Epoch 00462: val_accuracy did not improve from 0.81034\n","Epoch 463/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0154 - accuracy: 0.9994 - val_loss: 0.8729 - val_accuracy: 0.7709\n","\n","Epoch 00463: val_accuracy did not improve from 0.81034\n","Epoch 464/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0177 - accuracy: 0.9988 - val_loss: 0.8197 - val_accuracy: 0.7734\n","\n","Epoch 00464: val_accuracy did not improve from 0.81034\n","Epoch 465/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0210 - accuracy: 0.9982 - val_loss: 0.8186 - val_accuracy: 0.7611\n","\n","Epoch 00465: val_accuracy did not improve from 0.81034\n","Epoch 466/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 0.7923 - val_accuracy: 0.7734\n","\n","Epoch 00466: val_accuracy did not improve from 0.81034\n","Epoch 467/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.8764 - val_accuracy: 0.7635\n","\n","Epoch 00467: val_accuracy did not improve from 0.81034\n","Epoch 468/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.8005\n","\n","Epoch 00468: val_accuracy did not improve from 0.81034\n","Epoch 469/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: 0.8127 - val_accuracy: 0.7635\n","\n","Epoch 00469: val_accuracy did not improve from 0.81034\n","Epoch 470/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0132 - accuracy: 0.9988 - val_loss: 0.7626 - val_accuracy: 0.7808\n","\n","Epoch 00470: val_accuracy did not improve from 0.81034\n","Epoch 471/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0118 - accuracy: 0.9994 - val_loss: 0.7687 - val_accuracy: 0.7906\n","\n","Epoch 00471: val_accuracy did not improve from 0.81034\n","Epoch 472/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0216 - accuracy: 0.9988 - val_loss: 0.8269 - val_accuracy: 0.7759\n","\n","Epoch 00472: val_accuracy did not improve from 0.81034\n","Epoch 473/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0172 - accuracy: 0.9988 - val_loss: 0.8477 - val_accuracy: 0.7562\n","\n","Epoch 00473: val_accuracy did not improve from 0.81034\n","Epoch 474/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0123 - accuracy: 0.9994 - val_loss: 0.7857 - val_accuracy: 0.7759\n","\n","Epoch 00474: val_accuracy did not improve from 0.81034\n","Epoch 475/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.7906\n","\n","Epoch 00475: val_accuracy did not improve from 0.81034\n","Epoch 476/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0194 - accuracy: 0.9970 - val_loss: 0.7706 - val_accuracy: 0.7906\n","\n","Epoch 00476: val_accuracy did not improve from 0.81034\n","Epoch 477/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0177 - accuracy: 0.9982 - val_loss: 0.8047 - val_accuracy: 0.7709\n","\n","Epoch 00477: val_accuracy did not improve from 0.81034\n","Epoch 478/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0160 - accuracy: 0.9994 - val_loss: 0.8497 - val_accuracy: 0.7783\n","\n","Epoch 00478: val_accuracy did not improve from 0.81034\n","Epoch 479/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0190 - accuracy: 0.9988 - val_loss: 0.8617 - val_accuracy: 0.7709\n","\n","Epoch 00479: val_accuracy did not improve from 0.81034\n","Epoch 480/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0160 - accuracy: 0.9988 - val_loss: 0.8750 - val_accuracy: 0.7586\n","\n","Epoch 00480: val_accuracy did not improve from 0.81034\n","Epoch 481/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 0.8541 - val_accuracy: 0.7685\n","\n","Epoch 00481: val_accuracy did not improve from 0.81034\n","Epoch 482/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0178 - accuracy: 0.9976 - val_loss: 0.8563 - val_accuracy: 0.7611\n","\n","Epoch 00482: val_accuracy did not improve from 0.81034\n","Epoch 483/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0168 - accuracy: 0.9994 - val_loss: 0.8614 - val_accuracy: 0.7537\n","\n","Epoch 00483: val_accuracy did not improve from 0.81034\n","Epoch 484/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 0.8052 - val_accuracy: 0.7857\n","\n","Epoch 00484: val_accuracy did not improve from 0.81034\n","Epoch 485/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.7882\n","\n","Epoch 00485: val_accuracy did not improve from 0.81034\n","Epoch 486/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.7941 - val_accuracy: 0.7931\n","\n","Epoch 00486: val_accuracy did not improve from 0.81034\n","Epoch 487/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0168 - accuracy: 0.9976 - val_loss: 0.8551 - val_accuracy: 0.7635\n","\n","Epoch 00487: val_accuracy did not improve from 0.81034\n","Epoch 488/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0192 - accuracy: 0.9988 - val_loss: 0.9141 - val_accuracy: 0.7463\n","\n","Epoch 00488: val_accuracy did not improve from 0.81034\n","Epoch 489/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.7759\n","\n","Epoch 00489: val_accuracy did not improve from 0.81034\n","Epoch 490/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0189 - accuracy: 0.9982 - val_loss: 0.7722 - val_accuracy: 0.7734\n","\n","Epoch 00490: val_accuracy did not improve from 0.81034\n","Epoch 491/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.8069 - val_accuracy: 0.7857\n","\n","Epoch 00491: val_accuracy did not improve from 0.81034\n","Epoch 492/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 0.7737 - val_accuracy: 0.7857\n","\n","Epoch 00492: val_accuracy did not improve from 0.81034\n","Epoch 493/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.7748 - val_accuracy: 0.7833\n","\n","Epoch 00493: val_accuracy did not improve from 0.81034\n","Epoch 494/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0196 - accuracy: 0.9988 - val_loss: 0.8087 - val_accuracy: 0.7906\n","\n","Epoch 00494: val_accuracy did not improve from 0.81034\n","Epoch 495/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.7906\n","\n","Epoch 00495: val_accuracy did not improve from 0.81034\n","Epoch 496/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0150 - accuracy: 0.9982 - val_loss: 0.7781 - val_accuracy: 0.8005\n","\n","Epoch 00496: val_accuracy did not improve from 0.81034\n","Epoch 497/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0216 - accuracy: 0.9982 - val_loss: 0.8480 - val_accuracy: 0.7857\n","\n","Epoch 00497: val_accuracy did not improve from 0.81034\n","Epoch 498/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0132 - accuracy: 0.9988 - val_loss: 0.7231 - val_accuracy: 0.7931\n","\n","Epoch 00498: val_accuracy did not improve from 0.81034\n","Epoch 499/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.7635\n","\n","Epoch 00499: val_accuracy did not improve from 0.81034\n","Epoch 500/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0166 - accuracy: 0.9982 - val_loss: 0.7971 - val_accuracy: 0.7906\n","\n","Epoch 00500: val_accuracy did not improve from 0.81034\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6c33ee2dd0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1631468788403,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4b574bb9-2118-4476-d7d9-62194d49c13b"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1631468809247,"user_tz":-540,"elapsed":20853,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1631468809991,"user_tz":-540,"elapsed":751,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631468810365,"user_tz":-540,"elapsed":381,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"4e34c248-8281-405e-e2f4-e9e1257d2333"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631468869530,"user_tz":-540,"elapsed":59168,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b5c7da17-b7af-4778-e472-dca2315bcee7"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1631468869908,"user_tz":-540,"elapsed":380,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1631468869909,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1631468870598,"user_tz":-540,"elapsed":692,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1631468870599,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1631468881508,"user_tz":-540,"elapsed":10912,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1631468881508,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"74e2c4e4-5f4b-44b5-8256-0e4d1b7445b5"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      0\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1631468881509,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d1cb548f-bb71-4772-87aa-f614d01b6520"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Adagrad_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Adagrad_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_fba39c43-4213-47cd-b550-c0e9ae88b794\", \"Optimizer_Adagrad_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}