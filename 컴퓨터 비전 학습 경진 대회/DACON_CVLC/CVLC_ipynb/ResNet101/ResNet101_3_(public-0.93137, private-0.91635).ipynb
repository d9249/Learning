{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet101_3_(public-0.93137, private-0.91635).ipynb","provenance":[{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632332738292,"user_tz":-540,"elapsed":306,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c88c8fd4-7c37-4083-dc4d-5a07a531f1e2"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep 22 17:45:39 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632332758636,"user_tz":-540,"elapsed":20349,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e4e2f2d2-6e18-411f-9040-fc5eb9fcabe6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632332762308,"user_tz":-540,"elapsed":3409,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632332763691,"user_tz":-540,"elapsed":1388,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632332765572,"user_tz":-540,"elapsed":1886,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632332782524,"user_tz":-540,"elapsed":16956,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632332782528,"user_tz":-540,"elapsed":22,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["model_save = 'ResNet101_3'\n","Target_model = 'ResNet101_model'\n","Target_predict = 'ResNet101_predict'\n","Target_acc = 'ResNet101_acc'\n","Target_val = 'ResNet101_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632332788840,"user_tz":-540,"elapsed":6331,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.ResNet101(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632332788853,"user_tz":-540,"elapsed":31,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632332788855,"user_tz":-540,"elapsed":30,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"014f0097-39f2-47cb-9819-271d3818ff0a"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632332789219,"user_tz":-540,"elapsed":381,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632358306002,"user_tz":-540,"elapsed":25516790,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c4b0e112-8ebd-40df-9c92-7798064e32d3"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 74s 194ms/step - loss: 2.4408 - accuracy: 0.2611 - val_loss: 9.5357 - val_accuracy: 0.1014\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.5860 - accuracy: 0.4784 - val_loss: 4.9090 - val_accuracy: 0.2230\n","\n","Epoch 00002: val_accuracy improved from 0.10135 to 0.22297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 3/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.2572 - accuracy: 0.5837 - val_loss: 1.8237 - val_accuracy: 0.5000\n","\n","Epoch 00003: val_accuracy improved from 0.22297 to 0.50000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 4/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.0706 - accuracy: 0.6526 - val_loss: 0.8556 - val_accuracy: 0.7432\n","\n","Epoch 00004: val_accuracy improved from 0.50000 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 5/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.9138 - accuracy: 0.7095 - val_loss: 1.4088 - val_accuracy: 0.6081\n","\n","Epoch 00005: val_accuracy did not improve from 0.74324\n","Epoch 6/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.8148 - accuracy: 0.7363 - val_loss: 1.0607 - val_accuracy: 0.6959\n","\n","Epoch 00006: val_accuracy did not improve from 0.74324\n","Epoch 7/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.7161 - accuracy: 0.7732 - val_loss: 1.0812 - val_accuracy: 0.6824\n","\n","Epoch 00007: val_accuracy did not improve from 0.74324\n","Epoch 8/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.6274 - accuracy: 0.7811 - val_loss: 0.7978 - val_accuracy: 0.7635\n","\n","Epoch 00008: val_accuracy improved from 0.74324 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 9/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.6617 - accuracy: 0.7826 - val_loss: 0.8959 - val_accuracy: 0.6892\n","\n","Epoch 00009: val_accuracy did not improve from 0.76351\n","Epoch 10/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.5728 - accuracy: 0.8068 - val_loss: 0.7269 - val_accuracy: 0.7905\n","\n","Epoch 00010: val_accuracy improved from 0.76351 to 0.79054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 11/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.5426 - accuracy: 0.8247 - val_loss: 0.9441 - val_accuracy: 0.7027\n","\n","Epoch 00011: val_accuracy did not improve from 0.79054\n","Epoch 12/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.5628 - accuracy: 0.8179 - val_loss: 0.7109 - val_accuracy: 0.7973\n","\n","Epoch 00012: val_accuracy improved from 0.79054 to 0.79730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 13/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.5215 - accuracy: 0.8353 - val_loss: 0.5994 - val_accuracy: 0.7838\n","\n","Epoch 00013: val_accuracy did not improve from 0.79730\n","Epoch 14/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.4558 - accuracy: 0.8516 - val_loss: 0.7780 - val_accuracy: 0.7500\n","\n","Epoch 00014: val_accuracy did not improve from 0.79730\n","Epoch 15/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.4735 - accuracy: 0.8405 - val_loss: 0.4714 - val_accuracy: 0.8378\n","\n","Epoch 00015: val_accuracy improved from 0.79730 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 16/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.4834 - accuracy: 0.8405 - val_loss: 0.3963 - val_accuracy: 0.8649\n","\n","Epoch 00016: val_accuracy improved from 0.83784 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 17/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.4595 - accuracy: 0.8511 - val_loss: 0.7055 - val_accuracy: 0.7770\n","\n","Epoch 00017: val_accuracy did not improve from 0.86486\n","Epoch 18/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.4213 - accuracy: 0.8526 - val_loss: 0.6560 - val_accuracy: 0.8446\n","\n","Epoch 00018: val_accuracy did not improve from 0.86486\n","Epoch 19/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.4062 - accuracy: 0.8679 - val_loss: 0.4743 - val_accuracy: 0.8176\n","\n","Epoch 00019: val_accuracy did not improve from 0.86486\n","Epoch 20/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.3528 - accuracy: 0.8768 - val_loss: 0.4883 - val_accuracy: 0.8243\n","\n","Epoch 00020: val_accuracy did not improve from 0.86486\n","Epoch 21/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.3313 - accuracy: 0.8932 - val_loss: 0.8770 - val_accuracy: 0.8108\n","\n","Epoch 00021: val_accuracy did not improve from 0.86486\n","Epoch 22/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.3116 - accuracy: 0.8921 - val_loss: 0.4294 - val_accuracy: 0.8649\n","\n","Epoch 00022: val_accuracy did not improve from 0.86486\n","Epoch 23/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.3344 - accuracy: 0.8905 - val_loss: 0.5110 - val_accuracy: 0.8108\n","\n","Epoch 00023: val_accuracy did not improve from 0.86486\n","Epoch 24/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.3668 - accuracy: 0.8837 - val_loss: 0.4967 - val_accuracy: 0.8311\n","\n","Epoch 00024: val_accuracy did not improve from 0.86486\n","Epoch 25/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.3493 - accuracy: 0.8805 - val_loss: 0.4401 - val_accuracy: 0.8784\n","\n","Epoch 00025: val_accuracy improved from 0.86486 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 26/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.2960 - accuracy: 0.9005 - val_loss: 0.4636 - val_accuracy: 0.8514\n","\n","Epoch 00026: val_accuracy did not improve from 0.87838\n","Epoch 27/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.3099 - accuracy: 0.8879 - val_loss: 0.5120 - val_accuracy: 0.8311\n","\n","Epoch 00027: val_accuracy did not improve from 0.87838\n","Epoch 28/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2910 - accuracy: 0.9042 - val_loss: 0.6102 - val_accuracy: 0.8514\n","\n","Epoch 00028: val_accuracy did not improve from 0.87838\n","Epoch 29/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2785 - accuracy: 0.9079 - val_loss: 0.6531 - val_accuracy: 0.7973\n","\n","Epoch 00029: val_accuracy did not improve from 0.87838\n","Epoch 30/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2802 - accuracy: 0.9047 - val_loss: 0.3970 - val_accuracy: 0.8581\n","\n","Epoch 00030: val_accuracy did not improve from 0.87838\n","Epoch 31/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.2356 - accuracy: 0.9179 - val_loss: 0.4476 - val_accuracy: 0.8514\n","\n","Epoch 00031: val_accuracy did not improve from 0.87838\n","Epoch 32/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2836 - accuracy: 0.9032 - val_loss: 1.0333 - val_accuracy: 0.7703\n","\n","Epoch 00032: val_accuracy did not improve from 0.87838\n","Epoch 33/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2745 - accuracy: 0.9089 - val_loss: 0.3198 - val_accuracy: 0.8919\n","\n","Epoch 00033: val_accuracy improved from 0.87838 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 34/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.2236 - accuracy: 0.9253 - val_loss: 0.4063 - val_accuracy: 0.8784\n","\n","Epoch 00034: val_accuracy did not improve from 0.89189\n","Epoch 35/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.2382 - accuracy: 0.9247 - val_loss: 0.7259 - val_accuracy: 0.8041\n","\n","Epoch 00035: val_accuracy did not improve from 0.89189\n","Epoch 36/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.2442 - accuracy: 0.9132 - val_loss: 0.3437 - val_accuracy: 0.8716\n","\n","Epoch 00036: val_accuracy did not improve from 0.89189\n","Epoch 37/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1871 - accuracy: 0.9321 - val_loss: 0.5441 - val_accuracy: 0.8378\n","\n","Epoch 00037: val_accuracy did not improve from 0.89189\n","Epoch 38/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1840 - accuracy: 0.9384 - val_loss: 0.3418 - val_accuracy: 0.8716\n","\n","Epoch 00038: val_accuracy did not improve from 0.89189\n","Epoch 39/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1661 - accuracy: 0.9437 - val_loss: 0.4081 - val_accuracy: 0.8378\n","\n","Epoch 00039: val_accuracy did not improve from 0.89189\n","Epoch 40/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1897 - accuracy: 0.9274 - val_loss: 0.7041 - val_accuracy: 0.8108\n","\n","Epoch 00040: val_accuracy did not improve from 0.89189\n","Epoch 41/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.2585 - accuracy: 0.9100 - val_loss: 0.5062 - val_accuracy: 0.8514\n","\n","Epoch 00041: val_accuracy did not improve from 0.89189\n","Epoch 42/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1774 - accuracy: 0.9411 - val_loss: 0.5186 - val_accuracy: 0.8243\n","\n","Epoch 00042: val_accuracy did not improve from 0.89189\n","Epoch 43/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1793 - accuracy: 0.9379 - val_loss: 0.5459 - val_accuracy: 0.8378\n","\n","Epoch 00043: val_accuracy did not improve from 0.89189\n","Epoch 44/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.2068 - accuracy: 0.9311 - val_loss: 0.6501 - val_accuracy: 0.8446\n","\n","Epoch 00044: val_accuracy did not improve from 0.89189\n","Epoch 45/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.1421 - accuracy: 0.9505 - val_loss: 0.5021 - val_accuracy: 0.8581\n","\n","Epoch 00045: val_accuracy did not improve from 0.89189\n","Epoch 46/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1288 - accuracy: 0.9558 - val_loss: 0.4162 - val_accuracy: 0.8986\n","\n","Epoch 00046: val_accuracy improved from 0.89189 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 47/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.1397 - accuracy: 0.9579 - val_loss: 0.3999 - val_accuracy: 0.8919\n","\n","Epoch 00047: val_accuracy did not improve from 0.89865\n","Epoch 48/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1487 - accuracy: 0.9516 - val_loss: 0.4223 - val_accuracy: 0.8649\n","\n","Epoch 00048: val_accuracy did not improve from 0.89865\n","Epoch 49/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1251 - accuracy: 0.9589 - val_loss: 0.4833 - val_accuracy: 0.8581\n","\n","Epoch 00049: val_accuracy did not improve from 0.89865\n","Epoch 50/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1386 - accuracy: 0.9505 - val_loss: 0.4900 - val_accuracy: 0.8581\n","\n","Epoch 00050: val_accuracy did not improve from 0.89865\n","Epoch 51/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.1676 - accuracy: 0.9484 - val_loss: 0.4031 - val_accuracy: 0.8851\n","\n","Epoch 00051: val_accuracy did not improve from 0.89865\n","Epoch 52/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1211 - accuracy: 0.9553 - val_loss: 0.3118 - val_accuracy: 0.8986\n","\n","Epoch 00052: val_accuracy did not improve from 0.89865\n","Epoch 53/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1439 - accuracy: 0.9532 - val_loss: 0.3999 - val_accuracy: 0.8986\n","\n","Epoch 00053: val_accuracy did not improve from 0.89865\n","Epoch 54/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1236 - accuracy: 0.9600 - val_loss: 0.2776 - val_accuracy: 0.9054\n","\n","Epoch 00054: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 55/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.1175 - accuracy: 0.9632 - val_loss: 0.5099 - val_accuracy: 0.8446\n","\n","Epoch 00055: val_accuracy did not improve from 0.90541\n","Epoch 56/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.1128 - accuracy: 0.9616 - val_loss: 0.3599 - val_accuracy: 0.8986\n","\n","Epoch 00056: val_accuracy did not improve from 0.90541\n","Epoch 57/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1214 - accuracy: 0.9579 - val_loss: 0.3842 - val_accuracy: 0.9122\n","\n","Epoch 00057: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 58/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.1025 - accuracy: 0.9668 - val_loss: 0.3060 - val_accuracy: 0.8986\n","\n","Epoch 00058: val_accuracy did not improve from 0.91216\n","Epoch 59/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.4026 - val_accuracy: 0.9122\n","\n","Epoch 00059: val_accuracy did not improve from 0.91216\n","Epoch 60/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1327 - accuracy: 0.9553 - val_loss: 0.5801 - val_accuracy: 0.8716\n","\n","Epoch 00060: val_accuracy did not improve from 0.91216\n","Epoch 61/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0923 - accuracy: 0.9721 - val_loss: 0.2709 - val_accuracy: 0.8986\n","\n","Epoch 00061: val_accuracy did not improve from 0.91216\n","Epoch 62/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.5738 - val_accuracy: 0.8378\n","\n","Epoch 00062: val_accuracy did not improve from 0.91216\n","Epoch 63/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1482 - accuracy: 0.9484 - val_loss: 0.5031 - val_accuracy: 0.8446\n","\n","Epoch 00063: val_accuracy did not improve from 0.91216\n","Epoch 64/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1233 - accuracy: 0.9568 - val_loss: 0.4687 - val_accuracy: 0.8851\n","\n","Epoch 00064: val_accuracy did not improve from 0.91216\n","Epoch 65/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0913 - accuracy: 0.9716 - val_loss: 0.4069 - val_accuracy: 0.8919\n","\n","Epoch 00065: val_accuracy did not improve from 0.91216\n","Epoch 66/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.1083 - accuracy: 0.9663 - val_loss: 0.6736 - val_accuracy: 0.8378\n","\n","Epoch 00066: val_accuracy did not improve from 0.91216\n","Epoch 67/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.4058 - val_accuracy: 0.9054\n","\n","Epoch 00067: val_accuracy did not improve from 0.91216\n","Epoch 68/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1153 - accuracy: 0.9674 - val_loss: 0.5708 - val_accuracy: 0.8243\n","\n","Epoch 00068: val_accuracy did not improve from 0.91216\n","Epoch 69/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0730 - accuracy: 0.9753 - val_loss: 0.4270 - val_accuracy: 0.8784\n","\n","Epoch 00069: val_accuracy did not improve from 0.91216\n","Epoch 70/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0721 - accuracy: 0.9747 - val_loss: 0.4896 - val_accuracy: 0.8649\n","\n","Epoch 00070: val_accuracy did not improve from 0.91216\n","Epoch 71/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0934 - accuracy: 0.9700 - val_loss: 0.3735 - val_accuracy: 0.9122\n","\n","Epoch 00071: val_accuracy did not improve from 0.91216\n","Epoch 72/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.2734 - val_accuracy: 0.9054\n","\n","Epoch 00072: val_accuracy did not improve from 0.91216\n","Epoch 73/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0992 - accuracy: 0.9663 - val_loss: 0.4465 - val_accuracy: 0.8581\n","\n","Epoch 00073: val_accuracy did not improve from 0.91216\n","Epoch 74/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 0.4514 - val_accuracy: 0.8784\n","\n","Epoch 00074: val_accuracy did not improve from 0.91216\n","Epoch 75/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0690 - accuracy: 0.9774 - val_loss: 0.4698 - val_accuracy: 0.8649\n","\n","Epoch 00075: val_accuracy did not improve from 0.91216\n","Epoch 76/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.3341 - val_accuracy: 0.9054\n","\n","Epoch 00076: val_accuracy did not improve from 0.91216\n","Epoch 77/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0612 - accuracy: 0.9795 - val_loss: 0.3755 - val_accuracy: 0.8851\n","\n","Epoch 00077: val_accuracy did not improve from 0.91216\n","Epoch 78/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0752 - accuracy: 0.9763 - val_loss: 1.5154 - val_accuracy: 0.7162\n","\n","Epoch 00078: val_accuracy did not improve from 0.91216\n","Epoch 79/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 0.4335 - val_accuracy: 0.8784\n","\n","Epoch 00079: val_accuracy did not improve from 0.91216\n","Epoch 80/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0777 - accuracy: 0.9716 - val_loss: 0.3297 - val_accuracy: 0.9122\n","\n","Epoch 00080: val_accuracy did not improve from 0.91216\n","Epoch 81/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.1026 - accuracy: 0.9642 - val_loss: 0.5288 - val_accuracy: 0.8514\n","\n","Epoch 00081: val_accuracy did not improve from 0.91216\n","Epoch 82/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0726 - accuracy: 0.9768 - val_loss: 0.3278 - val_accuracy: 0.9054\n","\n","Epoch 00082: val_accuracy did not improve from 0.91216\n","Epoch 83/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0943 - accuracy: 0.9721 - val_loss: 0.3490 - val_accuracy: 0.9122\n","\n","Epoch 00083: val_accuracy did not improve from 0.91216\n","Epoch 84/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.5577 - val_accuracy: 0.8581\n","\n","Epoch 00084: val_accuracy did not improve from 0.91216\n","Epoch 85/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.5090 - val_accuracy: 0.8919\n","\n","Epoch 00085: val_accuracy did not improve from 0.91216\n","Epoch 86/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0826 - accuracy: 0.9747 - val_loss: 0.4851 - val_accuracy: 0.9054\n","\n","Epoch 00086: val_accuracy did not improve from 0.91216\n","Epoch 87/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0917 - accuracy: 0.9658 - val_loss: 0.4147 - val_accuracy: 0.8514\n","\n","Epoch 00087: val_accuracy did not improve from 0.91216\n","Epoch 88/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 0.3474 - val_accuracy: 0.8986\n","\n","Epoch 00088: val_accuracy did not improve from 0.91216\n","Epoch 89/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0419 - accuracy: 0.9842 - val_loss: 0.3091 - val_accuracy: 0.9122\n","\n","Epoch 00089: val_accuracy did not improve from 0.91216\n","Epoch 90/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 0.3451 - val_accuracy: 0.9122\n","\n","Epoch 00090: val_accuracy did not improve from 0.91216\n","Epoch 91/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.4687 - val_accuracy: 0.8919\n","\n","Epoch 00091: val_accuracy did not improve from 0.91216\n","Epoch 92/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.4511 - val_accuracy: 0.8649\n","\n","Epoch 00092: val_accuracy did not improve from 0.91216\n","Epoch 93/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.5912 - val_accuracy: 0.8446\n","\n","Epoch 00093: val_accuracy did not improve from 0.91216\n","Epoch 94/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0767 - accuracy: 0.9768 - val_loss: 0.4268 - val_accuracy: 0.8986\n","\n","Epoch 00094: val_accuracy did not improve from 0.91216\n","Epoch 95/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.3523 - val_accuracy: 0.8649\n","\n","Epoch 00095: val_accuracy did not improve from 0.91216\n","Epoch 96/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.4103 - val_accuracy: 0.8919\n","\n","Epoch 00096: val_accuracy did not improve from 0.91216\n","Epoch 97/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0632 - accuracy: 0.9784 - val_loss: 0.4066 - val_accuracy: 0.8784\n","\n","Epoch 00097: val_accuracy did not improve from 0.91216\n","Epoch 98/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.2787 - val_accuracy: 0.9189\n","\n","Epoch 00098: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 99/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.3791 - val_accuracy: 0.8919\n","\n","Epoch 00099: val_accuracy did not improve from 0.91892\n","Epoch 100/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.4570 - val_accuracy: 0.9054\n","\n","Epoch 00100: val_accuracy did not improve from 0.91892\n","Epoch 101/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0400 - accuracy: 0.9853 - val_loss: 1.5497 - val_accuracy: 0.7432\n","\n","Epoch 00101: val_accuracy did not improve from 0.91892\n","Epoch 102/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0596 - accuracy: 0.9795 - val_loss: 0.5967 - val_accuracy: 0.8716\n","\n","Epoch 00102: val_accuracy did not improve from 0.91892\n","Epoch 103/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0630 - accuracy: 0.9753 - val_loss: 0.4633 - val_accuracy: 0.8919\n","\n","Epoch 00103: val_accuracy did not improve from 0.91892\n","Epoch 104/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 0.2615 - val_accuracy: 0.9257\n","\n","Epoch 00104: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 105/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.2547 - val_accuracy: 0.9054\n","\n","Epoch 00105: val_accuracy did not improve from 0.92568\n","Epoch 106/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.4084 - val_accuracy: 0.8851\n","\n","Epoch 00106: val_accuracy did not improve from 0.92568\n","Epoch 107/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.4302 - val_accuracy: 0.9054\n","\n","Epoch 00107: val_accuracy did not improve from 0.92568\n","Epoch 108/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.3020 - val_accuracy: 0.8986\n","\n","Epoch 00108: val_accuracy did not improve from 0.92568\n","Epoch 109/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.3459 - val_accuracy: 0.9054\n","\n","Epoch 00109: val_accuracy did not improve from 0.92568\n","Epoch 110/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.3597 - val_accuracy: 0.9122\n","\n","Epoch 00110: val_accuracy did not improve from 0.92568\n","Epoch 111/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.5002 - val_accuracy: 0.8919\n","\n","Epoch 00111: val_accuracy did not improve from 0.92568\n","Epoch 112/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0804 - accuracy: 0.9747 - val_loss: 0.4578 - val_accuracy: 0.8581\n","\n","Epoch 00112: val_accuracy did not improve from 0.92568\n","Epoch 113/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0724 - accuracy: 0.9753 - val_loss: 0.6526 - val_accuracy: 0.8649\n","\n","Epoch 00113: val_accuracy did not improve from 0.92568\n","Epoch 114/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0421 - accuracy: 0.9837 - val_loss: 0.3279 - val_accuracy: 0.9122\n","\n","Epoch 00114: val_accuracy did not improve from 0.92568\n","Epoch 115/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0485 - accuracy: 0.9874 - val_loss: 0.2511 - val_accuracy: 0.9122\n","\n","Epoch 00115: val_accuracy did not improve from 0.92568\n","Epoch 116/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0469 - accuracy: 0.9868 - val_loss: 0.4111 - val_accuracy: 0.9054\n","\n","Epoch 00116: val_accuracy did not improve from 0.92568\n","Epoch 117/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.4910 - val_accuracy: 0.9122\n","\n","Epoch 00117: val_accuracy did not improve from 0.92568\n","Epoch 118/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0470 - accuracy: 0.9889 - val_loss: 0.4218 - val_accuracy: 0.8851\n","\n","Epoch 00118: val_accuracy did not improve from 0.92568\n","Epoch 119/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.4464 - val_accuracy: 0.8986\n","\n","Epoch 00119: val_accuracy did not improve from 0.92568\n","Epoch 120/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.5379 - val_accuracy: 0.8919\n","\n","Epoch 00120: val_accuracy did not improve from 0.92568\n","Epoch 121/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.2433 - val_accuracy: 0.9122\n","\n","Epoch 00121: val_accuracy did not improve from 0.92568\n","Epoch 122/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0415 - accuracy: 0.9858 - val_loss: 0.4674 - val_accuracy: 0.8919\n","\n","Epoch 00122: val_accuracy did not improve from 0.92568\n","Epoch 123/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.4694 - val_accuracy: 0.9054\n","\n","Epoch 00123: val_accuracy did not improve from 0.92568\n","Epoch 124/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0237 - accuracy: 0.9900 - val_loss: 0.5826 - val_accuracy: 0.8851\n","\n","Epoch 00124: val_accuracy did not improve from 0.92568\n","Epoch 125/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.4812 - val_accuracy: 0.8716\n","\n","Epoch 00125: val_accuracy did not improve from 0.92568\n","Epoch 126/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 0.4120 - val_accuracy: 0.9054\n","\n","Epoch 00126: val_accuracy did not improve from 0.92568\n","Epoch 127/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.3565 - val_accuracy: 0.8986\n","\n","Epoch 00127: val_accuracy did not improve from 0.92568\n","Epoch 128/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.4788 - val_accuracy: 0.8784\n","\n","Epoch 00128: val_accuracy did not improve from 0.92568\n","Epoch 129/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.4792 - val_accuracy: 0.9054\n","\n","Epoch 00129: val_accuracy did not improve from 0.92568\n","Epoch 130/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0775 - accuracy: 0.9747 - val_loss: 0.2896 - val_accuracy: 0.9257\n","\n","Epoch 00130: val_accuracy did not improve from 0.92568\n","Epoch 131/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.3584 - val_accuracy: 0.9054\n","\n","Epoch 00131: val_accuracy did not improve from 0.92568\n","Epoch 132/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.3534 - val_accuracy: 0.9122\n","\n","Epoch 00132: val_accuracy did not improve from 0.92568\n","Epoch 133/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.4058 - val_accuracy: 0.8919\n","\n","Epoch 00133: val_accuracy did not improve from 0.92568\n","Epoch 134/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.5644 - val_accuracy: 0.8716\n","\n","Epoch 00134: val_accuracy did not improve from 0.92568\n","Epoch 135/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.9716 - val_accuracy: 0.8311\n","\n","Epoch 00135: val_accuracy did not improve from 0.92568\n","Epoch 136/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.4136 - val_accuracy: 0.9054\n","\n","Epoch 00136: val_accuracy did not improve from 0.92568\n","Epoch 137/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.3223 - val_accuracy: 0.9054\n","\n","Epoch 00137: val_accuracy did not improve from 0.92568\n","Epoch 138/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.4828 - val_accuracy: 0.8784\n","\n","Epoch 00138: val_accuracy did not improve from 0.92568\n","Epoch 139/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.2865 - val_accuracy: 0.8986\n","\n","Epoch 00139: val_accuracy did not improve from 0.92568\n","Epoch 140/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4904 - val_accuracy: 0.8986\n","\n","Epoch 00140: val_accuracy did not improve from 0.92568\n","Epoch 141/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.3245 - val_accuracy: 0.9257\n","\n","Epoch 00141: val_accuracy did not improve from 0.92568\n","Epoch 142/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.3102 - val_accuracy: 0.9122\n","\n","Epoch 00142: val_accuracy did not improve from 0.92568\n","Epoch 143/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0575 - accuracy: 0.9842 - val_loss: 0.7559 - val_accuracy: 0.8514\n","\n","Epoch 00143: val_accuracy did not improve from 0.92568\n","Epoch 144/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0546 - accuracy: 0.9847 - val_loss: 0.6775 - val_accuracy: 0.8716\n","\n","Epoch 00144: val_accuracy did not improve from 0.92568\n","Epoch 145/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0184 - accuracy: 0.9926 - val_loss: 0.4171 - val_accuracy: 0.8784\n","\n","Epoch 00145: val_accuracy did not improve from 0.92568\n","Epoch 146/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.6750 - val_accuracy: 0.8716\n","\n","Epoch 00146: val_accuracy did not improve from 0.92568\n","Epoch 147/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.6313 - val_accuracy: 0.8919\n","\n","Epoch 00147: val_accuracy did not improve from 0.92568\n","Epoch 148/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.3801 - val_accuracy: 0.8986\n","\n","Epoch 00148: val_accuracy did not improve from 0.92568\n","Epoch 149/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.3071 - val_accuracy: 0.9257\n","\n","Epoch 00149: val_accuracy did not improve from 0.92568\n","Epoch 150/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.2502 - val_accuracy: 0.9324\n","\n","Epoch 00150: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 151/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0142 - accuracy: 0.9932 - val_loss: 0.4074 - val_accuracy: 0.8986\n","\n","Epoch 00151: val_accuracy did not improve from 0.93243\n","Epoch 152/500\n","238/238 [==============================] - 45s 190ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.5155 - val_accuracy: 0.8851\n","\n","Epoch 00152: val_accuracy did not improve from 0.93243\n","Epoch 153/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 0.5671 - val_accuracy: 0.8986\n","\n","Epoch 00153: val_accuracy did not improve from 0.93243\n","Epoch 154/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.3069 - val_accuracy: 0.9189\n","\n","Epoch 00154: val_accuracy did not improve from 0.93243\n","Epoch 155/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0297 - accuracy: 0.9884 - val_loss: 0.5872 - val_accuracy: 0.8649\n","\n","Epoch 00155: val_accuracy did not improve from 0.93243\n","Epoch 156/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.5378 - val_accuracy: 0.8649\n","\n","Epoch 00156: val_accuracy did not improve from 0.93243\n","Epoch 157/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0590 - accuracy: 0.9837 - val_loss: 0.4783 - val_accuracy: 0.8919\n","\n","Epoch 00157: val_accuracy did not improve from 0.93243\n","Epoch 158/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.3541 - val_accuracy: 0.8986\n","\n","Epoch 00158: val_accuracy did not improve from 0.93243\n","Epoch 159/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.4957 - val_accuracy: 0.9054\n","\n","Epoch 00159: val_accuracy did not improve from 0.93243\n","Epoch 160/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.2994 - val_accuracy: 0.9189\n","\n","Epoch 00160: val_accuracy did not improve from 0.93243\n","Epoch 161/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.4595 - val_accuracy: 0.8986\n","\n","Epoch 00161: val_accuracy did not improve from 0.93243\n","Epoch 162/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.4950 - val_accuracy: 0.8986\n","\n","Epoch 00162: val_accuracy did not improve from 0.93243\n","Epoch 163/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.6017 - val_accuracy: 0.8784\n","\n","Epoch 00163: val_accuracy did not improve from 0.93243\n","Epoch 164/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.5779 - val_accuracy: 0.8784\n","\n","Epoch 00164: val_accuracy did not improve from 0.93243\n","Epoch 165/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.2885 - val_accuracy: 0.9257\n","\n","Epoch 00165: val_accuracy did not improve from 0.93243\n","Epoch 166/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9122\n","\n","Epoch 00166: val_accuracy did not improve from 0.93243\n","Epoch 167/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.4847 - val_accuracy: 0.8986\n","\n","Epoch 00167: val_accuracy did not improve from 0.93243\n","Epoch 168/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.4201 - val_accuracy: 0.8919\n","\n","Epoch 00168: val_accuracy did not improve from 0.93243\n","Epoch 169/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.3941 - val_accuracy: 0.8986\n","\n","Epoch 00169: val_accuracy did not improve from 0.93243\n","Epoch 170/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0300 - accuracy: 0.9916 - val_loss: 0.4367 - val_accuracy: 0.8716\n","\n","Epoch 00170: val_accuracy did not improve from 0.93243\n","Epoch 171/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0309 - accuracy: 0.9937 - val_loss: 0.4126 - val_accuracy: 0.9122\n","\n","Epoch 00171: val_accuracy did not improve from 0.93243\n","Epoch 172/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.5354 - val_accuracy: 0.8919\n","\n","Epoch 00172: val_accuracy did not improve from 0.93243\n","Epoch 173/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.4583 - val_accuracy: 0.8851\n","\n","Epoch 00173: val_accuracy did not improve from 0.93243\n","Epoch 174/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.5717 - val_accuracy: 0.8446\n","\n","Epoch 00174: val_accuracy did not improve from 0.93243\n","Epoch 175/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0339 - accuracy: 0.9853 - val_loss: 0.3769 - val_accuracy: 0.8851\n","\n","Epoch 00175: val_accuracy did not improve from 0.93243\n","Epoch 176/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.4762 - val_accuracy: 0.8919\n","\n","Epoch 00176: val_accuracy did not improve from 0.93243\n","Epoch 177/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.7684 - val_accuracy: 0.8514\n","\n","Epoch 00177: val_accuracy did not improve from 0.93243\n","Epoch 178/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0401 - accuracy: 0.9889 - val_loss: 0.8417 - val_accuracy: 0.8378\n","\n","Epoch 00178: val_accuracy did not improve from 0.93243\n","Epoch 179/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.3677 - val_accuracy: 0.9054\n","\n","Epoch 00179: val_accuracy did not improve from 0.93243\n","Epoch 180/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.5336 - val_accuracy: 0.8919\n","\n","Epoch 00180: val_accuracy did not improve from 0.93243\n","Epoch 181/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 1.2204 - val_accuracy: 0.8041\n","\n","Epoch 00181: val_accuracy did not improve from 0.93243\n","Epoch 182/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.2266 - val_accuracy: 0.9189\n","\n","Epoch 00182: val_accuracy did not improve from 0.93243\n","Epoch 183/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.7713 - val_accuracy: 0.8176\n","\n","Epoch 00183: val_accuracy did not improve from 0.93243\n","Epoch 184/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.3783 - val_accuracy: 0.9122\n","\n","Epoch 00184: val_accuracy did not improve from 0.93243\n","Epoch 185/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.5284 - val_accuracy: 0.8851\n","\n","Epoch 00185: val_accuracy did not improve from 0.93243\n","Epoch 186/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.5023 - val_accuracy: 0.8986\n","\n","Epoch 00186: val_accuracy did not improve from 0.93243\n","Epoch 187/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.3004 - val_accuracy: 0.9257\n","\n","Epoch 00187: val_accuracy did not improve from 0.93243\n","Epoch 188/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.4767 - val_accuracy: 0.8716\n","\n","Epoch 00188: val_accuracy did not improve from 0.93243\n","Epoch 189/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4413 - val_accuracy: 0.8986\n","\n","Epoch 00189: val_accuracy did not improve from 0.93243\n","Epoch 190/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 0.5431 - val_accuracy: 0.8649\n","\n","Epoch 00190: val_accuracy did not improve from 0.93243\n","Epoch 191/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.4896 - val_accuracy: 0.8986\n","\n","Epoch 00191: val_accuracy did not improve from 0.93243\n","Epoch 192/500\n","238/238 [==============================] - 45s 191ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.3756 - val_accuracy: 0.8919\n","\n","Epoch 00192: val_accuracy did not improve from 0.93243\n","Epoch 193/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.4294 - val_accuracy: 0.8986\n","\n","Epoch 00193: val_accuracy did not improve from 0.93243\n","Epoch 194/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.3243 - val_accuracy: 0.8986\n","\n","Epoch 00194: val_accuracy did not improve from 0.93243\n","Epoch 195/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4527 - val_accuracy: 0.8986\n","\n","Epoch 00195: val_accuracy did not improve from 0.93243\n","Epoch 196/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.4168 - val_accuracy: 0.9054\n","\n","Epoch 00196: val_accuracy did not improve from 0.93243\n","Epoch 197/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.4589 - val_accuracy: 0.9054\n","\n","Epoch 00197: val_accuracy did not improve from 0.93243\n","Epoch 198/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.3828 - val_accuracy: 0.8784\n","\n","Epoch 00198: val_accuracy did not improve from 0.93243\n","Epoch 199/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.4851 - val_accuracy: 0.8851\n","\n","Epoch 00199: val_accuracy did not improve from 0.93243\n","Epoch 200/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.4437 - val_accuracy: 0.9189\n","\n","Epoch 00200: val_accuracy did not improve from 0.93243\n","Epoch 201/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.3642 - val_accuracy: 0.8986\n","\n","Epoch 00201: val_accuracy did not improve from 0.93243\n","Epoch 202/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4041 - val_accuracy: 0.9122\n","\n","Epoch 00202: val_accuracy did not improve from 0.93243\n","Epoch 203/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.6568 - val_accuracy: 0.8716\n","\n","Epoch 00203: val_accuracy did not improve from 0.93243\n","Epoch 204/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.3402 - val_accuracy: 0.9122\n","\n","Epoch 00204: val_accuracy did not improve from 0.93243\n","Epoch 205/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.4935 - val_accuracy: 0.8919\n","\n","Epoch 00205: val_accuracy did not improve from 0.93243\n","Epoch 206/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0528 - accuracy: 0.9863 - val_loss: 0.7785 - val_accuracy: 0.8446\n","\n","Epoch 00206: val_accuracy did not improve from 0.93243\n","Epoch 207/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.4052 - val_accuracy: 0.8986\n","\n","Epoch 00207: val_accuracy did not improve from 0.93243\n","Epoch 208/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.7083 - val_accuracy: 0.8784\n","\n","Epoch 00208: val_accuracy did not improve from 0.93243\n","Epoch 209/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.4644 - val_accuracy: 0.8986\n","\n","Epoch 00209: val_accuracy did not improve from 0.93243\n","Epoch 210/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.5727 - val_accuracy: 0.8784\n","\n","Epoch 00210: val_accuracy did not improve from 0.93243\n","Epoch 211/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.4111 - val_accuracy: 0.9054\n","\n","Epoch 00211: val_accuracy did not improve from 0.93243\n","Epoch 212/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.1626 - val_accuracy: 0.9595\n","\n","Epoch 00212: val_accuracy improved from 0.93243 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101_3.h5\n","Epoch 213/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0284 - accuracy: 0.9932 - val_loss: 0.2848 - val_accuracy: 0.9257\n","\n","Epoch 00213: val_accuracy did not improve from 0.95946\n","Epoch 214/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.3605 - val_accuracy: 0.8919\n","\n","Epoch 00214: val_accuracy did not improve from 0.95946\n","Epoch 215/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0146 - accuracy: 0.9937 - val_loss: 0.3712 - val_accuracy: 0.8784\n","\n","Epoch 00215: val_accuracy did not improve from 0.95946\n","Epoch 216/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.3040 - val_accuracy: 0.9392\n","\n","Epoch 00216: val_accuracy did not improve from 0.95946\n","Epoch 217/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.3600 - val_accuracy: 0.9054\n","\n","Epoch 00217: val_accuracy did not improve from 0.95946\n","Epoch 218/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5185 - val_accuracy: 0.9122\n","\n","Epoch 00218: val_accuracy did not improve from 0.95946\n","Epoch 219/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.4400 - val_accuracy: 0.9257\n","\n","Epoch 00219: val_accuracy did not improve from 0.95946\n","Epoch 220/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9324\n","\n","Epoch 00220: val_accuracy did not improve from 0.95946\n","Epoch 221/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.6840 - val_accuracy: 0.8581\n","\n","Epoch 00221: val_accuracy did not improve from 0.95946\n","Epoch 222/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.3282 - val_accuracy: 0.8919\n","\n","Epoch 00222: val_accuracy did not improve from 0.95946\n","Epoch 223/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 0.2746 - val_accuracy: 0.9189\n","\n","Epoch 00223: val_accuracy did not improve from 0.95946\n","Epoch 224/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3828 - val_accuracy: 0.9122\n","\n","Epoch 00224: val_accuracy did not improve from 0.95946\n","Epoch 225/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.4571 - val_accuracy: 0.9324\n","\n","Epoch 00225: val_accuracy did not improve from 0.95946\n","Epoch 226/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.2526 - val_accuracy: 0.9324\n","\n","Epoch 00226: val_accuracy did not improve from 0.95946\n","Epoch 227/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.2638 - val_accuracy: 0.9459\n","\n","Epoch 00227: val_accuracy did not improve from 0.95946\n","Epoch 228/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9189\n","\n","Epoch 00228: val_accuracy did not improve from 0.95946\n","Epoch 229/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.8402 - val_accuracy: 0.8716\n","\n","Epoch 00229: val_accuracy did not improve from 0.95946\n","Epoch 230/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.4571 - val_accuracy: 0.8784\n","\n","Epoch 00230: val_accuracy did not improve from 0.95946\n","Epoch 231/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5430 - val_accuracy: 0.8986\n","\n","Epoch 00231: val_accuracy did not improve from 0.95946\n","Epoch 232/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.6636 - val_accuracy: 0.8649\n","\n","Epoch 00232: val_accuracy did not improve from 0.95946\n","Epoch 233/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.4773 - val_accuracy: 0.8851\n","\n","Epoch 00233: val_accuracy did not improve from 0.95946\n","Epoch 234/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5408 - val_accuracy: 0.9122\n","\n","Epoch 00234: val_accuracy did not improve from 0.95946\n","Epoch 235/500\n","238/238 [==============================] - 46s 192ms/step - loss: 8.1657e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9122\n","\n","Epoch 00235: val_accuracy did not improve from 0.95946\n","Epoch 236/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4073 - val_accuracy: 0.9122\n","\n","Epoch 00236: val_accuracy did not improve from 0.95946\n","Epoch 237/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4141 - val_accuracy: 0.9054\n","\n","Epoch 00237: val_accuracy did not improve from 0.95946\n","Epoch 238/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 0.7198 - val_accuracy: 0.8851\n","\n","Epoch 00238: val_accuracy did not improve from 0.95946\n","Epoch 239/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.5390 - val_accuracy: 0.9189\n","\n","Epoch 00239: val_accuracy did not improve from 0.95946\n","Epoch 240/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.3592 - val_accuracy: 0.8986\n","\n","Epoch 00240: val_accuracy did not improve from 0.95946\n","Epoch 241/500\n","238/238 [==============================] - 46s 191ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.4393 - val_accuracy: 0.9257\n","\n","Epoch 00241: val_accuracy did not improve from 0.95946\n","Epoch 242/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.3827 - val_accuracy: 0.9257\n","\n","Epoch 00242: val_accuracy did not improve from 0.95946\n","Epoch 243/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.9093 - val_accuracy: 0.8649\n","\n","Epoch 00243: val_accuracy did not improve from 0.95946\n","Epoch 244/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.3354 - val_accuracy: 0.9324\n","\n","Epoch 00244: val_accuracy did not improve from 0.95946\n","Epoch 245/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0138 - accuracy: 0.9937 - val_loss: 0.5190 - val_accuracy: 0.8986\n","\n","Epoch 00245: val_accuracy did not improve from 0.95946\n","Epoch 246/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3675 - val_accuracy: 0.9324\n","\n","Epoch 00246: val_accuracy did not improve from 0.95946\n","Epoch 247/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3789 - val_accuracy: 0.9257\n","\n","Epoch 00247: val_accuracy did not improve from 0.95946\n","Epoch 248/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0324 - accuracy: 0.9905 - val_loss: 0.6760 - val_accuracy: 0.8851\n","\n","Epoch 00248: val_accuracy did not improve from 0.95946\n","Epoch 249/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.5690 - val_accuracy: 0.8919\n","\n","Epoch 00249: val_accuracy did not improve from 0.95946\n","Epoch 250/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4053 - val_accuracy: 0.9189\n","\n","Epoch 00250: val_accuracy did not improve from 0.95946\n","Epoch 251/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.3286 - val_accuracy: 0.9459\n","\n","Epoch 00251: val_accuracy did not improve from 0.95946\n","Epoch 252/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5378 - val_accuracy: 0.9324\n","\n","Epoch 00252: val_accuracy did not improve from 0.95946\n","Epoch 253/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 0.4961 - val_accuracy: 0.8851\n","\n","Epoch 00253: val_accuracy did not improve from 0.95946\n","Epoch 254/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0129 - accuracy: 0.9937 - val_loss: 0.5489 - val_accuracy: 0.8784\n","\n","Epoch 00254: val_accuracy did not improve from 0.95946\n","Epoch 255/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.4126 - val_accuracy: 0.9324\n","\n","Epoch 00255: val_accuracy did not improve from 0.95946\n","Epoch 256/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.4338 - val_accuracy: 0.8919\n","\n","Epoch 00256: val_accuracy did not improve from 0.95946\n","Epoch 257/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.5394 - val_accuracy: 0.9054\n","\n","Epoch 00257: val_accuracy did not improve from 0.95946\n","Epoch 258/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0268 - accuracy: 0.9937 - val_loss: 0.4147 - val_accuracy: 0.8851\n","\n","Epoch 00258: val_accuracy did not improve from 0.95946\n","Epoch 259/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.4345 - val_accuracy: 0.9054\n","\n","Epoch 00259: val_accuracy did not improve from 0.95946\n","Epoch 260/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.4823 - val_accuracy: 0.8919\n","\n","Epoch 00260: val_accuracy did not improve from 0.95946\n","Epoch 261/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.6324 - val_accuracy: 0.8986\n","\n","Epoch 00261: val_accuracy did not improve from 0.95946\n","Epoch 262/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9122\n","\n","Epoch 00262: val_accuracy did not improve from 0.95946\n","Epoch 263/500\n","238/238 [==============================] - 46s 193ms/step - loss: 9.4089e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9324\n","\n","Epoch 00263: val_accuracy did not improve from 0.95946\n","Epoch 264/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.2888 - val_accuracy: 0.9257\n","\n","Epoch 00264: val_accuracy did not improve from 0.95946\n","Epoch 265/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0294 - accuracy: 0.9926 - val_loss: 0.3620 - val_accuracy: 0.8919\n","\n","Epoch 00265: val_accuracy did not improve from 0.95946\n","Epoch 266/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.4917 - val_accuracy: 0.8919\n","\n","Epoch 00266: val_accuracy did not improve from 0.95946\n","Epoch 267/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.3670 - val_accuracy: 0.9054\n","\n","Epoch 00267: val_accuracy did not improve from 0.95946\n","Epoch 268/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4011 - val_accuracy: 0.9189\n","\n","Epoch 00268: val_accuracy did not improve from 0.95946\n","Epoch 269/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.4264 - val_accuracy: 0.9257\n","\n","Epoch 00269: val_accuracy did not improve from 0.95946\n","Epoch 270/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.4490 - val_accuracy: 0.8986\n","\n","Epoch 00270: val_accuracy did not improve from 0.95946\n","Epoch 271/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.3162 - val_accuracy: 0.9189\n","\n","Epoch 00271: val_accuracy did not improve from 0.95946\n","Epoch 272/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.5362 - val_accuracy: 0.8784\n","\n","Epoch 00272: val_accuracy did not improve from 0.95946\n","Epoch 273/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.5750 - val_accuracy: 0.8986\n","\n","Epoch 00273: val_accuracy did not improve from 0.95946\n","Epoch 274/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0142 - accuracy: 0.9926 - val_loss: 0.4316 - val_accuracy: 0.9122\n","\n","Epoch 00274: val_accuracy did not improve from 0.95946\n","Epoch 275/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.4986 - val_accuracy: 0.9122\n","\n","Epoch 00275: val_accuracy did not improve from 0.95946\n","Epoch 276/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.4460 - val_accuracy: 0.9122\n","\n","Epoch 00276: val_accuracy did not improve from 0.95946\n","Epoch 277/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4461 - val_accuracy: 0.8986\n","\n","Epoch 00277: val_accuracy did not improve from 0.95946\n","Epoch 278/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.4442 - val_accuracy: 0.9257\n","\n","Epoch 00278: val_accuracy did not improve from 0.95946\n","Epoch 279/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9324\n","\n","Epoch 00279: val_accuracy did not improve from 0.95946\n","Epoch 280/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.6571 - val_accuracy: 0.8986\n","\n","Epoch 00280: val_accuracy did not improve from 0.95946\n","Epoch 281/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.5522 - val_accuracy: 0.8649\n","\n","Epoch 00281: val_accuracy did not improve from 0.95946\n","Epoch 282/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.6088 - val_accuracy: 0.8851\n","\n","Epoch 00282: val_accuracy did not improve from 0.95946\n","Epoch 283/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.3180 - val_accuracy: 0.9189\n","\n","Epoch 00283: val_accuracy did not improve from 0.95946\n","Epoch 284/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0263 - accuracy: 0.9895 - val_loss: 0.4187 - val_accuracy: 0.8919\n","\n","Epoch 00284: val_accuracy did not improve from 0.95946\n","Epoch 285/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.4059 - val_accuracy: 0.9054\n","\n","Epoch 00285: val_accuracy did not improve from 0.95946\n","Epoch 286/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.5909 - val_accuracy: 0.8784\n","\n","Epoch 00286: val_accuracy did not improve from 0.95946\n","Epoch 287/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4442 - val_accuracy: 0.8851\n","\n","Epoch 00287: val_accuracy did not improve from 0.95946\n","Epoch 288/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4967 - val_accuracy: 0.8919\n","\n","Epoch 00288: val_accuracy did not improve from 0.95946\n","Epoch 289/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.5816 - val_accuracy: 0.8716\n","\n","Epoch 00289: val_accuracy did not improve from 0.95946\n","Epoch 290/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.8072 - val_accuracy: 0.8851\n","\n","Epoch 00290: val_accuracy did not improve from 0.95946\n","Epoch 291/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 0.4478 - val_accuracy: 0.9054\n","\n","Epoch 00291: val_accuracy did not improve from 0.95946\n","Epoch 292/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0098 - accuracy: 0.9953 - val_loss: 0.5904 - val_accuracy: 0.8784\n","\n","Epoch 00292: val_accuracy did not improve from 0.95946\n","Epoch 293/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.4395 - val_accuracy: 0.9054\n","\n","Epoch 00293: val_accuracy did not improve from 0.95946\n","Epoch 294/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.5261 - val_accuracy: 0.8919\n","\n","Epoch 00294: val_accuracy did not improve from 0.95946\n","Epoch 295/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.4493 - val_accuracy: 0.9122\n","\n","Epoch 00295: val_accuracy did not improve from 0.95946\n","Epoch 296/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.4553 - val_accuracy: 0.9189\n","\n","Epoch 00296: val_accuracy did not improve from 0.95946\n","Epoch 297/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2949 - val_accuracy: 0.9257\n","\n","Epoch 00297: val_accuracy did not improve from 0.95946\n","Epoch 298/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.3316 - val_accuracy: 0.8986\n","\n","Epoch 00298: val_accuracy did not improve from 0.95946\n","Epoch 299/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0133 - accuracy: 0.9937 - val_loss: 0.8081 - val_accuracy: 0.8784\n","\n","Epoch 00299: val_accuracy did not improve from 0.95946\n","Epoch 300/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.6683 - val_accuracy: 0.8784\n","\n","Epoch 00300: val_accuracy did not improve from 0.95946\n","Epoch 301/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.4938 - val_accuracy: 0.9054\n","\n","Epoch 00301: val_accuracy did not improve from 0.95946\n","Epoch 302/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.7770 - val_accuracy: 0.8851\n","\n","Epoch 00302: val_accuracy did not improve from 0.95946\n","Epoch 303/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.6755 - val_accuracy: 0.9054\n","\n","Epoch 00303: val_accuracy did not improve from 0.95946\n","Epoch 304/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.5834 - val_accuracy: 0.8919\n","\n","Epoch 00304: val_accuracy did not improve from 0.95946\n","Epoch 305/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0064 - accuracy: 0.9963 - val_loss: 0.3843 - val_accuracy: 0.8919\n","\n","Epoch 00305: val_accuracy did not improve from 0.95946\n","Epoch 306/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.3170 - val_accuracy: 0.9189\n","\n","Epoch 00306: val_accuracy did not improve from 0.95946\n","Epoch 307/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4795 - val_accuracy: 0.9257\n","\n","Epoch 00307: val_accuracy did not improve from 0.95946\n","Epoch 308/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5479 - val_accuracy: 0.9054\n","\n","Epoch 00308: val_accuracy did not improve from 0.95946\n","Epoch 309/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.4089 - val_accuracy: 0.9054\n","\n","Epoch 00309: val_accuracy did not improve from 0.95946\n","Epoch 310/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.6218 - val_accuracy: 0.8986\n","\n","Epoch 00310: val_accuracy did not improve from 0.95946\n","Epoch 311/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.6598 - val_accuracy: 0.8986\n","\n","Epoch 00311: val_accuracy did not improve from 0.95946\n","Epoch 312/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.5648 - val_accuracy: 0.8919\n","\n","Epoch 00312: val_accuracy did not improve from 0.95946\n","Epoch 313/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4478 - val_accuracy: 0.9054\n","\n","Epoch 00313: val_accuracy did not improve from 0.95946\n","Epoch 314/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4388 - val_accuracy: 0.9122\n","\n","Epoch 00314: val_accuracy did not improve from 0.95946\n","Epoch 315/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5153 - val_accuracy: 0.9257\n","\n","Epoch 00315: val_accuracy did not improve from 0.95946\n","Epoch 316/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5616 - val_accuracy: 0.9054\n","\n","Epoch 00316: val_accuracy did not improve from 0.95946\n","Epoch 317/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5835 - val_accuracy: 0.9054\n","\n","Epoch 00317: val_accuracy did not improve from 0.95946\n","Epoch 318/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.3964 - val_accuracy: 0.9054\n","\n","Epoch 00318: val_accuracy did not improve from 0.95946\n","Epoch 319/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.4044 - val_accuracy: 0.9122\n","\n","Epoch 00319: val_accuracy did not improve from 0.95946\n","Epoch 320/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0048 - accuracy: 0.9968 - val_loss: 0.8204 - val_accuracy: 0.8649\n","\n","Epoch 00320: val_accuracy did not improve from 0.95946\n","Epoch 321/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.4166 - val_accuracy: 0.9122\n","\n","Epoch 00321: val_accuracy did not improve from 0.95946\n","Epoch 322/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4166 - val_accuracy: 0.9257\n","\n","Epoch 00322: val_accuracy did not improve from 0.95946\n","Epoch 323/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3527 - val_accuracy: 0.9324\n","\n","Epoch 00323: val_accuracy did not improve from 0.95946\n","Epoch 324/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.6870 - val_accuracy: 0.8919\n","\n","Epoch 00324: val_accuracy did not improve from 0.95946\n","Epoch 325/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0211 - accuracy: 0.9963 - val_loss: 0.5631 - val_accuracy: 0.9054\n","\n","Epoch 00325: val_accuracy did not improve from 0.95946\n","Epoch 326/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.5740 - val_accuracy: 0.9122\n","\n","Epoch 00326: val_accuracy did not improve from 0.95946\n","Epoch 327/500\n","238/238 [==============================] - 46s 193ms/step - loss: 9.2244e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9122\n","\n","Epoch 00327: val_accuracy did not improve from 0.95946\n","Epoch 328/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5126 - val_accuracy: 0.9122\n","\n","Epoch 00328: val_accuracy did not improve from 0.95946\n","Epoch 329/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.6009 - val_accuracy: 0.8986\n","\n","Epoch 00329: val_accuracy did not improve from 0.95946\n","Epoch 330/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.4745 - val_accuracy: 0.9189\n","\n","Epoch 00330: val_accuracy did not improve from 0.95946\n","Epoch 331/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 0.4668 - val_accuracy: 0.9054\n","\n","Epoch 00331: val_accuracy did not improve from 0.95946\n","Epoch 332/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0075 - accuracy: 0.9958 - val_loss: 0.3835 - val_accuracy: 0.9257\n","\n","Epoch 00332: val_accuracy did not improve from 0.95946\n","Epoch 333/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0108 - accuracy: 0.9947 - val_loss: 0.7026 - val_accuracy: 0.8716\n","\n","Epoch 00333: val_accuracy did not improve from 0.95946\n","Epoch 334/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 0.5275 - val_accuracy: 0.9054\n","\n","Epoch 00334: val_accuracy did not improve from 0.95946\n","Epoch 335/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0298 - accuracy: 0.9947 - val_loss: 0.6500 - val_accuracy: 0.8716\n","\n","Epoch 00335: val_accuracy did not improve from 0.95946\n","Epoch 336/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.4460 - val_accuracy: 0.9054\n","\n","Epoch 00336: val_accuracy did not improve from 0.95946\n","Epoch 337/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.2837 - val_accuracy: 0.9392\n","\n","Epoch 00337: val_accuracy did not improve from 0.95946\n","Epoch 338/500\n","238/238 [==============================] - 46s 192ms/step - loss: 9.9927e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9257\n","\n","Epoch 00338: val_accuracy did not improve from 0.95946\n","Epoch 339/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.7077 - val_accuracy: 0.8378\n","\n","Epoch 00339: val_accuracy did not improve from 0.95946\n","Epoch 340/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.3864 - val_accuracy: 0.9189\n","\n","Epoch 00340: val_accuracy did not improve from 0.95946\n","Epoch 341/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3876 - val_accuracy: 0.9189\n","\n","Epoch 00341: val_accuracy did not improve from 0.95946\n","Epoch 342/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3841 - val_accuracy: 0.9189\n","\n","Epoch 00342: val_accuracy did not improve from 0.95946\n","Epoch 343/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.9054\n","\n","Epoch 00343: val_accuracy did not improve from 0.95946\n","Epoch 344/500\n","238/238 [==============================] - 46s 194ms/step - loss: 1.9409e-04 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.9257\n","\n","Epoch 00344: val_accuracy did not improve from 0.95946\n","Epoch 345/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.7815 - val_accuracy: 0.8986\n","\n","Epoch 00345: val_accuracy did not improve from 0.95946\n","Epoch 346/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.9054\n","\n","Epoch 00346: val_accuracy did not improve from 0.95946\n","Epoch 347/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.9239e-04 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8919\n","\n","Epoch 00347: val_accuracy did not improve from 0.95946\n","Epoch 348/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.5073e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.9054\n","\n","Epoch 00348: val_accuracy did not improve from 0.95946\n","Epoch 349/500\n","238/238 [==============================] - 46s 193ms/step - loss: 2.1896e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.9054\n","\n","Epoch 00349: val_accuracy did not improve from 0.95946\n","Epoch 350/500\n","238/238 [==============================] - 46s 193ms/step - loss: 3.4640e-04 - accuracy: 1.0000 - val_loss: 0.5822 - val_accuracy: 0.8986\n","\n","Epoch 00350: val_accuracy did not improve from 0.95946\n","Epoch 351/500\n","238/238 [==============================] - 46s 193ms/step - loss: 1.5816e-04 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.9257\n","\n","Epoch 00351: val_accuracy did not improve from 0.95946\n","Epoch 352/500\n","238/238 [==============================] - 46s 193ms/step - loss: 6.7979e-05 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9122\n","\n","Epoch 00352: val_accuracy did not improve from 0.95946\n","Epoch 353/500\n","238/238 [==============================] - 46s 193ms/step - loss: 4.7418e-05 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9122\n","\n","Epoch 00353: val_accuracy did not improve from 0.95946\n","Epoch 354/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 1.3389 - val_accuracy: 0.8243\n","\n","Epoch 00354: val_accuracy did not improve from 0.95946\n","Epoch 355/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0937 - accuracy: 0.9805 - val_loss: 0.6373 - val_accuracy: 0.8919\n","\n","Epoch 00355: val_accuracy did not improve from 0.95946\n","Epoch 356/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5138 - val_accuracy: 0.9189\n","\n","Epoch 00356: val_accuracy did not improve from 0.95946\n","Epoch 357/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5032 - val_accuracy: 0.9189\n","\n","Epoch 00357: val_accuracy did not improve from 0.95946\n","Epoch 358/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.4763 - val_accuracy: 0.8986\n","\n","Epoch 00358: val_accuracy did not improve from 0.95946\n","Epoch 359/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.6825 - val_accuracy: 0.8919\n","\n","Epoch 00359: val_accuracy did not improve from 0.95946\n","Epoch 360/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.4467 - val_accuracy: 0.9189\n","\n","Epoch 00360: val_accuracy did not improve from 0.95946\n","Epoch 361/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.4400 - val_accuracy: 0.9257\n","\n","Epoch 00361: val_accuracy did not improve from 0.95946\n","Epoch 362/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.6432 - val_accuracy: 0.8986\n","\n","Epoch 00362: val_accuracy did not improve from 0.95946\n","Epoch 363/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.6115 - val_accuracy: 0.8851\n","\n","Epoch 00363: val_accuracy did not improve from 0.95946\n","Epoch 364/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.7062 - val_accuracy: 0.8784\n","\n","Epoch 00364: val_accuracy did not improve from 0.95946\n","Epoch 365/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.6446 - val_accuracy: 0.8716\n","\n","Epoch 00365: val_accuracy did not improve from 0.95946\n","Epoch 366/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.6863 - val_accuracy: 0.8851\n","\n","Epoch 00366: val_accuracy did not improve from 0.95946\n","Epoch 367/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.4747 - val_accuracy: 0.9189\n","\n","Epoch 00367: val_accuracy did not improve from 0.95946\n","Epoch 368/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5276 - val_accuracy: 0.9122\n","\n","Epoch 00368: val_accuracy did not improve from 0.95946\n","Epoch 369/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.6601 - val_accuracy: 0.8784\n","\n","Epoch 00369: val_accuracy did not improve from 0.95946\n","Epoch 370/500\n","238/238 [==============================] - 46s 192ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.4041 - val_accuracy: 0.9189\n","\n","Epoch 00370: val_accuracy did not improve from 0.95946\n","Epoch 371/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4381 - val_accuracy: 0.9392\n","\n","Epoch 00371: val_accuracy did not improve from 0.95946\n","Epoch 372/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.3966 - val_accuracy: 0.9257\n","\n","Epoch 00372: val_accuracy did not improve from 0.95946\n","Epoch 373/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5159 - val_accuracy: 0.8986\n","\n","Epoch 00373: val_accuracy did not improve from 0.95946\n","Epoch 374/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.4383 - val_accuracy: 0.9189\n","\n","Epoch 00374: val_accuracy did not improve from 0.95946\n","Epoch 375/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4473 - val_accuracy: 0.9054\n","\n","Epoch 00375: val_accuracy did not improve from 0.95946\n","Epoch 376/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5189 - val_accuracy: 0.9122\n","\n","Epoch 00376: val_accuracy did not improve from 0.95946\n","Epoch 377/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.3844 - val_accuracy: 0.9324\n","\n","Epoch 00377: val_accuracy did not improve from 0.95946\n","Epoch 378/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.6228 - val_accuracy: 0.8986\n","\n","Epoch 00378: val_accuracy did not improve from 0.95946\n","Epoch 379/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4433 - val_accuracy: 0.9257\n","\n","Epoch 00379: val_accuracy did not improve from 0.95946\n","Epoch 380/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4094 - val_accuracy: 0.9122\n","\n","Epoch 00380: val_accuracy did not improve from 0.95946\n","Epoch 381/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4124 - val_accuracy: 0.9054\n","\n","Epoch 00381: val_accuracy did not improve from 0.95946\n","Epoch 382/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.4072 - val_accuracy: 0.9459\n","\n","Epoch 00382: val_accuracy did not improve from 0.95946\n","Epoch 383/500\n","238/238 [==============================] - 46s 193ms/step - loss: 8.0883e-04 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9324\n","\n","Epoch 00383: val_accuracy did not improve from 0.95946\n","Epoch 384/500\n","238/238 [==============================] - 46s 194ms/step - loss: 2.9996e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9054\n","\n","Epoch 00384: val_accuracy did not improve from 0.95946\n","Epoch 385/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0034 - accuracy: 0.9979 - val_loss: 0.2978 - val_accuracy: 0.9392\n","\n","Epoch 00385: val_accuracy did not improve from 0.95946\n","Epoch 386/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.7832 - val_accuracy: 0.8716\n","\n","Epoch 00386: val_accuracy did not improve from 0.95946\n","Epoch 387/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.6344 - val_accuracy: 0.8919\n","\n","Epoch 00387: val_accuracy did not improve from 0.95946\n","Epoch 388/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0239 - accuracy: 0.9958 - val_loss: 0.5501 - val_accuracy: 0.9189\n","\n","Epoch 00388: val_accuracy did not improve from 0.95946\n","Epoch 389/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.5547 - val_accuracy: 0.9054\n","\n","Epoch 00389: val_accuracy did not improve from 0.95946\n","Epoch 390/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7078 - val_accuracy: 0.8851\n","\n","Epoch 00390: val_accuracy did not improve from 0.95946\n","Epoch 391/500\n","238/238 [==============================] - 46s 194ms/step - loss: 8.2489e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9122\n","\n","Epoch 00391: val_accuracy did not improve from 0.95946\n","Epoch 392/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.4614 - val_accuracy: 0.9392\n","\n","Epoch 00392: val_accuracy did not improve from 0.95946\n","Epoch 393/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.6619 - val_accuracy: 0.8784\n","\n","Epoch 00393: val_accuracy did not improve from 0.95946\n","Epoch 394/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.5791 - val_accuracy: 0.8986\n","\n","Epoch 00394: val_accuracy did not improve from 0.95946\n","Epoch 395/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.6192 - val_accuracy: 0.8919\n","\n","Epoch 00395: val_accuracy did not improve from 0.95946\n","Epoch 396/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.6677 - val_accuracy: 0.8986\n","\n","Epoch 00396: val_accuracy did not improve from 0.95946\n","Epoch 397/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5297 - val_accuracy: 0.9122\n","\n","Epoch 00397: val_accuracy did not improve from 0.95946\n","Epoch 398/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.8851\n","\n","Epoch 00398: val_accuracy did not improve from 0.95946\n","Epoch 399/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.5771 - val_accuracy: 0.8716\n","\n","Epoch 00399: val_accuracy did not improve from 0.95946\n","Epoch 400/500\n","238/238 [==============================] - 47s 196ms/step - loss: 5.4005e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9189\n","\n","Epoch 00400: val_accuracy did not improve from 0.95946\n","Epoch 401/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 0.5810 - val_accuracy: 0.9054\n","\n","Epoch 00401: val_accuracy did not improve from 0.95946\n","Epoch 402/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.6439 - val_accuracy: 0.9122\n","\n","Epoch 00402: val_accuracy did not improve from 0.95946\n","Epoch 403/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0466 - accuracy: 0.9884 - val_loss: 0.4318 - val_accuracy: 0.9122\n","\n","Epoch 00403: val_accuracy did not improve from 0.95946\n","Epoch 404/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.4290 - val_accuracy: 0.9189\n","\n","Epoch 00404: val_accuracy did not improve from 0.95946\n","Epoch 405/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4696 - val_accuracy: 0.9122\n","\n","Epoch 00405: val_accuracy did not improve from 0.95946\n","Epoch 406/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.4388 - val_accuracy: 0.8919\n","\n","Epoch 00406: val_accuracy did not improve from 0.95946\n","Epoch 407/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5030 - val_accuracy: 0.9054\n","\n","Epoch 00407: val_accuracy did not improve from 0.95946\n","Epoch 408/500\n","238/238 [==============================] - 47s 196ms/step - loss: 5.0620e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9189\n","\n","Epoch 00408: val_accuracy did not improve from 0.95946\n","Epoch 409/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9122\n","\n","Epoch 00409: val_accuracy did not improve from 0.95946\n","Epoch 410/500\n","238/238 [==============================] - 46s 193ms/step - loss: 7.1382e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9257\n","\n","Epoch 00410: val_accuracy did not improve from 0.95946\n","Epoch 411/500\n","238/238 [==============================] - 47s 196ms/step - loss: 3.6329e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9324\n","\n","Epoch 00411: val_accuracy did not improve from 0.95946\n","Epoch 412/500\n","238/238 [==============================] - 46s 193ms/step - loss: 2.0243e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9054\n","\n","Epoch 00412: val_accuracy did not improve from 0.95946\n","Epoch 413/500\n","238/238 [==============================] - 46s 194ms/step - loss: 1.0483e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9189\n","\n","Epoch 00413: val_accuracy did not improve from 0.95946\n","Epoch 414/500\n","238/238 [==============================] - 47s 196ms/step - loss: 6.0858e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9122\n","\n","Epoch 00414: val_accuracy did not improve from 0.95946\n","Epoch 415/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.6890 - val_accuracy: 0.8649\n","\n","Epoch 00415: val_accuracy did not improve from 0.95946\n","Epoch 416/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.4114 - val_accuracy: 0.9122\n","\n","Epoch 00416: val_accuracy did not improve from 0.95946\n","Epoch 417/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.4797 - val_accuracy: 0.9054\n","\n","Epoch 00417: val_accuracy did not improve from 0.95946\n","Epoch 418/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.3720 - val_accuracy: 0.8919\n","\n","Epoch 00418: val_accuracy did not improve from 0.95946\n","Epoch 419/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.3333 - val_accuracy: 0.9324\n","\n","Epoch 00419: val_accuracy did not improve from 0.95946\n","Epoch 420/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4621 - val_accuracy: 0.9122\n","\n","Epoch 00420: val_accuracy did not improve from 0.95946\n","Epoch 421/500\n","238/238 [==============================] - 46s 195ms/step - loss: 5.1134e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9324\n","\n","Epoch 00421: val_accuracy did not improve from 0.95946\n","Epoch 422/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3005 - val_accuracy: 0.9189\n","\n","Epoch 00422: val_accuracy did not improve from 0.95946\n","Epoch 423/500\n","238/238 [==============================] - 47s 196ms/step - loss: 6.7029e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9257\n","\n","Epoch 00423: val_accuracy did not improve from 0.95946\n","Epoch 424/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 0.4064 - val_accuracy: 0.9257\n","\n","Epoch 00424: val_accuracy did not improve from 0.95946\n","Epoch 425/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3876 - val_accuracy: 0.9189\n","\n","Epoch 00425: val_accuracy did not improve from 0.95946\n","Epoch 426/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5130 - val_accuracy: 0.9257\n","\n","Epoch 00426: val_accuracy did not improve from 0.95946\n","Epoch 427/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9122\n","\n","Epoch 00427: val_accuracy did not improve from 0.95946\n","Epoch 428/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9122\n","\n","Epoch 00428: val_accuracy did not improve from 0.95946\n","Epoch 429/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6519 - val_accuracy: 0.9054\n","\n","Epoch 00429: val_accuracy did not improve from 0.95946\n","Epoch 430/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.5124 - val_accuracy: 0.8919\n","\n","Epoch 00430: val_accuracy did not improve from 0.95946\n","Epoch 431/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.5244 - val_accuracy: 0.9189\n","\n","Epoch 00431: val_accuracy did not improve from 0.95946\n","Epoch 432/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.5726 - val_accuracy: 0.9257\n","\n","Epoch 00432: val_accuracy did not improve from 0.95946\n","Epoch 433/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.6374 - val_accuracy: 0.8851\n","\n","Epoch 00433: val_accuracy did not improve from 0.95946\n","Epoch 434/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.6482 - val_accuracy: 0.8649\n","\n","Epoch 00434: val_accuracy did not improve from 0.95946\n","Epoch 435/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.4590 - val_accuracy: 0.9189\n","\n","Epoch 00435: val_accuracy did not improve from 0.95946\n","Epoch 436/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4781 - val_accuracy: 0.8649\n","\n","Epoch 00436: val_accuracy did not improve from 0.95946\n","Epoch 437/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4856 - val_accuracy: 0.9054\n","\n","Epoch 00437: val_accuracy did not improve from 0.95946\n","Epoch 438/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3760 - val_accuracy: 0.9324\n","\n","Epoch 00438: val_accuracy did not improve from 0.95946\n","Epoch 439/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.4314 - val_accuracy: 0.8919\n","\n","Epoch 00439: val_accuracy did not improve from 0.95946\n","Epoch 440/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5403 - val_accuracy: 0.9189\n","\n","Epoch 00440: val_accuracy did not improve from 0.95946\n","Epoch 441/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0237 - accuracy: 0.9953 - val_loss: 0.6379 - val_accuracy: 0.9189\n","\n","Epoch 00441: val_accuracy did not improve from 0.95946\n","Epoch 442/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0128 - accuracy: 0.9947 - val_loss: 0.2932 - val_accuracy: 0.8986\n","\n","Epoch 00442: val_accuracy did not improve from 0.95946\n","Epoch 443/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.2579 - val_accuracy: 0.9324\n","\n","Epoch 00443: val_accuracy did not improve from 0.95946\n","Epoch 444/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.5920 - val_accuracy: 0.8919\n","\n","Epoch 00444: val_accuracy did not improve from 0.95946\n","Epoch 445/500\n","238/238 [==============================] - 46s 195ms/step - loss: 4.3627e-04 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.9054\n","\n","Epoch 00445: val_accuracy did not improve from 0.95946\n","Epoch 446/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4681 - val_accuracy: 0.9122\n","\n","Epoch 00446: val_accuracy did not improve from 0.95946\n","Epoch 447/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9257\n","\n","Epoch 00447: val_accuracy did not improve from 0.95946\n","Epoch 448/500\n","238/238 [==============================] - 47s 196ms/step - loss: 4.4495e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9392\n","\n","Epoch 00448: val_accuracy did not improve from 0.95946\n","Epoch 449/500\n","238/238 [==============================] - 46s 193ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.6601 - val_accuracy: 0.8649\n","\n","Epoch 00449: val_accuracy did not improve from 0.95946\n","Epoch 450/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.6513 - val_accuracy: 0.8716\n","\n","Epoch 00450: val_accuracy did not improve from 0.95946\n","Epoch 451/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.5608 - val_accuracy: 0.8986\n","\n","Epoch 00451: val_accuracy did not improve from 0.95946\n","Epoch 452/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0222 - accuracy: 0.9947 - val_loss: 0.4903 - val_accuracy: 0.8986\n","\n","Epoch 00452: val_accuracy did not improve from 0.95946\n","Epoch 453/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.3481 - val_accuracy: 0.9392\n","\n","Epoch 00453: val_accuracy did not improve from 0.95946\n","Epoch 454/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.4578 - val_accuracy: 0.9054\n","\n","Epoch 00454: val_accuracy did not improve from 0.95946\n","Epoch 455/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.5582 - val_accuracy: 0.9257\n","\n","Epoch 00455: val_accuracy did not improve from 0.95946\n","Epoch 456/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.5305 - val_accuracy: 0.9257\n","\n","Epoch 00456: val_accuracy did not improve from 0.95946\n","Epoch 457/500\n","238/238 [==============================] - 46s 195ms/step - loss: 8.0467e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9189\n","\n","Epoch 00457: val_accuracy did not improve from 0.95946\n","Epoch 458/500\n","238/238 [==============================] - 46s 194ms/step - loss: 7.3661e-04 - accuracy: 0.9995 - val_loss: 0.3849 - val_accuracy: 0.9459\n","\n","Epoch 00458: val_accuracy did not improve from 0.95946\n","Epoch 459/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.5356 - val_accuracy: 0.8581\n","\n","Epoch 00459: val_accuracy did not improve from 0.95946\n","Epoch 460/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5295 - val_accuracy: 0.8986\n","\n","Epoch 00460: val_accuracy did not improve from 0.95946\n","Epoch 461/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5562 - val_accuracy: 0.8986\n","\n","Epoch 00461: val_accuracy did not improve from 0.95946\n","Epoch 462/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.7099 - val_accuracy: 0.8581\n","\n","Epoch 00462: val_accuracy did not improve from 0.95946\n","Epoch 463/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.5652 - val_accuracy: 0.8986\n","\n","Epoch 00463: val_accuracy did not improve from 0.95946\n","Epoch 464/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.2904 - val_accuracy: 0.9054\n","\n","Epoch 00464: val_accuracy did not improve from 0.95946\n","Epoch 465/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3352 - val_accuracy: 0.9054\n","\n","Epoch 00465: val_accuracy did not improve from 0.95946\n","Epoch 466/500\n","238/238 [==============================] - 46s 194ms/step - loss: 6.1662e-04 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.8986\n","\n","Epoch 00466: val_accuracy did not improve from 0.95946\n","Epoch 467/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5171 - val_accuracy: 0.9054\n","\n","Epoch 00467: val_accuracy did not improve from 0.95946\n","Epoch 468/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.3581 - val_accuracy: 0.9189\n","\n","Epoch 00468: val_accuracy did not improve from 0.95946\n","Epoch 469/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3231 - val_accuracy: 0.9324\n","\n","Epoch 00469: val_accuracy did not improve from 0.95946\n","Epoch 470/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6710 - val_accuracy: 0.8851\n","\n","Epoch 00470: val_accuracy did not improve from 0.95946\n","Epoch 471/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.6517 - val_accuracy: 0.8716\n","\n","Epoch 00471: val_accuracy did not improve from 0.95946\n","Epoch 472/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5959 - val_accuracy: 0.8919\n","\n","Epoch 00472: val_accuracy did not improve from 0.95946\n","Epoch 473/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.6855 - val_accuracy: 0.8919\n","\n","Epoch 00473: val_accuracy did not improve from 0.95946\n","Epoch 474/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.3239 - val_accuracy: 0.9189\n","\n","Epoch 00474: val_accuracy did not improve from 0.95946\n","Epoch 475/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.5063 - val_accuracy: 0.9054\n","\n","Epoch 00475: val_accuracy did not improve from 0.95946\n","Epoch 476/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.3791 - val_accuracy: 0.9054\n","\n","Epoch 00476: val_accuracy did not improve from 0.95946\n","Epoch 477/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.3513 - val_accuracy: 0.9257\n","\n","Epoch 00477: val_accuracy did not improve from 0.95946\n","Epoch 478/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6262 - val_accuracy: 0.8716\n","\n","Epoch 00478: val_accuracy did not improve from 0.95946\n","Epoch 479/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.3405 - val_accuracy: 0.9189\n","\n","Epoch 00479: val_accuracy did not improve from 0.95946\n","Epoch 480/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.6921 - val_accuracy: 0.8851\n","\n","Epoch 00480: val_accuracy did not improve from 0.95946\n","Epoch 481/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0261 - accuracy: 0.9942 - val_loss: 0.4560 - val_accuracy: 0.8716\n","\n","Epoch 00481: val_accuracy did not improve from 0.95946\n","Epoch 482/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.4494 - val_accuracy: 0.8986\n","\n","Epoch 00482: val_accuracy did not improve from 0.95946\n","Epoch 483/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.4238 - val_accuracy: 0.9189\n","\n","Epoch 00483: val_accuracy did not improve from 0.95946\n","Epoch 484/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5640 - val_accuracy: 0.8986\n","\n","Epoch 00484: val_accuracy did not improve from 0.95946\n","Epoch 485/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4598 - val_accuracy: 0.9189\n","\n","Epoch 00485: val_accuracy did not improve from 0.95946\n","Epoch 486/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4702 - val_accuracy: 0.8986\n","\n","Epoch 00486: val_accuracy did not improve from 0.95946\n","Epoch 487/500\n","238/238 [==============================] - 46s 194ms/step - loss: 4.9266e-04 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9122\n","\n","Epoch 00487: val_accuracy did not improve from 0.95946\n","Epoch 488/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.6170 - val_accuracy: 0.9122\n","\n","Epoch 00488: val_accuracy did not improve from 0.95946\n","Epoch 489/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0084 - accuracy: 0.9958 - val_loss: 0.4997 - val_accuracy: 0.9122\n","\n","Epoch 00489: val_accuracy did not improve from 0.95946\n","Epoch 490/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.6079 - val_accuracy: 0.9189\n","\n","Epoch 00490: val_accuracy did not improve from 0.95946\n","Epoch 491/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5274 - val_accuracy: 0.8851\n","\n","Epoch 00491: val_accuracy did not improve from 0.95946\n","Epoch 492/500\n","238/238 [==============================] - 46s 195ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.4808 - val_accuracy: 0.8986\n","\n","Epoch 00492: val_accuracy did not improve from 0.95946\n","Epoch 493/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.4729 - val_accuracy: 0.8851\n","\n","Epoch 00493: val_accuracy did not improve from 0.95946\n","Epoch 494/500\n","238/238 [==============================] - 46s 195ms/step - loss: 4.3329e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9189\n","\n","Epoch 00494: val_accuracy did not improve from 0.95946\n","Epoch 495/500\n","238/238 [==============================] - 47s 196ms/step - loss: 4.8404e-04 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.9054\n","\n","Epoch 00495: val_accuracy did not improve from 0.95946\n","Epoch 496/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6101 - val_accuracy: 0.8716\n","\n","Epoch 00496: val_accuracy did not improve from 0.95946\n","Epoch 497/500\n","238/238 [==============================] - 47s 196ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.9537 - val_accuracy: 0.8649\n","\n","Epoch 00497: val_accuracy did not improve from 0.95946\n","Epoch 498/500\n","238/238 [==============================] - 47s 197ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.0592 - val_accuracy: 0.8716\n","\n","Epoch 00498: val_accuracy did not improve from 0.95946\n","Epoch 499/500\n","238/238 [==============================] - 46s 194ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.6763 - val_accuracy: 0.8716\n","\n","Epoch 00499: val_accuracy did not improve from 0.95946\n","Epoch 500/500\n","238/238 [==============================] - 47s 195ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.9377 - val_accuracy: 0.8649\n","\n","Epoch 00500: val_accuracy did not improve from 0.95946\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe55fea41d0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632358306005,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"381d1cd9-6408-4f07-ad83-bd6c07751644"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632358345350,"user_tz":-540,"elapsed":38935,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1632358346016,"user_tz":-540,"elapsed":679,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632358346833,"user_tz":-540,"elapsed":819,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fbc567ec-808a-4e0d-f4e9-72735a4a6d3e"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632358463350,"user_tz":-540,"elapsed":116523,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d75dbd3e-c9e3-4f84-a905-d3e0e1412b97"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1632358463742,"user_tz":-540,"elapsed":402,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1632358463743,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1632358464937,"user_tz":-540,"elapsed":1198,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632358464938,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632358476096,"user_tz":-540,"elapsed":11161,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1632358476097,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632358476351,"user_tz":-540,"elapsed":266,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"268a2ca1-839b-4851-ab85-07e43ca45449"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ff8e55b1-c2ef-43f9-8a9d-fa567d8cc1b2\", \"ResNet101_3.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632358480007,"user_tz":-540,"elapsed":3660,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"65ad8a18-2d53-448f-e376-a3681fd2d705"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632358480890,"user_tz":-540,"elapsed":895,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e82f219a-4aec-4981-b194-1939aa09556f"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}