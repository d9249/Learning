{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet101V2_1_(public-, private-).ipynb","provenance":[{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632764758452,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"eac29533-824c-4f5a-9ae5-1ccea6be9c02"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 27 17:46:03 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632764777249,"user_tz":-540,"elapsed":18804,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"96f0de02-ac20-4a03-c92b-649f1862b653"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632764780373,"user_tz":-540,"elapsed":3135,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632764782028,"user_tz":-540,"elapsed":1664,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632764783951,"user_tz":-540,"elapsed":1927,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632764800364,"user_tz":-540,"elapsed":16418,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632764800370,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["model_save = 'ResNet101V2_1'\n","Target_model = 'ResNet101V2_model'\n","Target_predict = 'ResNet101V2_predict'\n","Target_acc = 'ResNet101V2_acc'\n","Target_val = 'ResNet101V2_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632764806740,"user_tz":-540,"elapsed":6378,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.ResNet101V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632764806749,"user_tz":-540,"elapsed":28,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632764807171,"user_tz":-540,"elapsed":448,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"957e2e66-078c-4ec9-f88d-7902ccc0b7c9"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632764807173,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632779388467,"user_tz":-540,"elapsed":14581302,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"5ee8456f-9510-4382-c271-9c577dd706cc"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 54s 117ms/step - loss: 1.9603 - accuracy: 0.3300 - val_loss: 18.9355 - val_accuracy: 0.0946\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 26s 111ms/step - loss: 1.3519 - accuracy: 0.5489 - val_loss: 2.5276 - val_accuracy: 0.3581\n","\n","Epoch 00002: val_accuracy improved from 0.09459 to 0.35811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 3/500\n","238/238 [==============================] - 26s 111ms/step - loss: 1.0915 - accuracy: 0.6311 - val_loss: 1.4969 - val_accuracy: 0.5608\n","\n","Epoch 00003: val_accuracy improved from 0.35811 to 0.56081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 4/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.9701 - accuracy: 0.6716 - val_loss: 15.8631 - val_accuracy: 0.0878\n","\n","Epoch 00004: val_accuracy did not improve from 0.56081\n","Epoch 5/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.8192 - accuracy: 0.7316 - val_loss: 1.1364 - val_accuracy: 0.6419\n","\n","Epoch 00005: val_accuracy improved from 0.56081 to 0.64189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 6/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.7998 - accuracy: 0.7326 - val_loss: 1.7465 - val_accuracy: 0.4865\n","\n","Epoch 00006: val_accuracy did not improve from 0.64189\n","Epoch 7/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.7033 - accuracy: 0.7579 - val_loss: 0.9507 - val_accuracy: 0.7230\n","\n","Epoch 00007: val_accuracy improved from 0.64189 to 0.72297, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 8/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.6325 - accuracy: 0.8021 - val_loss: 0.5617 - val_accuracy: 0.8108\n","\n","Epoch 00008: val_accuracy improved from 0.72297 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 9/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.6990 - accuracy: 0.7705 - val_loss: 0.6940 - val_accuracy: 0.7905\n","\n","Epoch 00009: val_accuracy did not improve from 0.81081\n","Epoch 10/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.6295 - accuracy: 0.8000 - val_loss: 1.2190 - val_accuracy: 0.6622\n","\n","Epoch 00010: val_accuracy did not improve from 0.81081\n","Epoch 11/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.5672 - accuracy: 0.8121 - val_loss: 0.8606 - val_accuracy: 0.7500\n","\n","Epoch 00011: val_accuracy did not improve from 0.81081\n","Epoch 12/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.4981 - accuracy: 0.8247 - val_loss: 0.5711 - val_accuracy: 0.7973\n","\n","Epoch 00012: val_accuracy did not improve from 0.81081\n","Epoch 13/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.5079 - accuracy: 0.8347 - val_loss: 5.7595 - val_accuracy: 0.2905\n","\n","Epoch 00013: val_accuracy did not improve from 0.81081\n","Epoch 14/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.5126 - accuracy: 0.8453 - val_loss: 0.5881 - val_accuracy: 0.8108\n","\n","Epoch 00014: val_accuracy did not improve from 0.81081\n","Epoch 15/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.4352 - accuracy: 0.8616 - val_loss: 0.4509 - val_accuracy: 0.8446\n","\n","Epoch 00015: val_accuracy improved from 0.81081 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 16/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.4115 - accuracy: 0.8663 - val_loss: 0.8357 - val_accuracy: 0.7297\n","\n","Epoch 00016: val_accuracy did not improve from 0.84459\n","Epoch 17/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.3903 - accuracy: 0.8626 - val_loss: 0.5456 - val_accuracy: 0.8041\n","\n","Epoch 00017: val_accuracy did not improve from 0.84459\n","Epoch 18/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.4515 - accuracy: 0.8595 - val_loss: 0.7931 - val_accuracy: 0.7703\n","\n","Epoch 00018: val_accuracy did not improve from 0.84459\n","Epoch 19/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.3712 - accuracy: 0.8726 - val_loss: 0.3744 - val_accuracy: 0.8716\n","\n","Epoch 00019: val_accuracy improved from 0.84459 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 20/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.3683 - accuracy: 0.8742 - val_loss: 2.2133 - val_accuracy: 0.5203\n","\n","Epoch 00020: val_accuracy did not improve from 0.87162\n","Epoch 21/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.3673 - accuracy: 0.8832 - val_loss: 0.3822 - val_accuracy: 0.8514\n","\n","Epoch 00021: val_accuracy did not improve from 0.87162\n","Epoch 22/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.3336 - accuracy: 0.8905 - val_loss: 1.4245 - val_accuracy: 0.6959\n","\n","Epoch 00022: val_accuracy did not improve from 0.87162\n","Epoch 23/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.4030 - accuracy: 0.8663 - val_loss: 0.4509 - val_accuracy: 0.8446\n","\n","Epoch 00023: val_accuracy did not improve from 0.87162\n","Epoch 24/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.3252 - accuracy: 0.8889 - val_loss: 0.5452 - val_accuracy: 0.8378\n","\n","Epoch 00024: val_accuracy did not improve from 0.87162\n","Epoch 25/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2815 - accuracy: 0.9047 - val_loss: 0.6379 - val_accuracy: 0.8243\n","\n","Epoch 00025: val_accuracy did not improve from 0.87162\n","Epoch 26/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2972 - accuracy: 0.8995 - val_loss: 10.5866 - val_accuracy: 0.1689\n","\n","Epoch 00026: val_accuracy did not improve from 0.87162\n","Epoch 27/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.3173 - accuracy: 0.8900 - val_loss: 0.4327 - val_accuracy: 0.8716\n","\n","Epoch 00027: val_accuracy did not improve from 0.87162\n","Epoch 28/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2592 - accuracy: 0.9058 - val_loss: 0.2612 - val_accuracy: 0.9054\n","\n","Epoch 00028: val_accuracy improved from 0.87162 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 29/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.2829 - accuracy: 0.9021 - val_loss: 0.3480 - val_accuracy: 0.8784\n","\n","Epoch 00029: val_accuracy did not improve from 0.90541\n","Epoch 30/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.2823 - accuracy: 0.9053 - val_loss: 0.3308 - val_accuracy: 0.8716\n","\n","Epoch 00030: val_accuracy did not improve from 0.90541\n","Epoch 31/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2439 - accuracy: 0.9105 - val_loss: 0.4780 - val_accuracy: 0.8311\n","\n","Epoch 00031: val_accuracy did not improve from 0.90541\n","Epoch 32/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2503 - accuracy: 0.9142 - val_loss: 0.5087 - val_accuracy: 0.8176\n","\n","Epoch 00032: val_accuracy did not improve from 0.90541\n","Epoch 33/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2511 - accuracy: 0.9237 - val_loss: 0.6688 - val_accuracy: 0.8176\n","\n","Epoch 00033: val_accuracy did not improve from 0.90541\n","Epoch 34/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2319 - accuracy: 0.9153 - val_loss: 0.4054 - val_accuracy: 0.8784\n","\n","Epoch 00034: val_accuracy did not improve from 0.90541\n","Epoch 35/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.1976 - accuracy: 0.9321 - val_loss: 0.3969 - val_accuracy: 0.8378\n","\n","Epoch 00035: val_accuracy did not improve from 0.90541\n","Epoch 36/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2187 - accuracy: 0.9258 - val_loss: 0.5661 - val_accuracy: 0.8446\n","\n","Epoch 00036: val_accuracy did not improve from 0.90541\n","Epoch 37/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.2096 - accuracy: 0.9263 - val_loss: 0.8248 - val_accuracy: 0.7703\n","\n","Epoch 00037: val_accuracy did not improve from 0.90541\n","Epoch 38/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2071 - accuracy: 0.9258 - val_loss: 0.3314 - val_accuracy: 0.9054\n","\n","Epoch 00038: val_accuracy did not improve from 0.90541\n","Epoch 39/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2281 - accuracy: 0.9305 - val_loss: 0.4682 - val_accuracy: 0.8649\n","\n","Epoch 00039: val_accuracy did not improve from 0.90541\n","Epoch 40/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2349 - accuracy: 0.9184 - val_loss: 0.4007 - val_accuracy: 0.8649\n","\n","Epoch 00040: val_accuracy did not improve from 0.90541\n","Epoch 41/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.2069 - accuracy: 0.9332 - val_loss: 0.4170 - val_accuracy: 0.8784\n","\n","Epoch 00041: val_accuracy did not improve from 0.90541\n","Epoch 42/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1457 - accuracy: 0.9521 - val_loss: 0.3714 - val_accuracy: 0.8716\n","\n","Epoch 00042: val_accuracy did not improve from 0.90541\n","Epoch 43/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1372 - accuracy: 0.9547 - val_loss: 0.5363 - val_accuracy: 0.8851\n","\n","Epoch 00043: val_accuracy did not improve from 0.90541\n","Epoch 44/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1417 - accuracy: 0.9479 - val_loss: 0.6246 - val_accuracy: 0.8041\n","\n","Epoch 00044: val_accuracy did not improve from 0.90541\n","Epoch 45/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1586 - accuracy: 0.9442 - val_loss: 0.4940 - val_accuracy: 0.8378\n","\n","Epoch 00045: val_accuracy did not improve from 0.90541\n","Epoch 46/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1556 - accuracy: 0.9458 - val_loss: 0.5153 - val_accuracy: 0.8784\n","\n","Epoch 00046: val_accuracy did not improve from 0.90541\n","Epoch 47/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.1588 - accuracy: 0.9479 - val_loss: 0.6098 - val_accuracy: 0.8716\n","\n","Epoch 00047: val_accuracy did not improve from 0.90541\n","Epoch 48/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1755 - accuracy: 0.9495 - val_loss: 0.4220 - val_accuracy: 0.8919\n","\n","Epoch 00048: val_accuracy did not improve from 0.90541\n","Epoch 49/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1440 - accuracy: 0.9574 - val_loss: 0.3778 - val_accuracy: 0.8716\n","\n","Epoch 00049: val_accuracy did not improve from 0.90541\n","Epoch 50/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0941 - accuracy: 0.9700 - val_loss: 0.3557 - val_accuracy: 0.8986\n","\n","Epoch 00050: val_accuracy did not improve from 0.90541\n","Epoch 51/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.1073 - accuracy: 0.9668 - val_loss: 0.5259 - val_accuracy: 0.8311\n","\n","Epoch 00051: val_accuracy did not improve from 0.90541\n","Epoch 52/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1352 - accuracy: 0.9495 - val_loss: 0.4172 - val_accuracy: 0.8986\n","\n","Epoch 00052: val_accuracy did not improve from 0.90541\n","Epoch 53/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1429 - accuracy: 0.9484 - val_loss: 0.7645 - val_accuracy: 0.8311\n","\n","Epoch 00053: val_accuracy did not improve from 0.90541\n","Epoch 54/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1350 - accuracy: 0.9542 - val_loss: 0.3891 - val_accuracy: 0.8851\n","\n","Epoch 00054: val_accuracy did not improve from 0.90541\n","Epoch 55/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1060 - accuracy: 0.9626 - val_loss: 0.4976 - val_accuracy: 0.8986\n","\n","Epoch 00055: val_accuracy did not improve from 0.90541\n","Epoch 56/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0932 - accuracy: 0.9711 - val_loss: 0.3428 - val_accuracy: 0.8784\n","\n","Epoch 00056: val_accuracy did not improve from 0.90541\n","Epoch 57/500\n","238/238 [==============================] - 26s 109ms/step - loss: 0.1017 - accuracy: 0.9642 - val_loss: 0.2840 - val_accuracy: 0.9122\n","\n","Epoch 00057: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 58/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.1002 - accuracy: 0.9668 - val_loss: 0.3090 - val_accuracy: 0.9122\n","\n","Epoch 00058: val_accuracy did not improve from 0.91216\n","Epoch 59/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1938 - accuracy: 0.9437 - val_loss: 0.5268 - val_accuracy: 0.8581\n","\n","Epoch 00059: val_accuracy did not improve from 0.91216\n","Epoch 60/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0873 - accuracy: 0.9689 - val_loss: 0.5105 - val_accuracy: 0.8378\n","\n","Epoch 00060: val_accuracy did not improve from 0.91216\n","Epoch 61/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0939 - accuracy: 0.9695 - val_loss: 3.2071 - val_accuracy: 0.5000\n","\n","Epoch 00061: val_accuracy did not improve from 0.91216\n","Epoch 62/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1021 - accuracy: 0.9647 - val_loss: 0.3250 - val_accuracy: 0.9257\n","\n","Epoch 00062: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 63/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.1046 - accuracy: 0.9653 - val_loss: 0.4420 - val_accuracy: 0.8581\n","\n","Epoch 00063: val_accuracy did not improve from 0.92568\n","Epoch 64/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0788 - accuracy: 0.9763 - val_loss: 0.5700 - val_accuracy: 0.8311\n","\n","Epoch 00064: val_accuracy did not improve from 0.92568\n","Epoch 65/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0854 - accuracy: 0.9732 - val_loss: 0.4286 - val_accuracy: 0.8986\n","\n","Epoch 00065: val_accuracy did not improve from 0.92568\n","Epoch 66/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.6938 - val_accuracy: 0.8311\n","\n","Epoch 00066: val_accuracy did not improve from 0.92568\n","Epoch 67/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.1008 - accuracy: 0.9674 - val_loss: 2.8034 - val_accuracy: 0.7027\n","\n","Epoch 00067: val_accuracy did not improve from 0.92568\n","Epoch 68/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.1095 - accuracy: 0.9663 - val_loss: 0.3590 - val_accuracy: 0.8919\n","\n","Epoch 00068: val_accuracy did not improve from 0.92568\n","Epoch 69/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 0.5754 - val_accuracy: 0.8176\n","\n","Epoch 00069: val_accuracy did not improve from 0.92568\n","Epoch 70/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.4848 - val_accuracy: 0.8919\n","\n","Epoch 00070: val_accuracy did not improve from 0.92568\n","Epoch 71/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.1037 - accuracy: 0.9653 - val_loss: 0.8959 - val_accuracy: 0.8378\n","\n","Epoch 00071: val_accuracy did not improve from 0.92568\n","Epoch 72/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0894 - accuracy: 0.9668 - val_loss: 0.6743 - val_accuracy: 0.8581\n","\n","Epoch 00072: val_accuracy did not improve from 0.92568\n","Epoch 73/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0950 - accuracy: 0.9637 - val_loss: 0.4915 - val_accuracy: 0.8514\n","\n","Epoch 00073: val_accuracy did not improve from 0.92568\n","Epoch 74/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.3430 - val_accuracy: 0.9054\n","\n","Epoch 00074: val_accuracy did not improve from 0.92568\n","Epoch 75/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0682 - accuracy: 0.9763 - val_loss: 0.5274 - val_accuracy: 0.8311\n","\n","Epoch 00075: val_accuracy did not improve from 0.92568\n","Epoch 76/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0692 - accuracy: 0.9763 - val_loss: 0.6064 - val_accuracy: 0.8784\n","\n","Epoch 00076: val_accuracy did not improve from 0.92568\n","Epoch 77/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 0.5063 - val_accuracy: 0.8784\n","\n","Epoch 00077: val_accuracy did not improve from 0.92568\n","Epoch 78/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0754 - accuracy: 0.9747 - val_loss: 0.6283 - val_accuracy: 0.8581\n","\n","Epoch 00078: val_accuracy did not improve from 0.92568\n","Epoch 79/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0714 - accuracy: 0.9774 - val_loss: 0.4542 - val_accuracy: 0.8446\n","\n","Epoch 00079: val_accuracy did not improve from 0.92568\n","Epoch 80/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 1.0037 - val_accuracy: 0.7162\n","\n","Epoch 00080: val_accuracy did not improve from 0.92568\n","Epoch 81/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0610 - accuracy: 0.9758 - val_loss: 0.4410 - val_accuracy: 0.8919\n","\n","Epoch 00081: val_accuracy did not improve from 0.92568\n","Epoch 82/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.5054 - val_accuracy: 0.9122\n","\n","Epoch 00082: val_accuracy did not improve from 0.92568\n","Epoch 83/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.5940 - val_accuracy: 0.8378\n","\n","Epoch 00083: val_accuracy did not improve from 0.92568\n","Epoch 84/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.4237 - val_accuracy: 0.8581\n","\n","Epoch 00084: val_accuracy did not improve from 0.92568\n","Epoch 85/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 1.1735 - val_accuracy: 0.7770\n","\n","Epoch 00085: val_accuracy did not improve from 0.92568\n","Epoch 86/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.1277 - accuracy: 0.9574 - val_loss: 0.4338 - val_accuracy: 0.8986\n","\n","Epoch 00086: val_accuracy did not improve from 0.92568\n","Epoch 87/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.3830 - val_accuracy: 0.8986\n","\n","Epoch 00087: val_accuracy did not improve from 0.92568\n","Epoch 88/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.5795 - val_accuracy: 0.8243\n","\n","Epoch 00088: val_accuracy did not improve from 0.92568\n","Epoch 89/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.6004 - val_accuracy: 0.8649\n","\n","Epoch 00089: val_accuracy did not improve from 0.92568\n","Epoch 90/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0562 - accuracy: 0.9826 - val_loss: 0.4624 - val_accuracy: 0.8649\n","\n","Epoch 00090: val_accuracy did not improve from 0.92568\n","Epoch 91/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.4823 - val_accuracy: 0.8851\n","\n","Epoch 00091: val_accuracy did not improve from 0.92568\n","Epoch 92/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0656 - accuracy: 0.9779 - val_loss: 0.7671 - val_accuracy: 0.8649\n","\n","Epoch 00092: val_accuracy did not improve from 0.92568\n","Epoch 93/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.7568 - val_accuracy: 0.8784\n","\n","Epoch 00093: val_accuracy did not improve from 0.92568\n","Epoch 94/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.3696 - val_accuracy: 0.8784\n","\n","Epoch 00094: val_accuracy did not improve from 0.92568\n","Epoch 95/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.4192 - val_accuracy: 0.8851\n","\n","Epoch 00095: val_accuracy did not improve from 0.92568\n","Epoch 96/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.5070 - val_accuracy: 0.8784\n","\n","Epoch 00096: val_accuracy did not improve from 0.92568\n","Epoch 97/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0763 - accuracy: 0.9768 - val_loss: 0.4180 - val_accuracy: 0.8919\n","\n","Epoch 00097: val_accuracy did not improve from 0.92568\n","Epoch 98/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.4491 - val_accuracy: 0.8649\n","\n","Epoch 00098: val_accuracy did not improve from 0.92568\n","Epoch 99/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.4272 - val_accuracy: 0.9054\n","\n","Epoch 00099: val_accuracy did not improve from 0.92568\n","Epoch 100/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0537 - accuracy: 0.9779 - val_loss: 0.5313 - val_accuracy: 0.8784\n","\n","Epoch 00100: val_accuracy did not improve from 0.92568\n","Epoch 101/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 0.8063 - val_accuracy: 0.8446\n","\n","Epoch 00101: val_accuracy did not improve from 0.92568\n","Epoch 102/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.6193 - val_accuracy: 0.8851\n","\n","Epoch 00102: val_accuracy did not improve from 0.92568\n","Epoch 103/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0742 - accuracy: 0.9732 - val_loss: 0.3978 - val_accuracy: 0.8851\n","\n","Epoch 00103: val_accuracy did not improve from 0.92568\n","Epoch 104/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.4610 - val_accuracy: 0.8784\n","\n","Epoch 00104: val_accuracy did not improve from 0.92568\n","Epoch 105/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0620 - accuracy: 0.9779 - val_loss: 0.4994 - val_accuracy: 0.8581\n","\n","Epoch 00105: val_accuracy did not improve from 0.92568\n","Epoch 106/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0687 - accuracy: 0.9716 - val_loss: 0.5257 - val_accuracy: 0.8919\n","\n","Epoch 00106: val_accuracy did not improve from 0.92568\n","Epoch 107/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0411 - accuracy: 0.9847 - val_loss: 0.4662 - val_accuracy: 0.8784\n","\n","Epoch 00107: val_accuracy did not improve from 0.92568\n","Epoch 108/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.3923 - val_accuracy: 0.8986\n","\n","Epoch 00108: val_accuracy did not improve from 0.92568\n","Epoch 109/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0300 - accuracy: 0.9863 - val_loss: 0.4157 - val_accuracy: 0.9189\n","\n","Epoch 00109: val_accuracy did not improve from 0.92568\n","Epoch 110/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0761 - accuracy: 0.9763 - val_loss: 0.7180 - val_accuracy: 0.8649\n","\n","Epoch 00110: val_accuracy did not improve from 0.92568\n","Epoch 111/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.5068 - val_accuracy: 0.8784\n","\n","Epoch 00111: val_accuracy did not improve from 0.92568\n","Epoch 112/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.5136 - val_accuracy: 0.8784\n","\n","Epoch 00112: val_accuracy did not improve from 0.92568\n","Epoch 113/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.6518 - val_accuracy: 0.8581\n","\n","Epoch 00113: val_accuracy did not improve from 0.92568\n","Epoch 114/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.5243 - val_accuracy: 0.8446\n","\n","Epoch 00114: val_accuracy did not improve from 0.92568\n","Epoch 115/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0305 - accuracy: 0.9884 - val_loss: 0.5269 - val_accuracy: 0.9054\n","\n","Epoch 00115: val_accuracy did not improve from 0.92568\n","Epoch 116/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 0.5025 - val_accuracy: 0.8919\n","\n","Epoch 00116: val_accuracy did not improve from 0.92568\n","Epoch 117/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.5735 - val_accuracy: 0.9189\n","\n","Epoch 00117: val_accuracy did not improve from 0.92568\n","Epoch 118/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0496 - accuracy: 0.9847 - val_loss: 0.4564 - val_accuracy: 0.8784\n","\n","Epoch 00118: val_accuracy did not improve from 0.92568\n","Epoch 119/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.3854 - val_accuracy: 0.9122\n","\n","Epoch 00119: val_accuracy did not improve from 0.92568\n","Epoch 120/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0301 - accuracy: 0.9879 - val_loss: 0.6149 - val_accuracy: 0.8649\n","\n","Epoch 00120: val_accuracy did not improve from 0.92568\n","Epoch 121/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.5159 - val_accuracy: 0.8649\n","\n","Epoch 00121: val_accuracy did not improve from 0.92568\n","Epoch 122/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0260 - accuracy: 0.9889 - val_loss: 0.5029 - val_accuracy: 0.8986\n","\n","Epoch 00122: val_accuracy did not improve from 0.92568\n","Epoch 123/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.6313 - val_accuracy: 0.8851\n","\n","Epoch 00123: val_accuracy did not improve from 0.92568\n","Epoch 124/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0255 - accuracy: 0.9953 - val_loss: 0.5260 - val_accuracy: 0.8784\n","\n","Epoch 00124: val_accuracy did not improve from 0.92568\n","Epoch 125/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 2.8294 - val_accuracy: 0.6149\n","\n","Epoch 00125: val_accuracy did not improve from 0.92568\n","Epoch 126/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 0.7667 - val_accuracy: 0.8514\n","\n","Epoch 00126: val_accuracy did not improve from 0.92568\n","Epoch 127/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0347 - accuracy: 0.9874 - val_loss: 0.4013 - val_accuracy: 0.8986\n","\n","Epoch 00127: val_accuracy did not improve from 0.92568\n","Epoch 128/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.4948 - val_accuracy: 0.8986\n","\n","Epoch 00128: val_accuracy did not improve from 0.92568\n","Epoch 129/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0199 - accuracy: 0.9911 - val_loss: 0.4078 - val_accuracy: 0.8986\n","\n","Epoch 00129: val_accuracy did not improve from 0.92568\n","Epoch 130/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.3306 - val_accuracy: 0.9054\n","\n","Epoch 00130: val_accuracy did not improve from 0.92568\n","Epoch 131/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.7136 - val_accuracy: 0.8649\n","\n","Epoch 00131: val_accuracy did not improve from 0.92568\n","Epoch 132/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.4428 - val_accuracy: 0.9054\n","\n","Epoch 00132: val_accuracy did not improve from 0.92568\n","Epoch 133/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.6202 - val_accuracy: 0.8919\n","\n","Epoch 00133: val_accuracy did not improve from 0.92568\n","Epoch 134/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.4307 - val_accuracy: 0.9257\n","\n","Epoch 00134: val_accuracy did not improve from 0.92568\n","Epoch 135/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0528 - accuracy: 0.9842 - val_loss: 0.6316 - val_accuracy: 0.8716\n","\n","Epoch 00135: val_accuracy did not improve from 0.92568\n","Epoch 136/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.5417 - val_accuracy: 0.8919\n","\n","Epoch 00136: val_accuracy did not improve from 0.92568\n","Epoch 137/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.3486 - val_accuracy: 0.9257\n","\n","Epoch 00137: val_accuracy did not improve from 0.92568\n","Epoch 138/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.4808 - val_accuracy: 0.9054\n","\n","Epoch 00138: val_accuracy did not improve from 0.92568\n","Epoch 139/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.5365 - val_accuracy: 0.8919\n","\n","Epoch 00139: val_accuracy did not improve from 0.92568\n","Epoch 140/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0559 - accuracy: 0.9789 - val_loss: 0.3496 - val_accuracy: 0.9054\n","\n","Epoch 00140: val_accuracy did not improve from 0.92568\n","Epoch 141/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.3532 - val_accuracy: 0.9189\n","\n","Epoch 00141: val_accuracy did not improve from 0.92568\n","Epoch 142/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.6571 - val_accuracy: 0.8581\n","\n","Epoch 00142: val_accuracy did not improve from 0.92568\n","Epoch 143/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 0.5828 - val_accuracy: 0.8784\n","\n","Epoch 00143: val_accuracy did not improve from 0.92568\n","Epoch 144/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0664 - accuracy: 0.9821 - val_loss: 0.3174 - val_accuracy: 0.9122\n","\n","Epoch 00144: val_accuracy did not improve from 0.92568\n","Epoch 145/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.4544 - val_accuracy: 0.8919\n","\n","Epoch 00145: val_accuracy did not improve from 0.92568\n","Epoch 146/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.4711 - val_accuracy: 0.8919\n","\n","Epoch 00146: val_accuracy did not improve from 0.92568\n","Epoch 147/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.5666 - val_accuracy: 0.8784\n","\n","Epoch 00147: val_accuracy did not improve from 0.92568\n","Epoch 148/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.4489 - val_accuracy: 0.9122\n","\n","Epoch 00148: val_accuracy did not improve from 0.92568\n","Epoch 149/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0480 - accuracy: 0.9837 - val_loss: 0.6583 - val_accuracy: 0.8986\n","\n","Epoch 00149: val_accuracy did not improve from 0.92568\n","Epoch 150/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.4164 - val_accuracy: 0.9054\n","\n","Epoch 00150: val_accuracy did not improve from 0.92568\n","Epoch 151/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.5453 - val_accuracy: 0.8919\n","\n","Epoch 00151: val_accuracy did not improve from 0.92568\n","Epoch 152/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.6244 - val_accuracy: 0.8851\n","\n","Epoch 00152: val_accuracy did not improve from 0.92568\n","Epoch 153/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.4357 - val_accuracy: 0.9122\n","\n","Epoch 00153: val_accuracy did not improve from 0.92568\n","Epoch 154/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.5487 - val_accuracy: 0.8919\n","\n","Epoch 00154: val_accuracy did not improve from 0.92568\n","Epoch 155/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.5746 - val_accuracy: 0.8986\n","\n","Epoch 00155: val_accuracy did not improve from 0.92568\n","Epoch 156/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.6704 - val_accuracy: 0.8716\n","\n","Epoch 00156: val_accuracy did not improve from 0.92568\n","Epoch 157/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.6499 - val_accuracy: 0.8851\n","\n","Epoch 00157: val_accuracy did not improve from 0.92568\n","Epoch 158/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0373 - accuracy: 0.9911 - val_loss: 0.5364 - val_accuracy: 0.8716\n","\n","Epoch 00158: val_accuracy did not improve from 0.92568\n","Epoch 159/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.5409 - val_accuracy: 0.8919\n","\n","Epoch 00159: val_accuracy did not improve from 0.92568\n","Epoch 160/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.6648 - val_accuracy: 0.8581\n","\n","Epoch 00160: val_accuracy did not improve from 0.92568\n","Epoch 161/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.4904 - val_accuracy: 0.8784\n","\n","Epoch 00161: val_accuracy did not improve from 0.92568\n","Epoch 162/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 0.2963 - val_accuracy: 0.9392\n","\n","Epoch 00162: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 163/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.4512 - val_accuracy: 0.9122\n","\n","Epoch 00163: val_accuracy did not improve from 0.93919\n","Epoch 164/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 0.5517 - val_accuracy: 0.8851\n","\n","Epoch 00164: val_accuracy did not improve from 0.93919\n","Epoch 165/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.2877 - val_accuracy: 0.9054\n","\n","Epoch 00165: val_accuracy did not improve from 0.93919\n","Epoch 166/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.4139 - val_accuracy: 0.9189\n","\n","Epoch 00166: val_accuracy did not improve from 0.93919\n","Epoch 167/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.3655 - val_accuracy: 0.9189\n","\n","Epoch 00167: val_accuracy did not improve from 0.93919\n","Epoch 168/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5034 - val_accuracy: 0.9257\n","\n","Epoch 00168: val_accuracy did not improve from 0.93919\n","Epoch 169/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.3920 - val_accuracy: 0.9189\n","\n","Epoch 00169: val_accuracy did not improve from 0.93919\n","Epoch 170/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.3438 - val_accuracy: 0.9189\n","\n","Epoch 00170: val_accuracy did not improve from 0.93919\n","Epoch 171/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.4028 - val_accuracy: 0.9324\n","\n","Epoch 00171: val_accuracy did not improve from 0.93919\n","Epoch 172/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.4603 - val_accuracy: 0.9189\n","\n","Epoch 00172: val_accuracy did not improve from 0.93919\n","Epoch 173/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.5749 - val_accuracy: 0.8986\n","\n","Epoch 00173: val_accuracy did not improve from 0.93919\n","Epoch 174/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0180 - accuracy: 0.9916 - val_loss: 0.5267 - val_accuracy: 0.8716\n","\n","Epoch 00174: val_accuracy did not improve from 0.93919\n","Epoch 175/500\n","238/238 [==============================] - 26s 110ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.3888 - val_accuracy: 0.9189\n","\n","Epoch 00175: val_accuracy did not improve from 0.93919\n","Epoch 176/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.4498 - val_accuracy: 0.9054\n","\n","Epoch 00176: val_accuracy did not improve from 0.93919\n","Epoch 177/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.6503 - val_accuracy: 0.8784\n","\n","Epoch 00177: val_accuracy did not improve from 0.93919\n","Epoch 178/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0358 - accuracy: 0.9858 - val_loss: 0.9150 - val_accuracy: 0.8649\n","\n","Epoch 00178: val_accuracy did not improve from 0.93919\n","Epoch 179/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.5170 - val_accuracy: 0.8986\n","\n","Epoch 00179: val_accuracy did not improve from 0.93919\n","Epoch 180/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.3727 - val_accuracy: 0.9189\n","\n","Epoch 00180: val_accuracy did not improve from 0.93919\n","Epoch 181/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0507 - accuracy: 0.9863 - val_loss: 0.7838 - val_accuracy: 0.8108\n","\n","Epoch 00181: val_accuracy did not improve from 0.93919\n","Epoch 182/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.3281 - val_accuracy: 0.9324\n","\n","Epoch 00182: val_accuracy did not improve from 0.93919\n","Epoch 183/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.7862 - val_accuracy: 0.8851\n","\n","Epoch 00183: val_accuracy did not improve from 0.93919\n","Epoch 184/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4081 - val_accuracy: 0.9054\n","\n","Epoch 00184: val_accuracy did not improve from 0.93919\n","Epoch 185/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.2057 - val_accuracy: 0.9527\n","\n","Epoch 00185: val_accuracy improved from 0.93919 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet101V2_1.h5\n","Epoch 186/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.3772 - val_accuracy: 0.9122\n","\n","Epoch 00186: val_accuracy did not improve from 0.95270\n","Epoch 187/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.3755 - val_accuracy: 0.8986\n","\n","Epoch 00187: val_accuracy did not improve from 0.95270\n","Epoch 188/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.6534 - val_accuracy: 0.8716\n","\n","Epoch 00188: val_accuracy did not improve from 0.95270\n","Epoch 189/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 0.6308 - val_accuracy: 0.8919\n","\n","Epoch 00189: val_accuracy did not improve from 0.95270\n","Epoch 190/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.5477 - val_accuracy: 0.8919\n","\n","Epoch 00190: val_accuracy did not improve from 0.95270\n","Epoch 191/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.2396 - val_accuracy: 0.9189\n","\n","Epoch 00191: val_accuracy did not improve from 0.95270\n","Epoch 192/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.5343 - val_accuracy: 0.8851\n","\n","Epoch 00192: val_accuracy did not improve from 0.95270\n","Epoch 193/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9257\n","\n","Epoch 00193: val_accuracy did not improve from 0.95270\n","Epoch 194/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.5017 - val_accuracy: 0.8851\n","\n","Epoch 00194: val_accuracy did not improve from 0.95270\n","Epoch 195/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.6211 - val_accuracy: 0.8851\n","\n","Epoch 00195: val_accuracy did not improve from 0.95270\n","Epoch 196/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.4339 - val_accuracy: 0.8851\n","\n","Epoch 00196: val_accuracy did not improve from 0.95270\n","Epoch 197/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 0.5649 - val_accuracy: 0.8649\n","\n","Epoch 00197: val_accuracy did not improve from 0.95270\n","Epoch 198/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0325 - accuracy: 0.9926 - val_loss: 0.4575 - val_accuracy: 0.8919\n","\n","Epoch 00198: val_accuracy did not improve from 0.95270\n","Epoch 199/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.4795 - val_accuracy: 0.8851\n","\n","Epoch 00199: val_accuracy did not improve from 0.95270\n","Epoch 200/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.4508 - val_accuracy: 0.9054\n","\n","Epoch 00200: val_accuracy did not improve from 0.95270\n","Epoch 201/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.3266 - val_accuracy: 0.8919\n","\n","Epoch 00201: val_accuracy did not improve from 0.95270\n","Epoch 202/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.5313 - val_accuracy: 0.8919\n","\n","Epoch 00202: val_accuracy did not improve from 0.95270\n","Epoch 203/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.4742 - val_accuracy: 0.8851\n","\n","Epoch 00203: val_accuracy did not improve from 0.95270\n","Epoch 204/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0333 - accuracy: 0.9879 - val_loss: 0.5914 - val_accuracy: 0.8851\n","\n","Epoch 00204: val_accuracy did not improve from 0.95270\n","Epoch 205/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.2522 - val_accuracy: 0.9392\n","\n","Epoch 00205: val_accuracy did not improve from 0.95270\n","Epoch 206/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.4903 - val_accuracy: 0.9122\n","\n","Epoch 00206: val_accuracy did not improve from 0.95270\n","Epoch 207/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0326 - accuracy: 0.9874 - val_loss: 0.8322 - val_accuracy: 0.8784\n","\n","Epoch 00207: val_accuracy did not improve from 0.95270\n","Epoch 208/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.3643 - val_accuracy: 0.9122\n","\n","Epoch 00208: val_accuracy did not improve from 0.95270\n","Epoch 209/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.4560 - val_accuracy: 0.9054\n","\n","Epoch 00209: val_accuracy did not improve from 0.95270\n","Epoch 210/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.5070 - val_accuracy: 0.8986\n","\n","Epoch 00210: val_accuracy did not improve from 0.95270\n","Epoch 211/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.3686 - val_accuracy: 0.9189\n","\n","Epoch 00211: val_accuracy did not improve from 0.95270\n","Epoch 212/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4478 - val_accuracy: 0.9257\n","\n","Epoch 00212: val_accuracy did not improve from 0.95270\n","Epoch 213/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4838 - val_accuracy: 0.8986\n","\n","Epoch 00213: val_accuracy did not improve from 0.95270\n","Epoch 214/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4052 - val_accuracy: 0.9189\n","\n","Epoch 00214: val_accuracy did not improve from 0.95270\n","Epoch 215/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 0.8797 - val_accuracy: 0.8378\n","\n","Epoch 00215: val_accuracy did not improve from 0.95270\n","Epoch 216/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.6601 - val_accuracy: 0.9054\n","\n","Epoch 00216: val_accuracy did not improve from 0.95270\n","Epoch 217/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.7541 - val_accuracy: 0.8784\n","\n","Epoch 00217: val_accuracy did not improve from 0.95270\n","Epoch 218/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.6094 - val_accuracy: 0.9189\n","\n","Epoch 00218: val_accuracy did not improve from 0.95270\n","Epoch 219/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.3613 - val_accuracy: 0.9122\n","\n","Epoch 00219: val_accuracy did not improve from 0.95270\n","Epoch 220/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.3115 - val_accuracy: 0.9459\n","\n","Epoch 00220: val_accuracy did not improve from 0.95270\n","Epoch 221/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.4966 - val_accuracy: 0.8986\n","\n","Epoch 00221: val_accuracy did not improve from 0.95270\n","Epoch 222/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0121 - accuracy: 0.9942 - val_loss: 0.4448 - val_accuracy: 0.9257\n","\n","Epoch 00222: val_accuracy did not improve from 0.95270\n","Epoch 223/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.4925 - val_accuracy: 0.9189\n","\n","Epoch 00223: val_accuracy did not improve from 0.95270\n","Epoch 224/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.6373 - val_accuracy: 0.8716\n","\n","Epoch 00224: val_accuracy did not improve from 0.95270\n","Epoch 225/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.5384 - val_accuracy: 0.8784\n","\n","Epoch 00225: val_accuracy did not improve from 0.95270\n","Epoch 226/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0075 - accuracy: 0.9958 - val_loss: 0.3820 - val_accuracy: 0.9122\n","\n","Epoch 00226: val_accuracy did not improve from 0.95270\n","Epoch 227/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.3765 - val_accuracy: 0.9257\n","\n","Epoch 00227: val_accuracy did not improve from 0.95270\n","Epoch 228/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3644 - val_accuracy: 0.9257\n","\n","Epoch 00228: val_accuracy did not improve from 0.95270\n","Epoch 229/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.4668 - val_accuracy: 0.9054\n","\n","Epoch 00229: val_accuracy did not improve from 0.95270\n","Epoch 230/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.4484 - val_accuracy: 0.9189\n","\n","Epoch 00230: val_accuracy did not improve from 0.95270\n","Epoch 231/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.5022 - val_accuracy: 0.8851\n","\n","Epoch 00231: val_accuracy did not improve from 0.95270\n","Epoch 232/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.7628 - val_accuracy: 0.8784\n","\n","Epoch 00232: val_accuracy did not improve from 0.95270\n","Epoch 233/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 0.5848 - val_accuracy: 0.8986\n","\n","Epoch 00233: val_accuracy did not improve from 0.95270\n","Epoch 234/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.8611 - val_accuracy: 0.8716\n","\n","Epoch 00234: val_accuracy did not improve from 0.95270\n","Epoch 235/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.7648 - val_accuracy: 0.8649\n","\n","Epoch 00235: val_accuracy did not improve from 0.95270\n","Epoch 236/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.5900 - val_accuracy: 0.8986\n","\n","Epoch 00236: val_accuracy did not improve from 0.95270\n","Epoch 237/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.5685 - val_accuracy: 0.8716\n","\n","Epoch 00237: val_accuracy did not improve from 0.95270\n","Epoch 238/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5569 - val_accuracy: 0.8919\n","\n","Epoch 00238: val_accuracy did not improve from 0.95270\n","Epoch 239/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.6328 - val_accuracy: 0.8784\n","\n","Epoch 00239: val_accuracy did not improve from 0.95270\n","Epoch 240/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.5309 - val_accuracy: 0.8784\n","\n","Epoch 00240: val_accuracy did not improve from 0.95270\n","Epoch 241/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.5334 - val_accuracy: 0.8986\n","\n","Epoch 00241: val_accuracy did not improve from 0.95270\n","Epoch 242/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.5753 - val_accuracy: 0.8716\n","\n","Epoch 00242: val_accuracy did not improve from 0.95270\n","Epoch 243/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.9008 - val_accuracy: 0.8851\n","\n","Epoch 00243: val_accuracy did not improve from 0.95270\n","Epoch 244/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.5537 - val_accuracy: 0.9054\n","\n","Epoch 00244: val_accuracy did not improve from 0.95270\n","Epoch 245/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.5008 - val_accuracy: 0.9054\n","\n","Epoch 00245: val_accuracy did not improve from 0.95270\n","Epoch 246/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 0.5990 - val_accuracy: 0.8716\n","\n","Epoch 00246: val_accuracy did not improve from 0.95270\n","Epoch 247/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.6068 - val_accuracy: 0.8784\n","\n","Epoch 00247: val_accuracy did not improve from 0.95270\n","Epoch 248/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.4168 - val_accuracy: 0.8986\n","\n","Epoch 00248: val_accuracy did not improve from 0.95270\n","Epoch 249/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.5900 - val_accuracy: 0.8851\n","\n","Epoch 00249: val_accuracy did not improve from 0.95270\n","Epoch 250/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3983 - val_accuracy: 0.9257\n","\n","Epoch 00250: val_accuracy did not improve from 0.95270\n","Epoch 251/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.4499 - val_accuracy: 0.8919\n","\n","Epoch 00251: val_accuracy did not improve from 0.95270\n","Epoch 252/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.3266 - val_accuracy: 0.9122\n","\n","Epoch 00252: val_accuracy did not improve from 0.95270\n","Epoch 253/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8716\n","\n","Epoch 00253: val_accuracy did not improve from 0.95270\n","Epoch 254/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.7399 - val_accuracy: 0.8378\n","\n","Epoch 00254: val_accuracy did not improve from 0.95270\n","Epoch 255/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.7654 - val_accuracy: 0.8784\n","\n","Epoch 00255: val_accuracy did not improve from 0.95270\n","Epoch 256/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.5327 - val_accuracy: 0.8986\n","\n","Epoch 00256: val_accuracy did not improve from 0.95270\n","Epoch 257/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0114 - accuracy: 0.9937 - val_loss: 0.6969 - val_accuracy: 0.8446\n","\n","Epoch 00257: val_accuracy did not improve from 0.95270\n","Epoch 258/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.4388 - val_accuracy: 0.9189\n","\n","Epoch 00258: val_accuracy did not improve from 0.95270\n","Epoch 259/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.5352 - val_accuracy: 0.9054\n","\n","Epoch 00259: val_accuracy did not improve from 0.95270\n","Epoch 260/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.9070 - val_accuracy: 0.8649\n","\n","Epoch 00260: val_accuracy did not improve from 0.95270\n","Epoch 261/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.4728 - val_accuracy: 0.9189\n","\n","Epoch 00261: val_accuracy did not improve from 0.95270\n","Epoch 262/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.4593 - val_accuracy: 0.9054\n","\n","Epoch 00262: val_accuracy did not improve from 0.95270\n","Epoch 263/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.5923 - val_accuracy: 0.8851\n","\n","Epoch 00263: val_accuracy did not improve from 0.95270\n","Epoch 264/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.6586 - val_accuracy: 0.8784\n","\n","Epoch 00264: val_accuracy did not improve from 0.95270\n","Epoch 265/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.9782 - val_accuracy: 0.8716\n","\n","Epoch 00265: val_accuracy did not improve from 0.95270\n","Epoch 266/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0184 - accuracy: 0.9921 - val_loss: 0.3896 - val_accuracy: 0.9189\n","\n","Epoch 00266: val_accuracy did not improve from 0.95270\n","Epoch 267/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4237 - val_accuracy: 0.9324\n","\n","Epoch 00267: val_accuracy did not improve from 0.95270\n","Epoch 268/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.2842 - val_accuracy: 0.9392\n","\n","Epoch 00268: val_accuracy did not improve from 0.95270\n","Epoch 269/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.4335 - val_accuracy: 0.9054\n","\n","Epoch 00269: val_accuracy did not improve from 0.95270\n","Epoch 270/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.6383 - val_accuracy: 0.8649\n","\n","Epoch 00270: val_accuracy did not improve from 0.95270\n","Epoch 271/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.4172 - val_accuracy: 0.9054\n","\n","Epoch 00271: val_accuracy did not improve from 0.95270\n","Epoch 272/500\n","238/238 [==============================] - 27s 111ms/step - loss: 9.3137e-04 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9189\n","\n","Epoch 00272: val_accuracy did not improve from 0.95270\n","Epoch 273/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.6630 - val_accuracy: 0.8986\n","\n","Epoch 00273: val_accuracy did not improve from 0.95270\n","Epoch 274/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.4564 - val_accuracy: 0.8986\n","\n","Epoch 00274: val_accuracy did not improve from 0.95270\n","Epoch 275/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9054\n","\n","Epoch 00275: val_accuracy did not improve from 0.95270\n","Epoch 276/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.3836 - val_accuracy: 0.9054\n","\n","Epoch 00276: val_accuracy did not improve from 0.95270\n","Epoch 277/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.4835 - val_accuracy: 0.9054\n","\n","Epoch 00277: val_accuracy did not improve from 0.95270\n","Epoch 278/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.6019 - val_accuracy: 0.8986\n","\n","Epoch 00278: val_accuracy did not improve from 0.95270\n","Epoch 279/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0441 - accuracy: 0.9821 - val_loss: 0.7943 - val_accuracy: 0.8581\n","\n","Epoch 00279: val_accuracy did not improve from 0.95270\n","Epoch 280/500\n","238/238 [==============================] - 26s 111ms/step - loss: 0.0170 - accuracy: 0.9932 - val_loss: 0.6003 - val_accuracy: 0.8784\n","\n","Epoch 00280: val_accuracy did not improve from 0.95270\n","Epoch 281/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0264 - accuracy: 0.9889 - val_loss: 0.2888 - val_accuracy: 0.9122\n","\n","Epoch 00281: val_accuracy did not improve from 0.95270\n","Epoch 282/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.4555 - val_accuracy: 0.8919\n","\n","Epoch 00282: val_accuracy did not improve from 0.95270\n","Epoch 283/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.5258 - val_accuracy: 0.8851\n","\n","Epoch 00283: val_accuracy did not improve from 0.95270\n","Epoch 284/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5684 - val_accuracy: 0.8784\n","\n","Epoch 00284: val_accuracy did not improve from 0.95270\n","Epoch 285/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4976 - val_accuracy: 0.8919\n","\n","Epoch 00285: val_accuracy did not improve from 0.95270\n","Epoch 286/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.5303 - val_accuracy: 0.8919\n","\n","Epoch 00286: val_accuracy did not improve from 0.95270\n","Epoch 287/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.9423 - val_accuracy: 0.8311\n","\n","Epoch 00287: val_accuracy did not improve from 0.95270\n","Epoch 288/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.4627 - val_accuracy: 0.8986\n","\n","Epoch 00288: val_accuracy did not improve from 0.95270\n","Epoch 289/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9122\n","\n","Epoch 00289: val_accuracy did not improve from 0.95270\n","Epoch 290/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.4852 - val_accuracy: 0.8919\n","\n","Epoch 00290: val_accuracy did not improve from 0.95270\n","Epoch 291/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.4358 - val_accuracy: 0.9054\n","\n","Epoch 00291: val_accuracy did not improve from 0.95270\n","Epoch 292/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.4663 - val_accuracy: 0.8986\n","\n","Epoch 00292: val_accuracy did not improve from 0.95270\n","Epoch 293/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9122\n","\n","Epoch 00293: val_accuracy did not improve from 0.95270\n","Epoch 294/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3546 - val_accuracy: 0.9122\n","\n","Epoch 00294: val_accuracy did not improve from 0.95270\n","Epoch 295/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8851\n","\n","Epoch 00295: val_accuracy did not improve from 0.95270\n","Epoch 296/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.6039 - val_accuracy: 0.8919\n","\n","Epoch 00296: val_accuracy did not improve from 0.95270\n","Epoch 297/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.7656 - val_accuracy: 0.8581\n","\n","Epoch 00297: val_accuracy did not improve from 0.95270\n","Epoch 298/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.7824 - val_accuracy: 0.8919\n","\n","Epoch 00298: val_accuracy did not improve from 0.95270\n","Epoch 299/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.5878 - val_accuracy: 0.8986\n","\n","Epoch 00299: val_accuracy did not improve from 0.95270\n","Epoch 300/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.4287 - val_accuracy: 0.8986\n","\n","Epoch 00300: val_accuracy did not improve from 0.95270\n","Epoch 301/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.5937 - val_accuracy: 0.8851\n","\n","Epoch 00301: val_accuracy did not improve from 0.95270\n","Epoch 302/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3973 - val_accuracy: 0.9122\n","\n","Epoch 00302: val_accuracy did not improve from 0.95270\n","Epoch 303/500\n","238/238 [==============================] - 27s 111ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.6140 - val_accuracy: 0.8851\n","\n","Epoch 00303: val_accuracy did not improve from 0.95270\n","Epoch 304/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.7113 - val_accuracy: 0.8716\n","\n","Epoch 00304: val_accuracy did not improve from 0.95270\n","Epoch 305/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0078 - accuracy: 0.9958 - val_loss: 0.4802 - val_accuracy: 0.8919\n","\n","Epoch 00305: val_accuracy did not improve from 0.95270\n","Epoch 306/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.5087 - val_accuracy: 0.9054\n","\n","Epoch 00306: val_accuracy did not improve from 0.95270\n","Epoch 307/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.6339 - val_accuracy: 0.8919\n","\n","Epoch 00307: val_accuracy did not improve from 0.95270\n","Epoch 308/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.6536 - val_accuracy: 0.8716\n","\n","Epoch 00308: val_accuracy did not improve from 0.95270\n","Epoch 309/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4400 - val_accuracy: 0.9189\n","\n","Epoch 00309: val_accuracy did not improve from 0.95270\n","Epoch 310/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.7410 - val_accuracy: 0.8716\n","\n","Epoch 00310: val_accuracy did not improve from 0.95270\n","Epoch 311/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4970 - val_accuracy: 0.9189\n","\n","Epoch 00311: val_accuracy did not improve from 0.95270\n","Epoch 312/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6250 - val_accuracy: 0.8581\n","\n","Epoch 00312: val_accuracy did not improve from 0.95270\n","Epoch 313/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.5591 - val_accuracy: 0.8919\n","\n","Epoch 00313: val_accuracy did not improve from 0.95270\n","Epoch 314/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4642 - val_accuracy: 0.8986\n","\n","Epoch 00314: val_accuracy did not improve from 0.95270\n","Epoch 315/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3992 - val_accuracy: 0.8851\n","\n","Epoch 00315: val_accuracy did not improve from 0.95270\n","Epoch 316/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.4199 - val_accuracy: 0.9122\n","\n","Epoch 00316: val_accuracy did not improve from 0.95270\n","Epoch 317/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5907 - val_accuracy: 0.8851\n","\n","Epoch 00317: val_accuracy did not improve from 0.95270\n","Epoch 318/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.5302 - val_accuracy: 0.8716\n","\n","Epoch 00318: val_accuracy did not improve from 0.95270\n","Epoch 319/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.6959 - val_accuracy: 0.8784\n","\n","Epoch 00319: val_accuracy did not improve from 0.95270\n","Epoch 320/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.5648 - val_accuracy: 0.8919\n","\n","Epoch 00320: val_accuracy did not improve from 0.95270\n","Epoch 321/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.4603 - val_accuracy: 0.9054\n","\n","Epoch 00321: val_accuracy did not improve from 0.95270\n","Epoch 322/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.6101 - val_accuracy: 0.8784\n","\n","Epoch 00322: val_accuracy did not improve from 0.95270\n","Epoch 323/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.5616 - val_accuracy: 0.8784\n","\n","Epoch 00323: val_accuracy did not improve from 0.95270\n","Epoch 324/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.4935 - val_accuracy: 0.8986\n","\n","Epoch 00324: val_accuracy did not improve from 0.95270\n","Epoch 325/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9189\n","\n","Epoch 00325: val_accuracy did not improve from 0.95270\n","Epoch 326/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.7850 - val_accuracy: 0.8446\n","\n","Epoch 00326: val_accuracy did not improve from 0.95270\n","Epoch 327/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.4992 - val_accuracy: 0.8919\n","\n","Epoch 00327: val_accuracy did not improve from 0.95270\n","Epoch 328/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3899 - val_accuracy: 0.9459\n","\n","Epoch 00328: val_accuracy did not improve from 0.95270\n","Epoch 329/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.3686 - val_accuracy: 0.9392\n","\n","Epoch 00329: val_accuracy did not improve from 0.95270\n","Epoch 330/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.9122\n","\n","Epoch 00330: val_accuracy did not improve from 0.95270\n","Epoch 331/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.4878 - val_accuracy: 0.9392\n","\n","Epoch 00331: val_accuracy did not improve from 0.95270\n","Epoch 332/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0568 - accuracy: 0.9858 - val_loss: 1.0586 - val_accuracy: 0.8446\n","\n","Epoch 00332: val_accuracy did not improve from 0.95270\n","Epoch 333/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.5969 - val_accuracy: 0.8784\n","\n","Epoch 00333: val_accuracy did not improve from 0.95270\n","Epoch 334/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.3326 - val_accuracy: 0.9392\n","\n","Epoch 00334: val_accuracy did not improve from 0.95270\n","Epoch 335/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4688 - val_accuracy: 0.9189\n","\n","Epoch 00335: val_accuracy did not improve from 0.95270\n","Epoch 336/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9122\n","\n","Epoch 00336: val_accuracy did not improve from 0.95270\n","Epoch 337/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.5159 - val_accuracy: 0.9054\n","\n","Epoch 00337: val_accuracy did not improve from 0.95270\n","Epoch 338/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.5961 - val_accuracy: 0.8716\n","\n","Epoch 00338: val_accuracy did not improve from 0.95270\n","Epoch 339/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6598 - val_accuracy: 0.8919\n","\n","Epoch 00339: val_accuracy did not improve from 0.95270\n","Epoch 340/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.4884 - val_accuracy: 0.9189\n","\n","Epoch 00340: val_accuracy did not improve from 0.95270\n","Epoch 341/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.4771 - val_accuracy: 0.8986\n","\n","Epoch 00341: val_accuracy did not improve from 0.95270\n","Epoch 342/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4870 - val_accuracy: 0.9189\n","\n","Epoch 00342: val_accuracy did not improve from 0.95270\n","Epoch 343/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.6599 - val_accuracy: 0.8716\n","\n","Epoch 00343: val_accuracy did not improve from 0.95270\n","Epoch 344/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.7880 - val_accuracy: 0.8378\n","\n","Epoch 00344: val_accuracy did not improve from 0.95270\n","Epoch 345/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.6619 - val_accuracy: 0.8784\n","\n","Epoch 00345: val_accuracy did not improve from 0.95270\n","Epoch 346/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.5294 - val_accuracy: 0.8919\n","\n","Epoch 00346: val_accuracy did not improve from 0.95270\n","Epoch 347/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.6750 - val_accuracy: 0.8514\n","\n","Epoch 00347: val_accuracy did not improve from 0.95270\n","Epoch 348/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6207 - val_accuracy: 0.9054\n","\n","Epoch 00348: val_accuracy did not improve from 0.95270\n","Epoch 349/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.4768 - val_accuracy: 0.9122\n","\n","Epoch 00349: val_accuracy did not improve from 0.95270\n","Epoch 350/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.4774 - val_accuracy: 0.9189\n","\n","Epoch 00350: val_accuracy did not improve from 0.95270\n","Epoch 351/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.5329 - val_accuracy: 0.9054\n","\n","Epoch 00351: val_accuracy did not improve from 0.95270\n","Epoch 352/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.5941 - val_accuracy: 0.9054\n","\n","Epoch 00352: val_accuracy did not improve from 0.95270\n","Epoch 353/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.8589 - val_accuracy: 0.8649\n","\n","Epoch 00353: val_accuracy did not improve from 0.95270\n","Epoch 354/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0326 - accuracy: 0.9911 - val_loss: 0.5207 - val_accuracy: 0.8851\n","\n","Epoch 00354: val_accuracy did not improve from 0.95270\n","Epoch 355/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 0.4779 - val_accuracy: 0.8986\n","\n","Epoch 00355: val_accuracy did not improve from 0.95270\n","Epoch 356/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.2823 - val_accuracy: 0.9257\n","\n","Epoch 00356: val_accuracy did not improve from 0.95270\n","Epoch 357/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.4389 - val_accuracy: 0.9324\n","\n","Epoch 00357: val_accuracy did not improve from 0.95270\n","Epoch 358/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.4074 - val_accuracy: 0.9122\n","\n","Epoch 00358: val_accuracy did not improve from 0.95270\n","Epoch 359/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.4349 - val_accuracy: 0.8986\n","\n","Epoch 00359: val_accuracy did not improve from 0.95270\n","Epoch 360/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.3537 - val_accuracy: 0.9257\n","\n","Epoch 00360: val_accuracy did not improve from 0.95270\n","Epoch 361/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.4008 - val_accuracy: 0.9257\n","\n","Epoch 00361: val_accuracy did not improve from 0.95270\n","Epoch 362/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3748 - val_accuracy: 0.8986\n","\n","Epoch 00362: val_accuracy did not improve from 0.95270\n","Epoch 363/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.4576 - val_accuracy: 0.9189\n","\n","Epoch 00363: val_accuracy did not improve from 0.95270\n","Epoch 364/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.6999 - val_accuracy: 0.8649\n","\n","Epoch 00364: val_accuracy did not improve from 0.95270\n","Epoch 365/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4906 - val_accuracy: 0.8851\n","\n","Epoch 00365: val_accuracy did not improve from 0.95270\n","Epoch 366/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.4745 - val_accuracy: 0.8919\n","\n","Epoch 00366: val_accuracy did not improve from 0.95270\n","Epoch 367/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.6015 - val_accuracy: 0.8851\n","\n","Epoch 00367: val_accuracy did not improve from 0.95270\n","Epoch 368/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3588 - val_accuracy: 0.9054\n","\n","Epoch 00368: val_accuracy did not improve from 0.95270\n","Epoch 369/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4083 - val_accuracy: 0.9257\n","\n","Epoch 00369: val_accuracy did not improve from 0.95270\n","Epoch 370/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.4375 - val_accuracy: 0.9189\n","\n","Epoch 00370: val_accuracy did not improve from 0.95270\n","Epoch 371/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.6599 - val_accuracy: 0.8716\n","\n","Epoch 00371: val_accuracy did not improve from 0.95270\n","Epoch 372/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.8919\n","\n","Epoch 00372: val_accuracy did not improve from 0.95270\n","Epoch 373/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.4594 - val_accuracy: 0.9122\n","\n","Epoch 00373: val_accuracy did not improve from 0.95270\n","Epoch 374/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9122\n","\n","Epoch 00374: val_accuracy did not improve from 0.95270\n","Epoch 375/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.0883 - val_accuracy: 0.8581\n","\n","Epoch 00375: val_accuracy did not improve from 0.95270\n","Epoch 376/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.5306 - val_accuracy: 0.8986\n","\n","Epoch 00376: val_accuracy did not improve from 0.95270\n","Epoch 377/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9257\n","\n","Epoch 00377: val_accuracy did not improve from 0.95270\n","Epoch 378/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5480 - val_accuracy: 0.9122\n","\n","Epoch 00378: val_accuracy did not improve from 0.95270\n","Epoch 379/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.6138 - val_accuracy: 0.8716\n","\n","Epoch 00379: val_accuracy did not improve from 0.95270\n","Epoch 380/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.6297 - val_accuracy: 0.8919\n","\n","Epoch 00380: val_accuracy did not improve from 0.95270\n","Epoch 381/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.5759 - val_accuracy: 0.8784\n","\n","Epoch 00381: val_accuracy did not improve from 0.95270\n","Epoch 382/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.5271 - val_accuracy: 0.8986\n","\n","Epoch 00382: val_accuracy did not improve from 0.95270\n","Epoch 383/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.7809 - val_accuracy: 0.8716\n","\n","Epoch 00383: val_accuracy did not improve from 0.95270\n","Epoch 384/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4988 - val_accuracy: 0.9189\n","\n","Epoch 00384: val_accuracy did not improve from 0.95270\n","Epoch 385/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5781 - val_accuracy: 0.9122\n","\n","Epoch 00385: val_accuracy did not improve from 0.95270\n","Epoch 386/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6145 - val_accuracy: 0.9257\n","\n","Epoch 00386: val_accuracy did not improve from 0.95270\n","Epoch 387/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.7757 - val_accuracy: 0.8514\n","\n","Epoch 00387: val_accuracy did not improve from 0.95270\n","Epoch 388/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5317 - val_accuracy: 0.9122\n","\n","Epoch 00388: val_accuracy did not improve from 0.95270\n","Epoch 389/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.8986\n","\n","Epoch 00389: val_accuracy did not improve from 0.95270\n","Epoch 390/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4773 - val_accuracy: 0.8986\n","\n","Epoch 00390: val_accuracy did not improve from 0.95270\n","Epoch 391/500\n","238/238 [==============================] - 27s 112ms/step - loss: 0.0123 - accuracy: 0.9947 - val_loss: 0.6398 - val_accuracy: 0.8784\n","\n","Epoch 00391: val_accuracy did not improve from 0.95270\n","Epoch 392/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.9146 - val_accuracy: 0.8851\n","\n","Epoch 00392: val_accuracy did not improve from 0.95270\n","Epoch 393/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.5434 - val_accuracy: 0.9054\n","\n","Epoch 00393: val_accuracy did not improve from 0.95270\n","Epoch 394/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.3262 - val_accuracy: 0.9257\n","\n","Epoch 00394: val_accuracy did not improve from 0.95270\n","Epoch 395/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.3591 - val_accuracy: 0.8919\n","\n","Epoch 00395: val_accuracy did not improve from 0.95270\n","Epoch 396/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.5471 - val_accuracy: 0.8784\n","\n","Epoch 00396: val_accuracy did not improve from 0.95270\n","Epoch 397/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.3597 - val_accuracy: 0.8919\n","\n","Epoch 00397: val_accuracy did not improve from 0.95270\n","Epoch 398/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.4241 - val_accuracy: 0.8986\n","\n","Epoch 00398: val_accuracy did not improve from 0.95270\n","Epoch 399/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4383 - val_accuracy: 0.8986\n","\n","Epoch 00399: val_accuracy did not improve from 0.95270\n","Epoch 400/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5132 - val_accuracy: 0.9054\n","\n","Epoch 00400: val_accuracy did not improve from 0.95270\n","Epoch 401/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.7346 - val_accuracy: 0.8919\n","\n","Epoch 00401: val_accuracy did not improve from 0.95270\n","Epoch 402/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.4158 - val_accuracy: 0.9324\n","\n","Epoch 00402: val_accuracy did not improve from 0.95270\n","Epoch 403/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5488 - val_accuracy: 0.8581\n","\n","Epoch 00403: val_accuracy did not improve from 0.95270\n","Epoch 404/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9122\n","\n","Epoch 00404: val_accuracy did not improve from 0.95270\n","Epoch 405/500\n","238/238 [==============================] - 27s 113ms/step - loss: 5.2015e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9054\n","\n","Epoch 00405: val_accuracy did not improve from 0.95270\n","Epoch 406/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6601 - val_accuracy: 0.8919\n","\n","Epoch 00406: val_accuracy did not improve from 0.95270\n","Epoch 407/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.4119 - val_accuracy: 0.9054\n","\n","Epoch 00407: val_accuracy did not improve from 0.95270\n","Epoch 408/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3148 - val_accuracy: 0.9189\n","\n","Epoch 00408: val_accuracy did not improve from 0.95270\n","Epoch 409/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.3847 - val_accuracy: 0.9122\n","\n","Epoch 00409: val_accuracy did not improve from 0.95270\n","Epoch 410/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.3897 - val_accuracy: 0.9324\n","\n","Epoch 00410: val_accuracy did not improve from 0.95270\n","Epoch 411/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.4600 - val_accuracy: 0.8986\n","\n","Epoch 00411: val_accuracy did not improve from 0.95270\n","Epoch 412/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.4472 - val_accuracy: 0.9122\n","\n","Epoch 00412: val_accuracy did not improve from 0.95270\n","Epoch 413/500\n","238/238 [==============================] - 27s 114ms/step - loss: 8.6175e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9324\n","\n","Epoch 00413: val_accuracy did not improve from 0.95270\n","Epoch 414/500\n","238/238 [==============================] - 27s 113ms/step - loss: 9.7690e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9392\n","\n","Epoch 00414: val_accuracy did not improve from 0.95270\n","Epoch 415/500\n","238/238 [==============================] - 27s 113ms/step - loss: 2.9573e-04 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9189\n","\n","Epoch 00415: val_accuracy did not improve from 0.95270\n","Epoch 416/500\n","238/238 [==============================] - 27s 113ms/step - loss: 3.8871e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9324\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5819 - val_accuracy: 0.8986\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 1.0738 - val_accuracy: 0.8176\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.2758 - val_accuracy: 0.9189\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3770 - val_accuracy: 0.9054\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.9218 - val_accuracy: 0.8446\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.3501 - val_accuracy: 0.9122\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.4004 - val_accuracy: 0.9257\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.5057 - val_accuracy: 0.8986\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.3633 - val_accuracy: 0.9189\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4813 - val_accuracy: 0.8986\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2897 - val_accuracy: 0.9257\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 27s 113ms/step - loss: 7.5967e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.8851\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.6384 - val_accuracy: 0.8919\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.6356 - val_accuracy: 0.8919\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 0.6739 - val_accuracy: 0.8919\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0386 - accuracy: 0.9863 - val_loss: 0.5749 - val_accuracy: 0.8919\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.3755 - val_accuracy: 0.9122\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.4384 - val_accuracy: 0.8919\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4962 - val_accuracy: 0.8919\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.6357 - val_accuracy: 0.9122\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4828 - val_accuracy: 0.9257\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.5417 - val_accuracy: 0.9054\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.6410 - val_accuracy: 0.8986\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.5069 - val_accuracy: 0.8919\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.3760 - val_accuracy: 0.9392\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 0.5727 - val_accuracy: 0.8919\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4895 - val_accuracy: 0.8986\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.5798 - val_accuracy: 0.8919\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6316 - val_accuracy: 0.8716\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.5448 - val_accuracy: 0.8851\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9054\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5490 - val_accuracy: 0.9122\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.5449 - val_accuracy: 0.9054\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.5552 - val_accuracy: 0.9189\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5125 - val_accuracy: 0.8986\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.4903 - val_accuracy: 0.9189\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.4474 - val_accuracy: 0.9122\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.6241 - val_accuracy: 0.8919\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4245 - val_accuracy: 0.9257\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.5459 - val_accuracy: 0.8986\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4957 - val_accuracy: 0.9054\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5591 - val_accuracy: 0.9054\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.4120 - val_accuracy: 0.9054\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.4322 - val_accuracy: 0.9054\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.4715 - val_accuracy: 0.9392\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 28s 116ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4489 - val_accuracy: 0.9122\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5345 - val_accuracy: 0.9189\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.5762 - val_accuracy: 0.8986\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.6634 - val_accuracy: 0.8784\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.4456 - val_accuracy: 0.9257\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.8190 - val_accuracy: 0.8919\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4000 - val_accuracy: 0.9459\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9324\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.6147 - val_accuracy: 0.8851\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.4950 - val_accuracy: 0.9189\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.4781 - val_accuracy: 0.8986\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.4465 - val_accuracy: 0.9054\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3799 - val_accuracy: 0.9054\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.4003 - val_accuracy: 0.9122\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4509 - val_accuracy: 0.9257\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 27s 114ms/step - loss: 4.4526e-04 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9257\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 27s 113ms/step - loss: 3.5423e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9257\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.6279 - val_accuracy: 0.8784\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.4989 - val_accuracy: 0.9189\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.7925 - val_accuracy: 0.8649\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 0.5932 - val_accuracy: 0.9122\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.5697 - val_accuracy: 0.9122\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.5191 - val_accuracy: 0.8784\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.7641 - val_accuracy: 0.9122\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4934 - val_accuracy: 0.9257\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.6165 - val_accuracy: 0.8919\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6330 - val_accuracy: 0.8986\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4766 - val_accuracy: 0.8986\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6137 - val_accuracy: 0.8919\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 1.1829 - val_accuracy: 0.8311\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.5802 - val_accuracy: 0.8919\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4032 - val_accuracy: 0.9257\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 27s 115ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5476 - val_accuracy: 0.9392\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.8457 - val_accuracy: 0.8716\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.7371 - val_accuracy: 0.8986\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4598 - val_accuracy: 0.8851\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.4197 - val_accuracy: 0.9122\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 27s 113ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.4407 - val_accuracy: 0.9122\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 27s 114ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4771 - val_accuracy: 0.8919\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff683125850>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632779388469,"user_tz":-540,"elapsed":27,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"741c1e4b-8378-4e0b-833a-78bb91a36b03"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632779412598,"user_tz":-540,"elapsed":24142,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1632779413026,"user_tz":-540,"elapsed":435,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632779413873,"user_tz":-540,"elapsed":858,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"12be9759-0832-4f69-ad9c-39df880bde5e"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632779466635,"user_tz":-540,"elapsed":52771,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"1b93362e-0a09-40f1-aaaf-a8e4757f2303"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1632779466640,"user_tz":-540,"elapsed":377,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1632779466641,"user_tz":-540,"elapsed":74,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1632779466992,"user_tz":-540,"elapsed":424,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632779466993,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632779478455,"user_tz":-540,"elapsed":11466,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1632779478456,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632779478457,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"d332156b-1910-4260-d9bc-ad3f1811811f"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_34946b49-7297-47e3-856d-3f363eb9a2cc\", \"ResNet101V2_1.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632779481454,"user_tz":-540,"elapsed":3007,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"6ff3f61c-1876-40f0-f12a-3d93e9829133"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632779497743,"user_tz":-540,"elapsed":16302,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"dd74a867-819b-44e3-8cdf-29279a0cd648"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': True, 'detail': 'Success'}\n"]}]}]}