{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet152_4_(public-0.91176, private-0.92079).ipynb","provenance":[{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632508583083,"user_tz":-540,"elapsed":316,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5b02a49f-2efe-45c8-83d1-bff66797cf9e"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep 24 18:36:28 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632508599010,"user_tz":-540,"elapsed":15934,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"869ea72e-a0bc-43ed-ea1d-d5997158d10a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1632508602352,"user_tz":-540,"elapsed":3350,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1632508603378,"user_tz":-540,"elapsed":1031,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1632508605653,"user_tz":-540,"elapsed":2278,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1632508621927,"user_tz":-540,"elapsed":16281,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1632508621932,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["model_save = 'ResNet152_4'\n","Target_model = 'ResNet152_model'\n","Target_predict = 'ResNet152_predict'\n","Target_acc = 'ResNet152_acc'\n","Target_val = 'ResNet152_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1632508629395,"user_tz":-540,"elapsed":7469,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.ResNet152(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1632508629396,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632508629829,"user_tz":-540,"elapsed":439,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"cafbbf94-e609-4d36-ba3b-2b8224689966"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1632508629830,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632542694069,"user_tz":-540,"elapsed":11955541,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9369119a-e6e2-4341-97b7-43169c8b6dcf"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/500\n","238/238 [==============================] - 97s 270ms/step - loss: 2.6497 - accuracy: 0.1595 - val_loss: 3.5522 - val_accuracy: 0.1014\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 63s 263ms/step - loss: 2.0542 - accuracy: 0.2768 - val_loss: 56.6182 - val_accuracy: 0.1014\n","\n","Epoch 00002: val_accuracy did not improve from 0.10135\n","Epoch 3/500\n","238/238 [==============================] - 64s 269ms/step - loss: 1.6443 - accuracy: 0.4432 - val_loss: 6.3615 - val_accuracy: 0.1824\n","\n","Epoch 00003: val_accuracy improved from 0.10135 to 0.18243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 4/500\n","238/238 [==============================] - 65s 272ms/step - loss: 1.2162 - accuracy: 0.5942 - val_loss: 1.9189 - val_accuracy: 0.5405\n","\n","Epoch 00004: val_accuracy improved from 0.18243 to 0.54054, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 5/500\n","238/238 [==============================] - 65s 274ms/step - loss: 1.0234 - accuracy: 0.6737 - val_loss: 20.8535 - val_accuracy: 0.1757\n","\n","Epoch 00005: val_accuracy did not improve from 0.54054\n","Epoch 6/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.9796 - accuracy: 0.6942 - val_loss: 1.8877 - val_accuracy: 0.4730\n","\n","Epoch 00006: val_accuracy did not improve from 0.54054\n","Epoch 7/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.8596 - accuracy: 0.7158 - val_loss: 0.8461 - val_accuracy: 0.7500\n","\n","Epoch 00007: val_accuracy improved from 0.54054 to 0.75000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 8/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.6990 - accuracy: 0.7600 - val_loss: 0.6504 - val_accuracy: 0.7500\n","\n","Epoch 00008: val_accuracy did not improve from 0.75000\n","Epoch 9/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.7018 - accuracy: 0.7716 - val_loss: 3.3579 - val_accuracy: 0.4122\n","\n","Epoch 00009: val_accuracy did not improve from 0.75000\n","Epoch 10/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.6243 - accuracy: 0.7953 - val_loss: 1.5030 - val_accuracy: 0.5405\n","\n","Epoch 00010: val_accuracy did not improve from 0.75000\n","Epoch 11/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.6186 - accuracy: 0.7989 - val_loss: 2.2853 - val_accuracy: 0.6149\n","\n","Epoch 00011: val_accuracy did not improve from 0.75000\n","Epoch 12/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.5503 - accuracy: 0.8189 - val_loss: 0.7644 - val_accuracy: 0.7432\n","\n","Epoch 00012: val_accuracy did not improve from 0.75000\n","Epoch 13/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.4907 - accuracy: 0.8379 - val_loss: 0.5084 - val_accuracy: 0.8649\n","\n","Epoch 00013: val_accuracy improved from 0.75000 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 14/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.5269 - accuracy: 0.8295 - val_loss: 1.7313 - val_accuracy: 0.5405\n","\n","Epoch 00014: val_accuracy did not improve from 0.86486\n","Epoch 15/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.5108 - accuracy: 0.8384 - val_loss: 1.1202 - val_accuracy: 0.6959\n","\n","Epoch 00015: val_accuracy did not improve from 0.86486\n","Epoch 16/500\n","238/238 [==============================] - 66s 275ms/step - loss: 0.4178 - accuracy: 0.8616 - val_loss: 0.6036 - val_accuracy: 0.8041\n","\n","Epoch 00016: val_accuracy did not improve from 0.86486\n","Epoch 17/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3901 - accuracy: 0.8626 - val_loss: 0.8028 - val_accuracy: 0.7432\n","\n","Epoch 00017: val_accuracy did not improve from 0.86486\n","Epoch 18/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.4272 - accuracy: 0.8579 - val_loss: 1.7594 - val_accuracy: 0.6824\n","\n","Epoch 00018: val_accuracy did not improve from 0.86486\n","Epoch 19/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.4183 - accuracy: 0.8584 - val_loss: 0.4530 - val_accuracy: 0.8649\n","\n","Epoch 00019: val_accuracy did not improve from 0.86486\n","Epoch 20/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3934 - accuracy: 0.8626 - val_loss: 248.5114 - val_accuracy: 0.1014\n","\n","Epoch 00020: val_accuracy did not improve from 0.86486\n","Epoch 21/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.4109 - accuracy: 0.8674 - val_loss: 1.5124 - val_accuracy: 0.6757\n","\n","Epoch 00021: val_accuracy did not improve from 0.86486\n","Epoch 22/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3489 - accuracy: 0.8842 - val_loss: 0.6573 - val_accuracy: 0.8176\n","\n","Epoch 00022: val_accuracy did not improve from 0.86486\n","Epoch 23/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.4055 - accuracy: 0.8711 - val_loss: 0.7375 - val_accuracy: 0.8108\n","\n","Epoch 00023: val_accuracy did not improve from 0.86486\n","Epoch 24/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3528 - accuracy: 0.8811 - val_loss: 0.9485 - val_accuracy: 0.7432\n","\n","Epoch 00024: val_accuracy did not improve from 0.86486\n","Epoch 25/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3225 - accuracy: 0.8821 - val_loss: 0.3442 - val_accuracy: 0.8581\n","\n","Epoch 00025: val_accuracy did not improve from 0.86486\n","Epoch 26/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3186 - accuracy: 0.8984 - val_loss: 0.7413 - val_accuracy: 0.7973\n","\n","Epoch 00026: val_accuracy did not improve from 0.86486\n","Epoch 27/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2848 - accuracy: 0.9058 - val_loss: 0.4848 - val_accuracy: 0.8176\n","\n","Epoch 00027: val_accuracy did not improve from 0.86486\n","Epoch 28/500\n","238/238 [==============================] - 66s 275ms/step - loss: 0.2677 - accuracy: 0.9105 - val_loss: 0.6126 - val_accuracy: 0.8311\n","\n","Epoch 00028: val_accuracy did not improve from 0.86486\n","Epoch 29/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3129 - accuracy: 0.8958 - val_loss: 0.4418 - val_accuracy: 0.8378\n","\n","Epoch 00029: val_accuracy did not improve from 0.86486\n","Epoch 30/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.3089 - accuracy: 0.9032 - val_loss: 0.4297 - val_accuracy: 0.8716\n","\n","Epoch 00030: val_accuracy improved from 0.86486 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 31/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.3029 - accuracy: 0.8942 - val_loss: 0.8927 - val_accuracy: 0.8108\n","\n","Epoch 00031: val_accuracy did not improve from 0.87162\n","Epoch 32/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2783 - accuracy: 0.9089 - val_loss: 0.3940 - val_accuracy: 0.8649\n","\n","Epoch 00032: val_accuracy did not improve from 0.87162\n","Epoch 33/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.2627 - accuracy: 0.9105 - val_loss: 0.6290 - val_accuracy: 0.7905\n","\n","Epoch 00033: val_accuracy did not improve from 0.87162\n","Epoch 34/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2189 - accuracy: 0.9232 - val_loss: 0.5790 - val_accuracy: 0.8176\n","\n","Epoch 00034: val_accuracy did not improve from 0.87162\n","Epoch 35/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2437 - accuracy: 0.9147 - val_loss: 0.4908 - val_accuracy: 0.8649\n","\n","Epoch 00035: val_accuracy did not improve from 0.87162\n","Epoch 36/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.2389 - accuracy: 0.9163 - val_loss: 0.4912 - val_accuracy: 0.8514\n","\n","Epoch 00036: val_accuracy did not improve from 0.87162\n","Epoch 37/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2532 - accuracy: 0.9163 - val_loss: 0.4917 - val_accuracy: 0.8243\n","\n","Epoch 00037: val_accuracy did not improve from 0.87162\n","Epoch 38/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1787 - accuracy: 0.9405 - val_loss: 0.2577 - val_accuracy: 0.9189\n","\n","Epoch 00038: val_accuracy improved from 0.87162 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 39/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.2228 - accuracy: 0.9268 - val_loss: 0.4358 - val_accuracy: 0.8446\n","\n","Epoch 00039: val_accuracy did not improve from 0.91892\n","Epoch 40/500\n","238/238 [==============================] - 66s 275ms/step - loss: 0.2142 - accuracy: 0.9195 - val_loss: 0.8649 - val_accuracy: 0.7703\n","\n","Epoch 00040: val_accuracy did not improve from 0.91892\n","Epoch 41/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.2457 - accuracy: 0.9195 - val_loss: 0.5259 - val_accuracy: 0.8378\n","\n","Epoch 00041: val_accuracy did not improve from 0.91892\n","Epoch 42/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1792 - accuracy: 0.9395 - val_loss: 0.4251 - val_accuracy: 0.8919\n","\n","Epoch 00042: val_accuracy did not improve from 0.91892\n","Epoch 43/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1784 - accuracy: 0.9395 - val_loss: 0.4809 - val_accuracy: 0.8716\n","\n","Epoch 00043: val_accuracy did not improve from 0.91892\n","Epoch 44/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1602 - accuracy: 0.9453 - val_loss: 0.5841 - val_accuracy: 0.8378\n","\n","Epoch 00044: val_accuracy did not improve from 0.91892\n","Epoch 45/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1446 - accuracy: 0.9516 - val_loss: 0.8658 - val_accuracy: 0.8176\n","\n","Epoch 00045: val_accuracy did not improve from 0.91892\n","Epoch 46/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1841 - accuracy: 0.9368 - val_loss: 0.4959 - val_accuracy: 0.8311\n","\n","Epoch 00046: val_accuracy did not improve from 0.91892\n","Epoch 47/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1668 - accuracy: 0.9400 - val_loss: 0.3940 - val_accuracy: 0.8581\n","\n","Epoch 00047: val_accuracy did not improve from 0.91892\n","Epoch 48/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.2086 - accuracy: 0.9284 - val_loss: 0.6253 - val_accuracy: 0.8311\n","\n","Epoch 00048: val_accuracy did not improve from 0.91892\n","Epoch 49/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1468 - accuracy: 0.9521 - val_loss: 0.8262 - val_accuracy: 0.8108\n","\n","Epoch 00049: val_accuracy did not improve from 0.91892\n","Epoch 50/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1671 - accuracy: 0.9389 - val_loss: 0.6188 - val_accuracy: 0.8311\n","\n","Epoch 00050: val_accuracy did not improve from 0.91892\n","Epoch 51/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1443 - accuracy: 0.9489 - val_loss: 0.2992 - val_accuracy: 0.8919\n","\n","Epoch 00051: val_accuracy did not improve from 0.91892\n","Epoch 52/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1082 - accuracy: 0.9605 - val_loss: 0.5996 - val_accuracy: 0.8716\n","\n","Epoch 00052: val_accuracy did not improve from 0.91892\n","Epoch 53/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1186 - accuracy: 0.9621 - val_loss: 0.3328 - val_accuracy: 0.8986\n","\n","Epoch 00053: val_accuracy did not improve from 0.91892\n","Epoch 54/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1099 - accuracy: 0.9679 - val_loss: 0.7106 - val_accuracy: 0.8041\n","\n","Epoch 00054: val_accuracy did not improve from 0.91892\n","Epoch 55/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1413 - accuracy: 0.9463 - val_loss: 0.6543 - val_accuracy: 0.8311\n","\n","Epoch 00055: val_accuracy did not improve from 0.91892\n","Epoch 56/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1371 - accuracy: 0.9532 - val_loss: 1.7283 - val_accuracy: 0.6689\n","\n","Epoch 00056: val_accuracy did not improve from 0.91892\n","Epoch 57/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1103 - accuracy: 0.9605 - val_loss: 0.4090 - val_accuracy: 0.8514\n","\n","Epoch 00057: val_accuracy did not improve from 0.91892\n","Epoch 58/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0977 - accuracy: 0.9689 - val_loss: 0.6170 - val_accuracy: 0.8784\n","\n","Epoch 00058: val_accuracy did not improve from 0.91892\n","Epoch 59/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0957 - accuracy: 0.9684 - val_loss: 0.4971 - val_accuracy: 0.8649\n","\n","Epoch 00059: val_accuracy did not improve from 0.91892\n","Epoch 60/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1220 - accuracy: 0.9616 - val_loss: 0.7090 - val_accuracy: 0.8784\n","\n","Epoch 00060: val_accuracy did not improve from 0.91892\n","Epoch 61/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1241 - accuracy: 0.9584 - val_loss: 0.4724 - val_accuracy: 0.8716\n","\n","Epoch 00061: val_accuracy did not improve from 0.91892\n","Epoch 62/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.9546 - val_accuracy: 0.8243\n","\n","Epoch 00062: val_accuracy did not improve from 0.91892\n","Epoch 63/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0897 - accuracy: 0.9721 - val_loss: 0.3440 - val_accuracy: 0.9122\n","\n","Epoch 00063: val_accuracy did not improve from 0.91892\n","Epoch 64/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0664 - accuracy: 0.9800 - val_loss: 0.3717 - val_accuracy: 0.8919\n","\n","Epoch 00064: val_accuracy did not improve from 0.91892\n","Epoch 65/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0782 - accuracy: 0.9716 - val_loss: 0.6484 - val_accuracy: 0.8311\n","\n","Epoch 00065: val_accuracy did not improve from 0.91892\n","Epoch 66/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1223 - accuracy: 0.9542 - val_loss: 0.4992 - val_accuracy: 0.8581\n","\n","Epoch 00066: val_accuracy did not improve from 0.91892\n","Epoch 67/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1511 - accuracy: 0.9526 - val_loss: 1.3798 - val_accuracy: 0.8243\n","\n","Epoch 00067: val_accuracy did not improve from 0.91892\n","Epoch 68/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1000 - accuracy: 0.9642 - val_loss: 0.3124 - val_accuracy: 0.9189\n","\n","Epoch 00068: val_accuracy did not improve from 0.91892\n","Epoch 69/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0617 - accuracy: 0.9805 - val_loss: 0.3934 - val_accuracy: 0.8919\n","\n","Epoch 00069: val_accuracy did not improve from 0.91892\n","Epoch 70/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0907 - accuracy: 0.9695 - val_loss: 0.5006 - val_accuracy: 0.8986\n","\n","Epoch 00070: val_accuracy did not improve from 0.91892\n","Epoch 71/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 0.5796 - val_accuracy: 0.8784\n","\n","Epoch 00071: val_accuracy did not improve from 0.91892\n","Epoch 72/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 0.5160 - val_accuracy: 0.8716\n","\n","Epoch 00072: val_accuracy did not improve from 0.91892\n","Epoch 73/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0581 - accuracy: 0.9784 - val_loss: 0.5143 - val_accuracy: 0.8716\n","\n","Epoch 00073: val_accuracy did not improve from 0.91892\n","Epoch 74/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.1394 - accuracy: 0.9505 - val_loss: 1.1073 - val_accuracy: 0.8243\n","\n","Epoch 00074: val_accuracy did not improve from 0.91892\n","Epoch 75/500\n","238/238 [==============================] - 66s 275ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.3112 - val_accuracy: 0.9054\n","\n","Epoch 00075: val_accuracy did not improve from 0.91892\n","Epoch 76/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0594 - accuracy: 0.9821 - val_loss: 0.4865 - val_accuracy: 0.8784\n","\n","Epoch 00076: val_accuracy did not improve from 0.91892\n","Epoch 77/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0555 - accuracy: 0.9800 - val_loss: 0.5774 - val_accuracy: 0.8649\n","\n","Epoch 00077: val_accuracy did not improve from 0.91892\n","Epoch 78/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.4632 - val_accuracy: 0.9054\n","\n","Epoch 00078: val_accuracy did not improve from 0.91892\n","Epoch 79/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0450 - accuracy: 0.9879 - val_loss: 0.4432 - val_accuracy: 0.8986\n","\n","Epoch 00079: val_accuracy did not improve from 0.91892\n","Epoch 80/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0617 - accuracy: 0.9800 - val_loss: 0.6145 - val_accuracy: 0.8311\n","\n","Epoch 00080: val_accuracy did not improve from 0.91892\n","Epoch 81/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0890 - accuracy: 0.9679 - val_loss: 0.4696 - val_accuracy: 0.8649\n","\n","Epoch 00081: val_accuracy did not improve from 0.91892\n","Epoch 82/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0579 - accuracy: 0.9847 - val_loss: 1.5099 - val_accuracy: 0.7635\n","\n","Epoch 00082: val_accuracy did not improve from 0.91892\n","Epoch 83/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0752 - accuracy: 0.9721 - val_loss: 0.6543 - val_accuracy: 0.8243\n","\n","Epoch 00083: val_accuracy did not improve from 0.91892\n","Epoch 84/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0645 - accuracy: 0.9774 - val_loss: 0.6648 - val_accuracy: 0.8716\n","\n","Epoch 00084: val_accuracy did not improve from 0.91892\n","Epoch 85/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0864 - accuracy: 0.9753 - val_loss: 0.3637 - val_accuracy: 0.8986\n","\n","Epoch 00085: val_accuracy did not improve from 0.91892\n","Epoch 86/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.3099 - val_accuracy: 0.9257\n","\n","Epoch 00086: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 87/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0444 - accuracy: 0.9879 - val_loss: 0.5331 - val_accuracy: 0.9054\n","\n","Epoch 00087: val_accuracy did not improve from 0.92568\n","Epoch 88/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0632 - accuracy: 0.9795 - val_loss: 0.6389 - val_accuracy: 0.8581\n","\n","Epoch 00088: val_accuracy did not improve from 0.92568\n","Epoch 89/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0634 - accuracy: 0.9768 - val_loss: 0.5961 - val_accuracy: 0.8851\n","\n","Epoch 00089: val_accuracy did not improve from 0.92568\n","Epoch 90/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.5164 - val_accuracy: 0.8581\n","\n","Epoch 00090: val_accuracy did not improve from 0.92568\n","Epoch 91/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.4974 - val_accuracy: 0.8581\n","\n","Epoch 00091: val_accuracy did not improve from 0.92568\n","Epoch 92/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0877 - accuracy: 0.9726 - val_loss: 0.5992 - val_accuracy: 0.8649\n","\n","Epoch 00092: val_accuracy did not improve from 0.92568\n","Epoch 93/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 0.4465 - val_accuracy: 0.8784\n","\n","Epoch 00093: val_accuracy did not improve from 0.92568\n","Epoch 94/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0454 - accuracy: 0.9826 - val_loss: 0.5015 - val_accuracy: 0.8919\n","\n","Epoch 00094: val_accuracy did not improve from 0.92568\n","Epoch 95/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0550 - accuracy: 0.9795 - val_loss: 0.5393 - val_accuracy: 0.8919\n","\n","Epoch 00095: val_accuracy did not improve from 0.92568\n","Epoch 96/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.3327 - val_accuracy: 0.9122\n","\n","Epoch 00096: val_accuracy did not improve from 0.92568\n","Epoch 97/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0536 - accuracy: 0.9800 - val_loss: 0.4868 - val_accuracy: 0.9054\n","\n","Epoch 00097: val_accuracy did not improve from 0.92568\n","Epoch 98/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.3282 - val_accuracy: 0.9257\n","\n","Epoch 00098: val_accuracy did not improve from 0.92568\n","Epoch 99/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.3296 - val_accuracy: 0.9054\n","\n","Epoch 00099: val_accuracy did not improve from 0.92568\n","Epoch 100/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0677 - accuracy: 0.9795 - val_loss: 0.7885 - val_accuracy: 0.8784\n","\n","Epoch 00100: val_accuracy did not improve from 0.92568\n","Epoch 101/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.1515 - accuracy: 0.9574 - val_loss: 0.4775 - val_accuracy: 0.8716\n","\n","Epoch 00101: val_accuracy did not improve from 0.92568\n","Epoch 102/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.4458 - val_accuracy: 0.8649\n","\n","Epoch 00102: val_accuracy did not improve from 0.92568\n","Epoch 103/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.5633 - val_accuracy: 0.8919\n","\n","Epoch 00103: val_accuracy did not improve from 0.92568\n","Epoch 104/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.3874 - val_accuracy: 0.8986\n","\n","Epoch 00104: val_accuracy did not improve from 0.92568\n","Epoch 105/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.5605 - val_accuracy: 0.8649\n","\n","Epoch 00105: val_accuracy did not improve from 0.92568\n","Epoch 106/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.4633 - val_accuracy: 0.8986\n","\n","Epoch 00106: val_accuracy did not improve from 0.92568\n","Epoch 107/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0342 - accuracy: 0.9863 - val_loss: 0.3521 - val_accuracy: 0.8986\n","\n","Epoch 00107: val_accuracy did not improve from 0.92568\n","Epoch 108/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0703 - accuracy: 0.9763 - val_loss: 0.7882 - val_accuracy: 0.8514\n","\n","Epoch 00108: val_accuracy did not improve from 0.92568\n","Epoch 109/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0367 - accuracy: 0.9911 - val_loss: 0.4100 - val_accuracy: 0.8716\n","\n","Epoch 00109: val_accuracy did not improve from 0.92568\n","Epoch 110/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.6559 - val_accuracy: 0.8919\n","\n","Epoch 00110: val_accuracy did not improve from 0.92568\n","Epoch 111/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0557 - accuracy: 0.9832 - val_loss: 0.3112 - val_accuracy: 0.9122\n","\n","Epoch 00111: val_accuracy did not improve from 0.92568\n","Epoch 112/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.2603 - val_accuracy: 0.9189\n","\n","Epoch 00112: val_accuracy did not improve from 0.92568\n","Epoch 113/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.5788 - val_accuracy: 0.8716\n","\n","Epoch 00113: val_accuracy did not improve from 0.92568\n","Epoch 114/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.5978 - val_accuracy: 0.8851\n","\n","Epoch 00114: val_accuracy did not improve from 0.92568\n","Epoch 115/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0976 - accuracy: 0.9674 - val_loss: 0.6016 - val_accuracy: 0.8716\n","\n","Epoch 00115: val_accuracy did not improve from 0.92568\n","Epoch 116/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0421 - accuracy: 0.9847 - val_loss: 0.4818 - val_accuracy: 0.8919\n","\n","Epoch 00116: val_accuracy did not improve from 0.92568\n","Epoch 117/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.4148 - val_accuracy: 0.8919\n","\n","Epoch 00117: val_accuracy did not improve from 0.92568\n","Epoch 118/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.3152 - val_accuracy: 0.9122\n","\n","Epoch 00118: val_accuracy did not improve from 0.92568\n","Epoch 119/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.7836 - val_accuracy: 0.8649\n","\n","Epoch 00119: val_accuracy did not improve from 0.92568\n","Epoch 120/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.6546 - val_accuracy: 0.8986\n","\n","Epoch 00120: val_accuracy did not improve from 0.92568\n","Epoch 121/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.4921 - val_accuracy: 0.8919\n","\n","Epoch 00121: val_accuracy did not improve from 0.92568\n","Epoch 122/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.4165 - val_accuracy: 0.8919\n","\n","Epoch 00122: val_accuracy did not improve from 0.92568\n","Epoch 123/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.5525 - val_accuracy: 0.8851\n","\n","Epoch 00123: val_accuracy did not improve from 0.92568\n","Epoch 124/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0433 - accuracy: 0.9842 - val_loss: 0.4954 - val_accuracy: 0.8986\n","\n","Epoch 00124: val_accuracy did not improve from 0.92568\n","Epoch 125/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0304 - accuracy: 0.9879 - val_loss: 0.5281 - val_accuracy: 0.8919\n","\n","Epoch 00125: val_accuracy did not improve from 0.92568\n","Epoch 126/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 0.9204 - val_accuracy: 0.8176\n","\n","Epoch 00126: val_accuracy did not improve from 0.92568\n","Epoch 127/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.7257 - val_accuracy: 0.8716\n","\n","Epoch 00127: val_accuracy did not improve from 0.92568\n","Epoch 128/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0371 - accuracy: 0.9868 - val_loss: 0.7201 - val_accuracy: 0.8784\n","\n","Epoch 00128: val_accuracy did not improve from 0.92568\n","Epoch 129/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.4880 - val_accuracy: 0.8716\n","\n","Epoch 00129: val_accuracy did not improve from 0.92568\n","Epoch 130/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0554 - accuracy: 0.9847 - val_loss: 0.5393 - val_accuracy: 0.8784\n","\n","Epoch 00130: val_accuracy did not improve from 0.92568\n","Epoch 131/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.4461 - val_accuracy: 0.9257\n","\n","Epoch 00131: val_accuracy did not improve from 0.92568\n","Epoch 132/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.3101 - val_accuracy: 0.9257\n","\n","Epoch 00132: val_accuracy did not improve from 0.92568\n","Epoch 133/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.3731 - val_accuracy: 0.8919\n","\n","Epoch 00133: val_accuracy did not improve from 0.92568\n","Epoch 134/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.4256 - val_accuracy: 0.8986\n","\n","Epoch 00134: val_accuracy did not improve from 0.92568\n","Epoch 135/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.5129 - val_accuracy: 0.8716\n","\n","Epoch 00135: val_accuracy did not improve from 0.92568\n","Epoch 136/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0711 - accuracy: 0.9800 - val_loss: 0.8580 - val_accuracy: 0.8311\n","\n","Epoch 00136: val_accuracy did not improve from 0.92568\n","Epoch 137/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0378 - accuracy: 0.9853 - val_loss: 0.6597 - val_accuracy: 0.8649\n","\n","Epoch 00137: val_accuracy did not improve from 0.92568\n","Epoch 138/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.4119 - val_accuracy: 0.9257\n","\n","Epoch 00138: val_accuracy did not improve from 0.92568\n","Epoch 139/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.4548 - val_accuracy: 0.8919\n","\n","Epoch 00139: val_accuracy did not improve from 0.92568\n","Epoch 140/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.5842 - val_accuracy: 0.8986\n","\n","Epoch 00140: val_accuracy did not improve from 0.92568\n","Epoch 141/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.4576 - val_accuracy: 0.8986\n","\n","Epoch 00141: val_accuracy did not improve from 0.92568\n","Epoch 142/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0266 - accuracy: 0.9942 - val_loss: 0.3923 - val_accuracy: 0.8986\n","\n","Epoch 00142: val_accuracy did not improve from 0.92568\n","Epoch 143/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.4970 - val_accuracy: 0.8851\n","\n","Epoch 00143: val_accuracy did not improve from 0.92568\n","Epoch 144/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0571 - accuracy: 0.9868 - val_loss: 0.5920 - val_accuracy: 0.8514\n","\n","Epoch 00144: val_accuracy did not improve from 0.92568\n","Epoch 145/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0452 - accuracy: 0.9874 - val_loss: 0.6037 - val_accuracy: 0.8919\n","\n","Epoch 00145: val_accuracy did not improve from 0.92568\n","Epoch 146/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0361 - accuracy: 0.9868 - val_loss: 0.5801 - val_accuracy: 0.8784\n","\n","Epoch 00146: val_accuracy did not improve from 0.92568\n","Epoch 147/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0234 - accuracy: 0.9900 - val_loss: 0.3549 - val_accuracy: 0.8919\n","\n","Epoch 00147: val_accuracy did not improve from 0.92568\n","Epoch 148/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.4785 - val_accuracy: 0.8716\n","\n","Epoch 00148: val_accuracy did not improve from 0.92568\n","Epoch 149/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.4284 - val_accuracy: 0.8919\n","\n","Epoch 00149: val_accuracy did not improve from 0.92568\n","Epoch 150/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.3214 - val_accuracy: 0.9189\n","\n","Epoch 00150: val_accuracy did not improve from 0.92568\n","Epoch 151/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.5514 - val_accuracy: 0.8716\n","\n","Epoch 00151: val_accuracy did not improve from 0.92568\n","Epoch 152/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0207 - accuracy: 0.9916 - val_loss: 0.3339 - val_accuracy: 0.9189\n","\n","Epoch 00152: val_accuracy did not improve from 0.92568\n","Epoch 153/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.7547 - val_accuracy: 0.8243\n","\n","Epoch 00153: val_accuracy did not improve from 0.92568\n","Epoch 154/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.4904 - val_accuracy: 0.8581\n","\n","Epoch 00154: val_accuracy did not improve from 0.92568\n","Epoch 155/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.4722 - val_accuracy: 0.9189\n","\n","Epoch 00155: val_accuracy did not improve from 0.92568\n","Epoch 156/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.6858 - val_accuracy: 0.8716\n","\n","Epoch 00156: val_accuracy did not improve from 0.92568\n","Epoch 157/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.3879 - val_accuracy: 0.8919\n","\n","Epoch 00157: val_accuracy did not improve from 0.92568\n","Epoch 158/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9054\n","\n","Epoch 00158: val_accuracy did not improve from 0.92568\n","Epoch 159/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0484 - accuracy: 0.9837 - val_loss: 0.5365 - val_accuracy: 0.8649\n","\n","Epoch 00159: val_accuracy did not improve from 0.92568\n","Epoch 160/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.4628 - val_accuracy: 0.9054\n","\n","Epoch 00160: val_accuracy did not improve from 0.92568\n","Epoch 161/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.3562 - val_accuracy: 0.9257\n","\n","Epoch 00161: val_accuracy did not improve from 0.92568\n","Epoch 162/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.6640 - val_accuracy: 0.8716\n","\n","Epoch 00162: val_accuracy did not improve from 0.92568\n","Epoch 163/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0391 - accuracy: 0.9879 - val_loss: 0.4964 - val_accuracy: 0.8784\n","\n","Epoch 00163: val_accuracy did not improve from 0.92568\n","Epoch 164/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.4005 - val_accuracy: 0.8986\n","\n","Epoch 00164: val_accuracy did not improve from 0.92568\n","Epoch 165/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.4565 - val_accuracy: 0.9054\n","\n","Epoch 00165: val_accuracy did not improve from 0.92568\n","Epoch 166/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5399 - val_accuracy: 0.8649\n","\n","Epoch 00166: val_accuracy did not improve from 0.92568\n","Epoch 167/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.5007 - val_accuracy: 0.8919\n","\n","Epoch 00167: val_accuracy did not improve from 0.92568\n","Epoch 168/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0272 - accuracy: 0.9879 - val_loss: 0.5414 - val_accuracy: 0.8784\n","\n","Epoch 00168: val_accuracy did not improve from 0.92568\n","Epoch 169/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.4135 - val_accuracy: 0.9054\n","\n","Epoch 00169: val_accuracy did not improve from 0.92568\n","Epoch 170/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.4764 - val_accuracy: 0.9054\n","\n","Epoch 00170: val_accuracy did not improve from 0.92568\n","Epoch 171/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.5009 - val_accuracy: 0.8784\n","\n","Epoch 00171: val_accuracy did not improve from 0.92568\n","Epoch 172/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.5338 - val_accuracy: 0.8851\n","\n","Epoch 00172: val_accuracy did not improve from 0.92568\n","Epoch 173/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.7852 - val_accuracy: 0.8243\n","\n","Epoch 00173: val_accuracy did not improve from 0.92568\n","Epoch 174/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.4142 - val_accuracy: 0.8919\n","\n","Epoch 00174: val_accuracy did not improve from 0.92568\n","Epoch 175/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.3436 - val_accuracy: 0.9189\n","\n","Epoch 00175: val_accuracy did not improve from 0.92568\n","Epoch 176/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.5072 - val_accuracy: 0.8784\n","\n","Epoch 00176: val_accuracy did not improve from 0.92568\n","Epoch 177/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 1.4401 - val_accuracy: 0.7973\n","\n","Epoch 00177: val_accuracy did not improve from 0.92568\n","Epoch 178/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.6746 - val_accuracy: 0.8986\n","\n","Epoch 00178: val_accuracy did not improve from 0.92568\n","Epoch 179/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.6545 - val_accuracy: 0.8919\n","\n","Epoch 00179: val_accuracy did not improve from 0.92568\n","Epoch 180/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.4393 - val_accuracy: 0.8919\n","\n","Epoch 00180: val_accuracy did not improve from 0.92568\n","Epoch 181/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.7809 - val_accuracy: 0.8581\n","\n","Epoch 00181: val_accuracy did not improve from 0.92568\n","Epoch 182/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.5102 - val_accuracy: 0.9189\n","\n","Epoch 00182: val_accuracy did not improve from 0.92568\n","Epoch 183/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.5281 - val_accuracy: 0.8919\n","\n","Epoch 00183: val_accuracy did not improve from 0.92568\n","Epoch 184/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.3402 - val_accuracy: 0.9392\n","\n","Epoch 00184: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 185/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.4798 - val_accuracy: 0.8851\n","\n","Epoch 00185: val_accuracy did not improve from 0.93919\n","Epoch 186/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.4804 - val_accuracy: 0.8716\n","\n","Epoch 00186: val_accuracy did not improve from 0.93919\n","Epoch 187/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.6044 - val_accuracy: 0.8581\n","\n","Epoch 00187: val_accuracy did not improve from 0.93919\n","Epoch 188/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.3774 - val_accuracy: 0.9324\n","\n","Epoch 00188: val_accuracy did not improve from 0.93919\n","Epoch 189/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5197 - val_accuracy: 0.8851\n","\n","Epoch 00189: val_accuracy did not improve from 0.93919\n","Epoch 190/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.4026 - val_accuracy: 0.9189\n","\n","Epoch 00190: val_accuracy did not improve from 0.93919\n","Epoch 191/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.5856 - val_accuracy: 0.8514\n","\n","Epoch 00191: val_accuracy did not improve from 0.93919\n","Epoch 192/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.4990 - val_accuracy: 0.9054\n","\n","Epoch 00192: val_accuracy did not improve from 0.93919\n","Epoch 193/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.6973 - val_accuracy: 0.8581\n","\n","Epoch 00193: val_accuracy did not improve from 0.93919\n","Epoch 194/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.4267 - val_accuracy: 0.9122\n","\n","Epoch 00194: val_accuracy did not improve from 0.93919\n","Epoch 195/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.4763 - val_accuracy: 0.8986\n","\n","Epoch 00195: val_accuracy did not improve from 0.93919\n","Epoch 196/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.4272 - val_accuracy: 0.9122\n","\n","Epoch 00196: val_accuracy did not improve from 0.93919\n","Epoch 197/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.4085 - val_accuracy: 0.9257\n","\n","Epoch 00197: val_accuracy did not improve from 0.93919\n","Epoch 198/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4372 - val_accuracy: 0.8986\n","\n","Epoch 00198: val_accuracy did not improve from 0.93919\n","Epoch 199/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.3744 - val_accuracy: 0.9257\n","\n","Epoch 00199: val_accuracy did not improve from 0.93919\n","Epoch 200/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.6068 - val_accuracy: 0.8716\n","\n","Epoch 00200: val_accuracy did not improve from 0.93919\n","Epoch 201/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.4190 - val_accuracy: 0.8986\n","\n","Epoch 00201: val_accuracy did not improve from 0.93919\n","Epoch 202/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.5567 - val_accuracy: 0.8784\n","\n","Epoch 00202: val_accuracy did not improve from 0.93919\n","Epoch 203/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0143 - accuracy: 0.9937 - val_loss: 0.3036 - val_accuracy: 0.9324\n","\n","Epoch 00203: val_accuracy did not improve from 0.93919\n","Epoch 204/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 0.4122 - val_accuracy: 0.8919\n","\n","Epoch 00204: val_accuracy did not improve from 0.93919\n","Epoch 205/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.5720 - val_accuracy: 0.8649\n","\n","Epoch 00205: val_accuracy did not improve from 0.93919\n","Epoch 206/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.3820 - val_accuracy: 0.8784\n","\n","Epoch 00206: val_accuracy did not improve from 0.93919\n","Epoch 207/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.4558 - val_accuracy: 0.9054\n","\n","Epoch 00207: val_accuracy did not improve from 0.93919\n","Epoch 208/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.4642 - val_accuracy: 0.9054\n","\n","Epoch 00208: val_accuracy did not improve from 0.93919\n","Epoch 209/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.7209 - val_accuracy: 0.8716\n","\n","Epoch 00209: val_accuracy did not improve from 0.93919\n","Epoch 210/500\n","238/238 [==============================] - 67s 282ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.4738 - val_accuracy: 0.9122\n","\n","Epoch 00210: val_accuracy did not improve from 0.93919\n","Epoch 211/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.5751 - val_accuracy: 0.8851\n","\n","Epoch 00211: val_accuracy did not improve from 0.93919\n","Epoch 212/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.9269 - val_accuracy: 0.8514\n","\n","Epoch 00212: val_accuracy did not improve from 0.93919\n","Epoch 213/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.5069 - val_accuracy: 0.8851\n","\n","Epoch 00213: val_accuracy did not improve from 0.93919\n","Epoch 214/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.5184 - val_accuracy: 0.8919\n","\n","Epoch 00214: val_accuracy did not improve from 0.93919\n","Epoch 215/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.5130 - val_accuracy: 0.8851\n","\n","Epoch 00215: val_accuracy did not improve from 0.93919\n","Epoch 216/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.6135 - val_accuracy: 0.8851\n","\n","Epoch 00216: val_accuracy did not improve from 0.93919\n","Epoch 217/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.6092 - val_accuracy: 0.8986\n","\n","Epoch 00217: val_accuracy did not improve from 0.93919\n","Epoch 218/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.6622 - val_accuracy: 0.8716\n","\n","Epoch 00218: val_accuracy did not improve from 0.93919\n","Epoch 219/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.5072 - val_accuracy: 0.9189\n","\n","Epoch 00219: val_accuracy did not improve from 0.93919\n","Epoch 220/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.4199 - val_accuracy: 0.9054\n","\n","Epoch 00220: val_accuracy did not improve from 0.93919\n","Epoch 221/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.4329 - val_accuracy: 0.9122\n","\n","Epoch 00221: val_accuracy did not improve from 0.93919\n","Epoch 222/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5198 - val_accuracy: 0.8919\n","\n","Epoch 00222: val_accuracy did not improve from 0.93919\n","Epoch 223/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5241 - val_accuracy: 0.8919\n","\n","Epoch 00223: val_accuracy did not improve from 0.93919\n","Epoch 224/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.4266 - val_accuracy: 0.9257\n","\n","Epoch 00224: val_accuracy did not improve from 0.93919\n","Epoch 225/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.6208 - val_accuracy: 0.8986\n","\n","Epoch 00225: val_accuracy did not improve from 0.93919\n","Epoch 226/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.5453 - val_accuracy: 0.8851\n","\n","Epoch 00226: val_accuracy did not improve from 0.93919\n","Epoch 227/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.3954 - val_accuracy: 0.9122\n","\n","Epoch 00227: val_accuracy did not improve from 0.93919\n","Epoch 228/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.9291 - val_accuracy: 0.8716\n","\n","Epoch 00228: val_accuracy did not improve from 0.93919\n","Epoch 229/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.5302 - val_accuracy: 0.8716\n","\n","Epoch 00229: val_accuracy did not improve from 0.93919\n","Epoch 230/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 0.6770 - val_accuracy: 0.8446\n","\n","Epoch 00230: val_accuracy did not improve from 0.93919\n","Epoch 231/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.9172 - val_accuracy: 0.8243\n","\n","Epoch 00231: val_accuracy did not improve from 0.93919\n","Epoch 232/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0253 - accuracy: 0.9953 - val_loss: 0.6816 - val_accuracy: 0.8581\n","\n","Epoch 00232: val_accuracy did not improve from 0.93919\n","Epoch 233/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.6608 - val_accuracy: 0.8919\n","\n","Epoch 00233: val_accuracy did not improve from 0.93919\n","Epoch 234/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.5967 - val_accuracy: 0.8919\n","\n","Epoch 00234: val_accuracy did not improve from 0.93919\n","Epoch 235/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4714 - val_accuracy: 0.8986\n","\n","Epoch 00235: val_accuracy did not improve from 0.93919\n","Epoch 236/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 0.4971 - val_accuracy: 0.9122\n","\n","Epoch 00236: val_accuracy did not improve from 0.93919\n","Epoch 237/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.5466 - val_accuracy: 0.8851\n","\n","Epoch 00237: val_accuracy did not improve from 0.93919\n","Epoch 238/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 0.6213 - val_accuracy: 0.8986\n","\n","Epoch 00238: val_accuracy did not improve from 0.93919\n","Epoch 239/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.7729 - val_accuracy: 0.8784\n","\n","Epoch 00239: val_accuracy did not improve from 0.93919\n","Epoch 240/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.7302 - val_accuracy: 0.8851\n","\n","Epoch 00240: val_accuracy did not improve from 0.93919\n","Epoch 241/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6087 - val_accuracy: 0.8716\n","\n","Epoch 00241: val_accuracy did not improve from 0.93919\n","Epoch 242/500\n","238/238 [==============================] - 67s 282ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5485 - val_accuracy: 0.8851\n","\n","Epoch 00242: val_accuracy did not improve from 0.93919\n","Epoch 243/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5746 - val_accuracy: 0.8986\n","\n","Epoch 00243: val_accuracy did not improve from 0.93919\n","Epoch 244/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6342 - val_accuracy: 0.8919\n","\n","Epoch 00244: val_accuracy did not improve from 0.93919\n","Epoch 245/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.6163 - val_accuracy: 0.9122\n","\n","Epoch 00245: val_accuracy did not improve from 0.93919\n","Epoch 246/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.0121 - val_accuracy: 0.8243\n","\n","Epoch 00246: val_accuracy did not improve from 0.93919\n","Epoch 247/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.8321 - val_accuracy: 0.8649\n","\n","Epoch 00247: val_accuracy did not improve from 0.93919\n","Epoch 248/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.5249 - val_accuracy: 0.9054\n","\n","Epoch 00248: val_accuracy did not improve from 0.93919\n","Epoch 249/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.7667 - val_accuracy: 0.8919\n","\n","Epoch 00249: val_accuracy did not improve from 0.93919\n","Epoch 250/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.4740 - val_accuracy: 0.9122\n","\n","Epoch 00250: val_accuracy did not improve from 0.93919\n","Epoch 251/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.7507 - val_accuracy: 0.9122\n","\n","Epoch 00251: val_accuracy did not improve from 0.93919\n","Epoch 252/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8851\n","\n","Epoch 00252: val_accuracy did not improve from 0.93919\n","Epoch 253/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.5693 - val_accuracy: 0.9122\n","\n","Epoch 00253: val_accuracy did not improve from 0.93919\n","Epoch 254/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.5620 - val_accuracy: 0.8919\n","\n","Epoch 00254: val_accuracy did not improve from 0.93919\n","Epoch 255/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0192 - accuracy: 0.9911 - val_loss: 0.7482 - val_accuracy: 0.8784\n","\n","Epoch 00255: val_accuracy did not improve from 0.93919\n","Epoch 256/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.5443 - val_accuracy: 0.8784\n","\n","Epoch 00256: val_accuracy did not improve from 0.93919\n","Epoch 257/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.8357 - val_accuracy: 0.8716\n","\n","Epoch 00257: val_accuracy did not improve from 0.93919\n","Epoch 258/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.7220 - val_accuracy: 0.8716\n","\n","Epoch 00258: val_accuracy did not improve from 0.93919\n","Epoch 259/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.4335 - val_accuracy: 0.8851\n","\n","Epoch 00259: val_accuracy did not improve from 0.93919\n","Epoch 260/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.6383 - val_accuracy: 0.9122\n","\n","Epoch 00260: val_accuracy did not improve from 0.93919\n","Epoch 261/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.6414 - val_accuracy: 0.8851\n","\n","Epoch 00261: val_accuracy did not improve from 0.93919\n","Epoch 262/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.7424 - val_accuracy: 0.8784\n","\n","Epoch 00262: val_accuracy did not improve from 0.93919\n","Epoch 263/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.4099 - val_accuracy: 0.9122\n","\n","Epoch 00263: val_accuracy did not improve from 0.93919\n","Epoch 264/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4193 - val_accuracy: 0.9257\n","\n","Epoch 00264: val_accuracy did not improve from 0.93919\n","Epoch 265/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0379 - accuracy: 0.9905 - val_loss: 1.1215 - val_accuracy: 0.8446\n","\n","Epoch 00265: val_accuracy did not improve from 0.93919\n","Epoch 266/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.4483 - val_accuracy: 0.9122\n","\n","Epoch 00266: val_accuracy did not improve from 0.93919\n","Epoch 267/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.4668 - val_accuracy: 0.9122\n","\n","Epoch 00267: val_accuracy did not improve from 0.93919\n","Epoch 268/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5439 - val_accuracy: 0.8919\n","\n","Epoch 00268: val_accuracy did not improve from 0.93919\n","Epoch 269/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.8441 - val_accuracy: 0.8649\n","\n","Epoch 00269: val_accuracy did not improve from 0.93919\n","Epoch 270/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.4624 - val_accuracy: 0.9189\n","\n","Epoch 00270: val_accuracy did not improve from 0.93919\n","Epoch 271/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8919\n","\n","Epoch 00271: val_accuracy did not improve from 0.93919\n","Epoch 272/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.4803 - val_accuracy: 0.8986\n","\n","Epoch 00272: val_accuracy did not improve from 0.93919\n","Epoch 273/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.6567 - val_accuracy: 0.8784\n","\n","Epoch 00273: val_accuracy did not improve from 0.93919\n","Epoch 274/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.6057 - val_accuracy: 0.8716\n","\n","Epoch 00274: val_accuracy did not improve from 0.93919\n","Epoch 275/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4244 - val_accuracy: 0.9054\n","\n","Epoch 00275: val_accuracy did not improve from 0.93919\n","Epoch 276/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.6022 - val_accuracy: 0.8514\n","\n","Epoch 00276: val_accuracy did not improve from 0.93919\n","Epoch 277/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5751 - val_accuracy: 0.8851\n","\n","Epoch 00277: val_accuracy did not improve from 0.93919\n","Epoch 278/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.6536 - val_accuracy: 0.8716\n","\n","Epoch 00278: val_accuracy did not improve from 0.93919\n","Epoch 279/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.6576 - val_accuracy: 0.8446\n","\n","Epoch 00279: val_accuracy did not improve from 0.93919\n","Epoch 280/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 0.6351 - val_accuracy: 0.8986\n","\n","Epoch 00280: val_accuracy did not improve from 0.93919\n","Epoch 281/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.5123 - val_accuracy: 0.8784\n","\n","Epoch 00281: val_accuracy did not improve from 0.93919\n","Epoch 282/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6497 - val_accuracy: 0.8851\n","\n","Epoch 00282: val_accuracy did not improve from 0.93919\n","Epoch 283/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.4269 - val_accuracy: 0.9122\n","\n","Epoch 00283: val_accuracy did not improve from 0.93919\n","Epoch 284/500\n","238/238 [==============================] - 66s 279ms/step - loss: 9.7823e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9189\n","\n","Epoch 00284: val_accuracy did not improve from 0.93919\n","Epoch 285/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6133 - val_accuracy: 0.8716\n","\n","Epoch 00285: val_accuracy did not improve from 0.93919\n","Epoch 286/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.4562 - val_accuracy: 0.8919\n","\n","Epoch 00286: val_accuracy did not improve from 0.93919\n","Epoch 287/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4735 - val_accuracy: 0.8919\n","\n","Epoch 00287: val_accuracy did not improve from 0.93919\n","Epoch 288/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 1.4139 - val_accuracy: 0.7770\n","\n","Epoch 00288: val_accuracy did not improve from 0.93919\n","Epoch 289/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.5518 - val_accuracy: 0.9257\n","\n","Epoch 00289: val_accuracy did not improve from 0.93919\n","Epoch 290/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5809 - val_accuracy: 0.8649\n","\n","Epoch 00290: val_accuracy did not improve from 0.93919\n","Epoch 291/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0091 - accuracy: 0.9953 - val_loss: 0.6160 - val_accuracy: 0.8716\n","\n","Epoch 00291: val_accuracy did not improve from 0.93919\n","Epoch 292/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.3995 - val_accuracy: 0.9122\n","\n","Epoch 00292: val_accuracy did not improve from 0.93919\n","Epoch 293/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5543 - val_accuracy: 0.9122\n","\n","Epoch 00293: val_accuracy did not improve from 0.93919\n","Epoch 294/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.2623 - val_accuracy: 0.9324\n","\n","Epoch 00294: val_accuracy did not improve from 0.93919\n","Epoch 295/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.4433 - val_accuracy: 0.9257\n","\n","Epoch 00295: val_accuracy did not improve from 0.93919\n","Epoch 296/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.3975 - val_accuracy: 0.9189\n","\n","Epoch 00296: val_accuracy did not improve from 0.93919\n","Epoch 297/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8986\n","\n","Epoch 00297: val_accuracy did not improve from 0.93919\n","Epoch 298/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.3298 - val_accuracy: 0.9189\n","\n","Epoch 00298: val_accuracy did not improve from 0.93919\n","Epoch 299/500\n","238/238 [==============================] - 66s 278ms/step - loss: 5.1509e-04 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9122\n","\n","Epoch 00299: val_accuracy did not improve from 0.93919\n","Epoch 300/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.6269 - val_accuracy: 0.8919\n","\n","Epoch 00300: val_accuracy did not improve from 0.93919\n","Epoch 301/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.7221 - val_accuracy: 0.8784\n","\n","Epoch 00301: val_accuracy did not improve from 0.93919\n","Epoch 302/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.6293 - val_accuracy: 0.8716\n","\n","Epoch 00302: val_accuracy did not improve from 0.93919\n","Epoch 303/500\n","238/238 [==============================] - 67s 283ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.3937 - val_accuracy: 0.9054\n","\n","Epoch 00303: val_accuracy did not improve from 0.93919\n","Epoch 304/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.5062 - val_accuracy: 0.8986\n","\n","Epoch 00304: val_accuracy did not improve from 0.93919\n","Epoch 305/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.8459 - val_accuracy: 0.8311\n","\n","Epoch 00305: val_accuracy did not improve from 0.93919\n","Epoch 306/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0459 - accuracy: 0.9874 - val_loss: 0.7972 - val_accuracy: 0.9054\n","\n","Epoch 00306: val_accuracy did not improve from 0.93919\n","Epoch 307/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.6492 - val_accuracy: 0.8784\n","\n","Epoch 00307: val_accuracy did not improve from 0.93919\n","Epoch 308/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9054\n","\n","Epoch 00308: val_accuracy did not improve from 0.93919\n","Epoch 309/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6386 - val_accuracy: 0.8716\n","\n","Epoch 00309: val_accuracy did not improve from 0.93919\n","Epoch 310/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.3300 - val_accuracy: 0.9122\n","\n","Epoch 00310: val_accuracy did not improve from 0.93919\n","Epoch 311/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.6461 - val_accuracy: 0.8986\n","\n","Epoch 00311: val_accuracy did not improve from 0.93919\n","Epoch 312/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.6709 - val_accuracy: 0.8716\n","\n","Epoch 00312: val_accuracy did not improve from 0.93919\n","Epoch 313/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.6245 - val_accuracy: 0.8784\n","\n","Epoch 00313: val_accuracy did not improve from 0.93919\n","Epoch 314/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.7043 - val_accuracy: 0.8784\n","\n","Epoch 00314: val_accuracy did not improve from 0.93919\n","Epoch 315/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.6437 - val_accuracy: 0.8716\n","\n","Epoch 00315: val_accuracy did not improve from 0.93919\n","Epoch 316/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 0.9443 - val_accuracy: 0.8784\n","\n","Epoch 00316: val_accuracy did not improve from 0.93919\n","Epoch 317/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0372 - accuracy: 0.9895 - val_loss: 0.4562 - val_accuracy: 0.8851\n","\n","Epoch 00317: val_accuracy did not improve from 0.93919\n","Epoch 318/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5653 - val_accuracy: 0.8649\n","\n","Epoch 00318: val_accuracy did not improve from 0.93919\n","Epoch 319/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.5305 - val_accuracy: 0.9122\n","\n","Epoch 00319: val_accuracy did not improve from 0.93919\n","Epoch 320/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.3940 - val_accuracy: 0.8919\n","\n","Epoch 00320: val_accuracy did not improve from 0.93919\n","Epoch 321/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5822 - val_accuracy: 0.8851\n","\n","Epoch 00321: val_accuracy did not improve from 0.93919\n","Epoch 322/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.6571 - val_accuracy: 0.9054\n","\n","Epoch 00322: val_accuracy did not improve from 0.93919\n","Epoch 323/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6899 - val_accuracy: 0.8851\n","\n","Epoch 00323: val_accuracy did not improve from 0.93919\n","Epoch 324/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.5047 - val_accuracy: 0.9122\n","\n","Epoch 00324: val_accuracy did not improve from 0.93919\n","Epoch 325/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.2655 - val_accuracy: 0.9392\n","\n","Epoch 00325: val_accuracy did not improve from 0.93919\n","Epoch 326/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.4665 - val_accuracy: 0.9324\n","\n","Epoch 00326: val_accuracy did not improve from 0.93919\n","Epoch 327/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.4563 - val_accuracy: 0.9054\n","\n","Epoch 00327: val_accuracy did not improve from 0.93919\n","Epoch 328/500\n","238/238 [==============================] - 66s 278ms/step - loss: 5.2307e-04 - accuracy: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.9122\n","\n","Epoch 00328: val_accuracy did not improve from 0.93919\n","Epoch 329/500\n","238/238 [==============================] - 66s 279ms/step - loss: 4.7067e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9324\n","\n","Epoch 00329: val_accuracy did not improve from 0.93919\n","Epoch 330/500\n","238/238 [==============================] - 66s 277ms/step - loss: 6.7483e-04 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.9189\n","\n","Epoch 00330: val_accuracy did not improve from 0.93919\n","Epoch 331/500\n","238/238 [==============================] - 66s 276ms/step - loss: 3.8394e-04 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8986\n","\n","Epoch 00331: val_accuracy did not improve from 0.93919\n","Epoch 332/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4311 - val_accuracy: 0.9459\n","\n","Epoch 00332: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_4.h5\n","Epoch 333/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.6434 - val_accuracy: 0.8986\n","\n","Epoch 00333: val_accuracy did not improve from 0.94595\n","Epoch 334/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.8798 - val_accuracy: 0.8581\n","\n","Epoch 00334: val_accuracy did not improve from 0.94595\n","Epoch 335/500\n","238/238 [==============================] - 67s 283ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.6093 - val_accuracy: 0.8716\n","\n","Epoch 00335: val_accuracy did not improve from 0.94595\n","Epoch 336/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.5642 - val_accuracy: 0.9122\n","\n","Epoch 00336: val_accuracy did not improve from 0.94595\n","Epoch 337/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.5991 - val_accuracy: 0.9054\n","\n","Epoch 00337: val_accuracy did not improve from 0.94595\n","Epoch 338/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.6863 - val_accuracy: 0.8851\n","\n","Epoch 00338: val_accuracy did not improve from 0.94595\n","Epoch 339/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.8009 - val_accuracy: 0.8716\n","\n","Epoch 00339: val_accuracy did not improve from 0.94595\n","Epoch 340/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.6978 - val_accuracy: 0.8986\n","\n","Epoch 00340: val_accuracy did not improve from 0.94595\n","Epoch 341/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.7836 - val_accuracy: 0.8716\n","\n","Epoch 00341: val_accuracy did not improve from 0.94595\n","Epoch 342/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6306 - val_accuracy: 0.8851\n","\n","Epoch 00342: val_accuracy did not improve from 0.94595\n","Epoch 343/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.7186 - val_accuracy: 0.8919\n","\n","Epoch 00343: val_accuracy did not improve from 0.94595\n","Epoch 344/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5241 - val_accuracy: 0.9122\n","\n","Epoch 00344: val_accuracy did not improve from 0.94595\n","Epoch 345/500\n","238/238 [==============================] - 66s 279ms/step - loss: 5.1991e-04 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8716\n","\n","Epoch 00345: val_accuracy did not improve from 0.94595\n","Epoch 346/500\n","238/238 [==============================] - 66s 278ms/step - loss: 7.3843e-04 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.8851\n","\n","Epoch 00346: val_accuracy did not improve from 0.94595\n","Epoch 347/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.7032 - val_accuracy: 0.8986\n","\n","Epoch 00347: val_accuracy did not improve from 0.94595\n","Epoch 348/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 0.6836 - val_accuracy: 0.8851\n","\n","Epoch 00348: val_accuracy did not improve from 0.94595\n","Epoch 349/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.5064 - val_accuracy: 0.9122\n","\n","Epoch 00349: val_accuracy did not improve from 0.94595\n","Epoch 350/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.5023 - val_accuracy: 0.8919\n","\n","Epoch 00350: val_accuracy did not improve from 0.94595\n","Epoch 351/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5334 - val_accuracy: 0.8986\n","\n","Epoch 00351: val_accuracy did not improve from 0.94595\n","Epoch 352/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.3340 - val_accuracy: 0.9122\n","\n","Epoch 00352: val_accuracy did not improve from 0.94595\n","Epoch 353/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.2538 - val_accuracy: 0.9459\n","\n","Epoch 00353: val_accuracy did not improve from 0.94595\n","Epoch 354/500\n","238/238 [==============================] - 66s 278ms/step - loss: 8.4472e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8986\n","\n","Epoch 00354: val_accuracy did not improve from 0.94595\n","Epoch 355/500\n","238/238 [==============================] - 66s 279ms/step - loss: 2.2264e-04 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9122\n","\n","Epoch 00355: val_accuracy did not improve from 0.94595\n","Epoch 356/500\n","238/238 [==============================] - 66s 278ms/step - loss: 5.4224e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9054\n","\n","Epoch 00356: val_accuracy did not improve from 0.94595\n","Epoch 357/500\n","238/238 [==============================] - 66s 278ms/step - loss: 6.5443e-04 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.8919\n","\n","Epoch 00357: val_accuracy did not improve from 0.94595\n","Epoch 358/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0325 - accuracy: 0.9942 - val_loss: 2.3250 - val_accuracy: 0.6757\n","\n","Epoch 00358: val_accuracy did not improve from 0.94595\n","Epoch 359/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.4494 - val_accuracy: 0.9054\n","\n","Epoch 00359: val_accuracy did not improve from 0.94595\n","Epoch 360/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.3233 - val_accuracy: 0.9189\n","\n","Epoch 00360: val_accuracy did not improve from 0.94595\n","Epoch 361/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4591 - val_accuracy: 0.9257\n","\n","Epoch 00361: val_accuracy did not improve from 0.94595\n","Epoch 362/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.2027 - val_accuracy: 0.9392\n","\n","Epoch 00362: val_accuracy did not improve from 0.94595\n","Epoch 363/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.4543 - val_accuracy: 0.8784\n","\n","Epoch 00363: val_accuracy did not improve from 0.94595\n","Epoch 364/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.4410 - val_accuracy: 0.8986\n","\n","Epoch 00364: val_accuracy did not improve from 0.94595\n","Epoch 365/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3299 - val_accuracy: 0.9324\n","\n","Epoch 00365: val_accuracy did not improve from 0.94595\n","Epoch 366/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3748 - val_accuracy: 0.9257\n","\n","Epoch 00366: val_accuracy did not improve from 0.94595\n","Epoch 367/500\n","238/238 [==============================] - 66s 279ms/step - loss: 3.9994e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9054\n","\n","Epoch 00367: val_accuracy did not improve from 0.94595\n","Epoch 368/500\n","238/238 [==============================] - 66s 279ms/step - loss: 4.3694e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9189\n","\n","Epoch 00368: val_accuracy did not improve from 0.94595\n","Epoch 369/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.5432 - val_accuracy: 0.8986\n","\n","Epoch 00369: val_accuracy did not improve from 0.94595\n","Epoch 370/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8851\n","\n","Epoch 00370: val_accuracy did not improve from 0.94595\n","Epoch 371/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5115 - val_accuracy: 0.8581\n","\n","Epoch 00371: val_accuracy did not improve from 0.94595\n","Epoch 372/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.5114 - val_accuracy: 0.9257\n","\n","Epoch 00372: val_accuracy did not improve from 0.94595\n","Epoch 373/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.5898 - val_accuracy: 0.8986\n","\n","Epoch 00373: val_accuracy did not improve from 0.94595\n","Epoch 374/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.5529 - val_accuracy: 0.9054\n","\n","Epoch 00374: val_accuracy did not improve from 0.94595\n","Epoch 375/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.3446 - val_accuracy: 0.9189\n","\n","Epoch 00375: val_accuracy did not improve from 0.94595\n","Epoch 376/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4483 - val_accuracy: 0.9257\n","\n","Epoch 00376: val_accuracy did not improve from 0.94595\n","Epoch 377/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4834 - val_accuracy: 0.9054\n","\n","Epoch 00377: val_accuracy did not improve from 0.94595\n","Epoch 378/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.6155 - val_accuracy: 0.9054\n","\n","Epoch 00378: val_accuracy did not improve from 0.94595\n","Epoch 379/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 1.3273 - val_accuracy: 0.8446\n","\n","Epoch 00379: val_accuracy did not improve from 0.94595\n","Epoch 380/500\n","238/238 [==============================] - 67s 283ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.4756 - val_accuracy: 0.9054\n","\n","Epoch 00380: val_accuracy did not improve from 0.94595\n","Epoch 381/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8851\n","\n","Epoch 00381: val_accuracy did not improve from 0.94595\n","Epoch 382/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4989 - val_accuracy: 0.9054\n","\n","Epoch 00382: val_accuracy did not improve from 0.94595\n","Epoch 383/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.5836 - val_accuracy: 0.8919\n","\n","Epoch 00383: val_accuracy did not improve from 0.94595\n","Epoch 384/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4398 - val_accuracy: 0.9189\n","\n","Epoch 00384: val_accuracy did not improve from 0.94595\n","Epoch 385/500\n","238/238 [==============================] - 66s 279ms/step - loss: 2.9920e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9189\n","\n","Epoch 00385: val_accuracy did not improve from 0.94595\n","Epoch 386/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5386 - val_accuracy: 0.8851\n","\n","Epoch 00386: val_accuracy did not improve from 0.94595\n","Epoch 387/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.7719 - val_accuracy: 0.8851\n","\n","Epoch 00387: val_accuracy did not improve from 0.94595\n","Epoch 388/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6117 - val_accuracy: 0.8919\n","\n","Epoch 00388: val_accuracy did not improve from 0.94595\n","Epoch 389/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.8849 - val_accuracy: 0.8581\n","\n","Epoch 00389: val_accuracy did not improve from 0.94595\n","Epoch 390/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.6050 - val_accuracy: 0.8986\n","\n","Epoch 00390: val_accuracy did not improve from 0.94595\n","Epoch 391/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.5746 - val_accuracy: 0.8986\n","\n","Epoch 00391: val_accuracy did not improve from 0.94595\n","Epoch 392/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.6658 - val_accuracy: 0.8851\n","\n","Epoch 00392: val_accuracy did not improve from 0.94595\n","Epoch 393/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9189\n","\n","Epoch 00393: val_accuracy did not improve from 0.94595\n","Epoch 394/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.6738 - val_accuracy: 0.9054\n","\n","Epoch 00394: val_accuracy did not improve from 0.94595\n","Epoch 395/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.4715 - val_accuracy: 0.9054\n","\n","Epoch 00395: val_accuracy did not improve from 0.94595\n","Epoch 396/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6310 - val_accuracy: 0.8716\n","\n","Epoch 00396: val_accuracy did not improve from 0.94595\n","Epoch 397/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.5438 - val_accuracy: 0.9054\n","\n","Epoch 00397: val_accuracy did not improve from 0.94595\n","Epoch 398/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5002 - val_accuracy: 0.9054\n","\n","Epoch 00398: val_accuracy did not improve from 0.94595\n","Epoch 399/500\n","238/238 [==============================] - 66s 278ms/step - loss: 5.9386e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9257\n","\n","Epoch 00399: val_accuracy did not improve from 0.94595\n","Epoch 400/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.8859 - val_accuracy: 0.8649\n","\n","Epoch 00400: val_accuracy did not improve from 0.94595\n","Epoch 401/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 0.5030 - val_accuracy: 0.8784\n","\n","Epoch 00401: val_accuracy did not improve from 0.94595\n","Epoch 402/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.4941 - val_accuracy: 0.8851\n","\n","Epoch 00402: val_accuracy did not improve from 0.94595\n","Epoch 403/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.4634 - val_accuracy: 0.8851\n","\n","Epoch 00403: val_accuracy did not improve from 0.94595\n","Epoch 404/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6413 - val_accuracy: 0.8716\n","\n","Epoch 00404: val_accuracy did not improve from 0.94595\n","Epoch 405/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.4008 - val_accuracy: 0.9189\n","\n","Epoch 00405: val_accuracy did not improve from 0.94595\n","Epoch 406/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9122\n","\n","Epoch 00406: val_accuracy did not improve from 0.94595\n","Epoch 407/500\n","238/238 [==============================] - 66s 279ms/step - loss: 7.7204e-04 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8986\n","\n","Epoch 00407: val_accuracy did not improve from 0.94595\n","Epoch 408/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6002 - val_accuracy: 0.8851\n","\n","Epoch 00408: val_accuracy did not improve from 0.94595\n","Epoch 409/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.4307 - val_accuracy: 0.8986\n","\n","Epoch 00409: val_accuracy did not improve from 0.94595\n","Epoch 410/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.3997 - val_accuracy: 0.9324\n","\n","Epoch 00410: val_accuracy did not improve from 0.94595\n","Epoch 411/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0111 - accuracy: 0.9984 - val_loss: 0.6551 - val_accuracy: 0.8851\n","\n","Epoch 00411: val_accuracy did not improve from 0.94595\n","Epoch 412/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5404 - val_accuracy: 0.8986\n","\n","Epoch 00412: val_accuracy did not improve from 0.94595\n","Epoch 413/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5410 - val_accuracy: 0.8919\n","\n","Epoch 00413: val_accuracy did not improve from 0.94595\n","Epoch 414/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.6338 - val_accuracy: 0.8851\n","\n","Epoch 00414: val_accuracy did not improve from 0.94595\n","Epoch 415/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6430 - val_accuracy: 0.8919\n","\n","Epoch 00415: val_accuracy did not improve from 0.94595\n","Epoch 416/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8919\n","\n","Epoch 00416: val_accuracy did not improve from 0.94595\n","Epoch 417/500\n","238/238 [==============================] - 66s 279ms/step - loss: 6.2349e-04 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.9189\n","\n","Epoch 00417: val_accuracy did not improve from 0.94595\n","Epoch 418/500\n","238/238 [==============================] - 66s 278ms/step - loss: 4.9360e-04 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8919\n","\n","Epoch 00418: val_accuracy did not improve from 0.94595\n","Epoch 419/500\n","238/238 [==============================] - 66s 279ms/step - loss: 2.7273e-04 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9257\n","\n","Epoch 00419: val_accuracy did not improve from 0.94595\n","Epoch 420/500\n","238/238 [==============================] - 66s 279ms/step - loss: 8.7401e-05 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9257\n","\n","Epoch 00420: val_accuracy did not improve from 0.94595\n","Epoch 421/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9122\n","\n","Epoch 00421: val_accuracy did not improve from 0.94595\n","Epoch 422/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 1.1279 - val_accuracy: 0.8649\n","\n","Epoch 00422: val_accuracy did not improve from 0.94595\n","Epoch 423/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.5438 - val_accuracy: 0.9054\n","\n","Epoch 00423: val_accuracy did not improve from 0.94595\n","Epoch 424/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.6886 - val_accuracy: 0.8851\n","\n","Epoch 00424: val_accuracy did not improve from 0.94595\n","Epoch 425/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.4049 - val_accuracy: 0.9189\n","\n","Epoch 00425: val_accuracy did not improve from 0.94595\n","Epoch 426/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.5642 - val_accuracy: 0.8784\n","\n","Epoch 00426: val_accuracy did not improve from 0.94595\n","Epoch 427/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.4950 - val_accuracy: 0.8851\n","\n","Epoch 00427: val_accuracy did not improve from 0.94595\n","Epoch 428/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.6800 - val_accuracy: 0.8784\n","\n","Epoch 00428: val_accuracy did not improve from 0.94595\n","Epoch 429/500\n","238/238 [==============================] - 66s 279ms/step - loss: 7.6077e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.8919\n","\n","Epoch 00429: val_accuracy did not improve from 0.94595\n","Epoch 430/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5192 - val_accuracy: 0.8919\n","\n","Epoch 00430: val_accuracy did not improve from 0.94595\n","Epoch 431/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.6910 - val_accuracy: 0.8919\n","\n","Epoch 00431: val_accuracy did not improve from 0.94595\n","Epoch 432/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.7561 - val_accuracy: 0.8784\n","\n","Epoch 00432: val_accuracy did not improve from 0.94595\n","Epoch 433/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.7136 - val_accuracy: 0.8784\n","\n","Epoch 00433: val_accuracy did not improve from 0.94595\n","Epoch 434/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.5346 - val_accuracy: 0.9122\n","\n","Epoch 00434: val_accuracy did not improve from 0.94595\n","Epoch 435/500\n","238/238 [==============================] - 66s 278ms/step - loss: 5.3053e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9122\n","\n","Epoch 00435: val_accuracy did not improve from 0.94595\n","Epoch 436/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4567 - val_accuracy: 0.8919\n","\n","Epoch 00436: val_accuracy did not improve from 0.94595\n","Epoch 437/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.3717 - val_accuracy: 0.9189\n","\n","Epoch 00437: val_accuracy did not improve from 0.94595\n","Epoch 438/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.4492 - val_accuracy: 0.9122\n","\n","Epoch 00438: val_accuracy did not improve from 0.94595\n","Epoch 439/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 0.4221 - val_accuracy: 0.9257\n","\n","Epoch 00439: val_accuracy did not improve from 0.94595\n","Epoch 440/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5129 - val_accuracy: 0.9122\n","\n","Epoch 00440: val_accuracy did not improve from 0.94595\n","Epoch 441/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.8661 - val_accuracy: 0.8851\n","\n","Epoch 00441: val_accuracy did not improve from 0.94595\n","Epoch 442/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5950 - val_accuracy: 0.8851\n","\n","Epoch 00442: val_accuracy did not improve from 0.94595\n","Epoch 443/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 0.4792 - val_accuracy: 0.9122\n","\n","Epoch 00443: val_accuracy did not improve from 0.94595\n","Epoch 444/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.6497 - val_accuracy: 0.9189\n","\n","Epoch 00444: val_accuracy did not improve from 0.94595\n","Epoch 445/500\n","238/238 [==============================] - 67s 280ms/step - loss: 3.3578e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9189\n","\n","Epoch 00445: val_accuracy did not improve from 0.94595\n","Epoch 446/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.6117 - val_accuracy: 0.9054\n","\n","Epoch 00446: val_accuracy did not improve from 0.94595\n","Epoch 447/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.6516 - val_accuracy: 0.8986\n","\n","Epoch 00447: val_accuracy did not improve from 0.94595\n","Epoch 448/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.4194 - val_accuracy: 0.9122\n","\n","Epoch 00448: val_accuracy did not improve from 0.94595\n","Epoch 449/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.7415 - val_accuracy: 0.8919\n","\n","Epoch 00449: val_accuracy did not improve from 0.94595\n","Epoch 450/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.4219 - val_accuracy: 0.8986\n","\n","Epoch 00450: val_accuracy did not improve from 0.94595\n","Epoch 451/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.4091 - val_accuracy: 0.9122\n","\n","Epoch 00451: val_accuracy did not improve from 0.94595\n","Epoch 452/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5064 - val_accuracy: 0.8986\n","\n","Epoch 00452: val_accuracy did not improve from 0.94595\n","Epoch 453/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.7557 - val_accuracy: 0.8919\n","\n","Epoch 00453: val_accuracy did not improve from 0.94595\n","Epoch 454/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.7075 - val_accuracy: 0.9054\n","\n","Epoch 00454: val_accuracy did not improve from 0.94595\n","Epoch 455/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.5378 - val_accuracy: 0.9054\n","\n","Epoch 00455: val_accuracy did not improve from 0.94595\n","Epoch 456/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 0.7126 - val_accuracy: 0.8986\n","\n","Epoch 00456: val_accuracy did not improve from 0.94595\n","Epoch 457/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.8919\n","\n","Epoch 00457: val_accuracy did not improve from 0.94595\n","Epoch 458/500\n","238/238 [==============================] - 67s 280ms/step - loss: 4.9961e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9122\n","\n","Epoch 00458: val_accuracy did not improve from 0.94595\n","Epoch 459/500\n","238/238 [==============================] - 66s 279ms/step - loss: 8.8309e-04 - accuracy: 0.9995 - val_loss: 0.7268 - val_accuracy: 0.8919\n","\n","Epoch 00459: val_accuracy did not improve from 0.94595\n","Epoch 460/500\n","238/238 [==============================] - 66s 279ms/step - loss: 2.7760e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.9122\n","\n","Epoch 00460: val_accuracy did not improve from 0.94595\n","Epoch 461/500\n","238/238 [==============================] - 67s 279ms/step - loss: 1.6629e-04 - accuracy: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9054\n","\n","Epoch 00461: val_accuracy did not improve from 0.94595\n","Epoch 462/500\n","238/238 [==============================] - 67s 280ms/step - loss: 9.2870e-04 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.8851\n","\n","Epoch 00462: val_accuracy did not improve from 0.94595\n","Epoch 463/500\n","238/238 [==============================] - 66s 279ms/step - loss: 6.8485e-04 - accuracy: 0.9995 - val_loss: 0.5514 - val_accuracy: 0.8851\n","\n","Epoch 00463: val_accuracy did not improve from 0.94595\n","Epoch 464/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.7112 - val_accuracy: 0.8919\n","\n","Epoch 00464: val_accuracy did not improve from 0.94595\n","Epoch 465/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0351 - accuracy: 0.9937 - val_loss: 2.0147 - val_accuracy: 0.7568\n","\n","Epoch 00465: val_accuracy did not improve from 0.94595\n","Epoch 466/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.7570 - val_accuracy: 0.8514\n","\n","Epoch 00466: val_accuracy did not improve from 0.94595\n","Epoch 467/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4878 - val_accuracy: 0.8919\n","\n","Epoch 00467: val_accuracy did not improve from 0.94595\n","Epoch 468/500\n","238/238 [==============================] - 66s 277ms/step - loss: 6.9186e-04 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8919\n","\n","Epoch 00468: val_accuracy did not improve from 0.94595\n","Epoch 469/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6779 - val_accuracy: 0.8851\n","\n","Epoch 00469: val_accuracy did not improve from 0.94595\n","Epoch 470/500\n","238/238 [==============================] - 66s 276ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5411 - val_accuracy: 0.8851\n","\n","Epoch 00470: val_accuracy did not improve from 0.94595\n","Epoch 471/500\n","238/238 [==============================] - 66s 279ms/step - loss: 2.5490e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8986\n","\n","Epoch 00471: val_accuracy did not improve from 0.94595\n","Epoch 472/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.6115 - val_accuracy: 0.8986\n","\n","Epoch 00472: val_accuracy did not improve from 0.94595\n","Epoch 473/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.4595 - val_accuracy: 0.9257\n","\n","Epoch 00473: val_accuracy did not improve from 0.94595\n","Epoch 474/500\n","238/238 [==============================] - 66s 279ms/step - loss: 5.5744e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9189\n","\n","Epoch 00474: val_accuracy did not improve from 0.94595\n","Epoch 475/500\n","238/238 [==============================] - 67s 280ms/step - loss: 8.2763e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9122\n","\n","Epoch 00475: val_accuracy did not improve from 0.94595\n","Epoch 476/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 0.6608 - val_accuracy: 0.8986\n","\n","Epoch 00476: val_accuracy did not improve from 0.94595\n","Epoch 477/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.6831 - val_accuracy: 0.9054\n","\n","Epoch 00477: val_accuracy did not improve from 0.94595\n","Epoch 478/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.8008 - val_accuracy: 0.8986\n","\n","Epoch 00478: val_accuracy did not improve from 0.94595\n","Epoch 479/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.9409 - val_accuracy: 0.8919\n","\n","Epoch 00479: val_accuracy did not improve from 0.94595\n","Epoch 480/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5172 - val_accuracy: 0.8986\n","\n","Epoch 00480: val_accuracy did not improve from 0.94595\n","Epoch 481/500\n","238/238 [==============================] - 66s 277ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5964 - val_accuracy: 0.8986\n","\n","Epoch 00481: val_accuracy did not improve from 0.94595\n","Epoch 482/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.7908 - val_accuracy: 0.8851\n","\n","Epoch 00482: val_accuracy did not improve from 0.94595\n","Epoch 483/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0232 - accuracy: 0.9958 - val_loss: 0.7757 - val_accuracy: 0.8581\n","\n","Epoch 00483: val_accuracy did not improve from 0.94595\n","Epoch 484/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5086 - val_accuracy: 0.8986\n","\n","Epoch 00484: val_accuracy did not improve from 0.94595\n","Epoch 485/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.5507 - val_accuracy: 0.8851\n","\n","Epoch 00485: val_accuracy did not improve from 0.94595\n","Epoch 486/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.5134 - val_accuracy: 0.8986\n","\n","Epoch 00486: val_accuracy did not improve from 0.94595\n","Epoch 487/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.4415 - val_accuracy: 0.9054\n","\n","Epoch 00487: val_accuracy did not improve from 0.94595\n","Epoch 488/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.7737 - val_accuracy: 0.8176\n","\n","Epoch 00488: val_accuracy did not improve from 0.94595\n","Epoch 489/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.5445 - val_accuracy: 0.9122\n","\n","Epoch 00489: val_accuracy did not improve from 0.94595\n","Epoch 490/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5729 - val_accuracy: 0.9257\n","\n","Epoch 00490: val_accuracy did not improve from 0.94595\n","Epoch 491/500\n","238/238 [==============================] - 67s 279ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.6747 - val_accuracy: 0.8919\n","\n","Epoch 00491: val_accuracy did not improve from 0.94595\n","Epoch 492/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.7205 - val_accuracy: 0.8784\n","\n","Epoch 00492: val_accuracy did not improve from 0.94595\n","Epoch 493/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.4043 - val_accuracy: 0.9324\n","\n","Epoch 00493: val_accuracy did not improve from 0.94595\n","Epoch 494/500\n","238/238 [==============================] - 66s 279ms/step - loss: 7.3198e-04 - accuracy: 0.9995 - val_loss: 0.2534 - val_accuracy: 0.9257\n","\n","Epoch 00494: val_accuracy did not improve from 0.94595\n","Epoch 495/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.8116 - val_accuracy: 0.8716\n","\n","Epoch 00495: val_accuracy did not improve from 0.94595\n","Epoch 496/500\n","238/238 [==============================] - 66s 278ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.8986\n","\n","Epoch 00496: val_accuracy did not improve from 0.94595\n","Epoch 497/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.5728 - val_accuracy: 0.8986\n","\n","Epoch 00497: val_accuracy did not improve from 0.94595\n","Epoch 498/500\n","238/238 [==============================] - 66s 279ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.7426 - val_accuracy: 0.8514\n","\n","Epoch 00498: val_accuracy did not improve from 0.94595\n","Epoch 499/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4552 - val_accuracy: 0.9189\n","\n","Epoch 00499: val_accuracy did not improve from 0.94595\n","Epoch 500/500\n","238/238 [==============================] - 67s 280ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.7647 - val_accuracy: 0.8919\n","\n","Epoch 00500: val_accuracy did not improve from 0.94595\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe71d265210>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1632542694072,"user_tz":-540,"elapsed":10,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0ad5cf0c-c5e8-47f0-d926-08d375583415"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1632542733885,"user_tz":-540,"elapsed":39550,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-"},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632542889533,"user_tz":-540,"elapsed":154201,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b049b12b-b277-4e8c-fff6-63cebbf07162"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD"},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz"},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK"},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1632542890836,"user_tz":-540,"elapsed":1,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1632542901979,"user_tz":-540,"elapsed":11144,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS"},"source":["submission = submission[['id', 'digit']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1632542901987,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a4181986-5dfa-420d-ba0a-fef83e674bd9"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_71213a24-4d5f-425f-9f6e-de9d642b95eb\", \"ResNet152_4.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632542905639,"user_tz":-540,"elapsed":3654,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"15b93eaa-bc16-4fe8-d5f4-ec0b97ad252d"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632542906886,"user_tz":-540,"elapsed":49,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"45146f9d-3a21-42d0-ff69-eeead705bb8c"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    # 'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Competition. 대회 기간 중 제출 가능한 최대 횟수가 초과 되었습니다'}\n"]}]}]}