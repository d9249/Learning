{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_00_1_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPTi+7ox/BYHqafZlLvSdYZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629800516543,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6c8a0ad6-cea0-4212-fd62-6f84bd5e407b"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 10:21:56 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629800534789,"user_tz":-540,"elapsed":18253,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1893dc41-708b-4823-9e8f-9eb61c82ab4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629800537974,"user_tz":-540,"elapsed":2912,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629800539163,"user_tz":-540,"elapsed":1195,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629800541389,"user_tz":-540,"elapsed":2229,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629800557586,"user_tz":-540,"elapsed":16201,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629800564411,"user_tz":-540,"elapsed":6847,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629800564411,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"10f74ee0-957c-46ab-f08e-b76652ba894e"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629800564412,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ecf263d8-c97c-4567-ab3f-10b73a2cc790"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=0,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629800564412,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629806272424,"user_tz":-540,"elapsed":5708019,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"edbcb8d3-58ad-4f21-bdee-c0398d036bfd"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 38s 259ms/step - loss: 1.8286 - accuracy: 0.3618 - val_loss: 9.4497 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1703 - accuracy: 0.6054 - val_loss: 6.9541 - val_accuracy: 0.0911\n","\n","Epoch 00002: val_accuracy did not improve from 0.09360\n","Epoch 3/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.9529 - accuracy: 0.6760 - val_loss: 5.1431 - val_accuracy: 0.0493\n","\n","Epoch 00003: val_accuracy did not improve from 0.09360\n","Epoch 4/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.7874 - accuracy: 0.7424 - val_loss: 5.5671 - val_accuracy: 0.1552\n","\n","Epoch 00004: val_accuracy improved from 0.09360 to 0.15517, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 5/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.6797 - accuracy: 0.7716 - val_loss: 9.5787 - val_accuracy: 0.1305\n","\n","Epoch 00005: val_accuracy did not improve from 0.15517\n","Epoch 6/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.6125 - accuracy: 0.7917 - val_loss: 5.2535 - val_accuracy: 0.2512\n","\n","Epoch 00006: val_accuracy improved from 0.15517 to 0.25123, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.5615 - accuracy: 0.8033 - val_loss: 5.9112 - val_accuracy: 0.2192\n","\n","Epoch 00007: val_accuracy did not improve from 0.25123\n","Epoch 8/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4899 - accuracy: 0.8356 - val_loss: 2.5974 - val_accuracy: 0.3916\n","\n","Epoch 00008: val_accuracy improved from 0.25123 to 0.39163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.4662 - accuracy: 0.8337 - val_loss: 1.3704 - val_accuracy: 0.6601\n","\n","Epoch 00009: val_accuracy improved from 0.39163 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4516 - accuracy: 0.8362 - val_loss: 2.1156 - val_accuracy: 0.5887\n","\n","Epoch 00010: val_accuracy did not improve from 0.66010\n","Epoch 11/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.4185 - accuracy: 0.8618 - val_loss: 1.2013 - val_accuracy: 0.7044\n","\n","Epoch 00011: val_accuracy improved from 0.66010 to 0.70443, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.3517 - accuracy: 0.8745 - val_loss: 0.6798 - val_accuracy: 0.7980\n","\n","Epoch 00012: val_accuracy improved from 0.70443 to 0.79803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.3346 - accuracy: 0.8922 - val_loss: 0.8529 - val_accuracy: 0.7488\n","\n","Epoch 00013: val_accuracy did not improve from 0.79803\n","Epoch 14/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.3187 - accuracy: 0.8892 - val_loss: 1.5491 - val_accuracy: 0.6305\n","\n","Epoch 00014: val_accuracy did not improve from 0.79803\n","Epoch 15/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.3766 - accuracy: 0.8776 - val_loss: 6.7171 - val_accuracy: 0.2512\n","\n","Epoch 00015: val_accuracy did not improve from 0.79803\n","Epoch 16/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.3675 - accuracy: 0.8770 - val_loss: 0.5782 - val_accuracy: 0.8374\n","\n","Epoch 00016: val_accuracy improved from 0.79803 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2807 - accuracy: 0.9068 - val_loss: 0.9635 - val_accuracy: 0.7291\n","\n","Epoch 00017: val_accuracy did not improve from 0.83744\n","Epoch 18/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.2624 - accuracy: 0.9160 - val_loss: 0.9363 - val_accuracy: 0.7562\n","\n","Epoch 00018: val_accuracy did not improve from 0.83744\n","Epoch 19/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2254 - accuracy: 0.9190 - val_loss: 0.5586 - val_accuracy: 0.8350\n","\n","Epoch 00019: val_accuracy did not improve from 0.83744\n","Epoch 20/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2336 - accuracy: 0.9153 - val_loss: 1.2924 - val_accuracy: 0.6946\n","\n","Epoch 00020: val_accuracy did not improve from 0.83744\n","Epoch 21/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2131 - accuracy: 0.9227 - val_loss: 0.6662 - val_accuracy: 0.8276\n","\n","Epoch 00021: val_accuracy did not improve from 0.83744\n","Epoch 22/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1967 - accuracy: 0.9263 - val_loss: 1.0220 - val_accuracy: 0.7734\n","\n","Epoch 00022: val_accuracy did not improve from 0.83744\n","Epoch 23/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2227 - accuracy: 0.9233 - val_loss: 0.5978 - val_accuracy: 0.8374\n","\n","Epoch 00023: val_accuracy did not improve from 0.83744\n","Epoch 24/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1635 - accuracy: 0.9379 - val_loss: 0.4269 - val_accuracy: 0.8670\n","\n","Epoch 00024: val_accuracy improved from 0.83744 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1454 - accuracy: 0.9501 - val_loss: 0.4494 - val_accuracy: 0.8596\n","\n","Epoch 00025: val_accuracy did not improve from 0.86700\n","Epoch 26/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1723 - accuracy: 0.9464 - val_loss: 1.1379 - val_accuracy: 0.7241\n","\n","Epoch 00026: val_accuracy did not improve from 0.86700\n","Epoch 27/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2408 - accuracy: 0.9129 - val_loss: 0.6718 - val_accuracy: 0.8276\n","\n","Epoch 00027: val_accuracy did not improve from 0.86700\n","Epoch 28/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1747 - accuracy: 0.9373 - val_loss: 1.0886 - val_accuracy: 0.7685\n","\n","Epoch 00028: val_accuracy did not improve from 0.86700\n","Epoch 29/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.2495 - accuracy: 0.9141 - val_loss: 8.2343 - val_accuracy: 0.2389\n","\n","Epoch 00029: val_accuracy did not improve from 0.86700\n","Epoch 30/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1688 - accuracy: 0.9403 - val_loss: 2.1928 - val_accuracy: 0.6601\n","\n","Epoch 00030: val_accuracy did not improve from 0.86700\n","Epoch 31/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1285 - accuracy: 0.9568 - val_loss: 0.5603 - val_accuracy: 0.8498\n","\n","Epoch 00031: val_accuracy did not improve from 0.86700\n","Epoch 32/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0984 - accuracy: 0.9665 - val_loss: 0.4046 - val_accuracy: 0.8842\n","\n","Epoch 00032: val_accuracy improved from 0.86700 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 33/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1339 - accuracy: 0.9501 - val_loss: 0.5213 - val_accuracy: 0.8621\n","\n","Epoch 00033: val_accuracy did not improve from 0.88424\n","Epoch 34/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1193 - accuracy: 0.9604 - val_loss: 0.4819 - val_accuracy: 0.8818\n","\n","Epoch 00034: val_accuracy did not improve from 0.88424\n","Epoch 35/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0892 - accuracy: 0.9744 - val_loss: 0.7170 - val_accuracy: 0.8153\n","\n","Epoch 00035: val_accuracy did not improve from 0.88424\n","Epoch 36/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1013 - accuracy: 0.9659 - val_loss: 0.8201 - val_accuracy: 0.8005\n","\n","Epoch 00036: val_accuracy did not improve from 0.88424\n","Epoch 37/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1361 - accuracy: 0.9525 - val_loss: 0.8375 - val_accuracy: 0.8227\n","\n","Epoch 00037: val_accuracy did not improve from 0.88424\n","Epoch 38/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1105 - accuracy: 0.9671 - val_loss: 0.5001 - val_accuracy: 0.8719\n","\n","Epoch 00038: val_accuracy did not improve from 0.88424\n","Epoch 39/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0743 - accuracy: 0.9775 - val_loss: 0.5741 - val_accuracy: 0.8374\n","\n","Epoch 00039: val_accuracy did not improve from 0.88424\n","Epoch 40/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1242 - accuracy: 0.9549 - val_loss: 0.7576 - val_accuracy: 0.7956\n","\n","Epoch 00040: val_accuracy did not improve from 0.88424\n","Epoch 41/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1104 - accuracy: 0.9562 - val_loss: 0.7141 - val_accuracy: 0.8276\n","\n","Epoch 00041: val_accuracy did not improve from 0.88424\n","Epoch 42/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1667 - accuracy: 0.9464 - val_loss: 1.1773 - val_accuracy: 0.7414\n","\n","Epoch 00042: val_accuracy did not improve from 0.88424\n","Epoch 43/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1145 - accuracy: 0.9629 - val_loss: 0.6952 - val_accuracy: 0.8251\n","\n","Epoch 00043: val_accuracy did not improve from 0.88424\n","Epoch 44/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 0.5404 - val_accuracy: 0.8448\n","\n","Epoch 00044: val_accuracy did not improve from 0.88424\n","Epoch 45/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 0.4520 - val_accuracy: 0.8867\n","\n","Epoch 00045: val_accuracy improved from 0.88424 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 46/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.4290 - val_accuracy: 0.8867\n","\n","Epoch 00046: val_accuracy did not improve from 0.88670\n","Epoch 47/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.3998 - val_accuracy: 0.8892\n","\n","Epoch 00047: val_accuracy improved from 0.88670 to 0.88916, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 48/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0423 - accuracy: 0.9896 - val_loss: 0.3847 - val_accuracy: 0.9015\n","\n","Epoch 00048: val_accuracy improved from 0.88916 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 49/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0700 - accuracy: 0.9750 - val_loss: 1.5812 - val_accuracy: 0.7414\n","\n","Epoch 00049: val_accuracy did not improve from 0.90148\n","Epoch 50/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1040 - accuracy: 0.9610 - val_loss: 0.5657 - val_accuracy: 0.8719\n","\n","Epoch 00050: val_accuracy did not improve from 0.90148\n","Epoch 51/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0856 - accuracy: 0.9714 - val_loss: 0.4364 - val_accuracy: 0.8842\n","\n","Epoch 00051: val_accuracy did not improve from 0.90148\n","Epoch 52/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0789 - accuracy: 0.9720 - val_loss: 0.6608 - val_accuracy: 0.8424\n","\n","Epoch 00052: val_accuracy did not improve from 0.90148\n","Epoch 53/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0891 - accuracy: 0.9677 - val_loss: 0.7085 - val_accuracy: 0.8399\n","\n","Epoch 00053: val_accuracy did not improve from 0.90148\n","Epoch 54/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0923 - accuracy: 0.9665 - val_loss: 0.5984 - val_accuracy: 0.8621\n","\n","Epoch 00054: val_accuracy did not improve from 0.90148\n","Epoch 55/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 0.6556 - val_accuracy: 0.8448\n","\n","Epoch 00055: val_accuracy did not improve from 0.90148\n","Epoch 56/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.6570 - val_accuracy: 0.8571\n","\n","Epoch 00056: val_accuracy did not improve from 0.90148\n","Epoch 57/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.3970 - val_accuracy: 0.8768\n","\n","Epoch 00057: val_accuracy did not improve from 0.90148\n","Epoch 58/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.3980 - val_accuracy: 0.8916\n","\n","Epoch 00058: val_accuracy did not improve from 0.90148\n","Epoch 59/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.5416 - val_accuracy: 0.8793\n","\n","Epoch 00059: val_accuracy did not improve from 0.90148\n","Epoch 60/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.4866 - val_accuracy: 0.8645\n","\n","Epoch 00060: val_accuracy did not improve from 0.90148\n","Epoch 61/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.4368 - val_accuracy: 0.8793\n","\n","Epoch 00061: val_accuracy did not improve from 0.90148\n","Epoch 62/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0550 - accuracy: 0.9817 - val_loss: 0.4762 - val_accuracy: 0.8768\n","\n","Epoch 00062: val_accuracy did not improve from 0.90148\n","Epoch 63/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0452 - accuracy: 0.9842 - val_loss: 0.4492 - val_accuracy: 0.8892\n","\n","Epoch 00063: val_accuracy did not improve from 0.90148\n","Epoch 64/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.5943 - val_accuracy: 0.8867\n","\n","Epoch 00064: val_accuracy did not improve from 0.90148\n","Epoch 65/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0616 - accuracy: 0.9793 - val_loss: 0.6956 - val_accuracy: 0.8768\n","\n","Epoch 00065: val_accuracy did not improve from 0.90148\n","Epoch 66/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0723 - accuracy: 0.9714 - val_loss: 0.7724 - val_accuracy: 0.8251\n","\n","Epoch 00066: val_accuracy did not improve from 0.90148\n","Epoch 67/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0740 - accuracy: 0.9720 - val_loss: 0.5056 - val_accuracy: 0.8621\n","\n","Epoch 00067: val_accuracy did not improve from 0.90148\n","Epoch 68/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0577 - accuracy: 0.9805 - val_loss: 0.7431 - val_accuracy: 0.8473\n","\n","Epoch 00068: val_accuracy did not improve from 0.90148\n","Epoch 69/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1028 - accuracy: 0.9647 - val_loss: 0.4799 - val_accuracy: 0.8818\n","\n","Epoch 00069: val_accuracy did not improve from 0.90148\n","Epoch 70/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.1364 - accuracy: 0.9531 - val_loss: 0.5786 - val_accuracy: 0.8670\n","\n","Epoch 00070: val_accuracy did not improve from 0.90148\n","Epoch 71/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0615 - accuracy: 0.9799 - val_loss: 0.5004 - val_accuracy: 0.8941\n","\n","Epoch 00071: val_accuracy did not improve from 0.90148\n","Epoch 72/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.5894 - val_accuracy: 0.8818\n","\n","Epoch 00072: val_accuracy did not improve from 0.90148\n","Epoch 73/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.5124 - val_accuracy: 0.8941\n","\n","Epoch 00073: val_accuracy did not improve from 0.90148\n","Epoch 74/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.3925 - val_accuracy: 0.9089\n","\n","Epoch 00074: val_accuracy improved from 0.90148 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.5036 - val_accuracy: 0.8818\n","\n","Epoch 00075: val_accuracy did not improve from 0.90887\n","Epoch 76/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.5038 - val_accuracy: 0.8719\n","\n","Epoch 00076: val_accuracy did not improve from 0.90887\n","Epoch 77/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.4609 - val_accuracy: 0.8892\n","\n","Epoch 00077: val_accuracy did not improve from 0.90887\n","Epoch 78/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1946 - accuracy: 0.9421 - val_loss: 4.1099 - val_accuracy: 0.6158\n","\n","Epoch 00078: val_accuracy did not improve from 0.90887\n","Epoch 79/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 1.7638 - val_accuracy: 0.7315\n","\n","Epoch 00079: val_accuracy did not improve from 0.90887\n","Epoch 80/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0466 - accuracy: 0.9842 - val_loss: 0.4657 - val_accuracy: 0.8990\n","\n","Epoch 00080: val_accuracy did not improve from 0.90887\n","Epoch 81/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: 0.5575 - val_accuracy: 0.8522\n","\n","Epoch 00081: val_accuracy did not improve from 0.90887\n","Epoch 82/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0265 - accuracy: 0.9890 - val_loss: 0.4302 - val_accuracy: 0.8842\n","\n","Epoch 00082: val_accuracy did not improve from 0.90887\n","Epoch 83/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0675 - accuracy: 0.9787 - val_loss: 0.6372 - val_accuracy: 0.8621\n","\n","Epoch 00083: val_accuracy did not improve from 0.90887\n","Epoch 84/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0256 - accuracy: 0.9884 - val_loss: 0.7662 - val_accuracy: 0.8350\n","\n","Epoch 00084: val_accuracy did not improve from 0.90887\n","Epoch 85/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0530 - accuracy: 0.9866 - val_loss: 0.4988 - val_accuracy: 0.8842\n","\n","Epoch 00085: val_accuracy did not improve from 0.90887\n","Epoch 86/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.4949 - val_accuracy: 0.8842\n","\n","Epoch 00086: val_accuracy did not improve from 0.90887\n","Epoch 87/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.4485 - val_accuracy: 0.8941\n","\n","Epoch 00087: val_accuracy did not improve from 0.90887\n","Epoch 88/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 0.3817 - val_accuracy: 0.8990\n","\n","Epoch 00088: val_accuracy did not improve from 0.90887\n","Epoch 89/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.3893 - val_accuracy: 0.9113\n","\n","Epoch 00089: val_accuracy improved from 0.90887 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 90/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.6743 - val_accuracy: 0.8621\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.5570 - val_accuracy: 0.8719\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.4941 - val_accuracy: 0.8867\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.7964 - val_accuracy: 0.8547\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.6905 - val_accuracy: 0.8596\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.5188 - val_accuracy: 0.8941\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.4805 - val_accuracy: 0.8966\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.6665 - val_accuracy: 0.8596\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0658 - accuracy: 0.9756 - val_loss: 1.0731 - val_accuracy: 0.7833\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 0.7851 - val_accuracy: 0.8473\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0639 - accuracy: 0.9805 - val_loss: 0.8601 - val_accuracy: 0.8251\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.8375 - val_accuracy: 0.8571\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.4971 - val_accuracy: 0.8768\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.5128 - val_accuracy: 0.8768\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.7180 - val_accuracy: 0.8596\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.7495 - val_accuracy: 0.8374\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 1.3329 - val_accuracy: 0.7882\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0498 - accuracy: 0.9836 - val_loss: 0.5923 - val_accuracy: 0.8645\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.5791 - val_accuracy: 0.8793\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.4273 - val_accuracy: 0.8966\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.3691 - val_accuracy: 0.9212\n","\n","Epoch 00110: val_accuracy improved from 0.91133 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 111/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1178 - accuracy: 0.9677 - val_loss: 1.6732 - val_accuracy: 0.7709\n","\n","Epoch 00111: val_accuracy did not improve from 0.92118\n","Epoch 112/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.5696 - val_accuracy: 0.8892\n","\n","Epoch 00112: val_accuracy did not improve from 0.92118\n","Epoch 113/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0327 - accuracy: 0.9915 - val_loss: 0.7213 - val_accuracy: 0.8768\n","\n","Epoch 00113: val_accuracy did not improve from 0.92118\n","Epoch 114/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.5068 - val_accuracy: 0.9015\n","\n","Epoch 00114: val_accuracy did not improve from 0.92118\n","Epoch 115/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.5185 - val_accuracy: 0.8842\n","\n","Epoch 00115: val_accuracy did not improve from 0.92118\n","Epoch 116/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0617 - accuracy: 0.9805 - val_loss: 1.2079 - val_accuracy: 0.7857\n","\n","Epoch 00116: val_accuracy did not improve from 0.92118\n","Epoch 117/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0757 - accuracy: 0.9708 - val_loss: 0.8411 - val_accuracy: 0.8276\n","\n","Epoch 00117: val_accuracy did not improve from 0.92118\n","Epoch 118/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.5269 - val_accuracy: 0.8867\n","\n","Epoch 00118: val_accuracy did not improve from 0.92118\n","Epoch 119/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.5814 - val_accuracy: 0.8818\n","\n","Epoch 00119: val_accuracy did not improve from 0.92118\n","Epoch 120/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.5649 - val_accuracy: 0.8867\n","\n","Epoch 00120: val_accuracy did not improve from 0.92118\n","Epoch 121/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.4663 - val_accuracy: 0.9064\n","\n","Epoch 00121: val_accuracy did not improve from 0.92118\n","Epoch 122/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.4876 - val_accuracy: 0.9089\n","\n","Epoch 00122: val_accuracy did not improve from 0.92118\n","Epoch 123/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5331 - val_accuracy: 0.8818\n","\n","Epoch 00123: val_accuracy did not improve from 0.92118\n","Epoch 124/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4538 - val_accuracy: 0.9064\n","\n","Epoch 00124: val_accuracy did not improve from 0.92118\n","Epoch 125/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.5096 - val_accuracy: 0.9039\n","\n","Epoch 00125: val_accuracy did not improve from 0.92118\n","Epoch 126/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.4809 - val_accuracy: 0.9064\n","\n","Epoch 00126: val_accuracy did not improve from 0.92118\n","Epoch 127/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0287 - accuracy: 0.9890 - val_loss: 0.7296 - val_accuracy: 0.8768\n","\n","Epoch 00127: val_accuracy did not improve from 0.92118\n","Epoch 128/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0699 - accuracy: 0.9787 - val_loss: 0.9848 - val_accuracy: 0.8202\n","\n","Epoch 00128: val_accuracy did not improve from 0.92118\n","Epoch 129/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0653 - accuracy: 0.9817 - val_loss: 1.4213 - val_accuracy: 0.7635\n","\n","Epoch 00129: val_accuracy did not improve from 0.92118\n","Epoch 130/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0444 - accuracy: 0.9811 - val_loss: 0.5654 - val_accuracy: 0.8941\n","\n","Epoch 00130: val_accuracy did not improve from 0.92118\n","Epoch 131/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0298 - accuracy: 0.9890 - val_loss: 0.5039 - val_accuracy: 0.8916\n","\n","Epoch 00131: val_accuracy did not improve from 0.92118\n","Epoch 132/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.7836 - val_accuracy: 0.8645\n","\n","Epoch 00132: val_accuracy did not improve from 0.92118\n","Epoch 133/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.8036 - val_accuracy: 0.8621\n","\n","Epoch 00133: val_accuracy did not improve from 0.92118\n","Epoch 134/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.5543 - val_accuracy: 0.8941\n","\n","Epoch 00134: val_accuracy did not improve from 0.92118\n","Epoch 135/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4161 - val_accuracy: 0.9039\n","\n","Epoch 00135: val_accuracy did not improve from 0.92118\n","Epoch 136/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.4545 - val_accuracy: 0.8990\n","\n","Epoch 00136: val_accuracy did not improve from 0.92118\n","Epoch 137/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4409 - val_accuracy: 0.9039\n","\n","Epoch 00137: val_accuracy did not improve from 0.92118\n","Epoch 138/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4156 - val_accuracy: 0.9089\n","\n","Epoch 00138: val_accuracy did not improve from 0.92118\n","Epoch 139/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4743 - val_accuracy: 0.9138\n","\n","Epoch 00139: val_accuracy did not improve from 0.92118\n","Epoch 140/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.3978 - val_accuracy: 0.9187\n","\n","Epoch 00140: val_accuracy did not improve from 0.92118\n","Epoch 141/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9310\n","\n","Epoch 00141: val_accuracy improved from 0.92118 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 142/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9236\n","\n","Epoch 00142: val_accuracy did not improve from 0.93103\n","Epoch 143/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.6199e-04 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9212\n","\n","Epoch 00143: val_accuracy did not improve from 0.93103\n","Epoch 144/500\n","52/52 [==============================] - 11s 207ms/step - loss: 4.5646e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9163\n","\n","Epoch 00144: val_accuracy did not improve from 0.93103\n","Epoch 145/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.4643e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9212\n","\n","Epoch 00145: val_accuracy did not improve from 0.93103\n","Epoch 146/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.2943e-04 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9187\n","\n","Epoch 00146: val_accuracy did not improve from 0.93103\n","Epoch 147/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.4861e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9236\n","\n","Epoch 00147: val_accuracy did not improve from 0.93103\n","Epoch 148/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.5983e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9286\n","\n","Epoch 00148: val_accuracy did not improve from 0.93103\n","Epoch 149/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.2938e-04 - accuracy: 0.9994 - val_loss: 0.4440 - val_accuracy: 0.9138\n","\n","Epoch 00149: val_accuracy did not improve from 0.93103\n","Epoch 150/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.7429e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9212\n","\n","Epoch 00150: val_accuracy did not improve from 0.93103\n","Epoch 151/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.6809e-04 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9286\n","\n","Epoch 00151: val_accuracy did not improve from 0.93103\n","Epoch 152/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3401e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9310\n","\n","Epoch 00152: val_accuracy did not improve from 0.93103\n","Epoch 153/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.1705e-04 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9335\n","\n","Epoch 00153: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 154/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.8334e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9212\n","\n","Epoch 00154: val_accuracy did not improve from 0.93350\n","Epoch 155/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.7988e-04 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9261\n","\n","Epoch 00155: val_accuracy did not improve from 0.93350\n","Epoch 156/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1227 - accuracy: 0.9641 - val_loss: 5.3375 - val_accuracy: 0.5000\n","\n","Epoch 00156: val_accuracy did not improve from 0.93350\n","Epoch 157/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2309 - accuracy: 0.9300 - val_loss: 4.2530 - val_accuracy: 0.5764\n","\n","Epoch 00157: val_accuracy did not improve from 0.93350\n","Epoch 158/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1090 - accuracy: 0.9635 - val_loss: 0.9609 - val_accuracy: 0.8374\n","\n","Epoch 00158: val_accuracy did not improve from 0.93350\n","Epoch 159/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0275 - accuracy: 0.9884 - val_loss: 0.5505 - val_accuracy: 0.8990\n","\n","Epoch 00159: val_accuracy did not improve from 0.93350\n","Epoch 160/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.4464 - val_accuracy: 0.9113\n","\n","Epoch 00160: val_accuracy did not improve from 0.93350\n","Epoch 161/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.3983 - val_accuracy: 0.9138\n","\n","Epoch 00161: val_accuracy did not improve from 0.93350\n","Epoch 162/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0164 - accuracy: 0.9970 - val_loss: 0.4448 - val_accuracy: 0.9039\n","\n","Epoch 00162: val_accuracy did not improve from 0.93350\n","Epoch 163/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3757 - val_accuracy: 0.9187\n","\n","Epoch 00163: val_accuracy did not improve from 0.93350\n","Epoch 164/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9212\n","\n","Epoch 00164: val_accuracy did not improve from 0.93350\n","Epoch 165/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4108 - val_accuracy: 0.8990\n","\n","Epoch 00165: val_accuracy did not improve from 0.93350\n","Epoch 166/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4711 - val_accuracy: 0.8990\n","\n","Epoch 00166: val_accuracy did not improve from 0.93350\n","Epoch 167/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9261\n","\n","Epoch 00167: val_accuracy did not improve from 0.93350\n","Epoch 168/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5041 - val_accuracy: 0.9138\n","\n","Epoch 00168: val_accuracy did not improve from 0.93350\n","Epoch 169/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9236\n","\n","Epoch 00169: val_accuracy did not improve from 0.93350\n","Epoch 170/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4472 - val_accuracy: 0.9163\n","\n","Epoch 00170: val_accuracy did not improve from 0.93350\n","Epoch 171/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3721 - val_accuracy: 0.9212\n","\n","Epoch 00171: val_accuracy did not improve from 0.93350\n","Epoch 172/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.6018 - val_accuracy: 0.8916\n","\n","Epoch 00172: val_accuracy did not improve from 0.93350\n","Epoch 173/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.5324 - val_accuracy: 0.9064\n","\n","Epoch 00173: val_accuracy did not improve from 0.93350\n","Epoch 174/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.5182 - val_accuracy: 0.8966\n","\n","Epoch 00174: val_accuracy did not improve from 0.93350\n","Epoch 175/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9927 - val_loss: 0.6791 - val_accuracy: 0.8867\n","\n","Epoch 00175: val_accuracy did not improve from 0.93350\n","Epoch 176/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.1049 - accuracy: 0.9762 - val_loss: 1.1464 - val_accuracy: 0.8079\n","\n","Epoch 00176: val_accuracy did not improve from 0.93350\n","Epoch 177/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1391 - accuracy: 0.9574 - val_loss: 2.5396 - val_accuracy: 0.7192\n","\n","Epoch 00177: val_accuracy did not improve from 0.93350\n","Epoch 178/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0647 - accuracy: 0.9781 - val_loss: 0.8758 - val_accuracy: 0.8399\n","\n","Epoch 00178: val_accuracy did not improve from 0.93350\n","Epoch 179/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.6614 - val_accuracy: 0.8695\n","\n","Epoch 00179: val_accuracy did not improve from 0.93350\n","Epoch 180/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.7239 - val_accuracy: 0.8793\n","\n","Epoch 00180: val_accuracy did not improve from 0.93350\n","Epoch 181/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.8446 - val_accuracy: 0.8374\n","\n","Epoch 00181: val_accuracy did not improve from 0.93350\n","Epoch 182/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0427 - accuracy: 0.9836 - val_loss: 0.7616 - val_accuracy: 0.8645\n","\n","Epoch 00182: val_accuracy did not improve from 0.93350\n","Epoch 183/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.7337 - val_accuracy: 0.8522\n","\n","Epoch 00183: val_accuracy did not improve from 0.93350\n","Epoch 184/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.6334 - val_accuracy: 0.8719\n","\n","Epoch 00184: val_accuracy did not improve from 0.93350\n","Epoch 185/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.4622 - val_accuracy: 0.9064\n","\n","Epoch 00185: val_accuracy did not improve from 0.93350\n","Epoch 186/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.4637 - val_accuracy: 0.9089\n","\n","Epoch 00186: val_accuracy did not improve from 0.93350\n","Epoch 187/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5470 - val_accuracy: 0.9039\n","\n","Epoch 00187: val_accuracy did not improve from 0.93350\n","Epoch 188/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9163\n","\n","Epoch 00188: val_accuracy did not improve from 0.93350\n","Epoch 189/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9261\n","\n","Epoch 00189: val_accuracy did not improve from 0.93350\n","Epoch 190/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3735 - val_accuracy: 0.9335\n","\n","Epoch 00190: val_accuracy did not improve from 0.93350\n","Epoch 191/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9089\n","\n","Epoch 00191: val_accuracy did not improve from 0.93350\n","Epoch 192/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9163\n","\n","Epoch 00192: val_accuracy did not improve from 0.93350\n","Epoch 193/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5550 - val_accuracy: 0.8941\n","\n","Epoch 00193: val_accuracy did not improve from 0.93350\n","Epoch 194/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6454 - val_accuracy: 0.8818\n","\n","Epoch 00194: val_accuracy did not improve from 0.93350\n","Epoch 195/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.7587 - val_accuracy: 0.8719\n","\n","Epoch 00195: val_accuracy did not improve from 0.93350\n","Epoch 196/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.6689 - val_accuracy: 0.8916\n","\n","Epoch 00196: val_accuracy did not improve from 0.93350\n","Epoch 197/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4908 - val_accuracy: 0.9064\n","\n","Epoch 00197: val_accuracy did not improve from 0.93350\n","Epoch 198/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4630 - val_accuracy: 0.9015\n","\n","Epoch 00198: val_accuracy did not improve from 0.93350\n","Epoch 199/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3871 - val_accuracy: 0.9236\n","\n","Epoch 00199: val_accuracy did not improve from 0.93350\n","Epoch 200/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.4984e-04 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9212\n","\n","Epoch 00200: val_accuracy did not improve from 0.93350\n","Epoch 201/500\n","52/52 [==============================] - 11s 204ms/step - loss: 8.3210e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9187\n","\n","Epoch 00201: val_accuracy did not improve from 0.93350\n","Epoch 202/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3569 - val_accuracy: 0.9335\n","\n","Epoch 00202: val_accuracy did not improve from 0.93350\n","Epoch 203/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.4580e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9212\n","\n","Epoch 00203: val_accuracy did not improve from 0.93350\n","Epoch 204/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.5805e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9212\n","\n","Epoch 00204: val_accuracy did not improve from 0.93350\n","Epoch 205/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.0869e-04 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9138\n","\n","Epoch 00205: val_accuracy did not improve from 0.93350\n","Epoch 206/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5023 - val_accuracy: 0.8990\n","\n","Epoch 00206: val_accuracy did not improve from 0.93350\n","Epoch 207/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.8506 - val_accuracy: 0.8670\n","\n","Epoch 00207: val_accuracy did not improve from 0.93350\n","Epoch 208/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.5556 - val_accuracy: 0.8941\n","\n","Epoch 00208: val_accuracy did not improve from 0.93350\n","Epoch 209/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.6789 - val_accuracy: 0.8768\n","\n","Epoch 00209: val_accuracy did not improve from 0.93350\n","Epoch 210/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1257 - accuracy: 0.9653 - val_loss: 2.0716 - val_accuracy: 0.7340\n","\n","Epoch 00210: val_accuracy did not improve from 0.93350\n","Epoch 211/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0754 - accuracy: 0.9750 - val_loss: 0.9316 - val_accuracy: 0.8498\n","\n","Epoch 00211: val_accuracy did not improve from 0.93350\n","Epoch 212/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.8816 - val_accuracy: 0.8596\n","\n","Epoch 00212: val_accuracy did not improve from 0.93350\n","Epoch 213/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.4764 - val_accuracy: 0.8966\n","\n","Epoch 00213: val_accuracy did not improve from 0.93350\n","Epoch 214/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.5024 - val_accuracy: 0.8941\n","\n","Epoch 00214: val_accuracy did not improve from 0.93350\n","Epoch 215/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4607 - val_accuracy: 0.9089\n","\n","Epoch 00215: val_accuracy did not improve from 0.93350\n","Epoch 216/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.3972 - val_accuracy: 0.9236\n","\n","Epoch 00216: val_accuracy did not improve from 0.93350\n","Epoch 217/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.4388 - val_accuracy: 0.9113\n","\n","Epoch 00217: val_accuracy did not improve from 0.93350\n","Epoch 218/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4194 - val_accuracy: 0.9236\n","\n","Epoch 00218: val_accuracy did not improve from 0.93350\n","Epoch 219/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9335\n","\n","Epoch 00219: val_accuracy did not improve from 0.93350\n","Epoch 220/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9310\n","\n","Epoch 00220: val_accuracy did not improve from 0.93350\n","Epoch 221/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.2322e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9335\n","\n","Epoch 00221: val_accuracy did not improve from 0.93350\n","Epoch 222/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.7945e-04 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9286\n","\n","Epoch 00222: val_accuracy did not improve from 0.93350\n","Epoch 223/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.2660e-04 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9286\n","\n","Epoch 00223: val_accuracy did not improve from 0.93350\n","Epoch 224/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.1697e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9286\n","\n","Epoch 00224: val_accuracy did not improve from 0.93350\n","Epoch 225/500\n","52/52 [==============================] - 11s 204ms/step - loss: 5.8812e-04 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9261\n","\n","Epoch 00225: val_accuracy did not improve from 0.93350\n","Epoch 226/500\n","52/52 [==============================] - 11s 204ms/step - loss: 4.9395e-04 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9310\n","\n","Epoch 00226: val_accuracy did not improve from 0.93350\n","Epoch 227/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.8325e-04 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9286\n","\n","Epoch 00227: val_accuracy did not improve from 0.93350\n","Epoch 228/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.1400e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9236\n","\n","Epoch 00228: val_accuracy did not improve from 0.93350\n","Epoch 229/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3977e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9138\n","\n","Epoch 00229: val_accuracy did not improve from 0.93350\n","Epoch 230/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.7902e-04 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9163\n","\n","Epoch 00230: val_accuracy did not improve from 0.93350\n","Epoch 231/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.5146e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9409\n","\n","Epoch 00231: val_accuracy improved from 0.93350 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 232/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.4544e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9286\n","\n","Epoch 00232: val_accuracy did not improve from 0.94089\n","Epoch 233/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.0185e-04 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9286\n","\n","Epoch 00233: val_accuracy did not improve from 0.94089\n","Epoch 234/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.7575e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9236\n","\n","Epoch 00234: val_accuracy did not improve from 0.94089\n","Epoch 235/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.0456e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9261\n","\n","Epoch 00235: val_accuracy did not improve from 0.94089\n","Epoch 236/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.6772e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9286\n","\n","Epoch 00236: val_accuracy did not improve from 0.94089\n","Epoch 237/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.6686e-04 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9236\n","\n","Epoch 00237: val_accuracy did not improve from 0.94089\n","Epoch 238/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0325 - accuracy: 0.9927 - val_loss: 0.8871 - val_accuracy: 0.8744\n","\n","Epoch 00238: val_accuracy did not improve from 0.94089\n","Epoch 239/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1130 - accuracy: 0.9659 - val_loss: 4.0471 - val_accuracy: 0.5493\n","\n","Epoch 00239: val_accuracy did not improve from 0.94089\n","Epoch 240/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.1885 - accuracy: 0.9403 - val_loss: 4.1380 - val_accuracy: 0.5443\n","\n","Epoch 00240: val_accuracy did not improve from 0.94089\n","Epoch 241/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0520 - accuracy: 0.9781 - val_loss: 0.8771 - val_accuracy: 0.8227\n","\n","Epoch 00241: val_accuracy did not improve from 0.94089\n","Epoch 242/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.5911 - val_accuracy: 0.8596\n","\n","Epoch 00242: val_accuracy did not improve from 0.94089\n","Epoch 243/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0242 - accuracy: 0.9903 - val_loss: 0.6727 - val_accuracy: 0.8596\n","\n","Epoch 00243: val_accuracy did not improve from 0.94089\n","Epoch 244/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5021 - val_accuracy: 0.8867\n","\n","Epoch 00244: val_accuracy did not improve from 0.94089\n","Epoch 245/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.6026 - val_accuracy: 0.8842\n","\n","Epoch 00245: val_accuracy did not improve from 0.94089\n","Epoch 246/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4877 - val_accuracy: 0.9163\n","\n","Epoch 00246: val_accuracy did not improve from 0.94089\n","Epoch 247/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9163\n","\n","Epoch 00247: val_accuracy did not improve from 0.94089\n","Epoch 248/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4731 - val_accuracy: 0.8941\n","\n","Epoch 00248: val_accuracy did not improve from 0.94089\n","Epoch 249/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9212\n","\n","Epoch 00249: val_accuracy did not improve from 0.94089\n","Epoch 250/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.6338e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9089\n","\n","Epoch 00250: val_accuracy did not improve from 0.94089\n","Epoch 251/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.3701e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9163\n","\n","Epoch 00251: val_accuracy did not improve from 0.94089\n","Epoch 252/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.1976e-04 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9212\n","\n","Epoch 00252: val_accuracy did not improve from 0.94089\n","Epoch 253/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.5242e-04 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9138\n","\n","Epoch 00253: val_accuracy did not improve from 0.94089\n","Epoch 254/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.0945e-04 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9236\n","\n","Epoch 00254: val_accuracy did not improve from 0.94089\n","Epoch 255/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3581 - val_accuracy: 0.9236\n","\n","Epoch 00255: val_accuracy did not improve from 0.94089\n","Epoch 256/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9138\n","\n","Epoch 00256: val_accuracy did not improve from 0.94089\n","Epoch 257/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.6327e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9138\n","\n","Epoch 00257: val_accuracy did not improve from 0.94089\n","Epoch 258/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3808 - val_accuracy: 0.9261\n","\n","Epoch 00258: val_accuracy did not improve from 0.94089\n","Epoch 259/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.4359 - val_accuracy: 0.9089\n","\n","Epoch 00259: val_accuracy did not improve from 0.94089\n","Epoch 260/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.5700 - val_accuracy: 0.8842\n","\n","Epoch 00260: val_accuracy did not improve from 0.94089\n","Epoch 261/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 4.4602 - val_accuracy: 0.5271\n","\n","Epoch 00261: val_accuracy did not improve from 0.94089\n","Epoch 262/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.7965 - val_accuracy: 0.8966\n","\n","Epoch 00262: val_accuracy did not improve from 0.94089\n","Epoch 263/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 1.0495 - val_accuracy: 0.8128\n","\n","Epoch 00263: val_accuracy did not improve from 0.94089\n","Epoch 264/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 0.9429 - val_accuracy: 0.8202\n","\n","Epoch 00264: val_accuracy did not improve from 0.94089\n","Epoch 265/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 0.5523 - val_accuracy: 0.8867\n","\n","Epoch 00265: val_accuracy did not improve from 0.94089\n","Epoch 266/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4465 - val_accuracy: 0.8941\n","\n","Epoch 00266: val_accuracy did not improve from 0.94089\n","Epoch 267/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.3555 - val_accuracy: 0.9163\n","\n","Epoch 00267: val_accuracy did not improve from 0.94089\n","Epoch 268/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3642 - val_accuracy: 0.9163\n","\n","Epoch 00268: val_accuracy did not improve from 0.94089\n","Epoch 269/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4321 - val_accuracy: 0.9113\n","\n","Epoch 00269: val_accuracy did not improve from 0.94089\n","Epoch 270/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5213 - val_accuracy: 0.8941\n","\n","Epoch 00270: val_accuracy did not improve from 0.94089\n","Epoch 271/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8990\n","\n","Epoch 00271: val_accuracy did not improve from 0.94089\n","Epoch 272/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.9782e-04 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9163\n","\n","Epoch 00272: val_accuracy did not improve from 0.94089\n","Epoch 273/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3383e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9163\n","\n","Epoch 00273: val_accuracy did not improve from 0.94089\n","Epoch 274/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.8353e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9261\n","\n","Epoch 00274: val_accuracy did not improve from 0.94089\n","Epoch 275/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.5864e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9261\n","\n","Epoch 00275: val_accuracy did not improve from 0.94089\n","Epoch 276/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.5942e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9212\n","\n","Epoch 00276: val_accuracy did not improve from 0.94089\n","Epoch 277/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.4108e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9310\n","\n","Epoch 00277: val_accuracy did not improve from 0.94089\n","Epoch 278/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.7309e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9286\n","\n","Epoch 00278: val_accuracy did not improve from 0.94089\n","Epoch 279/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.4986e-04 - accuracy: 0.9994 - val_loss: 0.4200 - val_accuracy: 0.9261\n","\n","Epoch 00279: val_accuracy did not improve from 0.94089\n","Epoch 280/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5312 - val_accuracy: 0.8990\n","\n","Epoch 00280: val_accuracy did not improve from 0.94089\n","Epoch 281/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4945 - val_accuracy: 0.9138\n","\n","Epoch 00281: val_accuracy did not improve from 0.94089\n","Epoch 282/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4591 - val_accuracy: 0.9187\n","\n","Epoch 00282: val_accuracy did not improve from 0.94089\n","Epoch 283/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.8005e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9236\n","\n","Epoch 00283: val_accuracy did not improve from 0.94089\n","Epoch 284/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.5067e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9261\n","\n","Epoch 00284: val_accuracy did not improve from 0.94089\n","Epoch 285/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.5235e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9236\n","\n","Epoch 00285: val_accuracy did not improve from 0.94089\n","Epoch 286/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.4401e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9187\n","\n","Epoch 00286: val_accuracy did not improve from 0.94089\n","Epoch 287/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.9423e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9187\n","\n","Epoch 00287: val_accuracy did not improve from 0.94089\n","Epoch 288/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.8331e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9138\n","\n","Epoch 00288: val_accuracy did not improve from 0.94089\n","Epoch 289/500\n","52/52 [==============================] - 11s 204ms/step - loss: 2.3028e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9236\n","\n","Epoch 00289: val_accuracy did not improve from 0.94089\n","Epoch 290/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.3336e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9163\n","\n","Epoch 00290: val_accuracy did not improve from 0.94089\n","Epoch 291/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.2262e-04 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9163\n","\n","Epoch 00291: val_accuracy did not improve from 0.94089\n","Epoch 292/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.1116e-04 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9236\n","\n","Epoch 00292: val_accuracy did not improve from 0.94089\n","Epoch 293/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9212\n","\n","Epoch 00293: val_accuracy did not improve from 0.94089\n","Epoch 294/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.8572e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9138\n","\n","Epoch 00294: val_accuracy did not improve from 0.94089\n","Epoch 295/500\n","52/52 [==============================] - 11s 205ms/step - loss: 9.1561e-05 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9212\n","\n","Epoch 00295: val_accuracy did not improve from 0.94089\n","Epoch 296/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.6351e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9236\n","\n","Epoch 00296: val_accuracy did not improve from 0.94089\n","Epoch 297/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1028e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9236\n","\n","Epoch 00297: val_accuracy did not improve from 0.94089\n","Epoch 298/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.1023e-04 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9236\n","\n","Epoch 00298: val_accuracy did not improve from 0.94089\n","Epoch 299/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.4036e-05 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9138\n","\n","Epoch 00299: val_accuracy did not improve from 0.94089\n","Epoch 300/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.8432e-05 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9212\n","\n","Epoch 00300: val_accuracy did not improve from 0.94089\n","Epoch 301/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1546e-04 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9286\n","\n","Epoch 00301: val_accuracy did not improve from 0.94089\n","Epoch 302/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.4559e-04 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9187\n","\n","Epoch 00302: val_accuracy did not improve from 0.94089\n","Epoch 303/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1751e-04 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9335\n","\n","Epoch 00303: val_accuracy did not improve from 0.94089\n","Epoch 304/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.7862e-05 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9187\n","\n","Epoch 00304: val_accuracy did not improve from 0.94089\n","Epoch 305/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.0436e-04 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9286\n","\n","Epoch 00305: val_accuracy did not improve from 0.94089\n","Epoch 306/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1145 - accuracy: 0.9689 - val_loss: 3.5091 - val_accuracy: 0.6379\n","\n","Epoch 00306: val_accuracy did not improve from 0.94089\n","Epoch 307/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.2258 - accuracy: 0.9367 - val_loss: 2.5840 - val_accuracy: 0.6897\n","\n","Epoch 00307: val_accuracy did not improve from 0.94089\n","Epoch 308/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0534 - accuracy: 0.9787 - val_loss: 0.6855 - val_accuracy: 0.8670\n","\n","Epoch 00308: val_accuracy did not improve from 0.94089\n","Epoch 309/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.4884 - val_accuracy: 0.8818\n","\n","Epoch 00309: val_accuracy did not improve from 0.94089\n","Epoch 310/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4059 - val_accuracy: 0.8966\n","\n","Epoch 00310: val_accuracy did not improve from 0.94089\n","Epoch 311/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4576 - val_accuracy: 0.8842\n","\n","Epoch 00311: val_accuracy did not improve from 0.94089\n","Epoch 312/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9138\n","\n","Epoch 00312: val_accuracy did not improve from 0.94089\n","Epoch 313/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3464 - val_accuracy: 0.9286\n","\n","Epoch 00313: val_accuracy did not improve from 0.94089\n","Epoch 314/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3025 - val_accuracy: 0.9483\n","\n","Epoch 00314: val_accuracy improved from 0.94089 to 0.94828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5\n","Epoch 315/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4565 - val_accuracy: 0.9089\n","\n","Epoch 00315: val_accuracy did not improve from 0.94828\n","Epoch 316/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4467 - val_accuracy: 0.9163\n","\n","Epoch 00316: val_accuracy did not improve from 0.94828\n","Epoch 317/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.7260 - val_accuracy: 0.8547\n","\n","Epoch 00317: val_accuracy did not improve from 0.94828\n","Epoch 318/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0492 - accuracy: 0.9909 - val_loss: 1.0266 - val_accuracy: 0.8103\n","\n","Epoch 00318: val_accuracy did not improve from 0.94828\n","Epoch 319/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0190 - accuracy: 0.9915 - val_loss: 0.5214 - val_accuracy: 0.8818\n","\n","Epoch 00319: val_accuracy did not improve from 0.94828\n","Epoch 320/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.4044 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.94828\n","Epoch 321/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.3943 - val_accuracy: 0.9212\n","\n","Epoch 00321: val_accuracy did not improve from 0.94828\n","Epoch 322/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4465 - val_accuracy: 0.9138\n","\n","Epoch 00322: val_accuracy did not improve from 0.94828\n","Epoch 323/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4098 - val_accuracy: 0.9236\n","\n","Epoch 00323: val_accuracy did not improve from 0.94828\n","Epoch 324/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3883 - val_accuracy: 0.9286\n","\n","Epoch 00324: val_accuracy did not improve from 0.94828\n","Epoch 325/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.5248 - val_accuracy: 0.8867\n","\n","Epoch 00325: val_accuracy did not improve from 0.94828\n","Epoch 326/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3704 - val_accuracy: 0.9236\n","\n","Epoch 00326: val_accuracy did not improve from 0.94828\n","Epoch 327/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9335\n","\n","Epoch 00327: val_accuracy did not improve from 0.94828\n","Epoch 328/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9286\n","\n","Epoch 00328: val_accuracy did not improve from 0.94828\n","Epoch 329/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3932 - val_accuracy: 0.9236\n","\n","Epoch 00329: val_accuracy did not improve from 0.94828\n","Epoch 330/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9335\n","\n","Epoch 00330: val_accuracy did not improve from 0.94828\n","Epoch 331/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.3375e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9212\n","\n","Epoch 00331: val_accuracy did not improve from 0.94828\n","Epoch 332/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.7179e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9261\n","\n","Epoch 00332: val_accuracy did not improve from 0.94828\n","Epoch 333/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.2744e-04 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9261\n","\n","Epoch 00333: val_accuracy did not improve from 0.94828\n","Epoch 334/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.4806e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9310\n","\n","Epoch 00334: val_accuracy did not improve from 0.94828\n","Epoch 335/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.5189e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9335\n","\n","Epoch 00335: val_accuracy did not improve from 0.94828\n","Epoch 336/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.8729e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9089\n","\n","Epoch 00336: val_accuracy did not improve from 0.94828\n","Epoch 337/500\n","52/52 [==============================] - 11s 207ms/step - loss: 4.9214e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9310\n","\n","Epoch 00337: val_accuracy did not improve from 0.94828\n","Epoch 338/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.6350e-04 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9187\n","\n","Epoch 00338: val_accuracy did not improve from 0.94828\n","Epoch 339/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.9805e-04 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9236\n","\n","Epoch 00339: val_accuracy did not improve from 0.94828\n","Epoch 340/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6876 - val_accuracy: 0.8867\n","\n","Epoch 00340: val_accuracy did not improve from 0.94828\n","Epoch 341/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1453 - accuracy: 0.9592 - val_loss: 1.4576 - val_accuracy: 0.7956\n","\n","Epoch 00341: val_accuracy did not improve from 0.94828\n","Epoch 342/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0982 - accuracy: 0.9720 - val_loss: 1.9490 - val_accuracy: 0.7685\n","\n","Epoch 00342: val_accuracy did not improve from 0.94828\n","Epoch 343/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.6791 - val_accuracy: 0.8793\n","\n","Epoch 00343: val_accuracy did not improve from 0.94828\n","Epoch 344/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4761 - val_accuracy: 0.9015\n","\n","Epoch 00344: val_accuracy did not improve from 0.94828\n","Epoch 345/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5011 - val_accuracy: 0.9138\n","\n","Epoch 00345: val_accuracy did not improve from 0.94828\n","Epoch 346/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9187\n","\n","Epoch 00346: val_accuracy did not improve from 0.94828\n","Epoch 347/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.3257e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9015\n","\n","Epoch 00347: val_accuracy did not improve from 0.94828\n","Epoch 348/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.1288e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9187\n","\n","Epoch 00348: val_accuracy did not improve from 0.94828\n","Epoch 349/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.6140e-04 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9187\n","\n","Epoch 00349: val_accuracy did not improve from 0.94828\n","Epoch 350/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.7686e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9236\n","\n","Epoch 00350: val_accuracy did not improve from 0.94828\n","Epoch 351/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.7965e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9138\n","\n","Epoch 00351: val_accuracy did not improve from 0.94828\n","Epoch 352/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.2780e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9089\n","\n","Epoch 00352: val_accuracy did not improve from 0.94828\n","Epoch 353/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.8423e-04 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9138\n","\n","Epoch 00353: val_accuracy did not improve from 0.94828\n","Epoch 354/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.4145e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9310\n","\n","Epoch 00354: val_accuracy did not improve from 0.94828\n","Epoch 355/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.4844e-04 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9187\n","\n","Epoch 00355: val_accuracy did not improve from 0.94828\n","Epoch 356/500\n","52/52 [==============================] - 11s 207ms/step - loss: 2.6644e-04 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9187\n","\n","Epoch 00356: val_accuracy did not improve from 0.94828\n","Epoch 357/500\n","52/52 [==============================] - 11s 207ms/step - loss: 3.2574e-04 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9163\n","\n","Epoch 00357: val_accuracy did not improve from 0.94828\n","Epoch 358/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4346 - val_accuracy: 0.9187\n","\n","Epoch 00358: val_accuracy did not improve from 0.94828\n","Epoch 359/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9310\n","\n","Epoch 00359: val_accuracy did not improve from 0.94828\n","Epoch 360/500\n","52/52 [==============================] - 11s 206ms/step - loss: 9.0795e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9138\n","\n","Epoch 00360: val_accuracy did not improve from 0.94828\n","Epoch 361/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4101 - val_accuracy: 0.9236\n","\n","Epoch 00361: val_accuracy did not improve from 0.94828\n","Epoch 362/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0572 - accuracy: 0.9860 - val_loss: 1.3236 - val_accuracy: 0.8202\n","\n","Epoch 00362: val_accuracy did not improve from 0.94828\n","Epoch 363/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0708 - accuracy: 0.9805 - val_loss: 1.4793 - val_accuracy: 0.7488\n","\n","Epoch 00363: val_accuracy did not improve from 0.94828\n","Epoch 364/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.5874 - val_accuracy: 0.8842\n","\n","Epoch 00364: val_accuracy did not improve from 0.94828\n","Epoch 365/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4983 - val_accuracy: 0.8966\n","\n","Epoch 00365: val_accuracy did not improve from 0.94828\n","Epoch 366/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 1.6636 - val_accuracy: 0.7562\n","\n","Epoch 00366: val_accuracy did not improve from 0.94828\n","Epoch 367/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4301 - val_accuracy: 0.9138\n","\n","Epoch 00367: val_accuracy did not improve from 0.94828\n","Epoch 368/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.4966e-04 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9138\n","\n","Epoch 00368: val_accuracy did not improve from 0.94828\n","Epoch 369/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4367 - val_accuracy: 0.9015\n","\n","Epoch 00369: val_accuracy did not improve from 0.94828\n","Epoch 370/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3497 - val_accuracy: 0.9212\n","\n","Epoch 00370: val_accuracy did not improve from 0.94828\n","Epoch 371/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9015\n","\n","Epoch 00371: val_accuracy did not improve from 0.94828\n","Epoch 372/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.7952e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9187\n","\n","Epoch 00372: val_accuracy did not improve from 0.94828\n","Epoch 373/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.3436 - val_accuracy: 0.9261\n","\n","Epoch 00373: val_accuracy did not improve from 0.94828\n","Epoch 374/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 0.5335 - val_accuracy: 0.9039\n","\n","Epoch 00374: val_accuracy did not improve from 0.94828\n","Epoch 375/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4949 - val_accuracy: 0.9064\n","\n","Epoch 00375: val_accuracy did not improve from 0.94828\n","Epoch 376/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9212\n","\n","Epoch 00376: val_accuracy did not improve from 0.94828\n","Epoch 377/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.1937e-04 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9187\n","\n","Epoch 00377: val_accuracy did not improve from 0.94828\n","Epoch 378/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5459 - val_accuracy: 0.8892\n","\n","Epoch 00378: val_accuracy did not improve from 0.94828\n","Epoch 379/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.6549 - val_accuracy: 0.8645\n","\n","Epoch 00379: val_accuracy did not improve from 0.94828\n","Epoch 380/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.7033 - val_accuracy: 0.8670\n","\n","Epoch 00380: val_accuracy did not improve from 0.94828\n","Epoch 381/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.5891 - val_accuracy: 0.8941\n","\n","Epoch 00381: val_accuracy did not improve from 0.94828\n","Epoch 382/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4723 - val_accuracy: 0.8867\n","\n","Epoch 00382: val_accuracy did not improve from 0.94828\n","Epoch 383/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4806 - val_accuracy: 0.9039\n","\n","Epoch 00383: val_accuracy did not improve from 0.94828\n","Epoch 384/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.6208 - val_accuracy: 0.8941\n","\n","Epoch 00384: val_accuracy did not improve from 0.94828\n","Epoch 385/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.9874 - val_accuracy: 0.8374\n","\n","Epoch 00385: val_accuracy did not improve from 0.94828\n","Epoch 386/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.4652 - val_accuracy: 0.8966\n","\n","Epoch 00386: val_accuracy did not improve from 0.94828\n","Epoch 387/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4594 - val_accuracy: 0.9039\n","\n","Epoch 00387: val_accuracy did not improve from 0.94828\n","Epoch 388/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4283 - val_accuracy: 0.9113\n","\n","Epoch 00388: val_accuracy did not improve from 0.94828\n","Epoch 389/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4982 - val_accuracy: 0.9113\n","\n","Epoch 00389: val_accuracy did not improve from 0.94828\n","Epoch 390/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9039\n","\n","Epoch 00390: val_accuracy did not improve from 0.94828\n","Epoch 391/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.5297e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9163\n","\n","Epoch 00391: val_accuracy did not improve from 0.94828\n","Epoch 392/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.4551e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9236\n","\n","Epoch 00392: val_accuracy did not improve from 0.94828\n","Epoch 393/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.1975e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9212\n","\n","Epoch 00393: val_accuracy did not improve from 0.94828\n","Epoch 394/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4675 - val_accuracy: 0.9015\n","\n","Epoch 00394: val_accuracy did not improve from 0.94828\n","Epoch 395/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.8724 - val_accuracy: 0.8670\n","\n","Epoch 00395: val_accuracy did not improve from 0.94828\n","Epoch 396/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0749 - accuracy: 0.9836 - val_loss: 0.9660 - val_accuracy: 0.8374\n","\n","Epoch 00396: val_accuracy did not improve from 0.94828\n","Epoch 397/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.8420 - val_accuracy: 0.8719\n","\n","Epoch 00397: val_accuracy did not improve from 0.94828\n","Epoch 398/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6073 - val_accuracy: 0.9015\n","\n","Epoch 00398: val_accuracy did not improve from 0.94828\n","Epoch 399/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4808 - val_accuracy: 0.9089\n","\n","Epoch 00399: val_accuracy did not improve from 0.94828\n","Epoch 400/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9236\n","\n","Epoch 00400: val_accuracy did not improve from 0.94828\n","Epoch 401/500\n","52/52 [==============================] - 11s 208ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9212\n","\n","Epoch 00401: val_accuracy did not improve from 0.94828\n","Epoch 402/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.6418e-04 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9236\n","\n","Epoch 00402: val_accuracy did not improve from 0.94828\n","Epoch 403/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.5764e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9113\n","\n","Epoch 00403: val_accuracy did not improve from 0.94828\n","Epoch 404/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.2303e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9113\n","\n","Epoch 00404: val_accuracy did not improve from 0.94828\n","Epoch 405/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.2162e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9286\n","\n","Epoch 00405: val_accuracy did not improve from 0.94828\n","Epoch 406/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.4494e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9212\n","\n","Epoch 00406: val_accuracy did not improve from 0.94828\n","Epoch 407/500\n","52/52 [==============================] - 11s 207ms/step - loss: 3.3873e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9163\n","\n","Epoch 00407: val_accuracy did not improve from 0.94828\n","Epoch 408/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.4719e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9187\n","\n","Epoch 00408: val_accuracy did not improve from 0.94828\n","Epoch 409/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.1383e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9163\n","\n","Epoch 00409: val_accuracy did not improve from 0.94828\n","Epoch 410/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.2056e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9187\n","\n","Epoch 00410: val_accuracy did not improve from 0.94828\n","Epoch 411/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.7820e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9187\n","\n","Epoch 00411: val_accuracy did not improve from 0.94828\n","Epoch 412/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.9321e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9236\n","\n","Epoch 00412: val_accuracy did not improve from 0.94828\n","Epoch 413/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.1416e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9261\n","\n","Epoch 00413: val_accuracy did not improve from 0.94828\n","Epoch 414/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.2968e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9163\n","\n","Epoch 00414: val_accuracy did not improve from 0.94828\n","Epoch 415/500\n","52/52 [==============================] - 11s 208ms/step - loss: 1.4698e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9286\n","\n","Epoch 00415: val_accuracy did not improve from 0.94828\n","Epoch 416/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.9345e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9236\n","\n","Epoch 00416: val_accuracy did not improve from 0.94828\n","Epoch 417/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.3780e-04 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9039\n","\n","Epoch 00417: val_accuracy did not improve from 0.94828\n","Epoch 418/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.8140e-04 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9113\n","\n","Epoch 00418: val_accuracy did not improve from 0.94828\n","Epoch 419/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.3008e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9163\n","\n","Epoch 00419: val_accuracy did not improve from 0.94828\n","Epoch 420/500\n","52/52 [==============================] - 11s 207ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5556 - val_accuracy: 0.8990\n","\n","Epoch 00420: val_accuracy did not improve from 0.94828\n","Epoch 421/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.4883 - val_accuracy: 0.9212\n","\n","Epoch 00421: val_accuracy did not improve from 0.94828\n","Epoch 422/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.7849 - val_accuracy: 0.8916\n","\n","Epoch 00422: val_accuracy did not improve from 0.94828\n","Epoch 423/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0685 - accuracy: 0.9799 - val_loss: 1.0734 - val_accuracy: 0.8522\n","\n","Epoch 00423: val_accuracy did not improve from 0.94828\n","Epoch 424/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 1.0960 - val_accuracy: 0.8571\n","\n","Epoch 00424: val_accuracy did not improve from 0.94828\n","Epoch 425/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.4922 - val_accuracy: 0.9064\n","\n","Epoch 00425: val_accuracy did not improve from 0.94828\n","Epoch 426/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5211 - val_accuracy: 0.9138\n","\n","Epoch 00426: val_accuracy did not improve from 0.94828\n","Epoch 427/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5415 - val_accuracy: 0.8990\n","\n","Epoch 00427: val_accuracy did not improve from 0.94828\n","Epoch 428/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5084 - val_accuracy: 0.9039\n","\n","Epoch 00428: val_accuracy did not improve from 0.94828\n","Epoch 429/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5335 - val_accuracy: 0.9064\n","\n","Epoch 00429: val_accuracy did not improve from 0.94828\n","Epoch 430/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.5254 - val_accuracy: 0.9015\n","\n","Epoch 00430: val_accuracy did not improve from 0.94828\n","Epoch 431/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 1.0080 - val_accuracy: 0.8768\n","\n","Epoch 00431: val_accuracy did not improve from 0.94828\n","Epoch 432/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.6958 - val_accuracy: 0.8916\n","\n","Epoch 00432: val_accuracy did not improve from 0.94828\n","Epoch 433/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.9039\n","\n","Epoch 00433: val_accuracy did not improve from 0.94828\n","Epoch 434/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.5019 - val_accuracy: 0.9113\n","\n","Epoch 00434: val_accuracy did not improve from 0.94828\n","Epoch 435/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.7346e-04 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9163\n","\n","Epoch 00435: val_accuracy did not improve from 0.94828\n","Epoch 436/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.8588 - val_accuracy: 0.8670\n","\n","Epoch 00436: val_accuracy did not improve from 0.94828\n","Epoch 437/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4796 - val_accuracy: 0.9138\n","\n","Epoch 00437: val_accuracy did not improve from 0.94828\n","Epoch 438/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.4596e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9113\n","\n","Epoch 00438: val_accuracy did not improve from 0.94828\n","Epoch 439/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.5932 - val_accuracy: 0.9089\n","\n","Epoch 00439: val_accuracy did not improve from 0.94828\n","Epoch 440/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.7982 - val_accuracy: 0.8719\n","\n","Epoch 00440: val_accuracy did not improve from 0.94828\n","Epoch 441/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4665 - val_accuracy: 0.9089\n","\n","Epoch 00441: val_accuracy did not improve from 0.94828\n","Epoch 442/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5041 - val_accuracy: 0.9187\n","\n","Epoch 00442: val_accuracy did not improve from 0.94828\n","Epoch 443/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4885 - val_accuracy: 0.9163\n","\n","Epoch 00443: val_accuracy did not improve from 0.94828\n","Epoch 444/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5861 - val_accuracy: 0.9039\n","\n","Epoch 00444: val_accuracy did not improve from 0.94828\n","Epoch 445/500\n","52/52 [==============================] - 11s 204ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5486 - val_accuracy: 0.8966\n","\n","Epoch 00445: val_accuracy did not improve from 0.94828\n","Epoch 446/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5704 - val_accuracy: 0.9039\n","\n","Epoch 00446: val_accuracy did not improve from 0.94828\n","Epoch 447/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9212\n","\n","Epoch 00447: val_accuracy did not improve from 0.94828\n","Epoch 448/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4487 - val_accuracy: 0.9187\n","\n","Epoch 00448: val_accuracy did not improve from 0.94828\n","Epoch 449/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4020 - val_accuracy: 0.9163\n","\n","Epoch 00449: val_accuracy did not improve from 0.94828\n","Epoch 450/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.3883e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9261\n","\n","Epoch 00450: val_accuracy did not improve from 0.94828\n","Epoch 451/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.5645e-04 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9261\n","\n","Epoch 00451: val_accuracy did not improve from 0.94828\n","Epoch 452/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.7620e-04 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9236\n","\n","Epoch 00452: val_accuracy did not improve from 0.94828\n","Epoch 453/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.7498e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9310\n","\n","Epoch 00453: val_accuracy did not improve from 0.94828\n","Epoch 454/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.8458e-04 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9335\n","\n","Epoch 00454: val_accuracy did not improve from 0.94828\n","Epoch 455/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.1781e-04 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9310\n","\n","Epoch 00455: val_accuracy did not improve from 0.94828\n","Epoch 456/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.5043e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9310\n","\n","Epoch 00456: val_accuracy did not improve from 0.94828\n","Epoch 457/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.5168e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9360\n","\n","Epoch 00457: val_accuracy did not improve from 0.94828\n","Epoch 458/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.4276e-05 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9236\n","\n","Epoch 00458: val_accuracy did not improve from 0.94828\n","Epoch 459/500\n","52/52 [==============================] - 11s 205ms/step - loss: 7.2352e-05 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9261\n","\n","Epoch 00459: val_accuracy did not improve from 0.94828\n","Epoch 460/500\n","52/52 [==============================] - 11s 207ms/step - loss: 8.0390e-05 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.94828\n","Epoch 461/500\n","52/52 [==============================] - 11s 205ms/step - loss: 2.3596e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9138\n","\n","Epoch 00461: val_accuracy did not improve from 0.94828\n","Epoch 462/500\n","52/52 [==============================] - 11s 205ms/step - loss: 1.1978e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9286\n","\n","Epoch 00462: val_accuracy did not improve from 0.94828\n","Epoch 463/500\n","52/52 [==============================] - 11s 205ms/step - loss: 6.2541e-05 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9360\n","\n","Epoch 00463: val_accuracy did not improve from 0.94828\n","Epoch 464/500\n","52/52 [==============================] - 11s 207ms/step - loss: 1.2373e-04 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9286\n","\n","Epoch 00464: val_accuracy did not improve from 0.94828\n","Epoch 465/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.8975e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9187\n","\n","Epoch 00465: val_accuracy did not improve from 0.94828\n","Epoch 466/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.1838e-05 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9236\n","\n","Epoch 00466: val_accuracy did not improve from 0.94828\n","Epoch 467/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.5225e-05 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9335\n","\n","Epoch 00467: val_accuracy did not improve from 0.94828\n","Epoch 468/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.5299e-05 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9286\n","\n","Epoch 00468: val_accuracy did not improve from 0.94828\n","Epoch 469/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3742e-05 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9335\n","\n","Epoch 00469: val_accuracy did not improve from 0.94828\n","Epoch 470/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.6609e-05 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9310\n","\n","Epoch 00470: val_accuracy did not improve from 0.94828\n","Epoch 471/500\n","52/52 [==============================] - 11s 206ms/step - loss: 1.2158e-04 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9310\n","\n","Epoch 00471: val_accuracy did not improve from 0.94828\n","Epoch 472/500\n","52/52 [==============================] - 11s 206ms/step - loss: 8.4829e-05 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9310\n","\n","Epoch 00472: val_accuracy did not improve from 0.94828\n","Epoch 473/500\n","52/52 [==============================] - 11s 206ms/step - loss: 6.7344e-05 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9163\n","\n","Epoch 00473: val_accuracy did not improve from 0.94828\n","Epoch 474/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.8227e-05 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9360\n","\n","Epoch 00474: val_accuracy did not improve from 0.94828\n","Epoch 475/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.9136e-05 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9310\n","\n","Epoch 00475: val_accuracy did not improve from 0.94828\n","Epoch 476/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.1117e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9310\n","\n","Epoch 00476: val_accuracy did not improve from 0.94828\n","Epoch 477/500\n","52/52 [==============================] - 11s 206ms/step - loss: 5.3647e-05 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9310\n","\n","Epoch 00477: val_accuracy did not improve from 0.94828\n","Epoch 478/500\n","52/52 [==============================] - 11s 205ms/step - loss: 3.8148e-05 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9310\n","\n","Epoch 00478: val_accuracy did not improve from 0.94828\n","Epoch 479/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.8570e-05 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9310\n","\n","Epoch 00479: val_accuracy did not improve from 0.94828\n","Epoch 480/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.1749 - accuracy: 0.9543 - val_loss: 2.3422 - val_accuracy: 0.7167\n","\n","Epoch 00480: val_accuracy did not improve from 0.94828\n","Epoch 481/500\n","52/52 [==============================] - 11s 205ms/step - loss: 0.0739 - accuracy: 0.9805 - val_loss: 1.3800 - val_accuracy: 0.8030\n","\n","Epoch 00481: val_accuracy did not improve from 0.94828\n","Epoch 482/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.6168 - val_accuracy: 0.8842\n","\n","Epoch 00482: val_accuracy did not improve from 0.94828\n","Epoch 483/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.5745 - val_accuracy: 0.9064\n","\n","Epoch 00483: val_accuracy did not improve from 0.94828\n","Epoch 484/500\n","52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4645 - val_accuracy: 0.9138\n","\n","Epoch 00484: val_accuracy did not improve from 0.94828\n","Epoch 485/500\n","52/52 [==============================] - 11s 205ms/step - loss: 8.8904e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9138\n","\n","Epoch 00485: val_accuracy did not improve from 0.94828\n","Epoch 486/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.0495e-04 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9113\n","\n","Epoch 00486: val_accuracy did not improve from 0.94828\n","Epoch 487/500\n","52/52 [==============================] - 11s 207ms/step - loss: 6.1314e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9064\n","\n","Epoch 00487: val_accuracy did not improve from 0.94828\n","Epoch 488/500\n","52/52 [==============================] - 11s 207ms/step - loss: 5.7453e-04 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9187\n","\n","Epoch 00488: val_accuracy did not improve from 0.94828\n","Epoch 489/500\n","52/52 [==============================] - 11s 205ms/step - loss: 5.2678e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9039\n","\n","Epoch 00489: val_accuracy did not improve from 0.94828\n","Epoch 490/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.1610e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9138\n","\n","Epoch 00490: val_accuracy did not improve from 0.94828\n","Epoch 491/500\n","52/52 [==============================] - 11s 206ms/step - loss: 7.8737e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9163\n","\n","Epoch 00491: val_accuracy did not improve from 0.94828\n","Epoch 492/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.8562e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9187\n","\n","Epoch 00492: val_accuracy did not improve from 0.94828\n","Epoch 493/500\n","52/52 [==============================] - 11s 206ms/step - loss: 4.8896e-04 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9089\n","\n","Epoch 00493: val_accuracy did not improve from 0.94828\n","Epoch 494/500\n","52/52 [==============================] - 11s 207ms/step - loss: 3.3520e-04 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9089\n","\n","Epoch 00494: val_accuracy did not improve from 0.94828\n","Epoch 495/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.2925e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9212\n","\n","Epoch 00495: val_accuracy did not improve from 0.94828\n","Epoch 496/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.8924e-04 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9138\n","\n","Epoch 00496: val_accuracy did not improve from 0.94828\n","Epoch 497/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.9283e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9138\n","\n","Epoch 00497: val_accuracy did not improve from 0.94828\n","Epoch 498/500\n","52/52 [==============================] - 11s 205ms/step - loss: 4.9259e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9187\n","\n","Epoch 00498: val_accuracy did not improve from 0.94828\n","Epoch 499/500\n","52/52 [==============================] - 11s 206ms/step - loss: 3.2780e-04 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9015\n","\n","Epoch 00499: val_accuracy did not improve from 0.94828\n","Epoch 500/500\n","52/52 [==============================] - 11s 206ms/step - loss: 2.8627e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9212\n","\n","Epoch 00500: val_accuracy did not improve from 0.94828\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd244dc9390>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629806272426,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5366dcb0-667a-4aa9-d0db-cfb6f18276cc"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629806294299,"user_tz":-540,"elapsed":21884,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_00_1_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629806294700,"user_tz":-540,"elapsed":406,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629806295363,"user_tz":-540,"elapsed":679,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"58c54083-a755-477b-fa43-a9e8ee97f685"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629806326005,"user_tz":-540,"elapsed":30646,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"aa72b4cb-25cb-4b9a-e9aa-d679c2c30af5"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629806326005,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629806326006,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629806327309,"user_tz":-540,"elapsed":1314,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629806327310,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629806337956,"user_tz":-540,"elapsed":10650,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629806337970,"user_tz":-540,"elapsed":36,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c5af594a-f446-459f-97fd-aba7c071d7b6"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629806337971,"user_tz":-540,"elapsed":33,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fadaf8c0-464c-4fe6-a4d6-9735fdcb24c3"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_00_1_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_00_1_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_2fc55f15-c9dd-44cd-ae92-7a50071d40c8\", \"Rotation_range_00_1_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}