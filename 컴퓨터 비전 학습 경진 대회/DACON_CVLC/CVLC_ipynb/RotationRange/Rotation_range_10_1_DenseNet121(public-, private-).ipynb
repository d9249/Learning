{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_10_1_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyP2zsS/cYEAcmJ/2MTYEnEB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629825091309,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"250bf5dd-8e68-418d-ab93-4e37853ced35"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 17:11:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629825110311,"user_tz":-540,"elapsed":19008,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a79b03b1-46ae-4e9a-ea41-8e5a69271d60"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629825114019,"user_tz":-540,"elapsed":3715,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629825115669,"user_tz":-540,"elapsed":1661,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629825117440,"user_tz":-540,"elapsed":1776,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629825134239,"user_tz":-540,"elapsed":16801,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629825140667,"user_tz":-540,"elapsed":6440,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629825140668,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a876798d-f9ed-4850-ae98-c1d087545c28"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629825141504,"user_tz":-540,"elapsed":844,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"fb8be7ae-96f3-4a2c-cea2-b684c8c14008"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629825141505,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831789221,"user_tz":-540,"elapsed":6647722,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5907d0da-0c1a-4409-c473-1b6ecde5ce97"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 39s 271ms/step - loss: 1.9024 - accuracy: 0.3295 - val_loss: 33.8863 - val_accuracy: 0.1010\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.1779 - accuracy: 0.6011 - val_loss: 14.6868 - val_accuracy: 0.0887\n","\n","Epoch 00002: val_accuracy did not improve from 0.10099\n","Epoch 3/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.9960 - accuracy: 0.6717 - val_loss: 6.4545 - val_accuracy: 0.0985\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.8420 - accuracy: 0.7241 - val_loss: 5.5657 - val_accuracy: 0.1478\n","\n","Epoch 00004: val_accuracy improved from 0.10099 to 0.14778, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 5/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.7290 - accuracy: 0.7546 - val_loss: 4.6086 - val_accuracy: 0.1700\n","\n","Epoch 00005: val_accuracy improved from 0.14778 to 0.16995, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.6689 - accuracy: 0.7808 - val_loss: 9.3056 - val_accuracy: 0.1305\n","\n","Epoch 00006: val_accuracy did not improve from 0.16995\n","Epoch 7/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.5797 - accuracy: 0.8057 - val_loss: 9.1275 - val_accuracy: 0.1084\n","\n","Epoch 00007: val_accuracy did not improve from 0.16995\n","Epoch 8/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.5804 - accuracy: 0.8082 - val_loss: 4.1209 - val_accuracy: 0.2685\n","\n","Epoch 00008: val_accuracy improved from 0.16995 to 0.26847, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.5053 - accuracy: 0.8343 - val_loss: 2.9567 - val_accuracy: 0.4483\n","\n","Epoch 00009: val_accuracy improved from 0.26847 to 0.44828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.4628 - accuracy: 0.8392 - val_loss: 1.6448 - val_accuracy: 0.6182\n","\n","Epoch 00010: val_accuracy improved from 0.44828 to 0.61823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.4347 - accuracy: 0.8544 - val_loss: 4.6014 - val_accuracy: 0.3300\n","\n","Epoch 00011: val_accuracy did not improve from 0.61823\n","Epoch 12/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.4944 - accuracy: 0.8307 - val_loss: 4.7760 - val_accuracy: 0.3670\n","\n","Epoch 00012: val_accuracy did not improve from 0.61823\n","Epoch 13/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.4889 - accuracy: 0.8362 - val_loss: 17.5647 - val_accuracy: 0.1601\n","\n","Epoch 00013: val_accuracy did not improve from 0.61823\n","Epoch 14/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.4280 - accuracy: 0.8502 - val_loss: 0.9565 - val_accuracy: 0.7143\n","\n","Epoch 00014: val_accuracy improved from 0.61823 to 0.71429, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.4074 - accuracy: 0.8520 - val_loss: 0.6298 - val_accuracy: 0.8153\n","\n","Epoch 00015: val_accuracy improved from 0.71429 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2945 - accuracy: 0.8971 - val_loss: 0.8822 - val_accuracy: 0.7315\n","\n","Epoch 00016: val_accuracy did not improve from 0.81527\n","Epoch 17/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.3221 - accuracy: 0.8971 - val_loss: 1.0344 - val_accuracy: 0.7118\n","\n","Epoch 00017: val_accuracy did not improve from 0.81527\n","Epoch 18/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2676 - accuracy: 0.9111 - val_loss: 0.5903 - val_accuracy: 0.8103\n","\n","Epoch 00018: val_accuracy did not improve from 0.81527\n","Epoch 19/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2781 - accuracy: 0.8995 - val_loss: 0.7843 - val_accuracy: 0.7931\n","\n","Epoch 00019: val_accuracy did not improve from 0.81527\n","Epoch 20/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2300 - accuracy: 0.9233 - val_loss: 0.9418 - val_accuracy: 0.7734\n","\n","Epoch 00020: val_accuracy did not improve from 0.81527\n","Epoch 21/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2977 - accuracy: 0.9032 - val_loss: 0.7963 - val_accuracy: 0.7906\n","\n","Epoch 00021: val_accuracy did not improve from 0.81527\n","Epoch 22/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2571 - accuracy: 0.9178 - val_loss: 0.5525 - val_accuracy: 0.8128\n","\n","Epoch 00022: val_accuracy did not improve from 0.81527\n","Epoch 23/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.2252 - accuracy: 0.9269 - val_loss: 0.7816 - val_accuracy: 0.7956\n","\n","Epoch 00023: val_accuracy did not improve from 0.81527\n","Epoch 24/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2238 - accuracy: 0.9257 - val_loss: 0.5559 - val_accuracy: 0.8399\n","\n","Epoch 00024: val_accuracy improved from 0.81527 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.2075 - accuracy: 0.9281 - val_loss: 0.6186 - val_accuracy: 0.8325\n","\n","Epoch 00025: val_accuracy did not improve from 0.83990\n","Epoch 26/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.5986 - val_accuracy: 0.8227\n","\n","Epoch 00026: val_accuracy did not improve from 0.83990\n","Epoch 27/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1882 - accuracy: 0.9348 - val_loss: 0.9147 - val_accuracy: 0.7537\n","\n","Epoch 00027: val_accuracy did not improve from 0.83990\n","Epoch 28/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1596 - accuracy: 0.9507 - val_loss: 1.3820 - val_accuracy: 0.6970\n","\n","Epoch 00028: val_accuracy did not improve from 0.83990\n","Epoch 29/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1883 - accuracy: 0.9354 - val_loss: 0.9321 - val_accuracy: 0.7931\n","\n","Epoch 00029: val_accuracy did not improve from 0.83990\n","Epoch 30/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1608 - accuracy: 0.9482 - val_loss: 0.5209 - val_accuracy: 0.8202\n","\n","Epoch 00030: val_accuracy did not improve from 0.83990\n","Epoch 31/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1404 - accuracy: 0.9507 - val_loss: 0.5366 - val_accuracy: 0.8424\n","\n","Epoch 00031: val_accuracy improved from 0.83990 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 32/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.2030 - accuracy: 0.9330 - val_loss: 0.9626 - val_accuracy: 0.7586\n","\n","Epoch 00032: val_accuracy did not improve from 0.84236\n","Epoch 33/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1851 - accuracy: 0.9385 - val_loss: 0.5986 - val_accuracy: 0.8300\n","\n","Epoch 00033: val_accuracy did not improve from 0.84236\n","Epoch 34/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1513 - accuracy: 0.9488 - val_loss: 0.8168 - val_accuracy: 0.8202\n","\n","Epoch 00034: val_accuracy did not improve from 0.84236\n","Epoch 35/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1665 - accuracy: 0.9403 - val_loss: 0.5392 - val_accuracy: 0.8448\n","\n","Epoch 00035: val_accuracy improved from 0.84236 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1220 - accuracy: 0.9574 - val_loss: 0.5853 - val_accuracy: 0.8276\n","\n","Epoch 00036: val_accuracy did not improve from 0.84483\n","Epoch 37/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1488 - accuracy: 0.9488 - val_loss: 0.7311 - val_accuracy: 0.8103\n","\n","Epoch 00037: val_accuracy did not improve from 0.84483\n","Epoch 38/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1328 - accuracy: 0.9622 - val_loss: 0.4790 - val_accuracy: 0.8596\n","\n","Epoch 00038: val_accuracy improved from 0.84483 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 39/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1025 - accuracy: 0.9641 - val_loss: 0.4151 - val_accuracy: 0.8867\n","\n","Epoch 00039: val_accuracy improved from 0.85961 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 40/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1166 - accuracy: 0.9641 - val_loss: 1.3657 - val_accuracy: 0.7340\n","\n","Epoch 00040: val_accuracy did not improve from 0.88670\n","Epoch 41/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1797 - accuracy: 0.9385 - val_loss: 0.7555 - val_accuracy: 0.8103\n","\n","Epoch 00041: val_accuracy did not improve from 0.88670\n","Epoch 42/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1280 - accuracy: 0.9598 - val_loss: 1.0892 - val_accuracy: 0.7217\n","\n","Epoch 00042: val_accuracy did not improve from 0.88670\n","Epoch 43/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1230 - accuracy: 0.9574 - val_loss: 0.5738 - val_accuracy: 0.8596\n","\n","Epoch 00043: val_accuracy did not improve from 0.88670\n","Epoch 44/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0923 - accuracy: 0.9677 - val_loss: 0.6975 - val_accuracy: 0.8177\n","\n","Epoch 00044: val_accuracy did not improve from 0.88670\n","Epoch 45/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1185 - accuracy: 0.9653 - val_loss: 0.8734 - val_accuracy: 0.8079\n","\n","Epoch 00045: val_accuracy did not improve from 0.88670\n","Epoch 46/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 0.4692 - val_accuracy: 0.8719\n","\n","Epoch 00046: val_accuracy did not improve from 0.88670\n","Epoch 47/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0622 - accuracy: 0.9817 - val_loss: 0.5767 - val_accuracy: 0.8473\n","\n","Epoch 00047: val_accuracy did not improve from 0.88670\n","Epoch 48/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.3803 - val_accuracy: 0.8719\n","\n","Epoch 00048: val_accuracy did not improve from 0.88670\n","Epoch 49/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0977 - accuracy: 0.9647 - val_loss: 0.4914 - val_accuracy: 0.8768\n","\n","Epoch 00049: val_accuracy did not improve from 0.88670\n","Epoch 50/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1069 - accuracy: 0.9689 - val_loss: 0.8739 - val_accuracy: 0.7882\n","\n","Epoch 00050: val_accuracy did not improve from 0.88670\n","Epoch 51/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0932 - accuracy: 0.9665 - val_loss: 0.5107 - val_accuracy: 0.8793\n","\n","Epoch 00051: val_accuracy did not improve from 0.88670\n","Epoch 52/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0694 - accuracy: 0.9720 - val_loss: 0.4671 - val_accuracy: 0.8719\n","\n","Epoch 00052: val_accuracy did not improve from 0.88670\n","Epoch 53/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0481 - accuracy: 0.9811 - val_loss: 0.5070 - val_accuracy: 0.8719\n","\n","Epoch 00053: val_accuracy did not improve from 0.88670\n","Epoch 54/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1028 - accuracy: 0.9598 - val_loss: 0.5497 - val_accuracy: 0.8522\n","\n","Epoch 00054: val_accuracy did not improve from 0.88670\n","Epoch 55/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0839 - accuracy: 0.9695 - val_loss: 0.8115 - val_accuracy: 0.8103\n","\n","Epoch 00055: val_accuracy did not improve from 0.88670\n","Epoch 56/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1578 - accuracy: 0.9470 - val_loss: 1.1016 - val_accuracy: 0.7586\n","\n","Epoch 00056: val_accuracy did not improve from 0.88670\n","Epoch 57/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1447 - accuracy: 0.9507 - val_loss: 0.5193 - val_accuracy: 0.8867\n","\n","Epoch 00057: val_accuracy did not improve from 0.88670\n","Epoch 58/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0794 - accuracy: 0.9787 - val_loss: 0.6281 - val_accuracy: 0.8498\n","\n","Epoch 00058: val_accuracy did not improve from 0.88670\n","Epoch 59/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 0.4949 - val_accuracy: 0.8670\n","\n","Epoch 00059: val_accuracy did not improve from 0.88670\n","Epoch 60/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0788 - accuracy: 0.9714 - val_loss: 0.5445 - val_accuracy: 0.8424\n","\n","Epoch 00060: val_accuracy did not improve from 0.88670\n","Epoch 61/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0730 - accuracy: 0.9793 - val_loss: 0.5683 - val_accuracy: 0.8842\n","\n","Epoch 00061: val_accuracy did not improve from 0.88670\n","Epoch 62/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0555 - accuracy: 0.9781 - val_loss: 0.5757 - val_accuracy: 0.8670\n","\n","Epoch 00062: val_accuracy did not improve from 0.88670\n","Epoch 63/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0545 - accuracy: 0.9848 - val_loss: 0.3869 - val_accuracy: 0.9015\n","\n","Epoch 00063: val_accuracy improved from 0.88670 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 64/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 0.5911 - val_accuracy: 0.8473\n","\n","Epoch 00064: val_accuracy did not improve from 0.90148\n","Epoch 65/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0902 - accuracy: 0.9689 - val_loss: 1.6692 - val_accuracy: 0.7291\n","\n","Epoch 00065: val_accuracy did not improve from 0.90148\n","Epoch 66/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 0.7790 - val_accuracy: 0.8202\n","\n","Epoch 00066: val_accuracy did not improve from 0.90148\n","Epoch 67/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0833 - accuracy: 0.9726 - val_loss: 0.8073 - val_accuracy: 0.8153\n","\n","Epoch 00067: val_accuracy did not improve from 0.90148\n","Epoch 68/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0832 - accuracy: 0.9714 - val_loss: 0.6234 - val_accuracy: 0.8621\n","\n","Epoch 00068: val_accuracy did not improve from 0.90148\n","Epoch 69/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0818 - accuracy: 0.9702 - val_loss: 0.4969 - val_accuracy: 0.8670\n","\n","Epoch 00069: val_accuracy did not improve from 0.90148\n","Epoch 70/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.3982 - val_accuracy: 0.8966\n","\n","Epoch 00070: val_accuracy did not improve from 0.90148\n","Epoch 71/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.5302 - val_accuracy: 0.8768\n","\n","Epoch 00071: val_accuracy did not improve from 0.90148\n","Epoch 72/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.3973 - val_accuracy: 0.9064\n","\n","Epoch 00072: val_accuracy improved from 0.90148 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 73/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.5228 - val_accuracy: 0.8670\n","\n","Epoch 00073: val_accuracy did not improve from 0.90640\n","Epoch 74/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 0.5146 - val_accuracy: 0.8596\n","\n","Epoch 00074: val_accuracy did not improve from 0.90640\n","Epoch 75/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.5266 - val_accuracy: 0.8768\n","\n","Epoch 00075: val_accuracy did not improve from 0.90640\n","Epoch 76/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0380 - accuracy: 0.9915 - val_loss: 0.4678 - val_accuracy: 0.8867\n","\n","Epoch 00076: val_accuracy did not improve from 0.90640\n","Epoch 77/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0824 - accuracy: 0.9738 - val_loss: 2.7812 - val_accuracy: 0.6133\n","\n","Epoch 00077: val_accuracy did not improve from 0.90640\n","Epoch 78/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0684 - accuracy: 0.9738 - val_loss: 0.8405 - val_accuracy: 0.8448\n","\n","Epoch 00078: val_accuracy did not improve from 0.90640\n","Epoch 79/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1234 - accuracy: 0.9610 - val_loss: 0.7089 - val_accuracy: 0.8473\n","\n","Epoch 00079: val_accuracy did not improve from 0.90640\n","Epoch 80/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.4742 - val_accuracy: 0.8867\n","\n","Epoch 00080: val_accuracy did not improve from 0.90640\n","Epoch 81/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.4329 - val_accuracy: 0.9015\n","\n","Epoch 00081: val_accuracy did not improve from 0.90640\n","Epoch 82/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.4910 - val_accuracy: 0.9064\n","\n","Epoch 00082: val_accuracy did not improve from 0.90640\n","Epoch 83/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 0.5041 - val_accuracy: 0.8916\n","\n","Epoch 00083: val_accuracy did not improve from 0.90640\n","Epoch 84/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.3882 - val_accuracy: 0.9113\n","\n","Epoch 00084: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 85/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.6388 - val_accuracy: 0.8621\n","\n","Epoch 00085: val_accuracy did not improve from 0.91133\n","Epoch 86/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.4755 - val_accuracy: 0.8818\n","\n","Epoch 00086: val_accuracy did not improve from 0.91133\n","Epoch 87/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.7027 - val_accuracy: 0.8399\n","\n","Epoch 00087: val_accuracy did not improve from 0.91133\n","Epoch 88/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.7348 - val_accuracy: 0.8621\n","\n","Epoch 00088: val_accuracy did not improve from 0.91133\n","Epoch 89/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1428 - accuracy: 0.9555 - val_loss: 0.9030 - val_accuracy: 0.8227\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0726 - accuracy: 0.9744 - val_loss: 0.7491 - val_accuracy: 0.8596\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.6024 - val_accuracy: 0.8547\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.5593 - val_accuracy: 0.8867\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.5234 - val_accuracy: 0.8941\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.5480 - val_accuracy: 0.8522\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.5534 - val_accuracy: 0.8793\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0807 - accuracy: 0.9653 - val_loss: 0.6444 - val_accuracy: 0.8448\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0573 - accuracy: 0.9823 - val_loss: 0.8754 - val_accuracy: 0.8300\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0656 - accuracy: 0.9817 - val_loss: 1.0163 - val_accuracy: 0.8103\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0349 - accuracy: 0.9872 - val_loss: 0.6443 - val_accuracy: 0.8473\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.5636 - val_accuracy: 0.8842\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.5872 - val_accuracy: 0.8892\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0388 - accuracy: 0.9915 - val_loss: 0.9785 - val_accuracy: 0.8448\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0681 - accuracy: 0.9708 - val_loss: 0.6166 - val_accuracy: 0.8670\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0632 - accuracy: 0.9805 - val_loss: 0.8547 - val_accuracy: 0.8571\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1080 - accuracy: 0.9659 - val_loss: 0.8847 - val_accuracy: 0.8177\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 0.6491 - val_accuracy: 0.8695\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0925 - accuracy: 0.9702 - val_loss: 0.9509 - val_accuracy: 0.8251\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.6821 - val_accuracy: 0.8571\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.4733 - val_accuracy: 0.8916\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.4896 - val_accuracy: 0.8990\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.5021 - val_accuracy: 0.8990\n","\n","Epoch 00111: val_accuracy did not improve from 0.91133\n","Epoch 112/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.4278 - val_accuracy: 0.9089\n","\n","Epoch 00112: val_accuracy did not improve from 0.91133\n","Epoch 113/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.4880 - val_accuracy: 0.8842\n","\n","Epoch 00113: val_accuracy did not improve from 0.91133\n","Epoch 114/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.5459 - val_accuracy: 0.8793\n","\n","Epoch 00114: val_accuracy did not improve from 0.91133\n","Epoch 115/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4266 - val_accuracy: 0.8941\n","\n","Epoch 00115: val_accuracy did not improve from 0.91133\n","Epoch 116/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.4670 - val_accuracy: 0.9113\n","\n","Epoch 00116: val_accuracy did not improve from 0.91133\n","Epoch 117/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.4769 - val_accuracy: 0.8990\n","\n","Epoch 00117: val_accuracy did not improve from 0.91133\n","Epoch 118/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.4879 - val_accuracy: 0.8892\n","\n","Epoch 00118: val_accuracy did not improve from 0.91133\n","Epoch 119/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.6182 - val_accuracy: 0.8744\n","\n","Epoch 00119: val_accuracy did not improve from 0.91133\n","Epoch 120/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.6014 - val_accuracy: 0.8818\n","\n","Epoch 00120: val_accuracy did not improve from 0.91133\n","Epoch 121/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 0.6018 - val_accuracy: 0.8670\n","\n","Epoch 00121: val_accuracy did not improve from 0.91133\n","Epoch 122/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0302 - accuracy: 0.9860 - val_loss: 0.4681 - val_accuracy: 0.8842\n","\n","Epoch 00122: val_accuracy did not improve from 0.91133\n","Epoch 123/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0364 - accuracy: 0.9854 - val_loss: 0.4842 - val_accuracy: 0.8867\n","\n","Epoch 00123: val_accuracy did not improve from 0.91133\n","Epoch 124/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0464 - accuracy: 0.9866 - val_loss: 0.7617 - val_accuracy: 0.8596\n","\n","Epoch 00124: val_accuracy did not improve from 0.91133\n","Epoch 125/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0548 - accuracy: 0.9817 - val_loss: 0.6014 - val_accuracy: 0.8695\n","\n","Epoch 00125: val_accuracy did not improve from 0.91133\n","Epoch 126/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.6265 - val_accuracy: 0.8818\n","\n","Epoch 00126: val_accuracy did not improve from 0.91133\n","Epoch 127/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.7063 - val_accuracy: 0.8621\n","\n","Epoch 00127: val_accuracy did not improve from 0.91133\n","Epoch 128/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.6540 - val_accuracy: 0.8621\n","\n","Epoch 00128: val_accuracy did not improve from 0.91133\n","Epoch 129/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.6472 - val_accuracy: 0.8768\n","\n","Epoch 00129: val_accuracy did not improve from 0.91133\n","Epoch 130/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.7164 - val_accuracy: 0.8473\n","\n","Epoch 00130: val_accuracy did not improve from 0.91133\n","Epoch 131/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0221 - accuracy: 0.9957 - val_loss: 0.5455 - val_accuracy: 0.8892\n","\n","Epoch 00131: val_accuracy did not improve from 0.91133\n","Epoch 132/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 1.0026 - val_accuracy: 0.8522\n","\n","Epoch 00132: val_accuracy did not improve from 0.91133\n","Epoch 133/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.9485 - val_accuracy: 0.8128\n","\n","Epoch 00133: val_accuracy did not improve from 0.91133\n","Epoch 134/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0465 - accuracy: 0.9866 - val_loss: 0.6092 - val_accuracy: 0.8768\n","\n","Epoch 00134: val_accuracy did not improve from 0.91133\n","Epoch 135/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.4832 - val_accuracy: 0.9064\n","\n","Epoch 00135: val_accuracy did not improve from 0.91133\n","Epoch 136/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.6027 - val_accuracy: 0.8867\n","\n","Epoch 00136: val_accuracy did not improve from 0.91133\n","Epoch 137/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.7288 - val_accuracy: 0.8571\n","\n","Epoch 00137: val_accuracy did not improve from 0.91133\n","Epoch 138/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.5015 - val_accuracy: 0.8768\n","\n","Epoch 00138: val_accuracy did not improve from 0.91133\n","Epoch 139/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0350 - accuracy: 0.9909 - val_loss: 0.9450 - val_accuracy: 0.8350\n","\n","Epoch 00139: val_accuracy did not improve from 0.91133\n","Epoch 140/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5061 - val_accuracy: 0.8842\n","\n","Epoch 00140: val_accuracy did not improve from 0.91133\n","Epoch 141/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.5044 - val_accuracy: 0.9138\n","\n","Epoch 00141: val_accuracy improved from 0.91133 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 142/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.5815 - val_accuracy: 0.8842\n","\n","Epoch 00142: val_accuracy did not improve from 0.91379\n","Epoch 143/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0836 - accuracy: 0.9720 - val_loss: 1.0710 - val_accuracy: 0.8227\n","\n","Epoch 00143: val_accuracy did not improve from 0.91379\n","Epoch 144/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 0.5501 - val_accuracy: 0.8818\n","\n","Epoch 00144: val_accuracy did not improve from 0.91379\n","Epoch 145/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.7275 - val_accuracy: 0.8719\n","\n","Epoch 00145: val_accuracy did not improve from 0.91379\n","Epoch 146/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0642 - accuracy: 0.9769 - val_loss: 0.9680 - val_accuracy: 0.8030\n","\n","Epoch 00146: val_accuracy did not improve from 0.91379\n","Epoch 147/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0619 - accuracy: 0.9823 - val_loss: 0.5838 - val_accuracy: 0.8645\n","\n","Epoch 00147: val_accuracy did not improve from 0.91379\n","Epoch 148/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.5815 - val_accuracy: 0.8719\n","\n","Epoch 00148: val_accuracy did not improve from 0.91379\n","Epoch 149/500\n","52/52 [==============================] - 12s 238ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.5204 - val_accuracy: 0.8892\n","\n","Epoch 00149: val_accuracy did not improve from 0.91379\n","Epoch 150/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0159 - accuracy: 0.9921 - val_loss: 0.5086 - val_accuracy: 0.9089\n","\n","Epoch 00150: val_accuracy did not improve from 0.91379\n","Epoch 151/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5426 - val_accuracy: 0.8867\n","\n","Epoch 00151: val_accuracy did not improve from 0.91379\n","Epoch 152/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4615 - val_accuracy: 0.8916\n","\n","Epoch 00152: val_accuracy did not improve from 0.91379\n","Epoch 153/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4762 - val_accuracy: 0.9039\n","\n","Epoch 00153: val_accuracy did not improve from 0.91379\n","Epoch 154/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.5553 - val_accuracy: 0.8842\n","\n","Epoch 00154: val_accuracy did not improve from 0.91379\n","Epoch 155/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.6229 - val_accuracy: 0.8842\n","\n","Epoch 00155: val_accuracy did not improve from 0.91379\n","Epoch 156/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.7754 - val_accuracy: 0.8621\n","\n","Epoch 00156: val_accuracy did not improve from 0.91379\n","Epoch 157/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0678 - accuracy: 0.9811 - val_loss: 0.8131 - val_accuracy: 0.8621\n","\n","Epoch 00157: val_accuracy did not improve from 0.91379\n","Epoch 158/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.6330 - val_accuracy: 0.8768\n","\n","Epoch 00158: val_accuracy did not improve from 0.91379\n","Epoch 159/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0125 - accuracy: 0.9988 - val_loss: 0.4146 - val_accuracy: 0.9187\n","\n","Epoch 00159: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 160/500\n","52/52 [==============================] - 11s 223ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5393 - val_accuracy: 0.9039\n","\n","Epoch 00160: val_accuracy did not improve from 0.91872\n","Epoch 161/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4753 - val_accuracy: 0.9039\n","\n","Epoch 00161: val_accuracy did not improve from 0.91872\n","Epoch 162/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4901 - val_accuracy: 0.9064\n","\n","Epoch 00162: val_accuracy did not improve from 0.91872\n","Epoch 163/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.8653 - val_accuracy: 0.8571\n","\n","Epoch 00163: val_accuracy did not improve from 0.91872\n","Epoch 164/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.8330 - val_accuracy: 0.8645\n","\n","Epoch 00164: val_accuracy did not improve from 0.91872\n","Epoch 165/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0466 - accuracy: 0.9872 - val_loss: 0.8096 - val_accuracy: 0.8399\n","\n","Epoch 00165: val_accuracy did not improve from 0.91872\n","Epoch 166/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 1.1057 - val_accuracy: 0.8005\n","\n","Epoch 00166: val_accuracy did not improve from 0.91872\n","Epoch 167/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1087 - accuracy: 0.9665 - val_loss: 1.0130 - val_accuracy: 0.8300\n","\n","Epoch 00167: val_accuracy did not improve from 0.91872\n","Epoch 168/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0394 - accuracy: 0.9866 - val_loss: 0.7589 - val_accuracy: 0.8571\n","\n","Epoch 00168: val_accuracy did not improve from 0.91872\n","Epoch 169/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.4361 - val_accuracy: 0.9039\n","\n","Epoch 00169: val_accuracy did not improve from 0.91872\n","Epoch 170/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4044 - val_accuracy: 0.8966\n","\n","Epoch 00170: val_accuracy did not improve from 0.91872\n","Epoch 171/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6224 - val_accuracy: 0.8768\n","\n","Epoch 00171: val_accuracy did not improve from 0.91872\n","Epoch 172/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4104 - val_accuracy: 0.9039\n","\n","Epoch 00172: val_accuracy did not improve from 0.91872\n","Epoch 173/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.5298 - val_accuracy: 0.8818\n","\n","Epoch 00173: val_accuracy did not improve from 0.91872\n","Epoch 174/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.6510 - val_accuracy: 0.8793\n","\n","Epoch 00174: val_accuracy did not improve from 0.91872\n","Epoch 175/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0443 - accuracy: 0.9878 - val_loss: 0.7966 - val_accuracy: 0.8645\n","\n","Epoch 00175: val_accuracy did not improve from 0.91872\n","Epoch 176/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 1.1770 - val_accuracy: 0.8054\n","\n","Epoch 00176: val_accuracy did not improve from 0.91872\n","Epoch 177/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.6305 - val_accuracy: 0.8695\n","\n","Epoch 00177: val_accuracy did not improve from 0.91872\n","Epoch 178/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.5970 - val_accuracy: 0.8966\n","\n","Epoch 00178: val_accuracy did not improve from 0.91872\n","Epoch 179/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.5493 - val_accuracy: 0.8793\n","\n","Epoch 00179: val_accuracy did not improve from 0.91872\n","Epoch 180/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.3630 - val_accuracy: 0.9138\n","\n","Epoch 00180: val_accuracy did not improve from 0.91872\n","Epoch 181/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.3961 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.91872\n","Epoch 182/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8966\n","\n","Epoch 00182: val_accuracy did not improve from 0.91872\n","Epoch 183/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.5034 - val_accuracy: 0.9039\n","\n","Epoch 00183: val_accuracy did not improve from 0.91872\n","Epoch 184/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.6836 - val_accuracy: 0.8867\n","\n","Epoch 00184: val_accuracy did not improve from 0.91872\n","Epoch 185/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6760 - val_accuracy: 0.8670\n","\n","Epoch 00185: val_accuracy did not improve from 0.91872\n","Epoch 186/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.7514 - val_accuracy: 0.8793\n","\n","Epoch 00186: val_accuracy did not improve from 0.91872\n","Epoch 187/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.5738 - val_accuracy: 0.8842\n","\n","Epoch 00187: val_accuracy did not improve from 0.91872\n","Epoch 188/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 0.5711 - val_accuracy: 0.8916\n","\n","Epoch 00188: val_accuracy did not improve from 0.91872\n","Epoch 189/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.7486 - val_accuracy: 0.8892\n","\n","Epoch 00189: val_accuracy did not improve from 0.91872\n","Epoch 190/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.9254 - val_accuracy: 0.8251\n","\n","Epoch 00190: val_accuracy did not improve from 0.91872\n","Epoch 191/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 2.1668 - val_accuracy: 0.7463\n","\n","Epoch 00191: val_accuracy did not improve from 0.91872\n","Epoch 192/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.6692 - val_accuracy: 0.8941\n","\n","Epoch 00192: val_accuracy did not improve from 0.91872\n","Epoch 193/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.5533 - val_accuracy: 0.8818\n","\n","Epoch 00193: val_accuracy did not improve from 0.91872\n","Epoch 194/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0089 - accuracy: 0.9957 - val_loss: 0.4884 - val_accuracy: 0.9089\n","\n","Epoch 00194: val_accuracy did not improve from 0.91872\n","Epoch 195/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4390 - val_accuracy: 0.9089\n","\n","Epoch 00195: val_accuracy did not improve from 0.91872\n","Epoch 196/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9015\n","\n","Epoch 00196: val_accuracy did not improve from 0.91872\n","Epoch 197/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9236\n","\n","Epoch 00197: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 198/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4818 - val_accuracy: 0.9089\n","\n","Epoch 00198: val_accuracy did not improve from 0.92365\n","Epoch 199/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9187\n","\n","Epoch 00199: val_accuracy did not improve from 0.92365\n","Epoch 200/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9064\n","\n","Epoch 00200: val_accuracy did not improve from 0.92365\n","Epoch 201/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4211 - val_accuracy: 0.9236\n","\n","Epoch 00201: val_accuracy did not improve from 0.92365\n","Epoch 202/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9286\n","\n","Epoch 00202: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 203/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.2770e-04 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9286\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6511 - val_accuracy: 0.8867\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3699 - val_accuracy: 0.9310\n","\n","Epoch 00205: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5\n","Epoch 206/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9212\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.6204 - val_accuracy: 0.8867\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.6383 - val_accuracy: 0.8941\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0342 - accuracy: 0.9872 - val_loss: 0.9223 - val_accuracy: 0.8325\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.7916 - val_accuracy: 0.8621\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.6431 - val_accuracy: 0.8842\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.4766 - val_accuracy: 0.9064\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.5214 - val_accuracy: 0.8867\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.7146 - val_accuracy: 0.8670\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.8525 - val_accuracy: 0.8571\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0415 - accuracy: 0.9860 - val_loss: 0.8664 - val_accuracy: 0.8596\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0228 - accuracy: 0.9896 - val_loss: 0.6071 - val_accuracy: 0.9039\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.5415 - val_accuracy: 0.8966\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.5701 - val_accuracy: 0.8695\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.3952 - val_accuracy: 0.9089\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9015\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3902 - val_accuracy: 0.9261\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3722 - val_accuracy: 0.8990\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9138\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9064\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9163\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3984 - val_accuracy: 0.9113\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.4903 - val_accuracy: 0.9064\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.4099 - val_accuracy: 0.9113\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6137 - val_accuracy: 0.8719\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0543 - accuracy: 0.9884 - val_loss: 1.3378 - val_accuracy: 0.8128\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0299 - accuracy: 0.9884 - val_loss: 0.8435 - val_accuracy: 0.8424\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0388 - accuracy: 0.9896 - val_loss: 0.7409 - val_accuracy: 0.8867\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.6269 - val_accuracy: 0.8842\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4459 - val_accuracy: 0.9064\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4040 - val_accuracy: 0.9089\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4949 - val_accuracy: 0.9015\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.4522 - val_accuracy: 0.9015\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.4670 - val_accuracy: 0.9015\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4398 - val_accuracy: 0.9138\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4322 - val_accuracy: 0.9163\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 1.5932 - val_accuracy: 0.7537\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1243 - accuracy: 0.9708 - val_loss: 1.0289 - val_accuracy: 0.8350\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.8925 - val_accuracy: 0.8473\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.6910 - val_accuracy: 0.8695\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0237 - accuracy: 0.9896 - val_loss: 1.0153 - val_accuracy: 0.8473\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.7246 - val_accuracy: 0.8670\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.4887 - val_accuracy: 0.9089\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.6749 - val_accuracy: 0.8670\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.6160 - val_accuracy: 0.8916\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.6121 - val_accuracy: 0.8719\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5960 - val_accuracy: 0.8842\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4754 - val_accuracy: 0.9039\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9138\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4628 - val_accuracy: 0.8966\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4716 - val_accuracy: 0.9064\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4361 - val_accuracy: 0.9064\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4913 - val_accuracy: 0.8990\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5037 - val_accuracy: 0.8892\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0604 - accuracy: 0.9823 - val_loss: 0.5982 - val_accuracy: 0.9039\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.7302 - val_accuracy: 0.8719\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.7034 - val_accuracy: 0.8695\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.6754 - val_accuracy: 0.8719\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.5898 - val_accuracy: 0.9039\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5367 - val_accuracy: 0.9039\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.5260 - val_accuracy: 0.8916\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 0.7507 - val_accuracy: 0.8350\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.6373 - val_accuracy: 0.8571\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4927 - val_accuracy: 0.9089\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 0.8990\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9064\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.6294e-04 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9064\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 12s 220ms/step - loss: 9.6440e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9089\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4240 - val_accuracy: 0.9163\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9039\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 12s 220ms/step - loss: 6.8573e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9236\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5039 - val_accuracy: 0.9064\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5190 - val_accuracy: 0.9089\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5420 - val_accuracy: 0.8966\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 11s 220ms/step - loss: 7.1871e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9064\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4591 - val_accuracy: 0.9187\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6015 - val_accuracy: 0.8966\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7172 - val_accuracy: 0.8768\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5787 - val_accuracy: 0.9064\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0960 - accuracy: 0.9738 - val_loss: 5.8045 - val_accuracy: 0.5074\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0901 - accuracy: 0.9793 - val_loss: 0.8583 - val_accuracy: 0.8522\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.5267 - val_accuracy: 0.9064\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5790 - val_accuracy: 0.8768\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.6728 - val_accuracy: 0.9015\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.9360 - val_accuracy: 0.8596\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.4444 - val_accuracy: 0.9138\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 0.6576 - val_accuracy: 0.8596\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.6300 - val_accuracy: 0.8842\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.3796 - val_accuracy: 0.9212\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4567 - val_accuracy: 0.9163\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.5404 - val_accuracy: 0.8916\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.8228 - val_accuracy: 0.8892\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.5898 - val_accuracy: 0.8966\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.4913 - val_accuracy: 0.9138\n","\n","Epoch 00299: val_accuracy did not improve from 0.93103\n","Epoch 300/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5042 - val_accuracy: 0.9089\n","\n","Epoch 00300: val_accuracy did not improve from 0.93103\n","Epoch 301/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5857 - val_accuracy: 0.9039\n","\n","Epoch 00301: val_accuracy did not improve from 0.93103\n","Epoch 302/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5502 - val_accuracy: 0.8818\n","\n","Epoch 00302: val_accuracy did not improve from 0.93103\n","Epoch 303/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4798 - val_accuracy: 0.8966\n","\n","Epoch 00303: val_accuracy did not improve from 0.93103\n","Epoch 304/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5467 - val_accuracy: 0.8867\n","\n","Epoch 00304: val_accuracy did not improve from 0.93103\n","Epoch 305/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4868 - val_accuracy: 0.9064\n","\n","Epoch 00305: val_accuracy did not improve from 0.93103\n","Epoch 306/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5941 - val_accuracy: 0.8695\n","\n","Epoch 00306: val_accuracy did not improve from 0.93103\n","Epoch 307/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5866 - val_accuracy: 0.8941\n","\n","Epoch 00307: val_accuracy did not improve from 0.93103\n","Epoch 308/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.6420e-04 - accuracy: 1.0000 - val_loss: 0.5688 - val_accuracy: 0.8941\n","\n","Epoch 00308: val_accuracy did not improve from 0.93103\n","Epoch 309/500\n","52/52 [==============================] - 12s 220ms/step - loss: 4.9110e-04 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.9064\n","\n","Epoch 00309: val_accuracy did not improve from 0.93103\n","Epoch 310/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5081 - val_accuracy: 0.9138\n","\n","Epoch 00310: val_accuracy did not improve from 0.93103\n","Epoch 311/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4621 - val_accuracy: 0.9138\n","\n","Epoch 00311: val_accuracy did not improve from 0.93103\n","Epoch 312/500\n","52/52 [==============================] - 12s 220ms/step - loss: 6.1578e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9163\n","\n","Epoch 00312: val_accuracy did not improve from 0.93103\n","Epoch 313/500\n","52/52 [==============================] - 13s 241ms/step - loss: 7.6040e-04 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.9113\n","\n","Epoch 00313: val_accuracy did not improve from 0.93103\n","Epoch 314/500\n","52/52 [==============================] - 12s 221ms/step - loss: 8.3910e-04 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.9064\n","\n","Epoch 00314: val_accuracy did not improve from 0.93103\n","Epoch 315/500\n","52/52 [==============================] - 12s 224ms/step - loss: 4.9004e-04 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.9039\n","\n","Epoch 00315: val_accuracy did not improve from 0.93103\n","Epoch 316/500\n","52/52 [==============================] - 12s 223ms/step - loss: 5.2109e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9163\n","\n","Epoch 00316: val_accuracy did not improve from 0.93103\n","Epoch 317/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.7228e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9187\n","\n","Epoch 00317: val_accuracy did not improve from 0.93103\n","Epoch 318/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.2095e-04 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9015\n","\n","Epoch 00318: val_accuracy did not improve from 0.93103\n","Epoch 319/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.5298e-04 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8916\n","\n","Epoch 00319: val_accuracy did not improve from 0.93103\n","Epoch 320/500\n","52/52 [==============================] - 12s 220ms/step - loss: 6.7355e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.93103\n","Epoch 321/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.9556e-04 - accuracy: 0.9994 - val_loss: 0.5043 - val_accuracy: 0.9138\n","\n","Epoch 00321: val_accuracy did not improve from 0.93103\n","Epoch 322/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.7336 - val_accuracy: 0.8793\n","\n","Epoch 00322: val_accuracy did not improve from 0.93103\n","Epoch 323/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0091 - accuracy: 0.9957 - val_loss: 1.1942 - val_accuracy: 0.8325\n","\n","Epoch 00323: val_accuracy did not improve from 0.93103\n","Epoch 324/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0447 - accuracy: 0.9878 - val_loss: 0.8773 - val_accuracy: 0.8793\n","\n","Epoch 00324: val_accuracy did not improve from 0.93103\n","Epoch 325/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.8994 - val_accuracy: 0.8448\n","\n","Epoch 00325: val_accuracy did not improve from 0.93103\n","Epoch 326/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0772 - accuracy: 0.9787 - val_loss: 1.0334 - val_accuracy: 0.8276\n","\n","Epoch 00326: val_accuracy did not improve from 0.93103\n","Epoch 327/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0769 - accuracy: 0.9787 - val_loss: 1.3341 - val_accuracy: 0.8128\n","\n","Epoch 00327: val_accuracy did not improve from 0.93103\n","Epoch 328/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.7267 - val_accuracy: 0.8768\n","\n","Epoch 00328: val_accuracy did not improve from 0.93103\n","Epoch 329/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.6482 - val_accuracy: 0.8695\n","\n","Epoch 00329: val_accuracy did not improve from 0.93103\n","Epoch 330/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5499 - val_accuracy: 0.9064\n","\n","Epoch 00330: val_accuracy did not improve from 0.93103\n","Epoch 331/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5551 - val_accuracy: 0.9039\n","\n","Epoch 00331: val_accuracy did not improve from 0.93103\n","Epoch 332/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0096 - accuracy: 0.9951 - val_loss: 0.5360 - val_accuracy: 0.8916\n","\n","Epoch 00332: val_accuracy did not improve from 0.93103\n","Epoch 333/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5532 - val_accuracy: 0.8842\n","\n","Epoch 00333: val_accuracy did not improve from 0.93103\n","Epoch 334/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5569 - val_accuracy: 0.8990\n","\n","Epoch 00334: val_accuracy did not improve from 0.93103\n","Epoch 335/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.8563 - val_accuracy: 0.8596\n","\n","Epoch 00335: val_accuracy did not improve from 0.93103\n","Epoch 336/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.6104 - val_accuracy: 0.8842\n","\n","Epoch 00336: val_accuracy did not improve from 0.93103\n","Epoch 337/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0548 - accuracy: 0.9884 - val_loss: 3.0482 - val_accuracy: 0.6207\n","\n","Epoch 00337: val_accuracy did not improve from 0.93103\n","Epoch 338/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0669 - accuracy: 0.9787 - val_loss: 1.2319 - val_accuracy: 0.8300\n","\n","Epoch 00338: val_accuracy did not improve from 0.93103\n","Epoch 339/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0612 - accuracy: 0.9860 - val_loss: 0.7408 - val_accuracy: 0.8695\n","\n","Epoch 00339: val_accuracy did not improve from 0.93103\n","Epoch 340/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.4290 - val_accuracy: 0.9163\n","\n","Epoch 00340: val_accuracy did not improve from 0.93103\n","Epoch 341/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4629 - val_accuracy: 0.8990\n","\n","Epoch 00341: val_accuracy did not improve from 0.93103\n","Epoch 342/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4590 - val_accuracy: 0.8990\n","\n","Epoch 00342: val_accuracy did not improve from 0.93103\n","Epoch 343/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.4856 - val_accuracy: 0.9089\n","\n","Epoch 00343: val_accuracy did not improve from 0.93103\n","Epoch 344/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4971 - val_accuracy: 0.8966\n","\n","Epoch 00344: val_accuracy did not improve from 0.93103\n","Epoch 345/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4606 - val_accuracy: 0.9039\n","\n","Epoch 00345: val_accuracy did not improve from 0.93103\n","Epoch 346/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4904 - val_accuracy: 0.8990\n","\n","Epoch 00346: val_accuracy did not improve from 0.93103\n","Epoch 347/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3488 - val_accuracy: 0.9261\n","\n","Epoch 00347: val_accuracy did not improve from 0.93103\n","Epoch 348/500\n","52/52 [==============================] - 12s 221ms/step - loss: 9.5557e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9015\n","\n","Epoch 00348: val_accuracy did not improve from 0.93103\n","Epoch 349/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.6774e-04 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9113\n","\n","Epoch 00349: val_accuracy did not improve from 0.93103\n","Epoch 350/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.2231e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9064\n","\n","Epoch 00350: val_accuracy did not improve from 0.93103\n","Epoch 351/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5055 - val_accuracy: 0.9039\n","\n","Epoch 00351: val_accuracy did not improve from 0.93103\n","Epoch 352/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0312 - accuracy: 0.9927 - val_loss: 0.5541 - val_accuracy: 0.8793\n","\n","Epoch 00352: val_accuracy did not improve from 0.93103\n","Epoch 353/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.7965 - val_accuracy: 0.8571\n","\n","Epoch 00353: val_accuracy did not improve from 0.93103\n","Epoch 354/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 0.6228 - val_accuracy: 0.8892\n","\n","Epoch 00354: val_accuracy did not improve from 0.93103\n","Epoch 355/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.5760 - val_accuracy: 0.8966\n","\n","Epoch 00355: val_accuracy did not improve from 0.93103\n","Epoch 356/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5361 - val_accuracy: 0.9113\n","\n","Epoch 00356: val_accuracy did not improve from 0.93103\n","Epoch 357/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5340 - val_accuracy: 0.9113\n","\n","Epoch 00357: val_accuracy did not improve from 0.93103\n","Epoch 358/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4518 - val_accuracy: 0.9163\n","\n","Epoch 00358: val_accuracy did not improve from 0.93103\n","Epoch 359/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.5124e-04 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9089\n","\n","Epoch 00359: val_accuracy did not improve from 0.93103\n","Epoch 360/500\n","52/52 [==============================] - 12s 225ms/step - loss: 6.4075e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9064\n","\n","Epoch 00360: val_accuracy did not improve from 0.93103\n","Epoch 361/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.6698e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9138\n","\n","Epoch 00361: val_accuracy did not improve from 0.93103\n","Epoch 362/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4227 - val_accuracy: 0.9138\n","\n","Epoch 00362: val_accuracy did not improve from 0.93103\n","Epoch 363/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5452 - val_accuracy: 0.9089\n","\n","Epoch 00363: val_accuracy did not improve from 0.93103\n","Epoch 364/500\n","52/52 [==============================] - 12s 223ms/step - loss: 9.9299e-04 - accuracy: 1.0000 - val_loss: 0.5622 - val_accuracy: 0.9015\n","\n","Epoch 00364: val_accuracy did not improve from 0.93103\n","Epoch 365/500\n","52/52 [==============================] - 12s 220ms/step - loss: 4.5094e-04 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9113\n","\n","Epoch 00365: val_accuracy did not improve from 0.93103\n","Epoch 366/500\n","52/52 [==============================] - 12s 222ms/step - loss: 8.5655e-04 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9163\n","\n","Epoch 00366: val_accuracy did not improve from 0.93103\n","Epoch 367/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.7046e-04 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.9064\n","\n","Epoch 00367: val_accuracy did not improve from 0.93103\n","Epoch 368/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5096 - val_accuracy: 0.9187\n","\n","Epoch 00368: val_accuracy did not improve from 0.93103\n","Epoch 369/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9064\n","\n","Epoch 00369: val_accuracy did not improve from 0.93103\n","Epoch 370/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4924 - val_accuracy: 0.9039\n","\n","Epoch 00370: val_accuracy did not improve from 0.93103\n","Epoch 371/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.7970e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.8941\n","\n","Epoch 00371: val_accuracy did not improve from 0.93103\n","Epoch 372/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.3185e-04 - accuracy: 1.0000 - val_loss: 0.5862 - val_accuracy: 0.9015\n","\n","Epoch 00372: val_accuracy did not improve from 0.93103\n","Epoch 373/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0174 - accuracy: 0.9921 - val_loss: 0.8519 - val_accuracy: 0.8522\n","\n","Epoch 00373: val_accuracy did not improve from 0.93103\n","Epoch 374/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.7291 - val_accuracy: 0.8596\n","\n","Epoch 00374: val_accuracy did not improve from 0.93103\n","Epoch 375/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.7339 - val_accuracy: 0.8719\n","\n","Epoch 00375: val_accuracy did not improve from 0.93103\n","Epoch 376/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7760 - val_accuracy: 0.8719\n","\n","Epoch 00376: val_accuracy did not improve from 0.93103\n","Epoch 377/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.9949 - val_accuracy: 0.8399\n","\n","Epoch 00377: val_accuracy did not improve from 0.93103\n","Epoch 378/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.5366 - val_accuracy: 0.8941\n","\n","Epoch 00378: val_accuracy did not improve from 0.93103\n","Epoch 379/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.5096 - val_accuracy: 0.9015\n","\n","Epoch 00379: val_accuracy did not improve from 0.93103\n","Epoch 380/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.6638 - val_accuracy: 0.8719\n","\n","Epoch 00380: val_accuracy did not improve from 0.93103\n","Epoch 381/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.6841 - val_accuracy: 0.8818\n","\n","Epoch 00381: val_accuracy did not improve from 0.93103\n","Epoch 382/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.5336 - val_accuracy: 0.8867\n","\n","Epoch 00382: val_accuracy did not improve from 0.93103\n","Epoch 383/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6115 - val_accuracy: 0.8990\n","\n","Epoch 00383: val_accuracy did not improve from 0.93103\n","Epoch 384/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.8941\n","\n","Epoch 00384: val_accuracy did not improve from 0.93103\n","Epoch 385/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5288 - val_accuracy: 0.9064\n","\n","Epoch 00385: val_accuracy did not improve from 0.93103\n","Epoch 386/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9138\n","\n","Epoch 00386: val_accuracy did not improve from 0.93103\n","Epoch 387/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.4378e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9039\n","\n","Epoch 00387: val_accuracy did not improve from 0.93103\n","Epoch 388/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.6838 - val_accuracy: 0.8867\n","\n","Epoch 00388: val_accuracy did not improve from 0.93103\n","Epoch 389/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4987 - val_accuracy: 0.8966\n","\n","Epoch 00389: val_accuracy did not improve from 0.93103\n","Epoch 390/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.6729 - val_accuracy: 0.8793\n","\n","Epoch 00390: val_accuracy did not improve from 0.93103\n","Epoch 391/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.6958 - val_accuracy: 0.8818\n","\n","Epoch 00391: val_accuracy did not improve from 0.93103\n","Epoch 392/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5077 - val_accuracy: 0.9015\n","\n","Epoch 00392: val_accuracy did not improve from 0.93103\n","Epoch 393/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6007 - val_accuracy: 0.9064\n","\n","Epoch 00393: val_accuracy did not improve from 0.93103\n","Epoch 394/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6047 - val_accuracy: 0.8990\n","\n","Epoch 00394: val_accuracy did not improve from 0.93103\n","Epoch 395/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8916\n","\n","Epoch 00395: val_accuracy did not improve from 0.93103\n","Epoch 396/500\n","52/52 [==============================] - 12s 221ms/step - loss: 6.7272e-04 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9163\n","\n","Epoch 00396: val_accuracy did not improve from 0.93103\n","Epoch 397/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.0691e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9039\n","\n","Epoch 00397: val_accuracy did not improve from 0.93103\n","Epoch 398/500\n","52/52 [==============================] - 12s 221ms/step - loss: 9.8169e-04 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.9064\n","\n","Epoch 00398: val_accuracy did not improve from 0.93103\n","Epoch 399/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.3254e-04 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8966\n","\n","Epoch 00399: val_accuracy did not improve from 0.93103\n","Epoch 400/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.2695e-04 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.9113\n","\n","Epoch 00400: val_accuracy did not improve from 0.93103\n","Epoch 401/500\n","52/52 [==============================] - 12s 223ms/step - loss: 7.6301e-04 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8941\n","\n","Epoch 00401: val_accuracy did not improve from 0.93103\n","Epoch 402/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.4621e-04 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.9039\n","\n","Epoch 00402: val_accuracy did not improve from 0.93103\n","Epoch 403/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.2120e-04 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8892\n","\n","Epoch 00403: val_accuracy did not improve from 0.93103\n","Epoch 404/500\n","52/52 [==============================] - 12s 222ms/step - loss: 5.6146e-04 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.9113\n","\n","Epoch 00404: val_accuracy did not improve from 0.93103\n","Epoch 405/500\n","52/52 [==============================] - 12s 226ms/step - loss: 1.3730e-04 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.9039\n","\n","Epoch 00405: val_accuracy did not improve from 0.93103\n","Epoch 406/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.3586e-04 - accuracy: 1.0000 - val_loss: 0.5792 - val_accuracy: 0.8941\n","\n","Epoch 00406: val_accuracy did not improve from 0.93103\n","Epoch 407/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.6393e-04 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.8990\n","\n","Epoch 00407: val_accuracy did not improve from 0.93103\n","Epoch 408/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 1.0424 - val_accuracy: 0.8448\n","\n","Epoch 00408: val_accuracy did not improve from 0.93103\n","Epoch 409/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 1.1024 - val_accuracy: 0.8596\n","\n","Epoch 00409: val_accuracy did not improve from 0.93103\n","Epoch 410/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 1.0112 - val_accuracy: 0.8522\n","\n","Epoch 00410: val_accuracy did not improve from 0.93103\n","Epoch 411/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0649 - accuracy: 0.9836 - val_loss: 0.6936 - val_accuracy: 0.8768\n","\n","Epoch 00411: val_accuracy did not improve from 0.93103\n","Epoch 412/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.4402 - val_accuracy: 0.8941\n","\n","Epoch 00412: val_accuracy did not improve from 0.93103\n","Epoch 413/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.8573 - val_accuracy: 0.8571\n","\n","Epoch 00413: val_accuracy did not improve from 0.93103\n","Epoch 414/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.5892 - val_accuracy: 0.8793\n","\n","Epoch 00414: val_accuracy did not improve from 0.93103\n","Epoch 415/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5157 - val_accuracy: 0.9015\n","\n","Epoch 00415: val_accuracy did not improve from 0.93103\n","Epoch 416/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6042 - val_accuracy: 0.8892\n","\n","Epoch 00416: val_accuracy did not improve from 0.93103\n","Epoch 417/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4661 - val_accuracy: 0.9236\n","\n","Epoch 00417: val_accuracy did not improve from 0.93103\n","Epoch 418/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.6067 - val_accuracy: 0.9015\n","\n","Epoch 00418: val_accuracy did not improve from 0.93103\n","Epoch 419/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5614 - val_accuracy: 0.9064\n","\n","Epoch 00419: val_accuracy did not improve from 0.93103\n","Epoch 420/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9113\n","\n","Epoch 00420: val_accuracy did not improve from 0.93103\n","Epoch 421/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5883 - val_accuracy: 0.9089\n","\n","Epoch 00421: val_accuracy did not improve from 0.93103\n","Epoch 422/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4747 - val_accuracy: 0.9089\n","\n","Epoch 00422: val_accuracy did not improve from 0.93103\n","Epoch 423/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.0366e-04 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.9138\n","\n","Epoch 00423: val_accuracy did not improve from 0.93103\n","Epoch 424/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.9138\n","\n","Epoch 00424: val_accuracy did not improve from 0.93103\n","Epoch 425/500\n","52/52 [==============================] - 12s 223ms/step - loss: 6.7438e-04 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.9015\n","\n","Epoch 00425: val_accuracy did not improve from 0.93103\n","Epoch 426/500\n","52/52 [==============================] - 12s 224ms/step - loss: 5.5186e-04 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.9039\n","\n","Epoch 00426: val_accuracy did not improve from 0.93103\n","Epoch 427/500\n","52/52 [==============================] - 12s 222ms/step - loss: 8.0059e-04 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.9064\n","\n","Epoch 00427: val_accuracy did not improve from 0.93103\n","Epoch 428/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.2259e-04 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9113\n","\n","Epoch 00428: val_accuracy did not improve from 0.93103\n","Epoch 429/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.6415e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9064\n","\n","Epoch 00429: val_accuracy did not improve from 0.93103\n","Epoch 430/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.9106e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9187\n","\n","Epoch 00430: val_accuracy did not improve from 0.93103\n","Epoch 431/500\n","52/52 [==============================] - 12s 223ms/step - loss: 2.2136e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9212\n","\n","Epoch 00431: val_accuracy did not improve from 0.93103\n","Epoch 432/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.7684e-04 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.9113\n","\n","Epoch 00432: val_accuracy did not improve from 0.93103\n","Epoch 433/500\n","52/52 [==============================] - 12s 221ms/step - loss: 7.2999e-05 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.9089\n","\n","Epoch 00433: val_accuracy did not improve from 0.93103\n","Epoch 434/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.7132e-04 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.9039\n","\n","Epoch 00434: val_accuracy did not improve from 0.93103\n","Epoch 435/500\n","52/52 [==============================] - 12s 222ms/step - loss: 1.9406e-04 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.8990\n","\n","Epoch 00435: val_accuracy did not improve from 0.93103\n","Epoch 436/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.7916e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9089\n","\n","Epoch 00436: val_accuracy did not improve from 0.93103\n","Epoch 437/500\n","52/52 [==============================] - 12s 223ms/step - loss: 2.9146e-04 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.9015\n","\n","Epoch 00437: val_accuracy did not improve from 0.93103\n","Epoch 438/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 3.5783 - val_accuracy: 0.5025\n","\n","Epoch 00438: val_accuracy did not improve from 0.93103\n","Epoch 439/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.1023 - accuracy: 0.9689 - val_loss: 2.5455 - val_accuracy: 0.5887\n","\n","Epoch 00439: val_accuracy did not improve from 0.93103\n","Epoch 440/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.6379 - val_accuracy: 0.8793\n","\n","Epoch 00440: val_accuracy did not improve from 0.93103\n","Epoch 441/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.6869 - val_accuracy: 0.8842\n","\n","Epoch 00441: val_accuracy did not improve from 0.93103\n","Epoch 442/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.6247 - val_accuracy: 0.8596\n","\n","Epoch 00442: val_accuracy did not improve from 0.93103\n","Epoch 443/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.6257 - val_accuracy: 0.8916\n","\n","Epoch 00443: val_accuracy did not improve from 0.93103\n","Epoch 444/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5091 - val_accuracy: 0.8818\n","\n","Epoch 00444: val_accuracy did not improve from 0.93103\n","Epoch 445/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.5657 - val_accuracy: 0.8818\n","\n","Epoch 00445: val_accuracy did not improve from 0.93103\n","Epoch 446/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5652 - val_accuracy: 0.9039\n","\n","Epoch 00446: val_accuracy did not improve from 0.93103\n","Epoch 447/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5561 - val_accuracy: 0.8941\n","\n","Epoch 00447: val_accuracy did not improve from 0.93103\n","Epoch 448/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5411 - val_accuracy: 0.8941\n","\n","Epoch 00448: val_accuracy did not improve from 0.93103\n","Epoch 449/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5502 - val_accuracy: 0.9089\n","\n","Epoch 00449: val_accuracy did not improve from 0.93103\n","Epoch 450/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.6520 - val_accuracy: 0.8645\n","\n","Epoch 00450: val_accuracy did not improve from 0.93103\n","Epoch 451/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5025 - val_accuracy: 0.8941\n","\n","Epoch 00451: val_accuracy did not improve from 0.93103\n","Epoch 452/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.8990\n","\n","Epoch 00452: val_accuracy did not improve from 0.93103\n","Epoch 453/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5290 - val_accuracy: 0.8966\n","\n","Epoch 00453: val_accuracy did not improve from 0.93103\n","Epoch 454/500\n","52/52 [==============================] - 12s 228ms/step - loss: 9.4468e-04 - accuracy: 1.0000 - val_loss: 0.5553 - val_accuracy: 0.9089\n","\n","Epoch 00454: val_accuracy did not improve from 0.93103\n","Epoch 455/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.3610e-04 - accuracy: 1.0000 - val_loss: 0.5553 - val_accuracy: 0.9064\n","\n","Epoch 00455: val_accuracy did not improve from 0.93103\n","Epoch 456/500\n","52/52 [==============================] - 12s 225ms/step - loss: 3.6090e-04 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.9064\n","\n","Epoch 00456: val_accuracy did not improve from 0.93103\n","Epoch 457/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.9467e-04 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9064\n","\n","Epoch 00457: val_accuracy did not improve from 0.93103\n","Epoch 458/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.7725e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9113\n","\n","Epoch 00458: val_accuracy did not improve from 0.93103\n","Epoch 459/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.6464e-04 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9039\n","\n","Epoch 00459: val_accuracy did not improve from 0.93103\n","Epoch 460/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.5453 - val_accuracy: 0.9113\n","\n","Epoch 00460: val_accuracy did not improve from 0.93103\n","Epoch 461/500\n","52/52 [==============================] - 12s 223ms/step - loss: 6.1614e-04 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8916\n","\n","Epoch 00461: val_accuracy did not improve from 0.93103\n","Epoch 462/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.9650e-04 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.9064\n","\n","Epoch 00462: val_accuracy did not improve from 0.93103\n","Epoch 463/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.4271e-04 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9015\n","\n","Epoch 00463: val_accuracy did not improve from 0.93103\n","Epoch 464/500\n","52/52 [==============================] - 12s 223ms/step - loss: 4.5098e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9138\n","\n","Epoch 00464: val_accuracy did not improve from 0.93103\n","Epoch 465/500\n","52/52 [==============================] - 12s 224ms/step - loss: 1.1677e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9015\n","\n","Epoch 00465: val_accuracy did not improve from 0.93103\n","Epoch 466/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.6708e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9064\n","\n","Epoch 00466: val_accuracy did not improve from 0.93103\n","Epoch 467/500\n","52/52 [==============================] - 12s 225ms/step - loss: 3.2188e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9138\n","\n","Epoch 00467: val_accuracy did not improve from 0.93103\n","Epoch 468/500\n","52/52 [==============================] - 12s 223ms/step - loss: 4.7832e-04 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.9039\n","\n","Epoch 00468: val_accuracy did not improve from 0.93103\n","Epoch 469/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.5653 - val_accuracy: 0.9015\n","\n","Epoch 00469: val_accuracy did not improve from 0.93103\n","Epoch 470/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5667 - val_accuracy: 0.8695\n","\n","Epoch 00470: val_accuracy did not improve from 0.93103\n","Epoch 471/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.7643 - val_accuracy: 0.8793\n","\n","Epoch 00471: val_accuracy did not improve from 0.93103\n","Epoch 472/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.8234 - val_accuracy: 0.8768\n","\n","Epoch 00472: val_accuracy did not improve from 0.93103\n","Epoch 473/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0480 - accuracy: 0.9866 - val_loss: 1.0108 - val_accuracy: 0.8670\n","\n","Epoch 00473: val_accuracy did not improve from 0.93103\n","Epoch 474/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.7651 - val_accuracy: 0.8966\n","\n","Epoch 00474: val_accuracy did not improve from 0.93103\n","Epoch 475/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5873 - val_accuracy: 0.8990\n","\n","Epoch 00475: val_accuracy did not improve from 0.93103\n","Epoch 476/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.6421 - val_accuracy: 0.8966\n","\n","Epoch 00476: val_accuracy did not improve from 0.93103\n","Epoch 477/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.6783 - val_accuracy: 0.8621\n","\n","Epoch 00477: val_accuracy did not improve from 0.93103\n","Epoch 478/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.6469 - val_accuracy: 0.8941\n","\n","Epoch 00478: val_accuracy did not improve from 0.93103\n","Epoch 479/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5575 - val_accuracy: 0.8966\n","\n","Epoch 00479: val_accuracy did not improve from 0.93103\n","Epoch 480/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4834 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.93103\n","Epoch 481/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5135 - val_accuracy: 0.8966\n","\n","Epoch 00481: val_accuracy did not improve from 0.93103\n","Epoch 482/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5254 - val_accuracy: 0.8990\n","\n","Epoch 00482: val_accuracy did not improve from 0.93103\n","Epoch 483/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5117 - val_accuracy: 0.9113\n","\n","Epoch 00483: val_accuracy did not improve from 0.93103\n","Epoch 484/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4639 - val_accuracy: 0.9064\n","\n","Epoch 00484: val_accuracy did not improve from 0.93103\n","Epoch 485/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5784 - val_accuracy: 0.9039\n","\n","Epoch 00485: val_accuracy did not improve from 0.93103\n","Epoch 486/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.5369 - val_accuracy: 0.8966\n","\n","Epoch 00486: val_accuracy did not improve from 0.93103\n","Epoch 487/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.0235e-04 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.8990\n","\n","Epoch 00487: val_accuracy did not improve from 0.93103\n","Epoch 488/500\n","52/52 [==============================] - 12s 223ms/step - loss: 4.3530e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9138\n","\n","Epoch 00488: val_accuracy did not improve from 0.93103\n","Epoch 489/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4644 - val_accuracy: 0.8990\n","\n","Epoch 00489: val_accuracy did not improve from 0.93103\n","Epoch 490/500\n","52/52 [==============================] - 12s 225ms/step - loss: 5.1033e-04 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9039\n","\n","Epoch 00490: val_accuracy did not improve from 0.93103\n","Epoch 491/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.4433e-04 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8990\n","\n","Epoch 00491: val_accuracy did not improve from 0.93103\n","Epoch 492/500\n","52/52 [==============================] - 12s 224ms/step - loss: 7.0484e-04 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.9163\n","\n","Epoch 00492: val_accuracy did not improve from 0.93103\n","Epoch 493/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.3077e-04 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9015\n","\n","Epoch 00493: val_accuracy did not improve from 0.93103\n","Epoch 494/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.8362e-04 - accuracy: 1.0000 - val_loss: 0.5316 - val_accuracy: 0.8990\n","\n","Epoch 00494: val_accuracy did not improve from 0.93103\n","Epoch 495/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.8142e-04 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9113\n","\n","Epoch 00495: val_accuracy did not improve from 0.93103\n","Epoch 496/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.5855e-04 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9064\n","\n","Epoch 00496: val_accuracy did not improve from 0.93103\n","Epoch 497/500\n","52/52 [==============================] - 12s 225ms/step - loss: 1.6162e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9064\n","\n","Epoch 00497: val_accuracy did not improve from 0.93103\n","Epoch 498/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.1371e-04 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9138\n","\n","Epoch 00498: val_accuracy did not improve from 0.93103\n","Epoch 499/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.3511e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9039\n","\n","Epoch 00499: val_accuracy did not improve from 0.93103\n","Epoch 500/500\n","52/52 [==============================] - 12s 222ms/step - loss: 1.8554e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9212\n","\n","Epoch 00500: val_accuracy did not improve from 0.93103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fdee0659d50>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629831789223,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b04a4552-eb2e-4915-fc0d-7657bad71f37"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629831817977,"user_tz":-540,"elapsed":28765,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_1_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629831818635,"user_tz":-540,"elapsed":673,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831819820,"user_tz":-540,"elapsed":1201,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b59c25e9-c66a-4ce8-fce6-5e98afe83d80"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831850226,"user_tz":-540,"elapsed":30413,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ea020057-7434-41fc-891d-1e0014d20bf6"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629831850233,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629831850234,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629831851730,"user_tz":-540,"elapsed":1507,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629831851732,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629831862928,"user_tz":-540,"elapsed":4435,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629831862929,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7724b89e-601a-43da-edb8-485cd87e69a9"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1629831862930,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d29a795c-7b6c-4b96-f67c-f552f00f9fec"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_1_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_1_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_bffc8659-175a-478f-a1cb-ce70a619777b\", \"Rotation_range_10_1_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}