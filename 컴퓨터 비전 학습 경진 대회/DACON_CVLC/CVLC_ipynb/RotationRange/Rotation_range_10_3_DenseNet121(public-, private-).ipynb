{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_10_3_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyMOoA45CRVtb9/rfMuVckBo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831921162,"user_tz":-540,"elapsed":370,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"82d1a2f8-57a0-4307-f5f7-be5c3bc9b36b"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 19:05:22 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831936786,"user_tz":-540,"elapsed":15628,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"94118383-b547-4edc-8905-00c1302fd383"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629831940770,"user_tz":-540,"elapsed":3989,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629831942224,"user_tz":-540,"elapsed":1457,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629831944151,"user_tz":-540,"elapsed":1929,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629831961291,"user_tz":-540,"elapsed":17143,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629831968035,"user_tz":-540,"elapsed":6747,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831968035,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"07877172-d98a-4404-8089-773953e20d30"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629831968036,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8cfdafea-6452-438c-c7fe-8b894c41edd3"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629831968037,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629842335536,"user_tz":-540,"elapsed":10367506,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0778a643-1446-43ec-d469-3c8774ebcd69"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 53s 475ms/step - loss: 1.9071 - accuracy: 0.3161 - val_loss: 20.8540 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 20s 374ms/step - loss: 1.2338 - accuracy: 0.5761 - val_loss: 21.8180 - val_accuracy: 0.1108\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 20s 378ms/step - loss: 1.0032 - accuracy: 0.6632 - val_loss: 13.3629 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.11084\n","Epoch 4/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.8121 - accuracy: 0.7369 - val_loss: 12.0054 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.11084\n","Epoch 5/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.7174 - accuracy: 0.7619 - val_loss: 12.8455 - val_accuracy: 0.1207\n","\n","Epoch 00005: val_accuracy improved from 0.11084 to 0.12069, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 395ms/step - loss: 0.6711 - accuracy: 0.7789 - val_loss: 8.8705 - val_accuracy: 0.1650\n","\n","Epoch 00006: val_accuracy improved from 0.12069 to 0.16502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.6043 - accuracy: 0.8069 - val_loss: 6.5734 - val_accuracy: 0.2734\n","\n","Epoch 00007: val_accuracy improved from 0.16502 to 0.27340, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.4990 - accuracy: 0.8240 - val_loss: 4.9585 - val_accuracy: 0.2906\n","\n","Epoch 00008: val_accuracy improved from 0.27340 to 0.29064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.4898 - accuracy: 0.8356 - val_loss: 1.8104 - val_accuracy: 0.5813\n","\n","Epoch 00009: val_accuracy improved from 0.29064 to 0.58128, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.5453 - accuracy: 0.8222 - val_loss: 1.4074 - val_accuracy: 0.6108\n","\n","Epoch 00010: val_accuracy improved from 0.58128 to 0.61084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.4777 - accuracy: 0.8410 - val_loss: 1.1528 - val_accuracy: 0.7094\n","\n","Epoch 00011: val_accuracy improved from 0.61084 to 0.70936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.3516 - accuracy: 0.8831 - val_loss: 0.5663 - val_accuracy: 0.8227\n","\n","Epoch 00012: val_accuracy improved from 0.70936 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.4037 - accuracy: 0.8624 - val_loss: 0.7977 - val_accuracy: 0.7488\n","\n","Epoch 00013: val_accuracy did not improve from 0.82266\n","Epoch 14/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.3286 - accuracy: 0.8952 - val_loss: 1.2124 - val_accuracy: 0.6502\n","\n","Epoch 00014: val_accuracy did not improve from 0.82266\n","Epoch 15/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.3593 - accuracy: 0.8849 - val_loss: 1.0529 - val_accuracy: 0.7044\n","\n","Epoch 00015: val_accuracy did not improve from 0.82266\n","Epoch 16/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.3246 - accuracy: 0.8892 - val_loss: 0.7333 - val_accuracy: 0.7562\n","\n","Epoch 00016: val_accuracy did not improve from 0.82266\n","Epoch 17/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2799 - accuracy: 0.9013 - val_loss: 0.7362 - val_accuracy: 0.7660\n","\n","Epoch 00017: val_accuracy did not improve from 0.82266\n","Epoch 18/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.3058 - accuracy: 0.8977 - val_loss: 0.7127 - val_accuracy: 0.7980\n","\n","Epoch 00018: val_accuracy did not improve from 0.82266\n","Epoch 19/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2969 - accuracy: 0.8934 - val_loss: 0.5579 - val_accuracy: 0.8251\n","\n","Epoch 00019: val_accuracy improved from 0.82266 to 0.82512, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 20/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.3019 - accuracy: 0.8916 - val_loss: 0.7631 - val_accuracy: 0.7709\n","\n","Epoch 00020: val_accuracy did not improve from 0.82512\n","Epoch 21/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.2153 - accuracy: 0.9342 - val_loss: 0.6414 - val_accuracy: 0.8005\n","\n","Epoch 00021: val_accuracy did not improve from 0.82512\n","Epoch 22/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.2208 - accuracy: 0.9227 - val_loss: 0.6974 - val_accuracy: 0.8227\n","\n","Epoch 00022: val_accuracy did not improve from 0.82512\n","Epoch 23/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2298 - accuracy: 0.9263 - val_loss: 0.7488 - val_accuracy: 0.7906\n","\n","Epoch 00023: val_accuracy did not improve from 0.82512\n","Epoch 24/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2253 - accuracy: 0.9190 - val_loss: 1.3697 - val_accuracy: 0.6970\n","\n","Epoch 00024: val_accuracy did not improve from 0.82512\n","Epoch 25/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2045 - accuracy: 0.9373 - val_loss: 0.7573 - val_accuracy: 0.8103\n","\n","Epoch 00025: val_accuracy did not improve from 0.82512\n","Epoch 26/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.2395 - accuracy: 0.9208 - val_loss: 0.6331 - val_accuracy: 0.8202\n","\n","Epoch 00026: val_accuracy did not improve from 0.82512\n","Epoch 27/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.2089 - accuracy: 0.9287 - val_loss: 0.5879 - val_accuracy: 0.8350\n","\n","Epoch 00027: val_accuracy improved from 0.82512 to 0.83498, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1918 - accuracy: 0.9361 - val_loss: 0.9078 - val_accuracy: 0.7709\n","\n","Epoch 00028: val_accuracy did not improve from 0.83498\n","Epoch 29/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.1595 - accuracy: 0.9488 - val_loss: 0.4635 - val_accuracy: 0.8571\n","\n","Epoch 00029: val_accuracy improved from 0.83498 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 30/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1632 - accuracy: 0.9470 - val_loss: 1.1760 - val_accuracy: 0.7217\n","\n","Epoch 00030: val_accuracy did not improve from 0.85714\n","Epoch 31/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2164 - accuracy: 0.9239 - val_loss: 0.4950 - val_accuracy: 0.8547\n","\n","Epoch 00031: val_accuracy did not improve from 0.85714\n","Epoch 32/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1449 - accuracy: 0.9549 - val_loss: 0.5512 - val_accuracy: 0.8325\n","\n","Epoch 00032: val_accuracy did not improve from 0.85714\n","Epoch 33/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.4122 - val_accuracy: 0.8695\n","\n","Epoch 00033: val_accuracy improved from 0.85714 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 34/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1458 - accuracy: 0.9531 - val_loss: 0.7173 - val_accuracy: 0.8128\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1723 - accuracy: 0.9415 - val_loss: 0.5404 - val_accuracy: 0.8325\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1655 - accuracy: 0.9403 - val_loss: 0.8263 - val_accuracy: 0.8251\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1462 - accuracy: 0.9543 - val_loss: 0.9981 - val_accuracy: 0.7635\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1478 - accuracy: 0.9452 - val_loss: 0.6106 - val_accuracy: 0.8350\n","\n","Epoch 00038: val_accuracy did not improve from 0.86946\n","Epoch 39/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1107 - accuracy: 0.9604 - val_loss: 0.7845 - val_accuracy: 0.8227\n","\n","Epoch 00039: val_accuracy did not improve from 0.86946\n","Epoch 40/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1140 - accuracy: 0.9622 - val_loss: 0.4319 - val_accuracy: 0.8818\n","\n","Epoch 00040: val_accuracy improved from 0.86946 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 41/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1016 - accuracy: 0.9604 - val_loss: 0.8455 - val_accuracy: 0.8005\n","\n","Epoch 00041: val_accuracy did not improve from 0.88177\n","Epoch 42/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.6059 - val_accuracy: 0.8374\n","\n","Epoch 00042: val_accuracy did not improve from 0.88177\n","Epoch 43/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0995 - accuracy: 0.9695 - val_loss: 0.7959 - val_accuracy: 0.8054\n","\n","Epoch 00043: val_accuracy did not improve from 0.88177\n","Epoch 44/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1917 - accuracy: 0.9354 - val_loss: 0.9235 - val_accuracy: 0.7980\n","\n","Epoch 00044: val_accuracy did not improve from 0.88177\n","Epoch 45/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1266 - accuracy: 0.9482 - val_loss: 0.6966 - val_accuracy: 0.8276\n","\n","Epoch 00045: val_accuracy did not improve from 0.88177\n","Epoch 46/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0863 - accuracy: 0.9714 - val_loss: 0.4820 - val_accuracy: 0.8768\n","\n","Epoch 00046: val_accuracy did not improve from 0.88177\n","Epoch 47/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0990 - accuracy: 0.9653 - val_loss: 0.6872 - val_accuracy: 0.8522\n","\n","Epoch 00047: val_accuracy did not improve from 0.88177\n","Epoch 48/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1339 - accuracy: 0.9482 - val_loss: 0.5049 - val_accuracy: 0.8695\n","\n","Epoch 00048: val_accuracy did not improve from 0.88177\n","Epoch 49/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1086 - accuracy: 0.9653 - val_loss: 0.5417 - val_accuracy: 0.8547\n","\n","Epoch 00049: val_accuracy did not improve from 0.88177\n","Epoch 50/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 0.4752 - val_accuracy: 0.8818\n","\n","Epoch 00050: val_accuracy did not improve from 0.88177\n","Epoch 51/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0810 - accuracy: 0.9738 - val_loss: 0.7607 - val_accuracy: 0.8153\n","\n","Epoch 00051: val_accuracy did not improve from 0.88177\n","Epoch 52/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1505 - accuracy: 0.9507 - val_loss: 0.7356 - val_accuracy: 0.8300\n","\n","Epoch 00052: val_accuracy did not improve from 0.88177\n","Epoch 53/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1236 - accuracy: 0.9598 - val_loss: 0.4653 - val_accuracy: 0.8670\n","\n","Epoch 00053: val_accuracy did not improve from 0.88177\n","Epoch 54/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0689 - accuracy: 0.9756 - val_loss: 0.5722 - val_accuracy: 0.8424\n","\n","Epoch 00054: val_accuracy did not improve from 0.88177\n","Epoch 55/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0623 - accuracy: 0.9823 - val_loss: 0.8358 - val_accuracy: 0.8202\n","\n","Epoch 00055: val_accuracy did not improve from 0.88177\n","Epoch 56/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.8695 - val_accuracy: 0.7980\n","\n","Epoch 00056: val_accuracy did not improve from 0.88177\n","Epoch 57/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.5970 - val_accuracy: 0.8547\n","\n","Epoch 00057: val_accuracy did not improve from 0.88177\n","Epoch 58/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0893 - accuracy: 0.9720 - val_loss: 0.4359 - val_accuracy: 0.8867\n","\n","Epoch 00058: val_accuracy improved from 0.88177 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 59/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 0.4063 - val_accuracy: 0.9089\n","\n","Epoch 00059: val_accuracy improved from 0.88670 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 60/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.4565 - val_accuracy: 0.8744\n","\n","Epoch 00060: val_accuracy did not improve from 0.90887\n","Epoch 61/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1367 - accuracy: 0.9525 - val_loss: 0.5319 - val_accuracy: 0.8621\n","\n","Epoch 00061: val_accuracy did not improve from 0.90887\n","Epoch 62/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1235 - accuracy: 0.9604 - val_loss: 0.6180 - val_accuracy: 0.8374\n","\n","Epoch 00062: val_accuracy did not improve from 0.90887\n","Epoch 63/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 0.4020 - val_accuracy: 0.9015\n","\n","Epoch 00063: val_accuracy did not improve from 0.90887\n","Epoch 64/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.4822 - val_accuracy: 0.8645\n","\n","Epoch 00064: val_accuracy did not improve from 0.90887\n","Epoch 65/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.5059 - val_accuracy: 0.8818\n","\n","Epoch 00065: val_accuracy did not improve from 0.90887\n","Epoch 66/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.5130 - val_accuracy: 0.8744\n","\n","Epoch 00066: val_accuracy did not improve from 0.90887\n","Epoch 67/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 0.5424 - val_accuracy: 0.8645\n","\n","Epoch 00067: val_accuracy did not improve from 0.90887\n","Epoch 68/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0549 - accuracy: 0.9817 - val_loss: 0.4900 - val_accuracy: 0.8744\n","\n","Epoch 00068: val_accuracy did not improve from 0.90887\n","Epoch 69/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.4391 - val_accuracy: 0.8818\n","\n","Epoch 00069: val_accuracy did not improve from 0.90887\n","Epoch 70/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0831 - accuracy: 0.9738 - val_loss: 0.9049 - val_accuracy: 0.7783\n","\n","Epoch 00070: val_accuracy did not improve from 0.90887\n","Epoch 71/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1459 - accuracy: 0.9519 - val_loss: 1.1550 - val_accuracy: 0.7833\n","\n","Epoch 00071: val_accuracy did not improve from 0.90887\n","Epoch 72/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1401 - accuracy: 0.9537 - val_loss: 0.5994 - val_accuracy: 0.8596\n","\n","Epoch 00072: val_accuracy did not improve from 0.90887\n","Epoch 73/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.5432 - val_accuracy: 0.8867\n","\n","Epoch 00073: val_accuracy did not improve from 0.90887\n","Epoch 74/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.5284 - val_accuracy: 0.8916\n","\n","Epoch 00074: val_accuracy did not improve from 0.90887\n","Epoch 75/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.3089 - val_accuracy: 0.9212\n","\n","Epoch 00075: val_accuracy improved from 0.90887 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 76/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.4221 - val_accuracy: 0.8793\n","\n","Epoch 00076: val_accuracy did not improve from 0.92118\n","Epoch 77/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.5448 - val_accuracy: 0.8670\n","\n","Epoch 00077: val_accuracy did not improve from 0.92118\n","Epoch 78/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0529 - accuracy: 0.9793 - val_loss: 0.5020 - val_accuracy: 0.8744\n","\n","Epoch 00078: val_accuracy did not improve from 0.92118\n","Epoch 79/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 0.8183 - val_accuracy: 0.8103\n","\n","Epoch 00079: val_accuracy did not improve from 0.92118\n","Epoch 80/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0626 - accuracy: 0.9762 - val_loss: 0.6555 - val_accuracy: 0.8522\n","\n","Epoch 00080: val_accuracy did not improve from 0.92118\n","Epoch 81/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 1.0731 - val_accuracy: 0.7931\n","\n","Epoch 00081: val_accuracy did not improve from 0.92118\n","Epoch 82/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0789 - accuracy: 0.9762 - val_loss: 0.6582 - val_accuracy: 0.8473\n","\n","Epoch 00082: val_accuracy did not improve from 0.92118\n","Epoch 83/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0735 - accuracy: 0.9732 - val_loss: 0.5283 - val_accuracy: 0.8645\n","\n","Epoch 00083: val_accuracy did not improve from 0.92118\n","Epoch 84/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 0.3938 - val_accuracy: 0.8867\n","\n","Epoch 00084: val_accuracy did not improve from 0.92118\n","Epoch 85/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.8734 - val_accuracy: 0.8399\n","\n","Epoch 00085: val_accuracy did not improve from 0.92118\n","Epoch 86/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.5877 - val_accuracy: 0.8571\n","\n","Epoch 00086: val_accuracy did not improve from 0.92118\n","Epoch 87/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.6380 - val_accuracy: 0.8596\n","\n","Epoch 00087: val_accuracy did not improve from 0.92118\n","Epoch 88/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0679 - accuracy: 0.9750 - val_loss: 0.5978 - val_accuracy: 0.8645\n","\n","Epoch 00088: val_accuracy did not improve from 0.92118\n","Epoch 89/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0502 - accuracy: 0.9848 - val_loss: 0.4737 - val_accuracy: 0.8867\n","\n","Epoch 00089: val_accuracy did not improve from 0.92118\n","Epoch 90/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 0.4853 - val_accuracy: 0.8892\n","\n","Epoch 00090: val_accuracy did not improve from 0.92118\n","Epoch 91/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0581 - accuracy: 0.9793 - val_loss: 0.5495 - val_accuracy: 0.8842\n","\n","Epoch 00091: val_accuracy did not improve from 0.92118\n","Epoch 92/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.5448 - val_accuracy: 0.8990\n","\n","Epoch 00092: val_accuracy did not improve from 0.92118\n","Epoch 93/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.6829 - val_accuracy: 0.8227\n","\n","Epoch 00093: val_accuracy did not improve from 0.92118\n","Epoch 94/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.5563 - val_accuracy: 0.8793\n","\n","Epoch 00094: val_accuracy did not improve from 0.92118\n","Epoch 95/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.7287 - val_accuracy: 0.8719\n","\n","Epoch 00095: val_accuracy did not improve from 0.92118\n","Epoch 96/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.6077 - val_accuracy: 0.8621\n","\n","Epoch 00096: val_accuracy did not improve from 0.92118\n","Epoch 97/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.4888 - val_accuracy: 0.8990\n","\n","Epoch 00097: val_accuracy did not improve from 0.92118\n","Epoch 98/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0314 - accuracy: 0.9878 - val_loss: 0.5429 - val_accuracy: 0.8793\n","\n","Epoch 00098: val_accuracy did not improve from 0.92118\n","Epoch 99/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.6797 - val_accuracy: 0.8300\n","\n","Epoch 00099: val_accuracy did not improve from 0.92118\n","Epoch 100/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0529 - accuracy: 0.9762 - val_loss: 0.5693 - val_accuracy: 0.8818\n","\n","Epoch 00100: val_accuracy did not improve from 0.92118\n","Epoch 101/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0833 - accuracy: 0.9695 - val_loss: 0.8893 - val_accuracy: 0.8399\n","\n","Epoch 00101: val_accuracy did not improve from 0.92118\n","Epoch 102/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0872 - accuracy: 0.9708 - val_loss: 0.7803 - val_accuracy: 0.8448\n","\n","Epoch 00102: val_accuracy did not improve from 0.92118\n","Epoch 103/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0673 - accuracy: 0.9781 - val_loss: 0.5519 - val_accuracy: 0.8867\n","\n","Epoch 00103: val_accuracy did not improve from 0.92118\n","Epoch 104/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.6803 - val_accuracy: 0.8744\n","\n","Epoch 00104: val_accuracy did not improve from 0.92118\n","Epoch 105/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.3921 - val_accuracy: 0.9236\n","\n","Epoch 00105: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 106/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.5675 - val_accuracy: 0.8768\n","\n","Epoch 00106: val_accuracy did not improve from 0.92365\n","Epoch 107/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.4228 - val_accuracy: 0.9039\n","\n","Epoch 00107: val_accuracy did not improve from 0.92365\n","Epoch 108/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.4477 - val_accuracy: 0.8892\n","\n","Epoch 00108: val_accuracy did not improve from 0.92365\n","Epoch 109/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.4629 - val_accuracy: 0.8966\n","\n","Epoch 00109: val_accuracy did not improve from 0.92365\n","Epoch 110/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.4065 - val_accuracy: 0.9113\n","\n","Epoch 00110: val_accuracy did not improve from 0.92365\n","Epoch 111/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.3606 - val_accuracy: 0.9113\n","\n","Epoch 00111: val_accuracy did not improve from 0.92365\n","Epoch 112/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0300 - accuracy: 0.9933 - val_loss: 0.5481 - val_accuracy: 0.8768\n","\n","Epoch 00112: val_accuracy did not improve from 0.92365\n","Epoch 113/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.6812 - val_accuracy: 0.8596\n","\n","Epoch 00113: val_accuracy did not improve from 0.92365\n","Epoch 114/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0517 - accuracy: 0.9817 - val_loss: 0.5568 - val_accuracy: 0.9015\n","\n","Epoch 00114: val_accuracy did not improve from 0.92365\n","Epoch 115/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.4870 - val_accuracy: 0.8966\n","\n","Epoch 00115: val_accuracy did not improve from 0.92365\n","Epoch 116/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0804 - accuracy: 0.9769 - val_loss: 0.4831 - val_accuracy: 0.8842\n","\n","Epoch 00116: val_accuracy did not improve from 0.92365\n","Epoch 117/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.5817 - val_accuracy: 0.8867\n","\n","Epoch 00117: val_accuracy did not improve from 0.92365\n","Epoch 118/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.6185 - val_accuracy: 0.8941\n","\n","Epoch 00118: val_accuracy did not improve from 0.92365\n","Epoch 119/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1001 - accuracy: 0.9677 - val_loss: 1.0678 - val_accuracy: 0.8005\n","\n","Epoch 00119: val_accuracy did not improve from 0.92365\n","Epoch 120/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.7725 - val_accuracy: 0.8670\n","\n","Epoch 00120: val_accuracy did not improve from 0.92365\n","Epoch 121/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0535 - accuracy: 0.9787 - val_loss: 0.7745 - val_accuracy: 0.8522\n","\n","Epoch 00121: val_accuracy did not improve from 0.92365\n","Epoch 122/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.4014 - val_accuracy: 0.8966\n","\n","Epoch 00122: val_accuracy did not improve from 0.92365\n","Epoch 123/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0363 - accuracy: 0.9903 - val_loss: 0.5873 - val_accuracy: 0.8695\n","\n","Epoch 00123: val_accuracy did not improve from 0.92365\n","Epoch 124/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.3705 - val_accuracy: 0.9064\n","\n","Epoch 00124: val_accuracy did not improve from 0.92365\n","Epoch 125/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0355 - accuracy: 0.9860 - val_loss: 0.4927 - val_accuracy: 0.8695\n","\n","Epoch 00125: val_accuracy did not improve from 0.92365\n","Epoch 126/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5631 - val_accuracy: 0.8768\n","\n","Epoch 00126: val_accuracy did not improve from 0.92365\n","Epoch 127/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4034 - val_accuracy: 0.9113\n","\n","Epoch 00127: val_accuracy did not improve from 0.92365\n","Epoch 128/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.7330 - val_accuracy: 0.8621\n","\n","Epoch 00128: val_accuracy did not improve from 0.92365\n","Epoch 129/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.8517 - val_accuracy: 0.7931\n","\n","Epoch 00129: val_accuracy did not improve from 0.92365\n","Epoch 130/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 0.4806 - val_accuracy: 0.8941\n","\n","Epoch 00130: val_accuracy did not improve from 0.92365\n","Epoch 131/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.6270 - val_accuracy: 0.8719\n","\n","Epoch 00131: val_accuracy did not improve from 0.92365\n","Epoch 132/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.5610 - val_accuracy: 0.8768\n","\n","Epoch 00132: val_accuracy did not improve from 0.92365\n","Epoch 133/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 0.6033 - val_accuracy: 0.8768\n","\n","Epoch 00133: val_accuracy did not improve from 0.92365\n","Epoch 134/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.5231 - val_accuracy: 0.8892\n","\n","Epoch 00134: val_accuracy did not improve from 0.92365\n","Epoch 135/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.6344 - val_accuracy: 0.8695\n","\n","Epoch 00135: val_accuracy did not improve from 0.92365\n","Epoch 136/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0350 - accuracy: 0.9848 - val_loss: 0.5546 - val_accuracy: 0.8842\n","\n","Epoch 00136: val_accuracy did not improve from 0.92365\n","Epoch 137/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0243 - accuracy: 0.9896 - val_loss: 0.4580 - val_accuracy: 0.8916\n","\n","Epoch 00137: val_accuracy did not improve from 0.92365\n","Epoch 138/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.5633 - val_accuracy: 0.8990\n","\n","Epoch 00138: val_accuracy did not improve from 0.92365\n","Epoch 139/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.7068 - val_accuracy: 0.8744\n","\n","Epoch 00139: val_accuracy did not improve from 0.92365\n","Epoch 140/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.5033 - val_accuracy: 0.8941\n","\n","Epoch 00140: val_accuracy did not improve from 0.92365\n","Epoch 141/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4801 - val_accuracy: 0.9015\n","\n","Epoch 00141: val_accuracy did not improve from 0.92365\n","Epoch 142/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.4993 - val_accuracy: 0.9163\n","\n","Epoch 00142: val_accuracy did not improve from 0.92365\n","Epoch 143/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.4486 - val_accuracy: 0.9089\n","\n","Epoch 00143: val_accuracy did not improve from 0.92365\n","Epoch 144/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.4817 - val_accuracy: 0.9113\n","\n","Epoch 00144: val_accuracy did not improve from 0.92365\n","Epoch 145/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4359 - val_accuracy: 0.9089\n","\n","Epoch 00145: val_accuracy did not improve from 0.92365\n","Epoch 146/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4127 - val_accuracy: 0.9236\n","\n","Epoch 00146: val_accuracy did not improve from 0.92365\n","Epoch 147/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.9152 - val_accuracy: 0.8227\n","\n","Epoch 00147: val_accuracy did not improve from 0.92365\n","Epoch 148/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1014 - accuracy: 0.9665 - val_loss: 0.9475 - val_accuracy: 0.8498\n","\n","Epoch 00148: val_accuracy did not improve from 0.92365\n","Epoch 149/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1538 - accuracy: 0.9562 - val_loss: 2.0775 - val_accuracy: 0.7143\n","\n","Epoch 00149: val_accuracy did not improve from 0.92365\n","Epoch 150/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 0.8355 - val_accuracy: 0.8498\n","\n","Epoch 00150: val_accuracy did not improve from 0.92365\n","Epoch 151/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.4610 - val_accuracy: 0.9064\n","\n","Epoch 00151: val_accuracy did not improve from 0.92365\n","Epoch 152/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0255 - accuracy: 0.9884 - val_loss: 0.7188 - val_accuracy: 0.8571\n","\n","Epoch 00152: val_accuracy did not improve from 0.92365\n","Epoch 153/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.6238 - val_accuracy: 0.8768\n","\n","Epoch 00153: val_accuracy did not improve from 0.92365\n","Epoch 154/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0481 - accuracy: 0.9866 - val_loss: 1.1531 - val_accuracy: 0.8325\n","\n","Epoch 00154: val_accuracy did not improve from 0.92365\n","Epoch 155/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 1.3269 - val_accuracy: 0.7512\n","\n","Epoch 00155: val_accuracy did not improve from 0.92365\n","Epoch 156/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 0.7427 - val_accuracy: 0.8547\n","\n","Epoch 00156: val_accuracy did not improve from 0.92365\n","Epoch 157/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5959 - val_accuracy: 0.8818\n","\n","Epoch 00157: val_accuracy did not improve from 0.92365\n","Epoch 158/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5153 - val_accuracy: 0.8966\n","\n","Epoch 00158: val_accuracy did not improve from 0.92365\n","Epoch 159/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4373 - val_accuracy: 0.9064\n","\n","Epoch 00159: val_accuracy did not improve from 0.92365\n","Epoch 160/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5294 - val_accuracy: 0.8892\n","\n","Epoch 00160: val_accuracy did not improve from 0.92365\n","Epoch 161/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.3735 - val_accuracy: 0.9163\n","\n","Epoch 00161: val_accuracy did not improve from 0.92365\n","Epoch 162/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3911 - val_accuracy: 0.9113\n","\n","Epoch 00162: val_accuracy did not improve from 0.92365\n","Epoch 163/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5080 - val_accuracy: 0.9039\n","\n","Epoch 00163: val_accuracy did not improve from 0.92365\n","Epoch 164/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9138\n","\n","Epoch 00164: val_accuracy did not improve from 0.92365\n","Epoch 165/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5403 - val_accuracy: 0.8867\n","\n","Epoch 00165: val_accuracy did not improve from 0.92365\n","Epoch 166/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5767 - val_accuracy: 0.8916\n","\n","Epoch 00166: val_accuracy did not improve from 0.92365\n","Epoch 167/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.4738 - val_accuracy: 0.9089\n","\n","Epoch 00167: val_accuracy did not improve from 0.92365\n","Epoch 168/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.5249 - val_accuracy: 0.8966\n","\n","Epoch 00168: val_accuracy did not improve from 0.92365\n","Epoch 169/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.3718 - val_accuracy: 0.9064\n","\n","Epoch 00169: val_accuracy did not improve from 0.92365\n","Epoch 170/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4859 - val_accuracy: 0.9039\n","\n","Epoch 00170: val_accuracy did not improve from 0.92365\n","Epoch 171/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.6422 - val_accuracy: 0.8670\n","\n","Epoch 00171: val_accuracy did not improve from 0.92365\n","Epoch 172/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0762 - accuracy: 0.9793 - val_loss: 1.4928 - val_accuracy: 0.7315\n","\n","Epoch 00172: val_accuracy did not improve from 0.92365\n","Epoch 173/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.1153 - accuracy: 0.9586 - val_loss: 1.8295 - val_accuracy: 0.7118\n","\n","Epoch 00173: val_accuracy did not improve from 0.92365\n","Epoch 174/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 1.0436 - val_accuracy: 0.8153\n","\n","Epoch 00174: val_accuracy did not improve from 0.92365\n","Epoch 175/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.6999 - val_accuracy: 0.8424\n","\n","Epoch 00175: val_accuracy did not improve from 0.92365\n","Epoch 176/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.8402 - val_accuracy: 0.8522\n","\n","Epoch 00176: val_accuracy did not improve from 0.92365\n","Epoch 177/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0638 - accuracy: 0.9756 - val_loss: 0.6009 - val_accuracy: 0.8547\n","\n","Epoch 00177: val_accuracy did not improve from 0.92365\n","Epoch 178/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0373 - accuracy: 0.9921 - val_loss: 0.5522 - val_accuracy: 0.8842\n","\n","Epoch 00178: val_accuracy did not improve from 0.92365\n","Epoch 179/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.5213 - val_accuracy: 0.8744\n","\n","Epoch 00179: val_accuracy did not improve from 0.92365\n","Epoch 180/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4929 - val_accuracy: 0.8990\n","\n","Epoch 00180: val_accuracy did not improve from 0.92365\n","Epoch 181/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.5432 - val_accuracy: 0.9015\n","\n","Epoch 00181: val_accuracy did not improve from 0.92365\n","Epoch 182/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3881 - val_accuracy: 0.9212\n","\n","Epoch 00182: val_accuracy did not improve from 0.92365\n","Epoch 183/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.4683 - val_accuracy: 0.9039\n","\n","Epoch 00183: val_accuracy did not improve from 0.92365\n","Epoch 184/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5111 - val_accuracy: 0.8941\n","\n","Epoch 00184: val_accuracy did not improve from 0.92365\n","Epoch 185/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.5950 - val_accuracy: 0.8744\n","\n","Epoch 00185: val_accuracy did not improve from 0.92365\n","Epoch 186/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9163\n","\n","Epoch 00186: val_accuracy did not improve from 0.92365\n","Epoch 187/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.4353 - val_accuracy: 0.9089\n","\n","Epoch 00187: val_accuracy did not improve from 0.92365\n","Epoch 188/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.5262 - val_accuracy: 0.8842\n","\n","Epoch 00188: val_accuracy did not improve from 0.92365\n","Epoch 189/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6398 - val_accuracy: 0.8695\n","\n","Epoch 00189: val_accuracy did not improve from 0.92365\n","Epoch 190/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.6733 - val_accuracy: 0.8744\n","\n","Epoch 00190: val_accuracy did not improve from 0.92365\n","Epoch 191/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4051 - val_accuracy: 0.9236\n","\n","Epoch 00191: val_accuracy did not improve from 0.92365\n","Epoch 192/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.5604 - val_accuracy: 0.8966\n","\n","Epoch 00192: val_accuracy did not improve from 0.92365\n","Epoch 193/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4230 - val_accuracy: 0.8966\n","\n","Epoch 00193: val_accuracy did not improve from 0.92365\n","Epoch 194/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.3764 - val_accuracy: 0.9286\n","\n","Epoch 00194: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 195/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.3576 - val_accuracy: 0.9261\n","\n","Epoch 00195: val_accuracy did not improve from 0.92857\n","Epoch 196/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.4647 - val_accuracy: 0.8966\n","\n","Epoch 00196: val_accuracy did not improve from 0.92857\n","Epoch 197/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9113\n","\n","Epoch 00197: val_accuracy did not improve from 0.92857\n","Epoch 198/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9236\n","\n","Epoch 00198: val_accuracy did not improve from 0.92857\n","Epoch 199/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9039\n","\n","Epoch 00199: val_accuracy did not improve from 0.92857\n","Epoch 200/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4004 - val_accuracy: 0.9187\n","\n","Epoch 00200: val_accuracy did not improve from 0.92857\n","Epoch 201/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9163\n","\n","Epoch 00201: val_accuracy did not improve from 0.92857\n","Epoch 202/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9015\n","\n","Epoch 00202: val_accuracy did not improve from 0.92857\n","Epoch 203/500\n","52/52 [==============================] - 20s 387ms/step - loss: 3.7593e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9064\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5200 - val_accuracy: 0.9015\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1004 - accuracy: 0.9805 - val_loss: 3.9259 - val_accuracy: 0.5739\n","\n","Epoch 00205: val_accuracy did not improve from 0.92857\n","Epoch 206/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1527 - accuracy: 0.9495 - val_loss: 2.3699 - val_accuracy: 0.7069\n","\n","Epoch 00206: val_accuracy did not improve from 0.92857\n","Epoch 207/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.6729 - val_accuracy: 0.8695\n","\n","Epoch 00207: val_accuracy did not improve from 0.92857\n","Epoch 208/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.5923 - val_accuracy: 0.8818\n","\n","Epoch 00208: val_accuracy did not improve from 0.92857\n","Epoch 209/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0514 - accuracy: 0.9805 - val_loss: 0.6715 - val_accuracy: 0.8670\n","\n","Epoch 00209: val_accuracy did not improve from 0.92857\n","Epoch 210/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.4621 - val_accuracy: 0.9064\n","\n","Epoch 00210: val_accuracy did not improve from 0.92857\n","Epoch 211/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.6019 - val_accuracy: 0.8645\n","\n","Epoch 00211: val_accuracy did not improve from 0.92857\n","Epoch 212/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0848 - accuracy: 0.9744 - val_loss: 0.4495 - val_accuracy: 0.9089\n","\n","Epoch 00212: val_accuracy did not improve from 0.92857\n","Epoch 213/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.6761 - val_accuracy: 0.8744\n","\n","Epoch 00213: val_accuracy did not improve from 0.92857\n","Epoch 214/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9113\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4551 - val_accuracy: 0.9039\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4699 - val_accuracy: 0.9015\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4938 - val_accuracy: 0.9064\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.5810 - val_accuracy: 0.8744\n","\n","Epoch 00218: val_accuracy did not improve from 0.92857\n","Epoch 219/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3941 - val_accuracy: 0.9187\n","\n","Epoch 00219: val_accuracy did not improve from 0.92857\n","Epoch 220/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5638 - val_accuracy: 0.8818\n","\n","Epoch 00220: val_accuracy did not improve from 0.92857\n","Epoch 221/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4101 - val_accuracy: 0.9212\n","\n","Epoch 00221: val_accuracy did not improve from 0.92857\n","Epoch 222/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4290 - val_accuracy: 0.9163\n","\n","Epoch 00222: val_accuracy did not improve from 0.92857\n","Epoch 223/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.3910 - val_accuracy: 0.9236\n","\n","Epoch 00223: val_accuracy did not improve from 0.92857\n","Epoch 224/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.5088 - val_accuracy: 0.9089\n","\n","Epoch 00224: val_accuracy did not improve from 0.92857\n","Epoch 225/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9039\n","\n","Epoch 00225: val_accuracy did not improve from 0.92857\n","Epoch 226/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4508 - val_accuracy: 0.9163\n","\n","Epoch 00226: val_accuracy did not improve from 0.92857\n","Epoch 227/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5316 - val_accuracy: 0.9015\n","\n","Epoch 00227: val_accuracy did not improve from 0.92857\n","Epoch 228/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0591 - accuracy: 0.9860 - val_loss: 1.4864 - val_accuracy: 0.7291\n","\n","Epoch 00228: val_accuracy did not improve from 0.92857\n","Epoch 229/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.8820 - val_accuracy: 0.8030\n","\n","Epoch 00229: val_accuracy did not improve from 0.92857\n","Epoch 230/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.7675 - val_accuracy: 0.8276\n","\n","Epoch 00230: val_accuracy did not improve from 0.92857\n","Epoch 231/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.5284 - val_accuracy: 0.8768\n","\n","Epoch 00231: val_accuracy did not improve from 0.92857\n","Epoch 232/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4827 - val_accuracy: 0.8916\n","\n","Epoch 00232: val_accuracy did not improve from 0.92857\n","Epoch 233/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.3997 - val_accuracy: 0.9236\n","\n","Epoch 00233: val_accuracy did not improve from 0.92857\n","Epoch 234/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4769 - val_accuracy: 0.8966\n","\n","Epoch 00234: val_accuracy did not improve from 0.92857\n","Epoch 235/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.5351 - val_accuracy: 0.8892\n","\n","Epoch 00235: val_accuracy did not improve from 0.92857\n","Epoch 236/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5409 - val_accuracy: 0.8941\n","\n","Epoch 00236: val_accuracy did not improve from 0.92857\n","Epoch 237/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.5218 - val_accuracy: 0.8818\n","\n","Epoch 00237: val_accuracy did not improve from 0.92857\n","Epoch 238/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4153 - val_accuracy: 0.9163\n","\n","Epoch 00238: val_accuracy did not improve from 0.92857\n","Epoch 239/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.5682 - val_accuracy: 0.8966\n","\n","Epoch 00239: val_accuracy did not improve from 0.92857\n","Epoch 240/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.4383 - val_accuracy: 0.9064\n","\n","Epoch 00240: val_accuracy did not improve from 0.92857\n","Epoch 241/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5481 - val_accuracy: 0.8892\n","\n","Epoch 00241: val_accuracy did not improve from 0.92857\n","Epoch 242/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.6197 - val_accuracy: 0.8867\n","\n","Epoch 00242: val_accuracy did not improve from 0.92857\n","Epoch 243/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.5322 - val_accuracy: 0.8744\n","\n","Epoch 00243: val_accuracy did not improve from 0.92857\n","Epoch 244/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.7695 - val_accuracy: 0.8744\n","\n","Epoch 00244: val_accuracy did not improve from 0.92857\n","Epoch 245/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0265 - accuracy: 0.9866 - val_loss: 0.5388 - val_accuracy: 0.9138\n","\n","Epoch 00245: val_accuracy did not improve from 0.92857\n","Epoch 246/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.8126 - val_accuracy: 0.8498\n","\n","Epoch 00246: val_accuracy did not improve from 0.92857\n","Epoch 247/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0382 - accuracy: 0.9903 - val_loss: 0.6371 - val_accuracy: 0.8842\n","\n","Epoch 00247: val_accuracy did not improve from 0.92857\n","Epoch 248/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0292 - accuracy: 0.9890 - val_loss: 0.8277 - val_accuracy: 0.8448\n","\n","Epoch 00248: val_accuracy did not improve from 0.92857\n","Epoch 249/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0654 - accuracy: 0.9817 - val_loss: 0.8799 - val_accuracy: 0.8522\n","\n","Epoch 00249: val_accuracy did not improve from 0.92857\n","Epoch 250/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.5185 - val_accuracy: 0.9163\n","\n","Epoch 00250: val_accuracy did not improve from 0.92857\n","Epoch 251/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.5169 - val_accuracy: 0.9113\n","\n","Epoch 00251: val_accuracy did not improve from 0.92857\n","Epoch 252/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5005 - val_accuracy: 0.9039\n","\n","Epoch 00252: val_accuracy did not improve from 0.92857\n","Epoch 253/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4701 - val_accuracy: 0.9015\n","\n","Epoch 00253: val_accuracy did not improve from 0.92857\n","Epoch 254/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4076 - val_accuracy: 0.9187\n","\n","Epoch 00254: val_accuracy did not improve from 0.92857\n","Epoch 255/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.5757 - val_accuracy: 0.8793\n","\n","Epoch 00255: val_accuracy did not improve from 0.92857\n","Epoch 256/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4654 - val_accuracy: 0.9064\n","\n","Epoch 00256: val_accuracy did not improve from 0.92857\n","Epoch 257/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8990\n","\n","Epoch 00257: val_accuracy did not improve from 0.92857\n","Epoch 258/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9064\n","\n","Epoch 00258: val_accuracy did not improve from 0.92857\n","Epoch 259/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.9163\n","\n","Epoch 00259: val_accuracy did not improve from 0.92857\n","Epoch 260/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.0852e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9335\n","\n","Epoch 00260: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 261/500\n","52/52 [==============================] - 20s 388ms/step - loss: 8.2974e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9261\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.0636e-04 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9212\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.4784 - val_accuracy: 0.9113\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.7680 - val_accuracy: 0.8867\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.5494 - val_accuracy: 0.9064\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9187\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4627 - val_accuracy: 0.9212\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5522 - val_accuracy: 0.9089\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5000 - val_accuracy: 0.9089\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6580 - val_accuracy: 0.8966\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6495 - val_accuracy: 0.8719\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.7041 - val_accuracy: 0.8744\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1048 - accuracy: 0.9714 - val_loss: 1.4821 - val_accuracy: 0.8005\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.5308 - val_accuracy: 0.9015\n","\n","Epoch 00274: val_accuracy did not improve from 0.93350\n","Epoch 275/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.0957 - val_accuracy: 0.8227\n","\n","Epoch 00275: val_accuracy did not improve from 0.93350\n","Epoch 276/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 1.1779 - val_accuracy: 0.8276\n","\n","Epoch 00276: val_accuracy did not improve from 0.93350\n","Epoch 277/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0264 - accuracy: 0.9884 - val_loss: 0.6435 - val_accuracy: 0.8793\n","\n","Epoch 00277: val_accuracy did not improve from 0.93350\n","Epoch 278/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.4995 - val_accuracy: 0.9064\n","\n","Epoch 00278: val_accuracy did not improve from 0.93350\n","Epoch 279/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.6727 - val_accuracy: 0.8818\n","\n","Epoch 00279: val_accuracy did not improve from 0.93350\n","Epoch 280/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.5329 - val_accuracy: 0.8916\n","\n","Epoch 00280: val_accuracy did not improve from 0.93350\n","Epoch 281/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6609 - val_accuracy: 0.8793\n","\n","Epoch 00281: val_accuracy did not improve from 0.93350\n","Epoch 282/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5630 - val_accuracy: 0.8793\n","\n","Epoch 00282: val_accuracy did not improve from 0.93350\n","Epoch 283/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.5300 - val_accuracy: 0.9089\n","\n","Epoch 00283: val_accuracy did not improve from 0.93350\n","Epoch 284/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4392 - val_accuracy: 0.9261\n","\n","Epoch 00284: val_accuracy did not improve from 0.93350\n","Epoch 285/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9113\n","\n","Epoch 00285: val_accuracy did not improve from 0.93350\n","Epoch 286/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0263 - accuracy: 0.9927 - val_loss: 0.5670 - val_accuracy: 0.8744\n","\n","Epoch 00286: val_accuracy did not improve from 0.93350\n","Epoch 287/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5286 - val_accuracy: 0.9039\n","\n","Epoch 00287: val_accuracy did not improve from 0.93350\n","Epoch 288/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4599 - val_accuracy: 0.9212\n","\n","Epoch 00288: val_accuracy did not improve from 0.93350\n","Epoch 289/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5008 - val_accuracy: 0.9113\n","\n","Epoch 00289: val_accuracy did not improve from 0.93350\n","Epoch 290/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4394 - val_accuracy: 0.8990\n","\n","Epoch 00290: val_accuracy did not improve from 0.93350\n","Epoch 291/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9212\n","\n","Epoch 00291: val_accuracy did not improve from 0.93350\n","Epoch 292/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4980 - val_accuracy: 0.9039\n","\n","Epoch 00292: val_accuracy did not improve from 0.93350\n","Epoch 293/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.6714 - val_accuracy: 0.8793\n","\n","Epoch 00293: val_accuracy did not improve from 0.93350\n","Epoch 294/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.7039 - val_accuracy: 0.8645\n","\n","Epoch 00294: val_accuracy did not improve from 0.93350\n","Epoch 295/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0149 - accuracy: 0.9927 - val_loss: 0.7798 - val_accuracy: 0.8793\n","\n","Epoch 00295: val_accuracy did not improve from 0.93350\n","Epoch 296/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.7168 - val_accuracy: 0.8571\n","\n","Epoch 00296: val_accuracy did not improve from 0.93350\n","Epoch 297/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0426 - accuracy: 0.9823 - val_loss: 0.6459 - val_accuracy: 0.8670\n","\n","Epoch 00297: val_accuracy did not improve from 0.93350\n","Epoch 298/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.6284 - val_accuracy: 0.9015\n","\n","Epoch 00298: val_accuracy did not improve from 0.93350\n","Epoch 299/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.6379 - val_accuracy: 0.8916\n","\n","Epoch 00299: val_accuracy did not improve from 0.93350\n","Epoch 300/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0401 - accuracy: 0.9903 - val_loss: 0.5601 - val_accuracy: 0.8941\n","\n","Epoch 00300: val_accuracy did not improve from 0.93350\n","Epoch 301/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.5592 - val_accuracy: 0.8768\n","\n","Epoch 00301: val_accuracy did not improve from 0.93350\n","Epoch 302/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.5326 - val_accuracy: 0.8941\n","\n","Epoch 00302: val_accuracy did not improve from 0.93350\n","Epoch 303/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5253 - val_accuracy: 0.9138\n","\n","Epoch 00303: val_accuracy did not improve from 0.93350\n","Epoch 304/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4733 - val_accuracy: 0.9089\n","\n","Epoch 00304: val_accuracy did not improve from 0.93350\n","Epoch 305/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.4825 - val_accuracy: 0.9113\n","\n","Epoch 00305: val_accuracy did not improve from 0.93350\n","Epoch 306/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.5152 - val_accuracy: 0.9039\n","\n","Epoch 00306: val_accuracy did not improve from 0.93350\n","Epoch 307/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4471 - val_accuracy: 0.9113\n","\n","Epoch 00307: val_accuracy did not improve from 0.93350\n","Epoch 308/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5117 - val_accuracy: 0.8916\n","\n","Epoch 00308: val_accuracy did not improve from 0.93350\n","Epoch 309/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4831 - val_accuracy: 0.9089\n","\n","Epoch 00309: val_accuracy did not improve from 0.93350\n","Epoch 310/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5414 - val_accuracy: 0.8916\n","\n","Epoch 00310: val_accuracy did not improve from 0.93350\n","Epoch 311/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4662 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.93350\n","Epoch 312/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4282 - val_accuracy: 0.9089\n","\n","Epoch 00312: val_accuracy did not improve from 0.93350\n","Epoch 313/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5184 - val_accuracy: 0.9113\n","\n","Epoch 00313: val_accuracy did not improve from 0.93350\n","Epoch 314/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.7040 - val_accuracy: 0.8670\n","\n","Epoch 00314: val_accuracy did not improve from 0.93350\n","Epoch 315/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.4695 - val_accuracy: 0.9113\n","\n","Epoch 00315: val_accuracy did not improve from 0.93350\n","Epoch 316/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.6300 - val_accuracy: 0.8695\n","\n","Epoch 00316: val_accuracy did not improve from 0.93350\n","Epoch 317/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.4493 - val_accuracy: 0.9113\n","\n","Epoch 00317: val_accuracy did not improve from 0.93350\n","Epoch 318/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.6145 - val_accuracy: 0.8768\n","\n","Epoch 00318: val_accuracy did not improve from 0.93350\n","Epoch 319/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6405 - val_accuracy: 0.8744\n","\n","Epoch 00319: val_accuracy did not improve from 0.93350\n","Epoch 320/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.4695 - val_accuracy: 0.9113\n","\n","Epoch 00320: val_accuracy did not improve from 0.93350\n","Epoch 321/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.4949 - val_accuracy: 0.9113\n","\n","Epoch 00321: val_accuracy did not improve from 0.93350\n","Epoch 322/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.5641 - val_accuracy: 0.8990\n","\n","Epoch 00322: val_accuracy did not improve from 0.93350\n","Epoch 323/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9163\n","\n","Epoch 00323: val_accuracy did not improve from 0.93350\n","Epoch 324/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.0092e-04 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9138\n","\n","Epoch 00324: val_accuracy did not improve from 0.93350\n","Epoch 325/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.5369e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9187\n","\n","Epoch 00325: val_accuracy did not improve from 0.93350\n","Epoch 326/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6251 - val_accuracy: 0.8966\n","\n","Epoch 00326: val_accuracy did not improve from 0.93350\n","Epoch 327/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5659 - val_accuracy: 0.8892\n","\n","Epoch 00327: val_accuracy did not improve from 0.93350\n","Epoch 328/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6063 - val_accuracy: 0.8842\n","\n","Epoch 00328: val_accuracy did not improve from 0.93350\n","Epoch 329/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4902 - val_accuracy: 0.9113\n","\n","Epoch 00329: val_accuracy did not improve from 0.93350\n","Epoch 330/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.5853 - val_accuracy: 0.9089\n","\n","Epoch 00330: val_accuracy did not improve from 0.93350\n","Epoch 331/500\n","52/52 [==============================] - 21s 404ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.9879 - val_accuracy: 0.8103\n","\n","Epoch 00331: val_accuracy did not improve from 0.93350\n","Epoch 332/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 0.7698 - val_accuracy: 0.8695\n","\n","Epoch 00332: val_accuracy did not improve from 0.93350\n","Epoch 333/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6367 - val_accuracy: 0.8719\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0094 - accuracy: 0.9951 - val_loss: 0.4075 - val_accuracy: 0.9187\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5039 - val_accuracy: 0.9163\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4749 - val_accuracy: 0.9089\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5379 - val_accuracy: 0.9089\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 20s 391ms/step - loss: 9.5491e-04 - accuracy: 0.9994 - val_loss: 0.4523 - val_accuracy: 0.9286\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 1.0240 - val_accuracy: 0.8621\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 1.8269 - val_accuracy: 0.8005\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.7131 - val_accuracy: 0.8941\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.6462 - val_accuracy: 0.9039\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.6042 - val_accuracy: 0.9064\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5003 - val_accuracy: 0.9064\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6018 - val_accuracy: 0.8966\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5620 - val_accuracy: 0.9039\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.5616 - val_accuracy: 0.8966\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.5828 - val_accuracy: 0.8990\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5411 - val_accuracy: 0.8892\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5103 - val_accuracy: 0.9163\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4977 - val_accuracy: 0.9039\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4526 - val_accuracy: 0.8990\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9039\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9113\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 20s 391ms/step - loss: 3.7590e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9187\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.5026e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9286\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.1240e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9113\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.4488e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9261\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5029 - val_accuracy: 0.9015\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.6106 - val_accuracy: 0.8842\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.7117 - val_accuracy: 0.8892\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.6034 - val_accuracy: 0.8966\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.6249 - val_accuracy: 0.9138\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.6545 - val_accuracy: 0.8867\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.5152 - val_accuracy: 0.9015\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.7102 - val_accuracy: 0.8916\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.8965 - val_accuracy: 0.8596\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0465 - accuracy: 0.9836 - val_loss: 1.1325 - val_accuracy: 0.7906\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.6585 - val_accuracy: 0.8695\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.6579 - val_accuracy: 0.8768\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5222 - val_accuracy: 0.9064\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4603 - val_accuracy: 0.9089\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 20s 386ms/step - loss: 7.5152e-04 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9089\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.4687e-04 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9212\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5312 - val_accuracy: 0.9163\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0365 - accuracy: 0.9927 - val_loss: 0.8795 - val_accuracy: 0.8547\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.6813 - val_accuracy: 0.8842\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.4977 - val_accuracy: 0.8966\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.5023 - val_accuracy: 0.8990\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4787 - val_accuracy: 0.9113\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4319 - val_accuracy: 0.9113\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.8941\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9163\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.7410e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9015\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4088 - val_accuracy: 0.9187\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4280 - val_accuracy: 0.9212\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4420 - val_accuracy: 0.9064\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5183 - val_accuracy: 0.9015\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9212\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.3985 - val_accuracy: 0.9163\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.6145 - val_accuracy: 0.8867\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.3959 - val_accuracy: 0.9089\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5437 - val_accuracy: 0.8916\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5402 - val_accuracy: 0.9163\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 1.1451 - val_accuracy: 0.8448\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0447 - accuracy: 0.9866 - val_loss: 0.7686 - val_accuracy: 0.8793\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.8323 - val_accuracy: 0.8522\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0178 - accuracy: 0.9927 - val_loss: 0.8713 - val_accuracy: 0.8374\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.6190 - val_accuracy: 0.8621\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.5053 - val_accuracy: 0.8990\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4384 - val_accuracy: 0.9113\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.7264e-04 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9015\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 20s 389ms/step - loss: 6.8911e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9064\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 20s 389ms/step - loss: 3.8828e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9212\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5375 - val_accuracy: 0.9113\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5582 - val_accuracy: 0.9064\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5252 - val_accuracy: 0.9089\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5282 - val_accuracy: 0.9015\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6072 - val_accuracy: 0.8818\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.8753 - val_accuracy: 0.8276\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5534 - val_accuracy: 0.8941\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5199 - val_accuracy: 0.9163\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6275 - val_accuracy: 0.8990\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.6558 - val_accuracy: 0.8842\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.5694 - val_accuracy: 0.9064\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5574 - val_accuracy: 0.9163\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5013 - val_accuracy: 0.9261\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5101 - val_accuracy: 0.9212\n","\n","Epoch 00418: val_accuracy did not improve from 0.93350\n","Epoch 419/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5758 - val_accuracy: 0.9089\n","\n","Epoch 00419: val_accuracy did not improve from 0.93350\n","Epoch 420/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9113\n","\n","Epoch 00420: val_accuracy did not improve from 0.93350\n","Epoch 421/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.5774e-04 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.9064\n","\n","Epoch 00421: val_accuracy did not improve from 0.93350\n","Epoch 422/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.6013e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9064\n","\n","Epoch 00422: val_accuracy did not improve from 0.93350\n","Epoch 423/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.0037e-04 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.9039\n","\n","Epoch 00423: val_accuracy did not improve from 0.93350\n","Epoch 424/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.0627e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9187\n","\n","Epoch 00424: val_accuracy did not improve from 0.93350\n","Epoch 425/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.5221 - val_accuracy: 0.9064\n","\n","Epoch 00425: val_accuracy did not improve from 0.93350\n","Epoch 426/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.0710e-04 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9212\n","\n","Epoch 00426: val_accuracy did not improve from 0.93350\n","Epoch 427/500\n","52/52 [==============================] - 20s 387ms/step - loss: 2.0647e-04 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9138\n","\n","Epoch 00427: val_accuracy did not improve from 0.93350\n","Epoch 428/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.9172e-04 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.9163\n","\n","Epoch 00428: val_accuracy did not improve from 0.93350\n","Epoch 429/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.8021e-04 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.9113\n","\n","Epoch 00429: val_accuracy did not improve from 0.93350\n","Epoch 430/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.5987e-04 - accuracy: 0.9994 - val_loss: 0.6364 - val_accuracy: 0.8867\n","\n","Epoch 00430: val_accuracy did not improve from 0.93350\n","Epoch 431/500\n","52/52 [==============================] - 20s 389ms/step - loss: 5.1877e-04 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.9187\n","\n","Epoch 00431: val_accuracy did not improve from 0.93350\n","Epoch 432/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.7660e-04 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9163\n","\n","Epoch 00432: val_accuracy did not improve from 0.93350\n","Epoch 433/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.1453e-04 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.9039\n","\n","Epoch 00433: val_accuracy did not improve from 0.93350\n","Epoch 434/500\n","52/52 [==============================] - 20s 391ms/step - loss: 2.1156e-04 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.9113\n","\n","Epoch 00434: val_accuracy did not improve from 0.93350\n","Epoch 435/500\n","52/52 [==============================] - 20s 388ms/step - loss: 6.3999e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9187\n","\n","Epoch 00435: val_accuracy did not improve from 0.93350\n","Epoch 436/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5837 - val_accuracy: 0.8966\n","\n","Epoch 00436: val_accuracy did not improve from 0.93350\n","Epoch 437/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.6830 - val_accuracy: 0.8793\n","\n","Epoch 00437: val_accuracy did not improve from 0.93350\n","Epoch 438/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.7757 - val_accuracy: 0.8966\n","\n","Epoch 00438: val_accuracy did not improve from 0.93350\n","Epoch 439/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 1.7750 - val_accuracy: 0.7833\n","\n","Epoch 00439: val_accuracy did not improve from 0.93350\n","Epoch 440/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0783 - accuracy: 0.9799 - val_loss: 1.6566 - val_accuracy: 0.7635\n","\n","Epoch 00440: val_accuracy did not improve from 0.93350\n","Epoch 441/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 1.3208 - val_accuracy: 0.8374\n","\n","Epoch 00441: val_accuracy did not improve from 0.93350\n","Epoch 442/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0476 - accuracy: 0.9866 - val_loss: 0.8726 - val_accuracy: 0.8670\n","\n","Epoch 00442: val_accuracy did not improve from 0.93350\n","Epoch 443/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.5588 - val_accuracy: 0.8621\n","\n","Epoch 00443: val_accuracy did not improve from 0.93350\n","Epoch 444/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0247 - accuracy: 0.9896 - val_loss: 0.5828 - val_accuracy: 0.8571\n","\n","Epoch 00444: val_accuracy did not improve from 0.93350\n","Epoch 445/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 0.4486 - val_accuracy: 0.9064\n","\n","Epoch 00445: val_accuracy did not improve from 0.93350\n","Epoch 446/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5330 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.93350\n","Epoch 447/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6382 - val_accuracy: 0.8867\n","\n","Epoch 00447: val_accuracy did not improve from 0.93350\n","Epoch 448/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5184 - val_accuracy: 0.9113\n","\n","Epoch 00448: val_accuracy did not improve from 0.93350\n","Epoch 449/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9015\n","\n","Epoch 00449: val_accuracy did not improve from 0.93350\n","Epoch 450/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.2058e-04 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9212\n","\n","Epoch 00450: val_accuracy did not improve from 0.93350\n","Epoch 451/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4378 - val_accuracy: 0.9113\n","\n","Epoch 00451: val_accuracy did not improve from 0.93350\n","Epoch 452/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4642 - val_accuracy: 0.9138\n","\n","Epoch 00452: val_accuracy did not improve from 0.93350\n","Epoch 453/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5092 - val_accuracy: 0.8941\n","\n","Epoch 00453: val_accuracy did not improve from 0.93350\n","Epoch 454/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9089\n","\n","Epoch 00454: val_accuracy did not improve from 0.93350\n","Epoch 455/500\n","52/52 [==============================] - 20s 390ms/step - loss: 6.2046e-04 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9039\n","\n","Epoch 00455: val_accuracy did not improve from 0.93350\n","Epoch 456/500\n","52/52 [==============================] - 20s 392ms/step - loss: 4.2396e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9187\n","\n","Epoch 00456: val_accuracy did not improve from 0.93350\n","Epoch 457/500\n","52/52 [==============================] - 20s 389ms/step - loss: 1.3287e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9064\n","\n","Epoch 00457: val_accuracy did not improve from 0.93350\n","Epoch 458/500\n","52/52 [==============================] - 20s 388ms/step - loss: 3.6039e-04 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9212\n","\n","Epoch 00458: val_accuracy did not improve from 0.93350\n","Epoch 459/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4864 - val_accuracy: 0.9113\n","\n","Epoch 00459: val_accuracy did not improve from 0.93350\n","Epoch 460/500\n","52/52 [==============================] - 20s 388ms/step - loss: 4.7177e-04 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9064\n","\n","Epoch 00460: val_accuracy did not improve from 0.93350\n","Epoch 461/500\n","52/52 [==============================] - 21s 402ms/step - loss: 4.9605e-04 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9089\n","\n","Epoch 00461: val_accuracy did not improve from 0.93350\n","Epoch 462/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.2157e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9089\n","\n","Epoch 00462: val_accuracy did not improve from 0.93350\n","Epoch 463/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.5393e-04 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9187\n","\n","Epoch 00463: val_accuracy did not improve from 0.93350\n","Epoch 464/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.8023 - val_accuracy: 0.8571\n","\n","Epoch 00464: val_accuracy did not improve from 0.93350\n","Epoch 465/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 1.3637 - val_accuracy: 0.8473\n","\n","Epoch 00465: val_accuracy did not improve from 0.93350\n","Epoch 466/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 1.5201 - val_accuracy: 0.7783\n","\n","Epoch 00466: val_accuracy did not improve from 0.93350\n","Epoch 467/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0324 - accuracy: 0.9927 - val_loss: 0.6281 - val_accuracy: 0.8916\n","\n","Epoch 00467: val_accuracy did not improve from 0.93350\n","Epoch 468/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5674 - val_accuracy: 0.9015\n","\n","Epoch 00468: val_accuracy did not improve from 0.93350\n","Epoch 469/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.5659 - val_accuracy: 0.9039\n","\n","Epoch 00469: val_accuracy did not improve from 0.93350\n","Epoch 470/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.1863e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9089\n","\n","Epoch 00470: val_accuracy did not improve from 0.93350\n","Epoch 471/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4630 - val_accuracy: 0.9138\n","\n","Epoch 00471: val_accuracy did not improve from 0.93350\n","Epoch 472/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5302 - val_accuracy: 0.9039\n","\n","Epoch 00472: val_accuracy did not improve from 0.93350\n","Epoch 473/500\n","52/52 [==============================] - 20s 387ms/step - loss: 4.7671e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9163\n","\n","Epoch 00473: val_accuracy did not improve from 0.93350\n","Epoch 474/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4075 - val_accuracy: 0.9064\n","\n","Epoch 00474: val_accuracy did not improve from 0.93350\n","Epoch 475/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9064\n","\n","Epoch 00475: val_accuracy did not improve from 0.93350\n","Epoch 476/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9261\n","\n","Epoch 00476: val_accuracy did not improve from 0.93350\n","Epoch 477/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.4078e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9236\n","\n","Epoch 00477: val_accuracy did not improve from 0.93350\n","Epoch 478/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3574 - val_accuracy: 0.9310\n","\n","Epoch 00478: val_accuracy did not improve from 0.93350\n","Epoch 479/500\n","52/52 [==============================] - 20s 388ms/step - loss: 5.9303e-04 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9236\n","\n","Epoch 00479: val_accuracy did not improve from 0.93350\n","Epoch 480/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4764 - val_accuracy: 0.9113\n","\n","Epoch 00480: val_accuracy did not improve from 0.93350\n","Epoch 481/500\n","52/52 [==============================] - 20s 388ms/step - loss: 7.1418e-04 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9286\n","\n","Epoch 00481: val_accuracy did not improve from 0.93350\n","Epoch 482/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.4759e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9433\n","\n","Epoch 00482: val_accuracy improved from 0.93350 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5\n","Epoch 483/500\n","52/52 [==============================] - 20s 389ms/step - loss: 2.4692e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9236\n","\n","Epoch 00483: val_accuracy did not improve from 0.94335\n","Epoch 484/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3879 - val_accuracy: 0.9212\n","\n","Epoch 00484: val_accuracy did not improve from 0.94335\n","Epoch 485/500\n","52/52 [==============================] - 20s 388ms/step - loss: 2.1342e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9286\n","\n","Epoch 00485: val_accuracy did not improve from 0.94335\n","Epoch 486/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4378 - val_accuracy: 0.9138\n","\n","Epoch 00486: val_accuracy did not improve from 0.94335\n","Epoch 487/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4842 - val_accuracy: 0.9236\n","\n","Epoch 00487: val_accuracy did not improve from 0.94335\n","Epoch 488/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9163\n","\n","Epoch 00488: val_accuracy did not improve from 0.94335\n","Epoch 489/500\n","52/52 [==============================] - 20s 391ms/step - loss: 3.4447e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9163\n","\n","Epoch 00489: val_accuracy did not improve from 0.94335\n","Epoch 490/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4321 - val_accuracy: 0.9187\n","\n","Epoch 00490: val_accuracy did not improve from 0.94335\n","Epoch 491/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.6796 - val_accuracy: 0.8768\n","\n","Epoch 00491: val_accuracy did not improve from 0.94335\n","Epoch 492/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 1.7692 - val_accuracy: 0.6970\n","\n","Epoch 00492: val_accuracy did not improve from 0.94335\n","Epoch 493/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0983 - accuracy: 0.9732 - val_loss: 1.3631 - val_accuracy: 0.7414\n","\n","Epoch 00493: val_accuracy did not improve from 0.94335\n","Epoch 494/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.9511 - val_accuracy: 0.8374\n","\n","Epoch 00494: val_accuracy did not improve from 0.94335\n","Epoch 495/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0132 - accuracy: 0.9945 - val_loss: 0.6605 - val_accuracy: 0.8744\n","\n","Epoch 00495: val_accuracy did not improve from 0.94335\n","Epoch 496/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6315 - val_accuracy: 0.8892\n","\n","Epoch 00496: val_accuracy did not improve from 0.94335\n","Epoch 497/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5148 - val_accuracy: 0.8966\n","\n","Epoch 00497: val_accuracy did not improve from 0.94335\n","Epoch 498/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5449 - val_accuracy: 0.9039\n","\n","Epoch 00498: val_accuracy did not improve from 0.94335\n","Epoch 499/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9113\n","\n","Epoch 00499: val_accuracy did not improve from 0.94335\n","Epoch 500/500\n","52/52 [==============================] - 20s 389ms/step - loss: 8.8309e-04 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9015\n","\n","Epoch 00500: val_accuracy did not improve from 0.94335\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f43d8ff5950>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629842335538,"user_tz":-540,"elapsed":66,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"78130c42-6c15-4217-f252-0c1857e11a62"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629842354791,"user_tz":-540,"elapsed":18911,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_3_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629842355545,"user_tz":-540,"elapsed":759,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629842356332,"user_tz":-540,"elapsed":789,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"ad0e36b3-1811-4c60-ab19-85f66b2ce809"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629842414328,"user_tz":-540,"elapsed":57999,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"52be2f45-1abc-4002-ab16-caccfd2a3d51"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629842414810,"user_tz":-540,"elapsed":484,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629842414812,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629842415823,"user_tz":-540,"elapsed":1017,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629842415827,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629842427298,"user_tz":-540,"elapsed":11476,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629842427304,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c2e22d10-ca87-408d-a68b-910a57cc674f"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629842427306,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d9430cfb-6b40-4e85-f745-d3bf2f1d7c3b"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_3_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_3_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ebc6e45e-8b9b-4a9c-807b-83d51712c2bc\", \"Rotation_range_10_3_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}