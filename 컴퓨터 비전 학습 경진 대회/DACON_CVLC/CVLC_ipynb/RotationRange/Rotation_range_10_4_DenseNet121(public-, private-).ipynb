{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotation_range_10_4_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyPkeLbO1aYjnZSm/jKVDdVZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629835441726,"user_tz":-540,"elapsed":366,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c4f59d39-c85b-4d3d-c3ef-786f00dc0363"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 20:04:01 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629835460563,"user_tz":-540,"elapsed":18843,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c9fd2ddb-1b37-4559-86f9-ee709adc87c3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629835464221,"user_tz":-540,"elapsed":3663,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629835465745,"user_tz":-540,"elapsed":1527,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629835467685,"user_tz":-540,"elapsed":1944,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629835484543,"user_tz":-540,"elapsed":16861,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629835491407,"user_tz":-540,"elapsed":6865,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629835491408,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"989abac9-bbde-4c2c-bbd4-aa6183be084c"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629835491409,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"5a683a00-22d7-4368-9096-04ac81fdad08"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629835491409,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629845635430,"user_tz":-540,"elapsed":10144036,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"cdb88175-e4fa-4823-a99e-0a9b1972fcc2"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 52s 465ms/step - loss: 1.7555 - accuracy: 0.3776 - val_loss: 5.4102 - val_accuracy: 0.1108\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 364ms/step - loss: 1.1934 - accuracy: 0.6041 - val_loss: 38.4124 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy did not improve from 0.11084\n","Epoch 3/500\n","52/52 [==============================] - 19s 365ms/step - loss: 0.9389 - accuracy: 0.6699 - val_loss: 20.8875 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.11084\n","Epoch 4/500\n","52/52 [==============================] - 19s 367ms/step - loss: 0.8441 - accuracy: 0.7199 - val_loss: 22.0910 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.11084\n","Epoch 5/500\n","52/52 [==============================] - 19s 373ms/step - loss: 0.7399 - accuracy: 0.7473 - val_loss: 5.6208 - val_accuracy: 0.2241\n","\n","Epoch 00005: val_accuracy improved from 0.11084 to 0.22414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 19s 369ms/step - loss: 0.6215 - accuracy: 0.7844 - val_loss: 8.1224 - val_accuracy: 0.1576\n","\n","Epoch 00006: val_accuracy did not improve from 0.22414\n","Epoch 7/500\n","52/52 [==============================] - 19s 372ms/step - loss: 0.5540 - accuracy: 0.8112 - val_loss: 6.6999 - val_accuracy: 0.1970\n","\n","Epoch 00007: val_accuracy did not improve from 0.22414\n","Epoch 8/500\n","52/52 [==============================] - 19s 373ms/step - loss: 0.5157 - accuracy: 0.8289 - val_loss: 4.5702 - val_accuracy: 0.2808\n","\n","Epoch 00008: val_accuracy improved from 0.22414 to 0.28079, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 19s 372ms/step - loss: 0.4662 - accuracy: 0.8392 - val_loss: 4.8093 - val_accuracy: 0.3079\n","\n","Epoch 00009: val_accuracy improved from 0.28079 to 0.30788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 374ms/step - loss: 0.4752 - accuracy: 0.8368 - val_loss: 2.7388 - val_accuracy: 0.4458\n","\n","Epoch 00010: val_accuracy improved from 0.30788 to 0.44581, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.4452 - accuracy: 0.8453 - val_loss: 3.3816 - val_accuracy: 0.4655\n","\n","Epoch 00011: val_accuracy improved from 0.44581 to 0.46552, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.4002 - accuracy: 0.8642 - val_loss: 1.3596 - val_accuracy: 0.6576\n","\n","Epoch 00012: val_accuracy improved from 0.46552 to 0.65764, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 20s 375ms/step - loss: 0.3901 - accuracy: 0.8715 - val_loss: 2.5974 - val_accuracy: 0.5197\n","\n","Epoch 00013: val_accuracy did not improve from 0.65764\n","Epoch 14/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.3492 - accuracy: 0.8800 - val_loss: 2.6665 - val_accuracy: 0.5443\n","\n","Epoch 00014: val_accuracy did not improve from 0.65764\n","Epoch 15/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.3053 - accuracy: 0.8983 - val_loss: 1.2256 - val_accuracy: 0.6773\n","\n","Epoch 00015: val_accuracy improved from 0.65764 to 0.67734, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2994 - accuracy: 0.8995 - val_loss: 0.6665 - val_accuracy: 0.7931\n","\n","Epoch 00016: val_accuracy improved from 0.67734 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.3684 - accuracy: 0.8678 - val_loss: 0.6928 - val_accuracy: 0.7931\n","\n","Epoch 00017: val_accuracy did not improve from 0.79310\n","Epoch 18/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.3042 - accuracy: 0.8989 - val_loss: 0.8720 - val_accuracy: 0.7808\n","\n","Epoch 00018: val_accuracy did not improve from 0.79310\n","Epoch 19/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2377 - accuracy: 0.9153 - val_loss: 0.9071 - val_accuracy: 0.7635\n","\n","Epoch 00019: val_accuracy did not improve from 0.79310\n","Epoch 20/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2709 - accuracy: 0.9080 - val_loss: 1.6585 - val_accuracy: 0.6207\n","\n","Epoch 00020: val_accuracy did not improve from 0.79310\n","Epoch 21/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2616 - accuracy: 0.9160 - val_loss: 1.1567 - val_accuracy: 0.7365\n","\n","Epoch 00021: val_accuracy did not improve from 0.79310\n","Epoch 22/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2931 - accuracy: 0.9086 - val_loss: 1.1633 - val_accuracy: 0.6970\n","\n","Epoch 00022: val_accuracy did not improve from 0.79310\n","Epoch 23/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2296 - accuracy: 0.9111 - val_loss: 0.6640 - val_accuracy: 0.8424\n","\n","Epoch 00023: val_accuracy improved from 0.79310 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2162 - accuracy: 0.9294 - val_loss: 0.6594 - val_accuracy: 0.8103\n","\n","Epoch 00024: val_accuracy did not improve from 0.84236\n","Epoch 25/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.2020 - accuracy: 0.9342 - val_loss: 0.5258 - val_accuracy: 0.8571\n","\n","Epoch 00025: val_accuracy improved from 0.84236 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1454 - accuracy: 0.9586 - val_loss: 0.6654 - val_accuracy: 0.8251\n","\n","Epoch 00026: val_accuracy did not improve from 0.85714\n","Epoch 27/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1509 - accuracy: 0.9513 - val_loss: 0.5805 - val_accuracy: 0.8350\n","\n","Epoch 00027: val_accuracy did not improve from 0.85714\n","Epoch 28/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1913 - accuracy: 0.9373 - val_loss: 1.1495 - val_accuracy: 0.7143\n","\n","Epoch 00028: val_accuracy did not improve from 0.85714\n","Epoch 29/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1514 - accuracy: 0.9470 - val_loss: 0.5797 - val_accuracy: 0.8424\n","\n","Epoch 00029: val_accuracy did not improve from 0.85714\n","Epoch 30/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1483 - accuracy: 0.9482 - val_loss: 0.9943 - val_accuracy: 0.7685\n","\n","Epoch 00030: val_accuracy did not improve from 0.85714\n","Epoch 31/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1453 - accuracy: 0.9525 - val_loss: 1.1044 - val_accuracy: 0.7611\n","\n","Epoch 00031: val_accuracy did not improve from 0.85714\n","Epoch 32/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2326 - accuracy: 0.9208 - val_loss: 12.8443 - val_accuracy: 0.1527\n","\n","Epoch 00032: val_accuracy did not improve from 0.85714\n","Epoch 33/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2859 - accuracy: 0.8959 - val_loss: 1.1859 - val_accuracy: 0.7143\n","\n","Epoch 00033: val_accuracy did not improve from 0.85714\n","Epoch 34/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1694 - accuracy: 0.9434 - val_loss: 0.9017 - val_accuracy: 0.7414\n","\n","Epoch 00034: val_accuracy did not improve from 0.85714\n","Epoch 35/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1271 - accuracy: 0.9622 - val_loss: 0.4428 - val_accuracy: 0.8818\n","\n","Epoch 00035: val_accuracy improved from 0.85714 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.1459 - accuracy: 0.9464 - val_loss: 0.6058 - val_accuracy: 0.8325\n","\n","Epoch 00036: val_accuracy did not improve from 0.88177\n","Epoch 37/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0887 - accuracy: 0.9726 - val_loss: 0.4678 - val_accuracy: 0.8498\n","\n","Epoch 00037: val_accuracy did not improve from 0.88177\n","Epoch 38/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0782 - accuracy: 0.9702 - val_loss: 0.3963 - val_accuracy: 0.8744\n","\n","Epoch 00038: val_accuracy did not improve from 0.88177\n","Epoch 39/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.1341 - accuracy: 0.9537 - val_loss: 1.7171 - val_accuracy: 0.6379\n","\n","Epoch 00039: val_accuracy did not improve from 0.88177\n","Epoch 40/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1320 - accuracy: 0.9537 - val_loss: 1.6629 - val_accuracy: 0.6626\n","\n","Epoch 00040: val_accuracy did not improve from 0.88177\n","Epoch 41/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1142 - accuracy: 0.9598 - val_loss: 0.4571 - val_accuracy: 0.8842\n","\n","Epoch 00041: val_accuracy improved from 0.88177 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 42/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0929 - accuracy: 0.9714 - val_loss: 0.7939 - val_accuracy: 0.8202\n","\n","Epoch 00042: val_accuracy did not improve from 0.88424\n","Epoch 43/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1067 - accuracy: 0.9610 - val_loss: 0.8739 - val_accuracy: 0.8103\n","\n","Epoch 00043: val_accuracy did not improve from 0.88424\n","Epoch 44/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0923 - accuracy: 0.9629 - val_loss: 0.5346 - val_accuracy: 0.8719\n","\n","Epoch 00044: val_accuracy did not improve from 0.88424\n","Epoch 45/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0889 - accuracy: 0.9677 - val_loss: 0.3842 - val_accuracy: 0.8916\n","\n","Epoch 00045: val_accuracy improved from 0.88424 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 46/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0968 - accuracy: 0.9653 - val_loss: 0.5332 - val_accuracy: 0.8473\n","\n","Epoch 00046: val_accuracy did not improve from 0.89163\n","Epoch 47/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 0.5463 - val_accuracy: 0.8547\n","\n","Epoch 00047: val_accuracy did not improve from 0.89163\n","Epoch 48/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0971 - accuracy: 0.9665 - val_loss: 0.4514 - val_accuracy: 0.8596\n","\n","Epoch 00048: val_accuracy did not improve from 0.89163\n","Epoch 49/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1290 - accuracy: 0.9586 - val_loss: 0.7818 - val_accuracy: 0.8103\n","\n","Epoch 00049: val_accuracy did not improve from 0.89163\n","Epoch 50/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0812 - accuracy: 0.9762 - val_loss: 0.5394 - val_accuracy: 0.8571\n","\n","Epoch 00050: val_accuracy did not improve from 0.89163\n","Epoch 51/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0831 - accuracy: 0.9708 - val_loss: 0.6378 - val_accuracy: 0.8424\n","\n","Epoch 00051: val_accuracy did not improve from 0.89163\n","Epoch 52/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0937 - accuracy: 0.9647 - val_loss: 0.4716 - val_accuracy: 0.8695\n","\n","Epoch 00052: val_accuracy did not improve from 0.89163\n","Epoch 53/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1054 - accuracy: 0.9677 - val_loss: 0.5281 - val_accuracy: 0.8744\n","\n","Epoch 00053: val_accuracy did not improve from 0.89163\n","Epoch 54/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.6695 - val_accuracy: 0.8448\n","\n","Epoch 00054: val_accuracy did not improve from 0.89163\n","Epoch 55/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0855 - accuracy: 0.9653 - val_loss: 0.6191 - val_accuracy: 0.8448\n","\n","Epoch 00055: val_accuracy did not improve from 0.89163\n","Epoch 56/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0784 - accuracy: 0.9702 - val_loss: 0.6785 - val_accuracy: 0.8374\n","\n","Epoch 00056: val_accuracy did not improve from 0.89163\n","Epoch 57/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1089 - accuracy: 0.9629 - val_loss: 0.8538 - val_accuracy: 0.8103\n","\n","Epoch 00057: val_accuracy did not improve from 0.89163\n","Epoch 58/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0462 - accuracy: 0.9836 - val_loss: 0.5630 - val_accuracy: 0.8695\n","\n","Epoch 00058: val_accuracy did not improve from 0.89163\n","Epoch 59/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.3865 - val_accuracy: 0.8990\n","\n","Epoch 00059: val_accuracy improved from 0.89163 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 60/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.5675 - val_accuracy: 0.8670\n","\n","Epoch 00060: val_accuracy did not improve from 0.89901\n","Epoch 61/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.5383 - val_accuracy: 0.8793\n","\n","Epoch 00061: val_accuracy did not improve from 0.89901\n","Epoch 62/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0932 - accuracy: 0.9702 - val_loss: 0.7474 - val_accuracy: 0.8498\n","\n","Epoch 00062: val_accuracy did not improve from 0.89901\n","Epoch 63/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.0960 - accuracy: 0.9744 - val_loss: 0.5968 - val_accuracy: 0.8547\n","\n","Epoch 00063: val_accuracy did not improve from 0.89901\n","Epoch 64/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1239 - accuracy: 0.9610 - val_loss: 0.6862 - val_accuracy: 0.8448\n","\n","Epoch 00064: val_accuracy did not improve from 0.89901\n","Epoch 65/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.6676 - val_accuracy: 0.8645\n","\n","Epoch 00065: val_accuracy did not improve from 0.89901\n","Epoch 66/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 0.5832 - val_accuracy: 0.8768\n","\n","Epoch 00066: val_accuracy did not improve from 0.89901\n","Epoch 67/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0735 - accuracy: 0.9769 - val_loss: 0.6411 - val_accuracy: 0.8448\n","\n","Epoch 00067: val_accuracy did not improve from 0.89901\n","Epoch 68/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.4710 - val_accuracy: 0.8818\n","\n","Epoch 00068: val_accuracy did not improve from 0.89901\n","Epoch 69/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0492 - accuracy: 0.9799 - val_loss: 0.7205 - val_accuracy: 0.8596\n","\n","Epoch 00069: val_accuracy did not improve from 0.89901\n","Epoch 70/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.4250 - val_accuracy: 0.8892\n","\n","Epoch 00070: val_accuracy did not improve from 0.89901\n","Epoch 71/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.7456 - val_accuracy: 0.8448\n","\n","Epoch 00071: val_accuracy did not improve from 0.89901\n","Epoch 72/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.6333 - val_accuracy: 0.8522\n","\n","Epoch 00072: val_accuracy did not improve from 0.89901\n","Epoch 73/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 0.8244 - val_accuracy: 0.8128\n","\n","Epoch 00073: val_accuracy did not improve from 0.89901\n","Epoch 74/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0939 - accuracy: 0.9708 - val_loss: 0.7838 - val_accuracy: 0.8522\n","\n","Epoch 00074: val_accuracy did not improve from 0.89901\n","Epoch 75/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.6694 - val_accuracy: 0.8596\n","\n","Epoch 00075: val_accuracy did not improve from 0.89901\n","Epoch 76/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0446 - accuracy: 0.9836 - val_loss: 0.5009 - val_accuracy: 0.8768\n","\n","Epoch 00076: val_accuracy did not improve from 0.89901\n","Epoch 77/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0435 - accuracy: 0.9848 - val_loss: 0.7094 - val_accuracy: 0.8424\n","\n","Epoch 00077: val_accuracy did not improve from 0.89901\n","Epoch 78/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.9707 - val_accuracy: 0.8177\n","\n","Epoch 00078: val_accuracy did not improve from 0.89901\n","Epoch 79/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0889 - accuracy: 0.9732 - val_loss: 1.2567 - val_accuracy: 0.7512\n","\n","Epoch 00079: val_accuracy did not improve from 0.89901\n","Epoch 80/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1107 - accuracy: 0.9671 - val_loss: 0.9185 - val_accuracy: 0.8005\n","\n","Epoch 00080: val_accuracy did not improve from 0.89901\n","Epoch 81/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0947 - accuracy: 0.9677 - val_loss: 0.6311 - val_accuracy: 0.8522\n","\n","Epoch 00081: val_accuracy did not improve from 0.89901\n","Epoch 82/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 1.0924 - val_accuracy: 0.7611\n","\n","Epoch 00082: val_accuracy did not improve from 0.89901\n","Epoch 83/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.8629 - val_accuracy: 0.8079\n","\n","Epoch 00083: val_accuracy did not improve from 0.89901\n","Epoch 84/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0813 - accuracy: 0.9756 - val_loss: 0.6008 - val_accuracy: 0.8596\n","\n","Epoch 00084: val_accuracy did not improve from 0.89901\n","Epoch 85/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.6804 - val_accuracy: 0.8596\n","\n","Epoch 00085: val_accuracy did not improve from 0.89901\n","Epoch 86/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.4243 - val_accuracy: 0.9261\n","\n","Epoch 00086: val_accuracy improved from 0.89901 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 87/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 1.4885 - val_accuracy: 0.7635\n","\n","Epoch 00087: val_accuracy did not improve from 0.92611\n","Epoch 88/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.8222 - val_accuracy: 0.8325\n","\n","Epoch 00088: val_accuracy did not improve from 0.92611\n","Epoch 89/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 0.6695 - val_accuracy: 0.8522\n","\n","Epoch 00089: val_accuracy did not improve from 0.92611\n","Epoch 90/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.4711 - val_accuracy: 0.8744\n","\n","Epoch 00090: val_accuracy did not improve from 0.92611\n","Epoch 91/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.4128 - val_accuracy: 0.8941\n","\n","Epoch 00091: val_accuracy did not improve from 0.92611\n","Epoch 92/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.7573 - val_accuracy: 0.8325\n","\n","Epoch 00092: val_accuracy did not improve from 0.92611\n","Epoch 93/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 0.6320 - val_accuracy: 0.8719\n","\n","Epoch 00093: val_accuracy did not improve from 0.92611\n","Epoch 94/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.6981 - val_accuracy: 0.8768\n","\n","Epoch 00094: val_accuracy did not improve from 0.92611\n","Epoch 95/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.5809 - val_accuracy: 0.8793\n","\n","Epoch 00095: val_accuracy did not improve from 0.92611\n","Epoch 96/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.5172 - val_accuracy: 0.8941\n","\n","Epoch 00096: val_accuracy did not improve from 0.92611\n","Epoch 97/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.7077 - val_accuracy: 0.8793\n","\n","Epoch 00097: val_accuracy did not improve from 0.92611\n","Epoch 98/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.4931 - val_accuracy: 0.8892\n","\n","Epoch 00098: val_accuracy did not improve from 0.92611\n","Epoch 99/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.4637 - val_accuracy: 0.8941\n","\n","Epoch 00099: val_accuracy did not improve from 0.92611\n","Epoch 100/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.4392 - val_accuracy: 0.8941\n","\n","Epoch 00100: val_accuracy did not improve from 0.92611\n","Epoch 101/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.5643 - val_accuracy: 0.8744\n","\n","Epoch 00101: val_accuracy did not improve from 0.92611\n","Epoch 102/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0591 - accuracy: 0.9860 - val_loss: 0.7628 - val_accuracy: 0.8547\n","\n","Epoch 00102: val_accuracy did not improve from 0.92611\n","Epoch 103/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0781 - accuracy: 0.9787 - val_loss: 0.7997 - val_accuracy: 0.8473\n","\n","Epoch 00103: val_accuracy did not improve from 0.92611\n","Epoch 104/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0980 - accuracy: 0.9671 - val_loss: 0.9890 - val_accuracy: 0.8153\n","\n","Epoch 00104: val_accuracy did not improve from 0.92611\n","Epoch 105/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1104 - accuracy: 0.9659 - val_loss: 0.7348 - val_accuracy: 0.8547\n","\n","Epoch 00105: val_accuracy did not improve from 0.92611\n","Epoch 106/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.7471 - val_accuracy: 0.8325\n","\n","Epoch 00106: val_accuracy did not improve from 0.92611\n","Epoch 107/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.4270 - val_accuracy: 0.8916\n","\n","Epoch 00107: val_accuracy did not improve from 0.92611\n","Epoch 108/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.7771 - val_accuracy: 0.8448\n","\n","Epoch 00108: val_accuracy did not improve from 0.92611\n","Epoch 109/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0369 - accuracy: 0.9915 - val_loss: 0.6139 - val_accuracy: 0.8744\n","\n","Epoch 00109: val_accuracy did not improve from 0.92611\n","Epoch 110/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0537 - accuracy: 0.9817 - val_loss: 0.7021 - val_accuracy: 0.8719\n","\n","Epoch 00110: val_accuracy did not improve from 0.92611\n","Epoch 111/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0593 - accuracy: 0.9817 - val_loss: 1.0367 - val_accuracy: 0.7783\n","\n","Epoch 00111: val_accuracy did not improve from 0.92611\n","Epoch 112/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.4282 - val_accuracy: 0.9089\n","\n","Epoch 00112: val_accuracy did not improve from 0.92611\n","Epoch 113/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.5859 - val_accuracy: 0.8744\n","\n","Epoch 00113: val_accuracy did not improve from 0.92611\n","Epoch 114/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5719 - val_accuracy: 0.8892\n","\n","Epoch 00114: val_accuracy did not improve from 0.92611\n","Epoch 115/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4198 - val_accuracy: 0.9089\n","\n","Epoch 00115: val_accuracy did not improve from 0.92611\n","Epoch 116/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.4153 - val_accuracy: 0.9138\n","\n","Epoch 00116: val_accuracy did not improve from 0.92611\n","Epoch 117/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4264 - val_accuracy: 0.9015\n","\n","Epoch 00117: val_accuracy did not improve from 0.92611\n","Epoch 118/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3828 - val_accuracy: 0.9163\n","\n","Epoch 00118: val_accuracy did not improve from 0.92611\n","Epoch 119/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9163\n","\n","Epoch 00119: val_accuracy did not improve from 0.92611\n","Epoch 120/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9212\n","\n","Epoch 00120: val_accuracy did not improve from 0.92611\n","Epoch 121/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9138\n","\n","Epoch 00121: val_accuracy did not improve from 0.92611\n","Epoch 122/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4469 - val_accuracy: 0.9212\n","\n","Epoch 00122: val_accuracy did not improve from 0.92611\n","Epoch 123/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5331 - val_accuracy: 0.8966\n","\n","Epoch 00123: val_accuracy did not improve from 0.92611\n","Epoch 124/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9064\n","\n","Epoch 00124: val_accuracy did not improve from 0.92611\n","Epoch 125/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.8398 - val_accuracy: 0.8498\n","\n","Epoch 00125: val_accuracy did not improve from 0.92611\n","Epoch 126/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.6687 - val_accuracy: 0.8596\n","\n","Epoch 00126: val_accuracy did not improve from 0.92611\n","Epoch 127/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1293 - accuracy: 0.9622 - val_loss: 2.7116 - val_accuracy: 0.6330\n","\n","Epoch 00127: val_accuracy did not improve from 0.92611\n","Epoch 128/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1112 - accuracy: 0.9616 - val_loss: 1.1550 - val_accuracy: 0.7956\n","\n","Epoch 00128: val_accuracy did not improve from 0.92611\n","Epoch 129/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 0.8323 - val_accuracy: 0.8276\n","\n","Epoch 00129: val_accuracy did not improve from 0.92611\n","Epoch 130/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0794 - accuracy: 0.9787 - val_loss: 0.9149 - val_accuracy: 0.8498\n","\n","Epoch 00130: val_accuracy did not improve from 0.92611\n","Epoch 131/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.9241 - val_accuracy: 0.8350\n","\n","Epoch 00131: val_accuracy did not improve from 0.92611\n","Epoch 132/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.5258 - val_accuracy: 0.8842\n","\n","Epoch 00132: val_accuracy did not improve from 0.92611\n","Epoch 133/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4462 - val_accuracy: 0.9113\n","\n","Epoch 00133: val_accuracy did not improve from 0.92611\n","Epoch 134/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5327 - val_accuracy: 0.8793\n","\n","Epoch 00134: val_accuracy did not improve from 0.92611\n","Epoch 135/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 0.4981 - val_accuracy: 0.8941\n","\n","Epoch 00135: val_accuracy did not improve from 0.92611\n","Epoch 136/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.7158 - val_accuracy: 0.8621\n","\n","Epoch 00136: val_accuracy did not improve from 0.92611\n","Epoch 137/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.7185 - val_accuracy: 0.8473\n","\n","Epoch 00137: val_accuracy did not improve from 0.92611\n","Epoch 138/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0226 - accuracy: 0.9903 - val_loss: 0.5221 - val_accuracy: 0.8892\n","\n","Epoch 00138: val_accuracy did not improve from 0.92611\n","Epoch 139/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.4858 - val_accuracy: 0.9064\n","\n","Epoch 00139: val_accuracy did not improve from 0.92611\n","Epoch 140/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.5775 - val_accuracy: 0.8892\n","\n","Epoch 00140: val_accuracy did not improve from 0.92611\n","Epoch 141/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0214 - accuracy: 0.9915 - val_loss: 0.7808 - val_accuracy: 0.8300\n","\n","Epoch 00141: val_accuracy did not improve from 0.92611\n","Epoch 142/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6410 - val_accuracy: 0.8719\n","\n","Epoch 00142: val_accuracy did not improve from 0.92611\n","Epoch 143/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.6923 - val_accuracy: 0.8719\n","\n","Epoch 00143: val_accuracy did not improve from 0.92611\n","Epoch 144/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.6006 - val_accuracy: 0.8916\n","\n","Epoch 00144: val_accuracy did not improve from 0.92611\n","Epoch 145/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.7350 - val_accuracy: 0.8793\n","\n","Epoch 00145: val_accuracy did not improve from 0.92611\n","Epoch 146/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.1083 - accuracy: 0.9641 - val_loss: 1.1693 - val_accuracy: 0.7980\n","\n","Epoch 00146: val_accuracy did not improve from 0.92611\n","Epoch 147/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.7676 - val_accuracy: 0.8547\n","\n","Epoch 00147: val_accuracy did not improve from 0.92611\n","Epoch 148/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.5801 - val_accuracy: 0.8867\n","\n","Epoch 00148: val_accuracy did not improve from 0.92611\n","Epoch 149/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0720 - accuracy: 0.9756 - val_loss: 0.9015 - val_accuracy: 0.8621\n","\n","Epoch 00149: val_accuracy did not improve from 0.92611\n","Epoch 150/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.5269 - val_accuracy: 0.8941\n","\n","Epoch 00150: val_accuracy did not improve from 0.92611\n","Epoch 151/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.5341 - val_accuracy: 0.8867\n","\n","Epoch 00151: val_accuracy did not improve from 0.92611\n","Epoch 152/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.4494 - val_accuracy: 0.8916\n","\n","Epoch 00152: val_accuracy did not improve from 0.92611\n","Epoch 153/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.6834 - val_accuracy: 0.8571\n","\n","Epoch 00153: val_accuracy did not improve from 0.92611\n","Epoch 154/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.5136 - val_accuracy: 0.8990\n","\n","Epoch 00154: val_accuracy did not improve from 0.92611\n","Epoch 155/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.5698 - val_accuracy: 0.8793\n","\n","Epoch 00155: val_accuracy did not improve from 0.92611\n","Epoch 156/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.4322 - val_accuracy: 0.9039\n","\n","Epoch 00156: val_accuracy did not improve from 0.92611\n","Epoch 157/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.7820 - val_accuracy: 0.8645\n","\n","Epoch 00157: val_accuracy did not improve from 0.92611\n","Epoch 158/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.6660 - val_accuracy: 0.8645\n","\n","Epoch 00158: val_accuracy did not improve from 0.92611\n","Epoch 159/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0241 - accuracy: 0.9903 - val_loss: 0.6671 - val_accuracy: 0.8768\n","\n","Epoch 00159: val_accuracy did not improve from 0.92611\n","Epoch 160/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0106 - accuracy: 0.9951 - val_loss: 0.5705 - val_accuracy: 0.8990\n","\n","Epoch 00160: val_accuracy did not improve from 0.92611\n","Epoch 161/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0172 - accuracy: 0.9927 - val_loss: 0.7982 - val_accuracy: 0.8744\n","\n","Epoch 00161: val_accuracy did not improve from 0.92611\n","Epoch 162/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4885 - val_accuracy: 0.9015\n","\n","Epoch 00162: val_accuracy did not improve from 0.92611\n","Epoch 163/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 0.6778 - val_accuracy: 0.8818\n","\n","Epoch 00163: val_accuracy did not improve from 0.92611\n","Epoch 164/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.6275 - val_accuracy: 0.8818\n","\n","Epoch 00164: val_accuracy did not improve from 0.92611\n","Epoch 165/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.5385 - val_accuracy: 0.9064\n","\n","Epoch 00165: val_accuracy did not improve from 0.92611\n","Epoch 166/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.4782 - val_accuracy: 0.9039\n","\n","Epoch 00166: val_accuracy did not improve from 0.92611\n","Epoch 167/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.5902 - val_accuracy: 0.8695\n","\n","Epoch 00167: val_accuracy did not improve from 0.92611\n","Epoch 168/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.6684 - val_accuracy: 0.8744\n","\n","Epoch 00168: val_accuracy did not improve from 0.92611\n","Epoch 169/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.6951 - val_accuracy: 0.8768\n","\n","Epoch 00169: val_accuracy did not improve from 0.92611\n","Epoch 170/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.6947 - val_accuracy: 0.8842\n","\n","Epoch 00170: val_accuracy did not improve from 0.92611\n","Epoch 171/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 0.5531 - val_accuracy: 0.8818\n","\n","Epoch 00171: val_accuracy did not improve from 0.92611\n","Epoch 172/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.5044 - val_accuracy: 0.9015\n","\n","Epoch 00172: val_accuracy did not improve from 0.92611\n","Epoch 173/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.4874 - val_accuracy: 0.8768\n","\n","Epoch 00173: val_accuracy did not improve from 0.92611\n","Epoch 174/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.6583 - val_accuracy: 0.8793\n","\n","Epoch 00174: val_accuracy did not improve from 0.92611\n","Epoch 175/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0241 - accuracy: 0.9909 - val_loss: 0.5770 - val_accuracy: 0.8670\n","\n","Epoch 00175: val_accuracy did not improve from 0.92611\n","Epoch 176/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.6115 - val_accuracy: 0.8916\n","\n","Epoch 00176: val_accuracy did not improve from 0.92611\n","Epoch 177/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.7316 - val_accuracy: 0.8596\n","\n","Epoch 00177: val_accuracy did not improve from 0.92611\n","Epoch 178/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.6223 - val_accuracy: 0.8916\n","\n","Epoch 00178: val_accuracy did not improve from 0.92611\n","Epoch 179/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5651 - val_accuracy: 0.8990\n","\n","Epoch 00179: val_accuracy did not improve from 0.92611\n","Epoch 180/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.5019 - val_accuracy: 0.8941\n","\n","Epoch 00180: val_accuracy did not improve from 0.92611\n","Epoch 181/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.4422 - val_accuracy: 0.9163\n","\n","Epoch 00181: val_accuracy did not improve from 0.92611\n","Epoch 182/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9310\n","\n","Epoch 00182: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 183/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.4354 - val_accuracy: 0.9138\n","\n","Epoch 00183: val_accuracy did not improve from 0.93103\n","Epoch 184/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.5177 - val_accuracy: 0.9015\n","\n","Epoch 00184: val_accuracy did not improve from 0.93103\n","Epoch 185/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5277 - val_accuracy: 0.8990\n","\n","Epoch 00185: val_accuracy did not improve from 0.93103\n","Epoch 186/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0053 - accuracy: 0.9970 - val_loss: 0.6911 - val_accuracy: 0.8941\n","\n","Epoch 00186: val_accuracy did not improve from 0.93103\n","Epoch 187/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.6925 - val_accuracy: 0.8867\n","\n","Epoch 00187: val_accuracy did not improve from 0.93103\n","Epoch 188/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 1.0711 - val_accuracy: 0.8350\n","\n","Epoch 00188: val_accuracy did not improve from 0.93103\n","Epoch 189/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0692 - accuracy: 0.9805 - val_loss: 1.0815 - val_accuracy: 0.7956\n","\n","Epoch 00189: val_accuracy did not improve from 0.93103\n","Epoch 190/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0566 - accuracy: 0.9787 - val_loss: 1.2141 - val_accuracy: 0.7980\n","\n","Epoch 00190: val_accuracy did not improve from 0.93103\n","Epoch 191/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.7764 - val_accuracy: 0.8227\n","\n","Epoch 00191: val_accuracy did not improve from 0.93103\n","Epoch 192/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.5777 - val_accuracy: 0.8966\n","\n","Epoch 00192: val_accuracy did not improve from 0.93103\n","Epoch 193/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0213 - accuracy: 0.9903 - val_loss: 0.7430 - val_accuracy: 0.8374\n","\n","Epoch 00193: val_accuracy did not improve from 0.93103\n","Epoch 194/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.6715 - val_accuracy: 0.8744\n","\n","Epoch 00194: val_accuracy did not improve from 0.93103\n","Epoch 195/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.4694 - val_accuracy: 0.9064\n","\n","Epoch 00195: val_accuracy did not improve from 0.93103\n","Epoch 196/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.7432 - val_accuracy: 0.8473\n","\n","Epoch 00196: val_accuracy did not improve from 0.93103\n","Epoch 197/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.7891 - val_accuracy: 0.8473\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0436 - accuracy: 0.9884 - val_loss: 1.0581 - val_accuracy: 0.8350\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.7680 - val_accuracy: 0.8621\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.6173 - val_accuracy: 0.8966\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.6485 - val_accuracy: 0.8744\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.4313 - val_accuracy: 0.9212\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.4337 - val_accuracy: 0.9064\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.7200 - val_accuracy: 0.8571\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.5695 - val_accuracy: 0.9015\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0294 - accuracy: 0.9890 - val_loss: 0.6702 - val_accuracy: 0.8695\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.5644 - val_accuracy: 0.9039\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9261\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9261\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.4668 - val_accuracy: 0.9212\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.5310 - val_accuracy: 0.9089\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4862 - val_accuracy: 0.9089\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5150 - val_accuracy: 0.9089\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.5511 - val_accuracy: 0.8793\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5455 - val_accuracy: 0.8941\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.5333 - val_accuracy: 0.8842\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4237 - val_accuracy: 0.9039\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.5967 - val_accuracy: 0.8719\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.4563 - val_accuracy: 0.8990\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4751 - val_accuracy: 0.8990\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.5689 - val_accuracy: 0.8892\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.5475 - val_accuracy: 0.8941\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.3985 - val_accuracy: 0.9089\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5130 - val_accuracy: 0.9039\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9138\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.2271e-04 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.8966\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0402 - accuracy: 0.9921 - val_loss: 1.2371 - val_accuracy: 0.8251\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0767 - accuracy: 0.9714 - val_loss: 1.3243 - val_accuracy: 0.7562\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0228 - accuracy: 0.9909 - val_loss: 0.6861 - val_accuracy: 0.8547\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.5251 - val_accuracy: 0.8916\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 0.8910 - val_accuracy: 0.8571\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0630 - accuracy: 0.9878 - val_loss: 1.2946 - val_accuracy: 0.8177\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0283 - accuracy: 0.9878 - val_loss: 0.6976 - val_accuracy: 0.8695\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.5042 - val_accuracy: 0.8793\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0108 - accuracy: 0.9951 - val_loss: 0.5826 - val_accuracy: 0.8670\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4075 - val_accuracy: 0.9015\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.4752 - val_accuracy: 0.9163\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4183 - val_accuracy: 0.9089\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5356 - val_accuracy: 0.9015\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4809 - val_accuracy: 0.9064\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4900 - val_accuracy: 0.9039\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8966\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9039\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.2706e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9039\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9039\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 20s 379ms/step - loss: 5.9925e-04 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.8990\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5674 - val_accuracy: 0.9015\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5748 - val_accuracy: 0.9089\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.6746 - val_accuracy: 0.8645\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.6436 - val_accuracy: 0.8818\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.6703 - val_accuracy: 0.8768\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.9211 - val_accuracy: 0.8350\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0725 - accuracy: 0.9787 - val_loss: 1.1159 - val_accuracy: 0.8374\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0541 - accuracy: 0.9842 - val_loss: 0.5253 - val_accuracy: 0.8892\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.4984 - val_accuracy: 0.8941\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.6306 - val_accuracy: 0.8719\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4988 - val_accuracy: 0.9015\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4729 - val_accuracy: 0.8916\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9286\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3590 - val_accuracy: 0.9212\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9138\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.4963 - val_accuracy: 0.9212\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4275 - val_accuracy: 0.9384\n","\n","Epoch 00263: val_accuracy improved from 0.93103 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5\n","Epoch 264/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.3841 - val_accuracy: 0.9089\n","\n","Epoch 00264: val_accuracy did not improve from 0.93842\n","Epoch 265/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5950 - val_accuracy: 0.9015\n","\n","Epoch 00265: val_accuracy did not improve from 0.93842\n","Epoch 266/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4997 - val_accuracy: 0.9015\n","\n","Epoch 00266: val_accuracy did not improve from 0.93842\n","Epoch 267/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9039\n","\n","Epoch 00267: val_accuracy did not improve from 0.93842\n","Epoch 268/500\n","52/52 [==============================] - 20s 379ms/step - loss: 6.9526e-04 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9039\n","\n","Epoch 00268: val_accuracy did not improve from 0.93842\n","Epoch 269/500\n","52/52 [==============================] - 20s 380ms/step - loss: 6.2073e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9163\n","\n","Epoch 00269: val_accuracy did not improve from 0.93842\n","Epoch 270/500\n","52/52 [==============================] - 20s 380ms/step - loss: 3.6258e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9212\n","\n","Epoch 00270: val_accuracy did not improve from 0.93842\n","Epoch 271/500\n","52/52 [==============================] - 20s 379ms/step - loss: 3.4619e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9261\n","\n","Epoch 00271: val_accuracy did not improve from 0.93842\n","Epoch 272/500\n","52/52 [==============================] - 20s 379ms/step - loss: 2.9531e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9138\n","\n","Epoch 00272: val_accuracy did not improve from 0.93842\n","Epoch 273/500\n","52/52 [==============================] - 20s 380ms/step - loss: 3.0604e-04 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9187\n","\n","Epoch 00273: val_accuracy did not improve from 0.93842\n","Epoch 274/500\n","52/52 [==============================] - 20s 379ms/step - loss: 1.6342e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9310\n","\n","Epoch 00274: val_accuracy did not improve from 0.93842\n","Epoch 275/500\n","52/52 [==============================] - 20s 379ms/step - loss: 2.2557e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9286\n","\n","Epoch 00275: val_accuracy did not improve from 0.93842\n","Epoch 276/500\n","52/52 [==============================] - 20s 379ms/step - loss: 1.1105e-04 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9187\n","\n","Epoch 00276: val_accuracy did not improve from 0.93842\n","Epoch 277/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 1.9005 - val_accuracy: 0.7709\n","\n","Epoch 00277: val_accuracy did not improve from 0.93842\n","Epoch 278/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 2.2106 - val_accuracy: 0.7389\n","\n","Epoch 00278: val_accuracy did not improve from 0.93842\n","Epoch 279/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.7918 - val_accuracy: 0.8842\n","\n","Epoch 00279: val_accuracy did not improve from 0.93842\n","Epoch 280/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.6445 - val_accuracy: 0.8670\n","\n","Epoch 00280: val_accuracy did not improve from 0.93842\n","Epoch 281/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.7085 - val_accuracy: 0.8276\n","\n","Epoch 00281: val_accuracy did not improve from 0.93842\n","Epoch 282/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4118 - val_accuracy: 0.9089\n","\n","Epoch 00282: val_accuracy did not improve from 0.93842\n","Epoch 283/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.4890 - val_accuracy: 0.9039\n","\n","Epoch 00283: val_accuracy did not improve from 0.93842\n","Epoch 284/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.8280 - val_accuracy: 0.8695\n","\n","Epoch 00284: val_accuracy did not improve from 0.93842\n","Epoch 285/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0093 - accuracy: 0.9957 - val_loss: 0.4960 - val_accuracy: 0.8842\n","\n","Epoch 00285: val_accuracy did not improve from 0.93842\n","Epoch 286/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5243 - val_accuracy: 0.9064\n","\n","Epoch 00286: val_accuracy did not improve from 0.93842\n","Epoch 287/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9261\n","\n","Epoch 00287: val_accuracy did not improve from 0.93842\n","Epoch 288/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3634 - val_accuracy: 0.9163\n","\n","Epoch 00288: val_accuracy did not improve from 0.93842\n","Epoch 289/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4742 - val_accuracy: 0.9089\n","\n","Epoch 00289: val_accuracy did not improve from 0.93842\n","Epoch 290/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5259 - val_accuracy: 0.9187\n","\n","Epoch 00290: val_accuracy did not improve from 0.93842\n","Epoch 291/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.6059 - val_accuracy: 0.9039\n","\n","Epoch 00291: val_accuracy did not improve from 0.93842\n","Epoch 292/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.6965e-04 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9089\n","\n","Epoch 00292: val_accuracy did not improve from 0.93842\n","Epoch 293/500\n","52/52 [==============================] - 20s 380ms/step - loss: 6.1933e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9236\n","\n","Epoch 00293: val_accuracy did not improve from 0.93842\n","Epoch 294/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.5039e-04 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9212\n","\n","Epoch 00294: val_accuracy did not improve from 0.93842\n","Epoch 295/500\n","52/52 [==============================] - 20s 383ms/step - loss: 9.9381e-04 - accuracy: 0.9994 - val_loss: 0.4998 - val_accuracy: 0.9138\n","\n","Epoch 00295: val_accuracy did not improve from 0.93842\n","Epoch 296/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5673 - val_accuracy: 0.9113\n","\n","Epoch 00296: val_accuracy did not improve from 0.93842\n","Epoch 297/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4670 - val_accuracy: 0.9236\n","\n","Epoch 00297: val_accuracy did not improve from 0.93842\n","Epoch 298/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.9774 - val_accuracy: 0.8571\n","\n","Epoch 00298: val_accuracy did not improve from 0.93842\n","Epoch 299/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 1.1321 - val_accuracy: 0.8103\n","\n","Epoch 00299: val_accuracy did not improve from 0.93842\n","Epoch 300/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1021 - accuracy: 0.9702 - val_loss: 1.4149 - val_accuracy: 0.7956\n","\n","Epoch 00300: val_accuracy did not improve from 0.93842\n","Epoch 301/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0912 - accuracy: 0.9720 - val_loss: 1.2746 - val_accuracy: 0.8374\n","\n","Epoch 00301: val_accuracy did not improve from 0.93842\n","Epoch 302/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 0.5001 - val_accuracy: 0.9113\n","\n","Epoch 00302: val_accuracy did not improve from 0.93842\n","Epoch 303/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0143 - accuracy: 0.9939 - val_loss: 0.4065 - val_accuracy: 0.9261\n","\n","Epoch 00303: val_accuracy did not improve from 0.93842\n","Epoch 304/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9138\n","\n","Epoch 00304: val_accuracy did not improve from 0.93842\n","Epoch 305/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9187\n","\n","Epoch 00305: val_accuracy did not improve from 0.93842\n","Epoch 306/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.1736 - val_accuracy: 0.8227\n","\n","Epoch 00306: val_accuracy did not improve from 0.93842\n","Epoch 307/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.4164 - val_accuracy: 0.9163\n","\n","Epoch 00307: val_accuracy did not improve from 0.93842\n","Epoch 308/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5916 - val_accuracy: 0.8916\n","\n","Epoch 00308: val_accuracy did not improve from 0.93842\n","Epoch 309/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5556 - val_accuracy: 0.8990\n","\n","Epoch 00309: val_accuracy did not improve from 0.93842\n","Epoch 310/500\n","52/52 [==============================] - 21s 396ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4878 - val_accuracy: 0.8941\n","\n","Epoch 00310: val_accuracy did not improve from 0.93842\n","Epoch 311/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5752 - val_accuracy: 0.9015\n","\n","Epoch 00311: val_accuracy did not improve from 0.93842\n","Epoch 312/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.5329 - val_accuracy: 0.9064\n","\n","Epoch 00312: val_accuracy did not improve from 0.93842\n","Epoch 313/500\n","52/52 [==============================] - 20s 379ms/step - loss: 6.9229e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9113\n","\n","Epoch 00313: val_accuracy did not improve from 0.93842\n","Epoch 314/500\n","52/52 [==============================] - 20s 381ms/step - loss: 5.9675e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9138\n","\n","Epoch 00314: val_accuracy did not improve from 0.93842\n","Epoch 315/500\n","52/52 [==============================] - 20s 379ms/step - loss: 7.0700e-04 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.9089\n","\n","Epoch 00315: val_accuracy did not improve from 0.93842\n","Epoch 316/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.1375e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9261\n","\n","Epoch 00316: val_accuracy did not improve from 0.93842\n","Epoch 317/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.7096e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9236\n","\n","Epoch 00317: val_accuracy did not improve from 0.93842\n","Epoch 318/500\n","52/52 [==============================] - 20s 380ms/step - loss: 3.3187e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9138\n","\n","Epoch 00318: val_accuracy did not improve from 0.93842\n","Epoch 319/500\n","52/52 [==============================] - 20s 381ms/step - loss: 5.8359e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9163\n","\n","Epoch 00319: val_accuracy did not improve from 0.93842\n","Epoch 320/500\n","52/52 [==============================] - 20s 379ms/step - loss: 6.9957e-04 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9163\n","\n","Epoch 00320: val_accuracy did not improve from 0.93842\n","Epoch 321/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4217 - val_accuracy: 0.9187\n","\n","Epoch 00321: val_accuracy did not improve from 0.93842\n","Epoch 322/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9212\n","\n","Epoch 00322: val_accuracy did not improve from 0.93842\n","Epoch 323/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.4255e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9310\n","\n","Epoch 00323: val_accuracy did not improve from 0.93842\n","Epoch 324/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4702 - val_accuracy: 0.9286\n","\n","Epoch 00324: val_accuracy did not improve from 0.93842\n","Epoch 325/500\n","52/52 [==============================] - 20s 384ms/step - loss: 3.7041e-04 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9138\n","\n","Epoch 00325: val_accuracy did not improve from 0.93842\n","Epoch 326/500\n","52/52 [==============================] - 20s 381ms/step - loss: 9.9430e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9212\n","\n","Epoch 00326: val_accuracy did not improve from 0.93842\n","Epoch 327/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4500 - val_accuracy: 0.9163\n","\n","Epoch 00327: val_accuracy did not improve from 0.93842\n","Epoch 328/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6047 - val_accuracy: 0.9039\n","\n","Epoch 00328: val_accuracy did not improve from 0.93842\n","Epoch 329/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.8060 - val_accuracy: 0.8325\n","\n","Epoch 00329: val_accuracy did not improve from 0.93842\n","Epoch 330/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.9994 - val_accuracy: 0.8695\n","\n","Epoch 00330: val_accuracy did not improve from 0.93842\n","Epoch 331/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0916 - accuracy: 0.9787 - val_loss: 1.5682 - val_accuracy: 0.7906\n","\n","Epoch 00331: val_accuracy did not improve from 0.93842\n","Epoch 332/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0496 - accuracy: 0.9811 - val_loss: 1.2508 - val_accuracy: 0.8030\n","\n","Epoch 00332: val_accuracy did not improve from 0.93842\n","Epoch 333/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.9036 - val_accuracy: 0.7956\n","\n","Epoch 00333: val_accuracy did not improve from 0.93842\n","Epoch 334/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5394 - val_accuracy: 0.8892\n","\n","Epoch 00334: val_accuracy did not improve from 0.93842\n","Epoch 335/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.5277 - val_accuracy: 0.8719\n","\n","Epoch 00335: val_accuracy did not improve from 0.93842\n","Epoch 336/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9089\n","\n","Epoch 00336: val_accuracy did not improve from 0.93842\n","Epoch 337/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4075 - val_accuracy: 0.9113\n","\n","Epoch 00337: val_accuracy did not improve from 0.93842\n","Epoch 338/500\n","52/52 [==============================] - 20s 380ms/step - loss: 5.8780e-04 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9236\n","\n","Epoch 00338: val_accuracy did not improve from 0.93842\n","Epoch 339/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6765 - val_accuracy: 0.8892\n","\n","Epoch 00339: val_accuracy did not improve from 0.93842\n","Epoch 340/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.6344 - val_accuracy: 0.9015\n","\n","Epoch 00340: val_accuracy did not improve from 0.93842\n","Epoch 341/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0274 - accuracy: 0.9884 - val_loss: 0.9621 - val_accuracy: 0.8350\n","\n","Epoch 00341: val_accuracy did not improve from 0.93842\n","Epoch 342/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.7076 - val_accuracy: 0.8645\n","\n","Epoch 00342: val_accuracy did not improve from 0.93842\n","Epoch 343/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4997 - val_accuracy: 0.9039\n","\n","Epoch 00343: val_accuracy did not improve from 0.93842\n","Epoch 344/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5260 - val_accuracy: 0.8941\n","\n","Epoch 00344: val_accuracy did not improve from 0.93842\n","Epoch 345/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.4972 - val_accuracy: 0.8990\n","\n","Epoch 00345: val_accuracy did not improve from 0.93842\n","Epoch 346/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4796 - val_accuracy: 0.8966\n","\n","Epoch 00346: val_accuracy did not improve from 0.93842\n","Epoch 347/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9089\n","\n","Epoch 00347: val_accuracy did not improve from 0.93842\n","Epoch 348/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.6631 - val_accuracy: 0.8916\n","\n","Epoch 00348: val_accuracy did not improve from 0.93842\n","Epoch 349/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5173 - val_accuracy: 0.9138\n","\n","Epoch 00349: val_accuracy did not improve from 0.93842\n","Epoch 350/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9310\n","\n","Epoch 00350: val_accuracy did not improve from 0.93842\n","Epoch 351/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9187\n","\n","Epoch 00351: val_accuracy did not improve from 0.93842\n","Epoch 352/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.4848 - val_accuracy: 0.9163\n","\n","Epoch 00352: val_accuracy did not improve from 0.93842\n","Epoch 353/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4722 - val_accuracy: 0.8990\n","\n","Epoch 00353: val_accuracy did not improve from 0.93842\n","Epoch 354/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5554 - val_accuracy: 0.8966\n","\n","Epoch 00354: val_accuracy did not improve from 0.93842\n","Epoch 355/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4828 - val_accuracy: 0.9236\n","\n","Epoch 00355: val_accuracy did not improve from 0.93842\n","Epoch 356/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.4531 - val_accuracy: 0.9015\n","\n","Epoch 00356: val_accuracy did not improve from 0.93842\n","Epoch 357/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.9187\n","\n","Epoch 00357: val_accuracy did not improve from 0.93842\n","Epoch 358/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4705 - val_accuracy: 0.9138\n","\n","Epoch 00358: val_accuracy did not improve from 0.93842\n","Epoch 359/500\n","52/52 [==============================] - 20s 379ms/step - loss: 3.0785e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9261\n","\n","Epoch 00359: val_accuracy did not improve from 0.93842\n","Epoch 360/500\n","52/52 [==============================] - 20s 379ms/step - loss: 3.1912e-04 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9187\n","\n","Epoch 00360: val_accuracy did not improve from 0.93842\n","Epoch 361/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5416 - val_accuracy: 0.9015\n","\n","Epoch 00361: val_accuracy did not improve from 0.93842\n","Epoch 362/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.4307 - val_accuracy: 0.9187\n","\n","Epoch 00362: val_accuracy did not improve from 0.93842\n","Epoch 363/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.6116 - val_accuracy: 0.8867\n","\n","Epoch 00363: val_accuracy did not improve from 0.93842\n","Epoch 364/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4424 - val_accuracy: 0.9163\n","\n","Epoch 00364: val_accuracy did not improve from 0.93842\n","Epoch 365/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.4626 - val_accuracy: 0.9163\n","\n","Epoch 00365: val_accuracy did not improve from 0.93842\n","Epoch 366/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4867 - val_accuracy: 0.9113\n","\n","Epoch 00366: val_accuracy did not improve from 0.93842\n","Epoch 367/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0863 - accuracy: 0.9738 - val_loss: 0.8717 - val_accuracy: 0.8300\n","\n","Epoch 00367: val_accuracy did not improve from 0.93842\n","Epoch 368/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.6975 - val_accuracy: 0.8424\n","\n","Epoch 00368: val_accuracy did not improve from 0.93842\n","Epoch 369/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.6018 - val_accuracy: 0.8744\n","\n","Epoch 00369: val_accuracy did not improve from 0.93842\n","Epoch 370/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4862 - val_accuracy: 0.9039\n","\n","Epoch 00370: val_accuracy did not improve from 0.93842\n","Epoch 371/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.4899 - val_accuracy: 0.9113\n","\n","Epoch 00371: val_accuracy did not improve from 0.93842\n","Epoch 372/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4656 - val_accuracy: 0.9015\n","\n","Epoch 00372: val_accuracy did not improve from 0.93842\n","Epoch 373/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5927 - val_accuracy: 0.9064\n","\n","Epoch 00373: val_accuracy did not improve from 0.93842\n","Epoch 374/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5848 - val_accuracy: 0.9064\n","\n","Epoch 00374: val_accuracy did not improve from 0.93842\n","Epoch 375/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5914 - val_accuracy: 0.8892\n","\n","Epoch 00375: val_accuracy did not improve from 0.93842\n","Epoch 376/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.8001 - val_accuracy: 0.8892\n","\n","Epoch 00376: val_accuracy did not improve from 0.93842\n","Epoch 377/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.7090 - val_accuracy: 0.8892\n","\n","Epoch 00377: val_accuracy did not improve from 0.93842\n","Epoch 378/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.6047 - val_accuracy: 0.9089\n","\n","Epoch 00378: val_accuracy did not improve from 0.93842\n","Epoch 379/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9064\n","\n","Epoch 00379: val_accuracy did not improve from 0.93842\n","Epoch 380/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4260 - val_accuracy: 0.9064\n","\n","Epoch 00380: val_accuracy did not improve from 0.93842\n","Epoch 381/500\n","52/52 [==============================] - 20s 379ms/step - loss: 6.6537e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9187\n","\n","Epoch 00381: val_accuracy did not improve from 0.93842\n","Epoch 382/500\n","52/52 [==============================] - 20s 380ms/step - loss: 5.1551e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9236\n","\n","Epoch 00382: val_accuracy did not improve from 0.93842\n","Epoch 383/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.6458e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9187\n","\n","Epoch 00383: val_accuracy did not improve from 0.93842\n","Epoch 384/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.2590e-04 - accuracy: 0.9994 - val_loss: 0.4816 - val_accuracy: 0.9039\n","\n","Epoch 00384: val_accuracy did not improve from 0.93842\n","Epoch 385/500\n","52/52 [==============================] - 20s 379ms/step - loss: 6.2552e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9236\n","\n","Epoch 00385: val_accuracy did not improve from 0.93842\n","Epoch 386/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5687 - val_accuracy: 0.8744\n","\n","Epoch 00386: val_accuracy did not improve from 0.93842\n","Epoch 387/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9015\n","\n","Epoch 00387: val_accuracy did not improve from 0.93842\n","Epoch 388/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4465 - val_accuracy: 0.9138\n","\n","Epoch 00388: val_accuracy did not improve from 0.93842\n","Epoch 389/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4963 - val_accuracy: 0.9064\n","\n","Epoch 00389: val_accuracy did not improve from 0.93842\n","Epoch 390/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5058 - val_accuracy: 0.9064\n","\n","Epoch 00390: val_accuracy did not improve from 0.93842\n","Epoch 391/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4989 - val_accuracy: 0.9138\n","\n","Epoch 00391: val_accuracy did not improve from 0.93842\n","Epoch 392/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.7397 - val_accuracy: 0.8818\n","\n","Epoch 00392: val_accuracy did not improve from 0.93842\n","Epoch 393/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 1.2471 - val_accuracy: 0.8128\n","\n","Epoch 00393: val_accuracy did not improve from 0.93842\n","Epoch 394/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 1.4327 - val_accuracy: 0.8079\n","\n","Epoch 00394: val_accuracy did not improve from 0.93842\n","Epoch 395/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 2.2810 - val_accuracy: 0.6872\n","\n","Epoch 00395: val_accuracy did not improve from 0.93842\n","Epoch 396/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.5349 - val_accuracy: 0.9113\n","\n","Epoch 00396: val_accuracy did not improve from 0.93842\n","Epoch 397/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.5544 - val_accuracy: 0.8966\n","\n","Epoch 00397: val_accuracy did not improve from 0.93842\n","Epoch 398/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 1.2781 - val_accuracy: 0.7906\n","\n","Epoch 00398: val_accuracy did not improve from 0.93842\n","Epoch 399/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.7403 - val_accuracy: 0.8867\n","\n","Epoch 00399: val_accuracy did not improve from 0.93842\n","Epoch 400/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4913 - val_accuracy: 0.9163\n","\n","Epoch 00400: val_accuracy did not improve from 0.93842\n","Epoch 401/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4708 - val_accuracy: 0.9138\n","\n","Epoch 00401: val_accuracy did not improve from 0.93842\n","Epoch 402/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4558 - val_accuracy: 0.9138\n","\n","Epoch 00402: val_accuracy did not improve from 0.93842\n","Epoch 403/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3510 - val_accuracy: 0.9212\n","\n","Epoch 00403: val_accuracy did not improve from 0.93842\n","Epoch 404/500\n","52/52 [==============================] - 21s 395ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4717 - val_accuracy: 0.9261\n","\n","Epoch 00404: val_accuracy did not improve from 0.93842\n","Epoch 405/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4165 - val_accuracy: 0.9163\n","\n","Epoch 00405: val_accuracy did not improve from 0.93842\n","Epoch 406/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.5615 - val_accuracy: 0.8892\n","\n","Epoch 00406: val_accuracy did not improve from 0.93842\n","Epoch 407/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5348 - val_accuracy: 0.9064\n","\n","Epoch 00407: val_accuracy did not improve from 0.93842\n","Epoch 408/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4078 - val_accuracy: 0.9138\n","\n","Epoch 00408: val_accuracy did not improve from 0.93842\n","Epoch 409/500\n","52/52 [==============================] - 20s 380ms/step - loss: 9.6081e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9335\n","\n","Epoch 00409: val_accuracy did not improve from 0.93842\n","Epoch 410/500\n","52/52 [==============================] - 20s 379ms/step - loss: 4.4419e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9113\n","\n","Epoch 00410: val_accuracy did not improve from 0.93842\n","Epoch 411/500\n","52/52 [==============================] - 20s 378ms/step - loss: 5.5225e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9286\n","\n","Epoch 00411: val_accuracy did not improve from 0.93842\n","Epoch 412/500\n","52/52 [==============================] - 20s 379ms/step - loss: 7.9774e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9138\n","\n","Epoch 00412: val_accuracy did not improve from 0.93842\n","Epoch 413/500\n","52/52 [==============================] - 20s 382ms/step - loss: 3.9646e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9236\n","\n","Epoch 00413: val_accuracy did not improve from 0.93842\n","Epoch 414/500\n","52/52 [==============================] - 20s 378ms/step - loss: 7.4731e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9236\n","\n","Epoch 00414: val_accuracy did not improve from 0.93842\n","Epoch 415/500\n","52/52 [==============================] - 20s 380ms/step - loss: 3.5913e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9360\n","\n","Epoch 00415: val_accuracy did not improve from 0.93842\n","Epoch 416/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.5304e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9163\n","\n","Epoch 00416: val_accuracy did not improve from 0.93842\n","Epoch 417/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.3938 - val_accuracy: 0.9360\n","\n","Epoch 00417: val_accuracy did not improve from 0.93842\n","Epoch 418/500\n","52/52 [==============================] - 20s 379ms/step - loss: 8.1525e-04 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9261\n","\n","Epoch 00418: val_accuracy did not improve from 0.93842\n","Epoch 419/500\n","52/52 [==============================] - 20s 378ms/step - loss: 3.8018e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.9236\n","\n","Epoch 00419: val_accuracy did not improve from 0.93842\n","Epoch 420/500\n","52/52 [==============================] - 20s 381ms/step - loss: 8.0682e-04 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9261\n","\n","Epoch 00420: val_accuracy did not improve from 0.93842\n","Epoch 421/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.1946e-04 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9212\n","\n","Epoch 00421: val_accuracy did not improve from 0.93842\n","Epoch 422/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.4996e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9286\n","\n","Epoch 00422: val_accuracy did not improve from 0.93842\n","Epoch 423/500\n","52/52 [==============================] - 20s 383ms/step - loss: 2.0825e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9384\n","\n","Epoch 00423: val_accuracy did not improve from 0.93842\n","Epoch 424/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.7123e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9286\n","\n","Epoch 00424: val_accuracy did not improve from 0.93842\n","Epoch 425/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.6061e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.93842\n","Epoch 426/500\n","52/52 [==============================] - 20s 379ms/step - loss: 1.2213e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9236\n","\n","Epoch 00426: val_accuracy did not improve from 0.93842\n","Epoch 427/500\n","52/52 [==============================] - 20s 380ms/step - loss: 2.6282e-04 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9163\n","\n","Epoch 00427: val_accuracy did not improve from 0.93842\n","Epoch 428/500\n","52/52 [==============================] - 20s 379ms/step - loss: 7.3151e-05 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9310\n","\n","Epoch 00428: val_accuracy did not improve from 0.93842\n","Epoch 429/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5501 - val_accuracy: 0.9113\n","\n","Epoch 00429: val_accuracy did not improve from 0.93842\n","Epoch 430/500\n","52/52 [==============================] - 20s 380ms/step - loss: 9.2611e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9261\n","\n","Epoch 00430: val_accuracy did not improve from 0.93842\n","Epoch 431/500\n","52/52 [==============================] - 20s 379ms/step - loss: 1.6633e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9236\n","\n","Epoch 00431: val_accuracy did not improve from 0.93842\n","Epoch 432/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.7658e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9138\n","\n","Epoch 00432: val_accuracy did not improve from 0.93842\n","Epoch 433/500\n","52/52 [==============================] - 20s 379ms/step - loss: 3.4558e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9212\n","\n","Epoch 00433: val_accuracy did not improve from 0.93842\n","Epoch 434/500\n","52/52 [==============================] - 20s 381ms/step - loss: 1.8945e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9261\n","\n","Epoch 00434: val_accuracy did not improve from 0.93842\n","Epoch 435/500\n","52/52 [==============================] - 20s 381ms/step - loss: 1.1079e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9163\n","\n","Epoch 00435: val_accuracy did not improve from 0.93842\n","Epoch 436/500\n","52/52 [==============================] - 20s 380ms/step - loss: 1.3130e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9187\n","\n","Epoch 00436: val_accuracy did not improve from 0.93842\n","Epoch 437/500\n","52/52 [==============================] - 20s 380ms/step - loss: 1.2483e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9187\n","\n","Epoch 00437: val_accuracy did not improve from 0.93842\n","Epoch 438/500\n","52/52 [==============================] - 20s 382ms/step - loss: 3.3887e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9089\n","\n","Epoch 00438: val_accuracy did not improve from 0.93842\n","Epoch 439/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.6109 - val_accuracy: 0.9064\n","\n","Epoch 00439: val_accuracy did not improve from 0.93842\n","Epoch 440/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.8916\n","\n","Epoch 00440: val_accuracy did not improve from 0.93842\n","Epoch 441/500\n","52/52 [==============================] - 20s 382ms/step - loss: 7.4450e-04 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.9113\n","\n","Epoch 00441: val_accuracy did not improve from 0.93842\n","Epoch 442/500\n","52/52 [==============================] - 20s 380ms/step - loss: 4.1828e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9089\n","\n","Epoch 00442: val_accuracy did not improve from 0.93842\n","Epoch 443/500\n","52/52 [==============================] - 20s 380ms/step - loss: 3.5407e-04 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.9015\n","\n","Epoch 00443: val_accuracy did not improve from 0.93842\n","Epoch 444/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.7911e-04 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.9089\n","\n","Epoch 00444: val_accuracy did not improve from 0.93842\n","Epoch 445/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.5375e-04 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9113\n","\n","Epoch 00445: val_accuracy did not improve from 0.93842\n","Epoch 446/500\n","52/52 [==============================] - 20s 381ms/step - loss: 4.1482e-04 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9113\n","\n","Epoch 00446: val_accuracy did not improve from 0.93842\n","Epoch 447/500\n","52/52 [==============================] - 20s 378ms/step - loss: 3.7957e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9261\n","\n","Epoch 00447: val_accuracy did not improve from 0.93842\n","Epoch 448/500\n","52/52 [==============================] - 20s 381ms/step - loss: 3.5079e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9212\n","\n","Epoch 00448: val_accuracy did not improve from 0.93842\n","Epoch 449/500\n","52/52 [==============================] - 20s 381ms/step - loss: 1.3006e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9163\n","\n","Epoch 00449: val_accuracy did not improve from 0.93842\n","Epoch 450/500\n","52/52 [==============================] - 20s 381ms/step - loss: 1.0893e-04 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9138\n","\n","Epoch 00450: val_accuracy did not improve from 0.93842\n","Epoch 451/500\n","52/52 [==============================] - 20s 380ms/step - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9187\n","\n","Epoch 00451: val_accuracy did not improve from 0.93842\n","Epoch 452/500\n","52/52 [==============================] - 20s 379ms/step - loss: 2.3548e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9212\n","\n","Epoch 00452: val_accuracy did not improve from 0.93842\n","Epoch 453/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.4531e-04 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.93842\n","Epoch 454/500\n","52/52 [==============================] - 20s 383ms/step - loss: 6.0646e-05 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9113\n","\n","Epoch 00454: val_accuracy did not improve from 0.93842\n","Epoch 455/500\n","52/52 [==============================] - 20s 380ms/step - loss: 1.3722e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9039\n","\n","Epoch 00455: val_accuracy did not improve from 0.93842\n","Epoch 456/500\n","52/52 [==============================] - 20s 379ms/step - loss: 3.8862e-05 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9163\n","\n","Epoch 00456: val_accuracy did not improve from 0.93842\n","Epoch 457/500\n","52/52 [==============================] - 20s 382ms/step - loss: 7.2757e-05 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9039\n","\n","Epoch 00457: val_accuracy did not improve from 0.93842\n","Epoch 458/500\n","52/52 [==============================] - 20s 379ms/step - loss: 7.0150e-05 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9187\n","\n","Epoch 00458: val_accuracy did not improve from 0.93842\n","Epoch 459/500\n","52/52 [==============================] - 20s 383ms/step - loss: 3.9460e-05 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.9113\n","\n","Epoch 00459: val_accuracy did not improve from 0.93842\n","Epoch 460/500\n","52/52 [==============================] - 20s 382ms/step - loss: 8.6939e-05 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.93842\n","Epoch 461/500\n","52/52 [==============================] - 20s 381ms/step - loss: 6.1035e-05 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9261\n","\n","Epoch 00461: val_accuracy did not improve from 0.93842\n","Epoch 462/500\n","52/52 [==============================] - 20s 379ms/step - loss: 7.4626e-05 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9138\n","\n","Epoch 00462: val_accuracy did not improve from 0.93842\n","Epoch 463/500\n","52/52 [==============================] - 20s 382ms/step - loss: 4.2997e-05 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9286\n","\n","Epoch 00463: val_accuracy did not improve from 0.93842\n","Epoch 464/500\n","52/52 [==============================] - 20s 384ms/step - loss: 3.4249e-05 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.9212\n","\n","Epoch 00464: val_accuracy did not improve from 0.93842\n","Epoch 465/500\n","52/52 [==============================] - 20s 381ms/step - loss: 6.7037e-05 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9236\n","\n","Epoch 00465: val_accuracy did not improve from 0.93842\n","Epoch 466/500\n","52/52 [==============================] - 20s 381ms/step - loss: 7.7823e-05 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.9138\n","\n","Epoch 00466: val_accuracy did not improve from 0.93842\n","Epoch 467/500\n","52/52 [==============================] - 20s 379ms/step - loss: 8.0159e-05 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9236\n","\n","Epoch 00467: val_accuracy did not improve from 0.93842\n","Epoch 468/500\n","52/52 [==============================] - 20s 381ms/step - loss: 2.7350e-05 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9261\n","\n","Epoch 00468: val_accuracy did not improve from 0.93842\n","Epoch 469/500\n","52/52 [==============================] - 20s 381ms/step - loss: 5.2937e-05 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9187\n","\n","Epoch 00469: val_accuracy did not improve from 0.93842\n","Epoch 470/500\n","52/52 [==============================] - 20s 381ms/step - loss: 3.5686e-05 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9113\n","\n","Epoch 00470: val_accuracy did not improve from 0.93842\n","Epoch 471/500\n","52/52 [==============================] - 20s 378ms/step - loss: 3.9790e-05 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9310\n","\n","Epoch 00471: val_accuracy did not improve from 0.93842\n","Epoch 472/500\n","52/52 [==============================] - 20s 382ms/step - loss: 2.9914e-05 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9310\n","\n","Epoch 00472: val_accuracy did not improve from 0.93842\n","Epoch 473/500\n","52/52 [==============================] - 20s 379ms/step - loss: 5.8372e-05 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9212\n","\n","Epoch 00473: val_accuracy did not improve from 0.93842\n","Epoch 474/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5851 - val_accuracy: 0.9064\n","\n","Epoch 00474: val_accuracy did not improve from 0.93842\n","Epoch 475/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1692 - accuracy: 0.9562 - val_loss: 5.8473 - val_accuracy: 0.5961\n","\n","Epoch 00475: val_accuracy did not improve from 0.93842\n","Epoch 476/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.1579 - accuracy: 0.9537 - val_loss: 1.0958 - val_accuracy: 0.8571\n","\n","Epoch 00476: val_accuracy did not improve from 0.93842\n","Epoch 477/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 1.3791 - val_accuracy: 0.7562\n","\n","Epoch 00477: val_accuracy did not improve from 0.93842\n","Epoch 478/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.6315 - val_accuracy: 0.8916\n","\n","Epoch 00478: val_accuracy did not improve from 0.93842\n","Epoch 479/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.4188 - val_accuracy: 0.9187\n","\n","Epoch 00479: val_accuracy did not improve from 0.93842\n","Epoch 480/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.4435 - val_accuracy: 0.9064\n","\n","Epoch 00480: val_accuracy did not improve from 0.93842\n","Epoch 481/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.3832 - val_accuracy: 0.9039\n","\n","Epoch 00481: val_accuracy did not improve from 0.93842\n","Epoch 482/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3323 - val_accuracy: 0.9163\n","\n","Epoch 00482: val_accuracy did not improve from 0.93842\n","Epoch 483/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2955 - val_accuracy: 0.9236\n","\n","Epoch 00483: val_accuracy did not improve from 0.93842\n","Epoch 484/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9236\n","\n","Epoch 00484: val_accuracy did not improve from 0.93842\n","Epoch 485/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.3383 - val_accuracy: 0.9236\n","\n","Epoch 00485: val_accuracy did not improve from 0.93842\n","Epoch 486/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9138\n","\n","Epoch 00486: val_accuracy did not improve from 0.93842\n","Epoch 487/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9335\n","\n","Epoch 00487: val_accuracy did not improve from 0.93842\n","Epoch 488/500\n","52/52 [==============================] - 20s 380ms/step - loss: 7.4001e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9187\n","\n","Epoch 00488: val_accuracy did not improve from 0.93842\n","Epoch 489/500\n","52/52 [==============================] - 20s 380ms/step - loss: 8.2745e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9212\n","\n","Epoch 00489: val_accuracy did not improve from 0.93842\n","Epoch 490/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3434 - val_accuracy: 0.9113\n","\n","Epoch 00490: val_accuracy did not improve from 0.93842\n","Epoch 491/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4915 - val_accuracy: 0.9113\n","\n","Epoch 00491: val_accuracy did not improve from 0.93842\n","Epoch 492/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9163\n","\n","Epoch 00492: val_accuracy did not improve from 0.93842\n","Epoch 493/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4194 - val_accuracy: 0.9015\n","\n","Epoch 00493: val_accuracy did not improve from 0.93842\n","Epoch 494/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4964 - val_accuracy: 0.9113\n","\n","Epoch 00494: val_accuracy did not improve from 0.93842\n","Epoch 495/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5069 - val_accuracy: 0.9187\n","\n","Epoch 00495: val_accuracy did not improve from 0.93842\n","Epoch 496/500\n","52/52 [==============================] - 20s 380ms/step - loss: 6.4181e-04 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9163\n","\n","Epoch 00496: val_accuracy did not improve from 0.93842\n","Epoch 497/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.8983 - val_accuracy: 0.8251\n","\n","Epoch 00497: val_accuracy did not improve from 0.93842\n","Epoch 498/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0222 - accuracy: 0.9903 - val_loss: 0.5467 - val_accuracy: 0.8645\n","\n","Epoch 00498: val_accuracy did not improve from 0.93842\n","Epoch 499/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.4891 - val_accuracy: 0.9089\n","\n","Epoch 00499: val_accuracy did not improve from 0.93842\n","Epoch 500/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5157 - val_accuracy: 0.8941\n","\n","Epoch 00500: val_accuracy did not improve from 0.93842\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7feff4788c10>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629845635879,"user_tz":-540,"elapsed":463,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7a50cc41-3911-4cb9-d934-ce2d6aaef8cb"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629845661079,"user_tz":-540,"elapsed":25204,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_4_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629845661462,"user_tz":-540,"elapsed":393,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629845662086,"user_tz":-540,"elapsed":627,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"cc789076-892a-499e-ac93-dc70ce416728"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629845717073,"user_tz":-540,"elapsed":54993,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9fbc9437-5ff1-4704-c4a1-789ccd361c8e"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629845717448,"user_tz":-540,"elapsed":387,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629845717449,"user_tz":-540,"elapsed":3,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629845718652,"user_tz":-540,"elapsed":1206,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629845718654,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629845729647,"user_tz":-540,"elapsed":10999,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629845729656,"user_tz":-540,"elapsed":23,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"126c03e8-6458-4508-c983-b179f1f75de7"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629845729657,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"9873c80e-52b9-49bf-e7d4-6af52126826b"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_4_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_4_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e1ff8e48-8ecc-4b12-87ba-dee6e461da5f\", \"Rotation_range_10_4_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}