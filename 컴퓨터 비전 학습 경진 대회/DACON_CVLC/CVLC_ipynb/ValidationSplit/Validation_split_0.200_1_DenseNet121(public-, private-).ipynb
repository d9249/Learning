{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Validation_split_0.200_1_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyOvEqJa+/wRlaobQylQntvc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629730874005,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"08dfe78f-1a4c-4e60-e02c-b99f452de877"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mon Aug 23 15:01:13 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629730891276,"user_tz":-540,"elapsed":17277,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"bd9dbc49-a59f-4ecf-8224-7120cb21a67b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629730894423,"user_tz":-540,"elapsed":3152,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629730895976,"user_tz":-540,"elapsed":1559,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629730898286,"user_tz":-540,"elapsed":2314,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629730914686,"user_tz":-540,"elapsed":16405,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629730921801,"user_tz":-540,"elapsed":7120,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629730921802,"user_tz":-540,"elapsed":14,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"7adfc250-7af7-4a95-ae54-53728831d9d0"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629730921804,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e8697de5-c690-4695-9007-020c0d618c97"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629730921805,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629737460741,"user_tz":-540,"elapsed":6538945,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"78471eaf-082b-4239-9ec3-1e73340b5d5c"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 39s 272ms/step - loss: 1.8792 - accuracy: 0.3459 - val_loss: 3.8630 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 11s 218ms/step - loss: 1.1999 - accuracy: 0.5914 - val_loss: 12.6708 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.9495 - accuracy: 0.6876 - val_loss: 21.6941 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.8505 - accuracy: 0.7132 - val_loss: 19.2218 - val_accuracy: 0.1010\n","\n","Epoch 00004: val_accuracy did not improve from 0.10099\n","Epoch 5/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.7027 - accuracy: 0.7613 - val_loss: 9.2919 - val_accuracy: 0.0985\n","\n","Epoch 00005: val_accuracy did not improve from 0.10099\n","Epoch 6/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.6725 - accuracy: 0.7655 - val_loss: 5.2322 - val_accuracy: 0.2217\n","\n","Epoch 00006: val_accuracy improved from 0.10099 to 0.22167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.5615 - accuracy: 0.8179 - val_loss: 5.1693 - val_accuracy: 0.2241\n","\n","Epoch 00007: val_accuracy improved from 0.22167 to 0.22414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5382 - accuracy: 0.8264 - val_loss: 3.8778 - val_accuracy: 0.3128\n","\n","Epoch 00008: val_accuracy improved from 0.22414 to 0.31281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.4896 - accuracy: 0.8423 - val_loss: 3.3454 - val_accuracy: 0.4483\n","\n","Epoch 00009: val_accuracy improved from 0.31281 to 0.44828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.5046 - accuracy: 0.8295 - val_loss: 2.0202 - val_accuracy: 0.5123\n","\n","Epoch 00010: val_accuracy improved from 0.44828 to 0.51232, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.4373 - accuracy: 0.8544 - val_loss: 1.3262 - val_accuracy: 0.6478\n","\n","Epoch 00011: val_accuracy improved from 0.51232 to 0.64778, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3958 - accuracy: 0.8605 - val_loss: 0.9716 - val_accuracy: 0.7291\n","\n","Epoch 00012: val_accuracy improved from 0.64778 to 0.72906, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3867 - accuracy: 0.8733 - val_loss: 0.8020 - val_accuracy: 0.7512\n","\n","Epoch 00013: val_accuracy improved from 0.72906 to 0.75123, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.3185 - accuracy: 0.8983 - val_loss: 1.4291 - val_accuracy: 0.6330\n","\n","Epoch 00014: val_accuracy did not improve from 0.75123\n","Epoch 15/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.4166 - accuracy: 0.8551 - val_loss: 1.4410 - val_accuracy: 0.6872\n","\n","Epoch 00015: val_accuracy did not improve from 0.75123\n","Epoch 16/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.3150 - accuracy: 0.8898 - val_loss: 0.7275 - val_accuracy: 0.7635\n","\n","Epoch 00016: val_accuracy improved from 0.75123 to 0.76355, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 17/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2756 - accuracy: 0.9038 - val_loss: 0.6656 - val_accuracy: 0.8079\n","\n","Epoch 00017: val_accuracy improved from 0.76355 to 0.80788, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.3722 - accuracy: 0.8764 - val_loss: 2.5140 - val_accuracy: 0.5468\n","\n","Epoch 00018: val_accuracy did not improve from 0.80788\n","Epoch 19/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2801 - accuracy: 0.9105 - val_loss: 0.8039 - val_accuracy: 0.7660\n","\n","Epoch 00019: val_accuracy did not improve from 0.80788\n","Epoch 20/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.2404 - accuracy: 0.9141 - val_loss: 0.5168 - val_accuracy: 0.8448\n","\n","Epoch 00020: val_accuracy improved from 0.80788 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 21/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2239 - accuracy: 0.9227 - val_loss: 0.7026 - val_accuracy: 0.7783\n","\n","Epoch 00021: val_accuracy did not improve from 0.84483\n","Epoch 22/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2104 - accuracy: 0.9196 - val_loss: 0.7814 - val_accuracy: 0.7906\n","\n","Epoch 00022: val_accuracy did not improve from 0.84483\n","Epoch 23/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2543 - accuracy: 0.9123 - val_loss: 0.5050 - val_accuracy: 0.8424\n","\n","Epoch 00023: val_accuracy did not improve from 0.84483\n","Epoch 24/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.2406 - accuracy: 0.9135 - val_loss: 1.6549 - val_accuracy: 0.6946\n","\n","Epoch 00024: val_accuracy did not improve from 0.84483\n","Epoch 25/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1967 - accuracy: 0.9361 - val_loss: 0.6997 - val_accuracy: 0.8350\n","\n","Epoch 00025: val_accuracy did not improve from 0.84483\n","Epoch 26/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1942 - accuracy: 0.9354 - val_loss: 0.7376 - val_accuracy: 0.7956\n","\n","Epoch 00026: val_accuracy did not improve from 0.84483\n","Epoch 27/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1711 - accuracy: 0.9391 - val_loss: 0.9948 - val_accuracy: 0.7611\n","\n","Epoch 00027: val_accuracy did not improve from 0.84483\n","Epoch 28/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1682 - accuracy: 0.9464 - val_loss: 0.4308 - val_accuracy: 0.8695\n","\n","Epoch 00028: val_accuracy improved from 0.84483 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 29/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1335 - accuracy: 0.9562 - val_loss: 0.6875 - val_accuracy: 0.8103\n","\n","Epoch 00029: val_accuracy did not improve from 0.86946\n","Epoch 30/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1756 - accuracy: 0.9440 - val_loss: 0.8557 - val_accuracy: 0.7906\n","\n","Epoch 00030: val_accuracy did not improve from 0.86946\n","Epoch 31/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1895 - accuracy: 0.9318 - val_loss: 0.4458 - val_accuracy: 0.8670\n","\n","Epoch 00031: val_accuracy did not improve from 0.86946\n","Epoch 32/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1637 - accuracy: 0.9415 - val_loss: 0.5245 - val_accuracy: 0.8571\n","\n","Epoch 00032: val_accuracy did not improve from 0.86946\n","Epoch 33/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1288 - accuracy: 0.9537 - val_loss: 0.8736 - val_accuracy: 0.7956\n","\n","Epoch 00033: val_accuracy did not improve from 0.86946\n","Epoch 34/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1095 - accuracy: 0.9647 - val_loss: 0.7270 - val_accuracy: 0.8202\n","\n","Epoch 00034: val_accuracy did not improve from 0.86946\n","Epoch 35/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1134 - accuracy: 0.9622 - val_loss: 0.6854 - val_accuracy: 0.8374\n","\n","Epoch 00035: val_accuracy did not improve from 0.86946\n","Epoch 36/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1112 - accuracy: 0.9622 - val_loss: 0.6160 - val_accuracy: 0.8276\n","\n","Epoch 00036: val_accuracy did not improve from 0.86946\n","Epoch 37/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1896 - accuracy: 0.9336 - val_loss: 3.4464 - val_accuracy: 0.5493\n","\n","Epoch 00037: val_accuracy did not improve from 0.86946\n","Epoch 38/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.1631 - accuracy: 0.9446 - val_loss: 0.6004 - val_accuracy: 0.8424\n","\n","Epoch 00038: val_accuracy did not improve from 0.86946\n","Epoch 39/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1199 - accuracy: 0.9641 - val_loss: 0.7387 - val_accuracy: 0.8374\n","\n","Epoch 00039: val_accuracy did not improve from 0.86946\n","Epoch 40/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0911 - accuracy: 0.9714 - val_loss: 0.6434 - val_accuracy: 0.8300\n","\n","Epoch 00040: val_accuracy did not improve from 0.86946\n","Epoch 41/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1119 - accuracy: 0.9604 - val_loss: 0.7594 - val_accuracy: 0.8399\n","\n","Epoch 00041: val_accuracy did not improve from 0.86946\n","Epoch 42/500\n","52/52 [==============================] - 12s 236ms/step - loss: 0.1277 - accuracy: 0.9507 - val_loss: 0.7395 - val_accuracy: 0.8350\n","\n","Epoch 00042: val_accuracy did not improve from 0.86946\n","Epoch 43/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1411 - accuracy: 0.9482 - val_loss: 0.4871 - val_accuracy: 0.8547\n","\n","Epoch 00043: val_accuracy did not improve from 0.86946\n","Epoch 44/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0939 - accuracy: 0.9677 - val_loss: 0.6518 - val_accuracy: 0.8522\n","\n","Epoch 00044: val_accuracy did not improve from 0.86946\n","Epoch 45/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1224 - accuracy: 0.9549 - val_loss: 1.2483 - val_accuracy: 0.7389\n","\n","Epoch 00045: val_accuracy did not improve from 0.86946\n","Epoch 46/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1269 - accuracy: 0.9543 - val_loss: 0.8229 - val_accuracy: 0.8350\n","\n","Epoch 00046: val_accuracy did not improve from 0.86946\n","Epoch 47/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0963 - accuracy: 0.9671 - val_loss: 0.6850 - val_accuracy: 0.8276\n","\n","Epoch 00047: val_accuracy did not improve from 0.86946\n","Epoch 48/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1223 - accuracy: 0.9562 - val_loss: 0.9028 - val_accuracy: 0.7931\n","\n","Epoch 00048: val_accuracy did not improve from 0.86946\n","Epoch 49/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1013 - accuracy: 0.9683 - val_loss: 0.5556 - val_accuracy: 0.8448\n","\n","Epoch 00049: val_accuracy did not improve from 0.86946\n","Epoch 50/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0921 - accuracy: 0.9641 - val_loss: 0.9606 - val_accuracy: 0.7882\n","\n","Epoch 00050: val_accuracy did not improve from 0.86946\n","Epoch 51/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0984 - accuracy: 0.9665 - val_loss: 0.5395 - val_accuracy: 0.8596\n","\n","Epoch 00051: val_accuracy did not improve from 0.86946\n","Epoch 52/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0782 - accuracy: 0.9732 - val_loss: 0.6969 - val_accuracy: 0.8399\n","\n","Epoch 00052: val_accuracy did not improve from 0.86946\n","Epoch 53/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0656 - accuracy: 0.9836 - val_loss: 0.4678 - val_accuracy: 0.8645\n","\n","Epoch 00053: val_accuracy did not improve from 0.86946\n","Epoch 54/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.7153 - val_accuracy: 0.8399\n","\n","Epoch 00054: val_accuracy did not improve from 0.86946\n","Epoch 55/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0596 - accuracy: 0.9836 - val_loss: 0.6025 - val_accuracy: 0.8621\n","\n","Epoch 00055: val_accuracy did not improve from 0.86946\n","Epoch 56/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0851 - accuracy: 0.9708 - val_loss: 0.6223 - val_accuracy: 0.8300\n","\n","Epoch 00056: val_accuracy did not improve from 0.86946\n","Epoch 57/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.5488 - val_accuracy: 0.8571\n","\n","Epoch 00057: val_accuracy did not improve from 0.86946\n","Epoch 58/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0976 - accuracy: 0.9598 - val_loss: 0.9426 - val_accuracy: 0.8005\n","\n","Epoch 00058: val_accuracy did not improve from 0.86946\n","Epoch 59/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.1582 - accuracy: 0.9482 - val_loss: 1.1044 - val_accuracy: 0.7759\n","\n","Epoch 00059: val_accuracy did not improve from 0.86946\n","Epoch 60/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0829 - accuracy: 0.9732 - val_loss: 0.7256 - val_accuracy: 0.8374\n","\n","Epoch 00060: val_accuracy did not improve from 0.86946\n","Epoch 61/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0508 - accuracy: 0.9823 - val_loss: 0.4298 - val_accuracy: 0.8768\n","\n","Epoch 00061: val_accuracy improved from 0.86946 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 62/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0633 - accuracy: 0.9750 - val_loss: 0.5808 - val_accuracy: 0.8448\n","\n","Epoch 00062: val_accuracy did not improve from 0.87685\n","Epoch 63/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.5892 - val_accuracy: 0.8645\n","\n","Epoch 00063: val_accuracy did not improve from 0.87685\n","Epoch 64/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 0.7274 - val_accuracy: 0.8202\n","\n","Epoch 00064: val_accuracy did not improve from 0.87685\n","Epoch 65/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0819 - accuracy: 0.9708 - val_loss: 0.9220 - val_accuracy: 0.8005\n","\n","Epoch 00065: val_accuracy did not improve from 0.87685\n","Epoch 66/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0794 - accuracy: 0.9720 - val_loss: 0.5623 - val_accuracy: 0.8522\n","\n","Epoch 00066: val_accuracy did not improve from 0.87685\n","Epoch 67/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0612 - accuracy: 0.9744 - val_loss: 0.5619 - val_accuracy: 0.8547\n","\n","Epoch 00067: val_accuracy did not improve from 0.87685\n","Epoch 68/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 0.6856 - val_accuracy: 0.8498\n","\n","Epoch 00068: val_accuracy did not improve from 0.87685\n","Epoch 69/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0470 - accuracy: 0.9829 - val_loss: 0.7777 - val_accuracy: 0.8202\n","\n","Epoch 00069: val_accuracy did not improve from 0.87685\n","Epoch 70/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.5516 - val_accuracy: 0.8867\n","\n","Epoch 00070: val_accuracy improved from 0.87685 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 71/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.5879 - val_accuracy: 0.8768\n","\n","Epoch 00071: val_accuracy did not improve from 0.88670\n","Epoch 72/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.4440 - val_accuracy: 0.8842\n","\n","Epoch 00072: val_accuracy did not improve from 0.88670\n","Epoch 73/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 0.5313 - val_accuracy: 0.8916\n","\n","Epoch 00073: val_accuracy improved from 0.88670 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 74/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.5518 - val_accuracy: 0.8744\n","\n","Epoch 00074: val_accuracy did not improve from 0.89163\n","Epoch 75/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 1.0036 - val_accuracy: 0.7759\n","\n","Epoch 00075: val_accuracy did not improve from 0.89163\n","Epoch 76/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 1.1979 - val_accuracy: 0.7389\n","\n","Epoch 00076: val_accuracy did not improve from 0.89163\n","Epoch 77/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0794 - accuracy: 0.9756 - val_loss: 0.6958 - val_accuracy: 0.8621\n","\n","Epoch 00077: val_accuracy did not improve from 0.89163\n","Epoch 78/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.5169 - val_accuracy: 0.8498\n","\n","Epoch 00078: val_accuracy did not improve from 0.89163\n","Epoch 79/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0406 - accuracy: 0.9884 - val_loss: 0.8459 - val_accuracy: 0.8005\n","\n","Epoch 00079: val_accuracy did not improve from 0.89163\n","Epoch 80/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1125 - accuracy: 0.9647 - val_loss: 0.9821 - val_accuracy: 0.8498\n","\n","Epoch 00080: val_accuracy did not improve from 0.89163\n","Epoch 81/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0664 - accuracy: 0.9805 - val_loss: 0.5313 - val_accuracy: 0.8695\n","\n","Epoch 00081: val_accuracy did not improve from 0.89163\n","Epoch 82/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0761 - accuracy: 0.9775 - val_loss: 1.0520 - val_accuracy: 0.8325\n","\n","Epoch 00082: val_accuracy did not improve from 0.89163\n","Epoch 83/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0730 - accuracy: 0.9750 - val_loss: 0.8243 - val_accuracy: 0.8448\n","\n","Epoch 00083: val_accuracy did not improve from 0.89163\n","Epoch 84/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0449 - accuracy: 0.9811 - val_loss: 0.4906 - val_accuracy: 0.8916\n","\n","Epoch 00084: val_accuracy did not improve from 0.89163\n","Epoch 85/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0887 - accuracy: 0.9677 - val_loss: 0.7407 - val_accuracy: 0.8399\n","\n","Epoch 00085: val_accuracy did not improve from 0.89163\n","Epoch 86/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0820 - accuracy: 0.9805 - val_loss: 0.6647 - val_accuracy: 0.8547\n","\n","Epoch 00086: val_accuracy did not improve from 0.89163\n","Epoch 87/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1363 - accuracy: 0.9653 - val_loss: 0.6051 - val_accuracy: 0.8547\n","\n","Epoch 00087: val_accuracy did not improve from 0.89163\n","Epoch 88/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0516 - accuracy: 0.9799 - val_loss: 0.5915 - val_accuracy: 0.8695\n","\n","Epoch 00088: val_accuracy did not improve from 0.89163\n","Epoch 89/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.9015 - val_accuracy: 0.8079\n","\n","Epoch 00089: val_accuracy did not improve from 0.89163\n","Epoch 90/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0586 - accuracy: 0.9836 - val_loss: 0.5899 - val_accuracy: 0.8768\n","\n","Epoch 00090: val_accuracy did not improve from 0.89163\n","Epoch 91/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 0.7061 - val_accuracy: 0.8621\n","\n","Epoch 00091: val_accuracy did not improve from 0.89163\n","Epoch 92/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0217 - accuracy: 0.9909 - val_loss: 0.4812 - val_accuracy: 0.9039\n","\n","Epoch 00092: val_accuracy improved from 0.89163 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 93/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 0.9112 - val_accuracy: 0.8202\n","\n","Epoch 00093: val_accuracy did not improve from 0.90394\n","Epoch 94/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0360 - accuracy: 0.9842 - val_loss: 0.5665 - val_accuracy: 0.8744\n","\n","Epoch 00094: val_accuracy did not improve from 0.90394\n","Epoch 95/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0476 - accuracy: 0.9817 - val_loss: 1.1528 - val_accuracy: 0.8202\n","\n","Epoch 00095: val_accuracy did not improve from 0.90394\n","Epoch 96/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0239 - accuracy: 0.9951 - val_loss: 0.5142 - val_accuracy: 0.8892\n","\n","Epoch 00096: val_accuracy did not improve from 0.90394\n","Epoch 97/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.3680 - val_accuracy: 0.8990\n","\n","Epoch 00097: val_accuracy did not improve from 0.90394\n","Epoch 98/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.7176 - val_accuracy: 0.7980\n","\n","Epoch 00098: val_accuracy did not improve from 0.90394\n","Epoch 99/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.8393 - val_accuracy: 0.8128\n","\n","Epoch 00099: val_accuracy did not improve from 0.90394\n","Epoch 100/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.5594 - val_accuracy: 0.8744\n","\n","Epoch 00100: val_accuracy did not improve from 0.90394\n","Epoch 101/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.5490 - val_accuracy: 0.8892\n","\n","Epoch 00101: val_accuracy did not improve from 0.90394\n","Epoch 102/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.6005 - val_accuracy: 0.8473\n","\n","Epoch 00102: val_accuracy did not improve from 0.90394\n","Epoch 103/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.7373 - val_accuracy: 0.8054\n","\n","Epoch 00103: val_accuracy did not improve from 0.90394\n","Epoch 104/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0489 - accuracy: 0.9848 - val_loss: 0.9288 - val_accuracy: 0.7882\n","\n","Epoch 00104: val_accuracy did not improve from 0.90394\n","Epoch 105/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0502 - accuracy: 0.9854 - val_loss: 0.6268 - val_accuracy: 0.8473\n","\n","Epoch 00105: val_accuracy did not improve from 0.90394\n","Epoch 106/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0429 - accuracy: 0.9823 - val_loss: 0.9109 - val_accuracy: 0.7783\n","\n","Epoch 00106: val_accuracy did not improve from 0.90394\n","Epoch 107/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.7008 - val_accuracy: 0.8448\n","\n","Epoch 00107: val_accuracy did not improve from 0.90394\n","Epoch 108/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.5979 - val_accuracy: 0.8867\n","\n","Epoch 00108: val_accuracy did not improve from 0.90394\n","Epoch 109/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.5029 - val_accuracy: 0.8916\n","\n","Epoch 00109: val_accuracy did not improve from 0.90394\n","Epoch 110/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.4407 - val_accuracy: 0.8990\n","\n","Epoch 00110: val_accuracy did not improve from 0.90394\n","Epoch 111/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4800 - val_accuracy: 0.8892\n","\n","Epoch 00111: val_accuracy did not improve from 0.90394\n","Epoch 112/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0215 - accuracy: 0.9903 - val_loss: 0.5198 - val_accuracy: 0.9064\n","\n","Epoch 00112: val_accuracy improved from 0.90394 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 113/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1503 - accuracy: 0.9574 - val_loss: 3.7724 - val_accuracy: 0.5837\n","\n","Epoch 00113: val_accuracy did not improve from 0.90640\n","Epoch 114/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 1.6245 - val_accuracy: 0.7438\n","\n","Epoch 00114: val_accuracy did not improve from 0.90640\n","Epoch 115/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1096 - accuracy: 0.9622 - val_loss: 1.1145 - val_accuracy: 0.8054\n","\n","Epoch 00115: val_accuracy did not improve from 0.90640\n","Epoch 116/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.9330 - val_accuracy: 0.7980\n","\n","Epoch 00116: val_accuracy did not improve from 0.90640\n","Epoch 117/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 1.4274 - val_accuracy: 0.7266\n","\n","Epoch 00117: val_accuracy did not improve from 0.90640\n","Epoch 118/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 0.5777 - val_accuracy: 0.8744\n","\n","Epoch 00118: val_accuracy did not improve from 0.90640\n","Epoch 119/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.4184 - val_accuracy: 0.9039\n","\n","Epoch 00119: val_accuracy did not improve from 0.90640\n","Epoch 120/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.4192 - val_accuracy: 0.9113\n","\n","Epoch 00120: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 121/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0337 - accuracy: 0.9903 - val_loss: 0.3976 - val_accuracy: 0.9138\n","\n","Epoch 00121: val_accuracy improved from 0.91133 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 122/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.3782 - val_accuracy: 0.8990\n","\n","Epoch 00122: val_accuracy did not improve from 0.91379\n","Epoch 123/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.3930 - val_accuracy: 0.8990\n","\n","Epoch 00123: val_accuracy did not improve from 0.91379\n","Epoch 124/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.7788 - val_accuracy: 0.8202\n","\n","Epoch 00124: val_accuracy did not improve from 0.91379\n","Epoch 125/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.4848 - val_accuracy: 0.9015\n","\n","Epoch 00125: val_accuracy did not improve from 0.91379\n","Epoch 126/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5475 - val_accuracy: 0.8842\n","\n","Epoch 00126: val_accuracy did not improve from 0.91379\n","Epoch 127/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0586 - accuracy: 0.9781 - val_loss: 1.1169 - val_accuracy: 0.7562\n","\n","Epoch 00127: val_accuracy did not improve from 0.91379\n","Epoch 128/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0552 - accuracy: 0.9842 - val_loss: 0.6205 - val_accuracy: 0.8768\n","\n","Epoch 00128: val_accuracy did not improve from 0.91379\n","Epoch 129/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0804 - accuracy: 0.9762 - val_loss: 0.7629 - val_accuracy: 0.8374\n","\n","Epoch 00129: val_accuracy did not improve from 0.91379\n","Epoch 130/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1657 - accuracy: 0.9464 - val_loss: 2.6211 - val_accuracy: 0.6355\n","\n","Epoch 00130: val_accuracy did not improve from 0.91379\n","Epoch 131/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 0.5972 - val_accuracy: 0.8916\n","\n","Epoch 00131: val_accuracy did not improve from 0.91379\n","Epoch 132/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.4306 - val_accuracy: 0.9089\n","\n","Epoch 00132: val_accuracy did not improve from 0.91379\n","Epoch 133/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.4858 - val_accuracy: 0.8990\n","\n","Epoch 00133: val_accuracy did not improve from 0.91379\n","Epoch 134/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.4331 - val_accuracy: 0.8941\n","\n","Epoch 00134: val_accuracy did not improve from 0.91379\n","Epoch 135/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5745 - val_accuracy: 0.8695\n","\n","Epoch 00135: val_accuracy did not improve from 0.91379\n","Epoch 136/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3925 - val_accuracy: 0.9113\n","\n","Epoch 00136: val_accuracy did not improve from 0.91379\n","Epoch 137/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4948 - val_accuracy: 0.9064\n","\n","Epoch 00137: val_accuracy did not improve from 0.91379\n","Epoch 138/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8990\n","\n","Epoch 00138: val_accuracy did not improve from 0.91379\n","Epoch 139/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4855 - val_accuracy: 0.8990\n","\n","Epoch 00139: val_accuracy did not improve from 0.91379\n","Epoch 140/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9039\n","\n","Epoch 00140: val_accuracy did not improve from 0.91379\n","Epoch 141/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.4711 - val_accuracy: 0.8892\n","\n","Epoch 00141: val_accuracy did not improve from 0.91379\n","Epoch 142/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0355 - accuracy: 0.9921 - val_loss: 0.5801 - val_accuracy: 0.8916\n","\n","Epoch 00142: val_accuracy did not improve from 0.91379\n","Epoch 143/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.9102 - val_accuracy: 0.8251\n","\n","Epoch 00143: val_accuracy did not improve from 0.91379\n","Epoch 144/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 1.1059 - val_accuracy: 0.7808\n","\n","Epoch 00144: val_accuracy did not improve from 0.91379\n","Epoch 145/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.5392 - val_accuracy: 0.8621\n","\n","Epoch 00145: val_accuracy did not improve from 0.91379\n","Epoch 146/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 1.3282 - val_accuracy: 0.7833\n","\n","Epoch 00146: val_accuracy did not improve from 0.91379\n","Epoch 147/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0777 - accuracy: 0.9726 - val_loss: 1.2578 - val_accuracy: 0.8005\n","\n","Epoch 00147: val_accuracy did not improve from 0.91379\n","Epoch 148/500\n","52/52 [==============================] - 11s 216ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.9534 - val_accuracy: 0.8424\n","\n","Epoch 00148: val_accuracy did not improve from 0.91379\n","Epoch 149/500\n","52/52 [==============================] - 11s 215ms/step - loss: 0.0675 - accuracy: 0.9781 - val_loss: 1.1207 - val_accuracy: 0.8030\n","\n","Epoch 00149: val_accuracy did not improve from 0.91379\n","Epoch 150/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1224 - accuracy: 0.9610 - val_loss: 1.8955 - val_accuracy: 0.6355\n","\n","Epoch 00150: val_accuracy did not improve from 0.91379\n","Epoch 151/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 1.0060 - val_accuracy: 0.7759\n","\n","Epoch 00151: val_accuracy did not improve from 0.91379\n","Epoch 152/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.6048 - val_accuracy: 0.8399\n","\n","Epoch 00152: val_accuracy did not improve from 0.91379\n","Epoch 153/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.5256 - val_accuracy: 0.8744\n","\n","Epoch 00153: val_accuracy did not improve from 0.91379\n","Epoch 154/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.5278 - val_accuracy: 0.8892\n","\n","Epoch 00154: val_accuracy did not improve from 0.91379\n","Epoch 155/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.5765 - val_accuracy: 0.8842\n","\n","Epoch 00155: val_accuracy did not improve from 0.91379\n","Epoch 156/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.4349 - val_accuracy: 0.8966\n","\n","Epoch 00156: val_accuracy did not improve from 0.91379\n","Epoch 157/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.4865 - val_accuracy: 0.8966\n","\n","Epoch 00157: val_accuracy did not improve from 0.91379\n","Epoch 158/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4100 - val_accuracy: 0.9163\n","\n","Epoch 00158: val_accuracy improved from 0.91379 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 159/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.4415 - val_accuracy: 0.8966\n","\n","Epoch 00159: val_accuracy did not improve from 0.91626\n","Epoch 160/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4757 - val_accuracy: 0.9138\n","\n","Epoch 00160: val_accuracy did not improve from 0.91626\n","Epoch 161/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4405 - val_accuracy: 0.9089\n","\n","Epoch 00161: val_accuracy did not improve from 0.91626\n","Epoch 162/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4334 - val_accuracy: 0.9089\n","\n","Epoch 00162: val_accuracy did not improve from 0.91626\n","Epoch 163/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.3856 - val_accuracy: 0.9187\n","\n","Epoch 00163: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 164/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4089 - val_accuracy: 0.9089\n","\n","Epoch 00164: val_accuracy did not improve from 0.91872\n","Epoch 165/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4932 - val_accuracy: 0.9015\n","\n","Epoch 00165: val_accuracy did not improve from 0.91872\n","Epoch 166/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4109 - val_accuracy: 0.9163\n","\n","Epoch 00166: val_accuracy did not improve from 0.91872\n","Epoch 167/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5184 - val_accuracy: 0.8941\n","\n","Epoch 00167: val_accuracy did not improve from 0.91872\n","Epoch 168/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.7371 - val_accuracy: 0.8719\n","\n","Epoch 00168: val_accuracy did not improve from 0.91872\n","Epoch 169/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5701 - val_accuracy: 0.9015\n","\n","Epoch 00169: val_accuracy did not improve from 0.91872\n","Epoch 170/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0038 - accuracy: 0.9976 - val_loss: 0.5542 - val_accuracy: 0.9138\n","\n","Epoch 00170: val_accuracy did not improve from 0.91872\n","Epoch 171/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.6690 - val_accuracy: 0.8768\n","\n","Epoch 00171: val_accuracy did not improve from 0.91872\n","Epoch 172/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 0.9891 - val_accuracy: 0.8202\n","\n","Epoch 00172: val_accuracy did not improve from 0.91872\n","Epoch 173/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0688 - accuracy: 0.9744 - val_loss: 1.1893 - val_accuracy: 0.8202\n","\n","Epoch 00173: val_accuracy did not improve from 0.91872\n","Epoch 174/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0821 - accuracy: 0.9744 - val_loss: 2.1859 - val_accuracy: 0.7143\n","\n","Epoch 00174: val_accuracy did not improve from 0.91872\n","Epoch 175/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.7786 - val_accuracy: 0.8818\n","\n","Epoch 00175: val_accuracy did not improve from 0.91872\n","Epoch 176/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.8202 - val_accuracy: 0.8547\n","\n","Epoch 00176: val_accuracy did not improve from 0.91872\n","Epoch 177/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.6392 - val_accuracy: 0.8695\n","\n","Epoch 00177: val_accuracy did not improve from 0.91872\n","Epoch 178/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.9833 - val_accuracy: 0.8350\n","\n","Epoch 00178: val_accuracy did not improve from 0.91872\n","Epoch 179/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.6946 - val_accuracy: 0.8719\n","\n","Epoch 00179: val_accuracy did not improve from 0.91872\n","Epoch 180/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.8890 - val_accuracy: 0.8448\n","\n","Epoch 00180: val_accuracy did not improve from 0.91872\n","Epoch 181/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.7314 - val_accuracy: 0.8621\n","\n","Epoch 00181: val_accuracy did not improve from 0.91872\n","Epoch 182/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.7047 - val_accuracy: 0.8448\n","\n","Epoch 00182: val_accuracy did not improve from 0.91872\n","Epoch 183/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0772 - accuracy: 0.9769 - val_loss: 1.5419 - val_accuracy: 0.7759\n","\n","Epoch 00183: val_accuracy did not improve from 0.91872\n","Epoch 184/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 1.2663 - val_accuracy: 0.8227\n","\n","Epoch 00184: val_accuracy did not improve from 0.91872\n","Epoch 185/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.4820 - val_accuracy: 0.9089\n","\n","Epoch 00185: val_accuracy did not improve from 0.91872\n","Epoch 186/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0178 - accuracy: 0.9921 - val_loss: 0.4990 - val_accuracy: 0.8941\n","\n","Epoch 00186: val_accuracy did not improve from 0.91872\n","Epoch 187/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.4382 - val_accuracy: 0.9015\n","\n","Epoch 00187: val_accuracy did not improve from 0.91872\n","Epoch 188/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.5462 - val_accuracy: 0.8867\n","\n","Epoch 00188: val_accuracy did not improve from 0.91872\n","Epoch 189/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.7334 - val_accuracy: 0.8498\n","\n","Epoch 00189: val_accuracy did not improve from 0.91872\n","Epoch 190/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.5300 - val_accuracy: 0.8892\n","\n","Epoch 00190: val_accuracy did not improve from 0.91872\n","Epoch 191/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.7838 - val_accuracy: 0.8645\n","\n","Epoch 00191: val_accuracy did not improve from 0.91872\n","Epoch 192/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.6814 - val_accuracy: 0.8621\n","\n","Epoch 00192: val_accuracy did not improve from 0.91872\n","Epoch 193/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0143 - accuracy: 0.9939 - val_loss: 0.5655 - val_accuracy: 0.8867\n","\n","Epoch 00193: val_accuracy did not improve from 0.91872\n","Epoch 194/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.5496 - val_accuracy: 0.8818\n","\n","Epoch 00194: val_accuracy did not improve from 0.91872\n","Epoch 195/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.5259 - val_accuracy: 0.8768\n","\n","Epoch 00195: val_accuracy did not improve from 0.91872\n","Epoch 196/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.8941\n","\n","Epoch 00196: val_accuracy did not improve from 0.91872\n","Epoch 197/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4879 - val_accuracy: 0.9113\n","\n","Epoch 00197: val_accuracy did not improve from 0.91872\n","Epoch 198/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.4870 - val_accuracy: 0.8916\n","\n","Epoch 00198: val_accuracy did not improve from 0.91872\n","Epoch 199/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5019 - val_accuracy: 0.8818\n","\n","Epoch 00199: val_accuracy did not improve from 0.91872\n","Epoch 200/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4827 - val_accuracy: 0.8990\n","\n","Epoch 00200: val_accuracy did not improve from 0.91872\n","Epoch 201/500\n","52/52 [==============================] - 11s 218ms/step - loss: 8.4860e-04 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9138\n","\n","Epoch 00201: val_accuracy did not improve from 0.91872\n","Epoch 202/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9015\n","\n","Epoch 00202: val_accuracy did not improve from 0.91872\n","Epoch 203/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9113\n","\n","Epoch 00203: val_accuracy did not improve from 0.91872\n","Epoch 204/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4788 - val_accuracy: 0.9015\n","\n","Epoch 00204: val_accuracy did not improve from 0.91872\n","Epoch 205/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4603 - val_accuracy: 0.8941\n","\n","Epoch 00205: val_accuracy did not improve from 0.91872\n","Epoch 206/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 1.5825 - val_accuracy: 0.7685\n","\n","Epoch 00206: val_accuracy did not improve from 0.91872\n","Epoch 207/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0753 - accuracy: 0.9787 - val_loss: 0.8767 - val_accuracy: 0.8227\n","\n","Epoch 00207: val_accuracy did not improve from 0.91872\n","Epoch 208/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 2.5100 - val_accuracy: 0.6232\n","\n","Epoch 00208: val_accuracy did not improve from 0.91872\n","Epoch 209/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0741 - accuracy: 0.9793 - val_loss: 1.4901 - val_accuracy: 0.7438\n","\n","Epoch 00209: val_accuracy did not improve from 0.91872\n","Epoch 210/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.8880 - val_accuracy: 0.8719\n","\n","Epoch 00210: val_accuracy did not improve from 0.91872\n","Epoch 211/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 1.1331 - val_accuracy: 0.8054\n","\n","Epoch 00211: val_accuracy did not improve from 0.91872\n","Epoch 212/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.7798 - val_accuracy: 0.8276\n","\n","Epoch 00212: val_accuracy did not improve from 0.91872\n","Epoch 213/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.6931 - val_accuracy: 0.8399\n","\n","Epoch 00213: val_accuracy did not improve from 0.91872\n","Epoch 214/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.6909 - val_accuracy: 0.8473\n","\n","Epoch 00214: val_accuracy did not improve from 0.91872\n","Epoch 215/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5738 - val_accuracy: 0.8990\n","\n","Epoch 00215: val_accuracy did not improve from 0.91872\n","Epoch 216/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1372 - accuracy: 0.9689 - val_loss: 0.9705 - val_accuracy: 0.8374\n","\n","Epoch 00216: val_accuracy did not improve from 0.91872\n","Epoch 217/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.8740 - val_accuracy: 0.8350\n","\n","Epoch 00217: val_accuracy did not improve from 0.91872\n","Epoch 218/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0484 - accuracy: 0.9811 - val_loss: 0.8882 - val_accuracy: 0.8571\n","\n","Epoch 00218: val_accuracy did not improve from 0.91872\n","Epoch 219/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.5752 - val_accuracy: 0.8768\n","\n","Epoch 00219: val_accuracy did not improve from 0.91872\n","Epoch 220/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.6019 - val_accuracy: 0.8892\n","\n","Epoch 00220: val_accuracy did not improve from 0.91872\n","Epoch 221/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.6046 - val_accuracy: 0.8744\n","\n","Epoch 00221: val_accuracy did not improve from 0.91872\n","Epoch 222/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8990\n","\n","Epoch 00222: val_accuracy did not improve from 0.91872\n","Epoch 223/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4779 - val_accuracy: 0.8990\n","\n","Epoch 00223: val_accuracy did not improve from 0.91872\n","Epoch 224/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9064\n","\n","Epoch 00224: val_accuracy did not improve from 0.91872\n","Epoch 225/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4391 - val_accuracy: 0.9039\n","\n","Epoch 00225: val_accuracy did not improve from 0.91872\n","Epoch 226/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9212\n","\n","Epoch 00226: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 227/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9187\n","\n","Epoch 00227: val_accuracy did not improve from 0.92118\n","Epoch 228/500\n","52/52 [==============================] - 11s 219ms/step - loss: 6.4755e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9113\n","\n","Epoch 00228: val_accuracy did not improve from 0.92118\n","Epoch 229/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.2961e-04 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9187\n","\n","Epoch 00229: val_accuracy did not improve from 0.92118\n","Epoch 230/500\n","52/52 [==============================] - 11s 219ms/step - loss: 8.4349e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9089\n","\n","Epoch 00230: val_accuracy did not improve from 0.92118\n","Epoch 231/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4181 - val_accuracy: 0.9212\n","\n","Epoch 00231: val_accuracy did not improve from 0.92118\n","Epoch 232/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9138\n","\n","Epoch 00232: val_accuracy did not improve from 0.92118\n","Epoch 233/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4326 - val_accuracy: 0.8990\n","\n","Epoch 00233: val_accuracy did not improve from 0.92118\n","Epoch 234/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9064\n","\n","Epoch 00234: val_accuracy did not improve from 0.92118\n","Epoch 235/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5482 - val_accuracy: 0.8744\n","\n","Epoch 00235: val_accuracy did not improve from 0.92118\n","Epoch 236/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.7316 - val_accuracy: 0.8793\n","\n","Epoch 00236: val_accuracy did not improve from 0.92118\n","Epoch 237/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.9800 - val_accuracy: 0.8374\n","\n","Epoch 00237: val_accuracy did not improve from 0.92118\n","Epoch 238/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0597 - accuracy: 0.9829 - val_loss: 0.8365 - val_accuracy: 0.8571\n","\n","Epoch 00238: val_accuracy did not improve from 0.92118\n","Epoch 239/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.6598 - val_accuracy: 0.8719\n","\n","Epoch 00239: val_accuracy did not improve from 0.92118\n","Epoch 240/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0316 - accuracy: 0.9872 - val_loss: 0.6511 - val_accuracy: 0.8670\n","\n","Epoch 00240: val_accuracy did not improve from 0.92118\n","Epoch 241/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.5322 - val_accuracy: 0.8818\n","\n","Epoch 00241: val_accuracy did not improve from 0.92118\n","Epoch 242/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.6335 - val_accuracy: 0.8768\n","\n","Epoch 00242: val_accuracy did not improve from 0.92118\n","Epoch 243/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5553 - val_accuracy: 0.9015\n","\n","Epoch 00243: val_accuracy did not improve from 0.92118\n","Epoch 244/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.6879 - val_accuracy: 0.8793\n","\n","Epoch 00244: val_accuracy did not improve from 0.92118\n","Epoch 245/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0200 - accuracy: 0.9921 - val_loss: 0.6563 - val_accuracy: 0.8522\n","\n","Epoch 00245: val_accuracy did not improve from 0.92118\n","Epoch 246/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5036 - val_accuracy: 0.8990\n","\n","Epoch 00246: val_accuracy did not improve from 0.92118\n","Epoch 247/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.6038 - val_accuracy: 0.8768\n","\n","Epoch 00247: val_accuracy did not improve from 0.92118\n","Epoch 248/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5461 - val_accuracy: 0.8818\n","\n","Epoch 00248: val_accuracy did not improve from 0.92118\n","Epoch 249/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.6728 - val_accuracy: 0.8719\n","\n","Epoch 00249: val_accuracy did not improve from 0.92118\n","Epoch 250/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.8422 - val_accuracy: 0.8621\n","\n","Epoch 00250: val_accuracy did not improve from 0.92118\n","Epoch 251/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0210 - accuracy: 0.9909 - val_loss: 0.7497 - val_accuracy: 0.8867\n","\n","Epoch 00251: val_accuracy did not improve from 0.92118\n","Epoch 252/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.7089 - val_accuracy: 0.8744\n","\n","Epoch 00252: val_accuracy did not improve from 0.92118\n","Epoch 253/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.6484 - val_accuracy: 0.8916\n","\n","Epoch 00253: val_accuracy did not improve from 0.92118\n","Epoch 254/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.7426 - val_accuracy: 0.8966\n","\n","Epoch 00254: val_accuracy did not improve from 0.92118\n","Epoch 255/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6504 - val_accuracy: 0.8596\n","\n","Epoch 00255: val_accuracy did not improve from 0.92118\n","Epoch 256/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.6460 - val_accuracy: 0.8867\n","\n","Epoch 00256: val_accuracy did not improve from 0.92118\n","Epoch 257/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.7124 - val_accuracy: 0.8473\n","\n","Epoch 00257: val_accuracy did not improve from 0.92118\n","Epoch 258/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5598 - val_accuracy: 0.8768\n","\n","Epoch 00258: val_accuracy did not improve from 0.92118\n","Epoch 259/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5993 - val_accuracy: 0.8892\n","\n","Epoch 00259: val_accuracy did not improve from 0.92118\n","Epoch 260/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.6439 - val_accuracy: 0.8892\n","\n","Epoch 00260: val_accuracy did not improve from 0.92118\n","Epoch 261/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6344 - val_accuracy: 0.8916\n","\n","Epoch 00261: val_accuracy did not improve from 0.92118\n","Epoch 262/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.8916\n","\n","Epoch 00262: val_accuracy did not improve from 0.92118\n","Epoch 263/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.9553 - val_accuracy: 0.8103\n","\n","Epoch 00263: val_accuracy did not improve from 0.92118\n","Epoch 264/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0378 - accuracy: 0.9866 - val_loss: 0.8213 - val_accuracy: 0.8473\n","\n","Epoch 00264: val_accuracy did not improve from 0.92118\n","Epoch 265/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.9843 - val_accuracy: 0.8251\n","\n","Epoch 00265: val_accuracy did not improve from 0.92118\n","Epoch 266/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5654 - val_accuracy: 0.8916\n","\n","Epoch 00266: val_accuracy did not improve from 0.92118\n","Epoch 267/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.5287 - val_accuracy: 0.9064\n","\n","Epoch 00267: val_accuracy did not improve from 0.92118\n","Epoch 268/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5134 - val_accuracy: 0.9089\n","\n","Epoch 00268: val_accuracy did not improve from 0.92118\n","Epoch 269/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9113\n","\n","Epoch 00269: val_accuracy did not improve from 0.92118\n","Epoch 270/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5358 - val_accuracy: 0.8916\n","\n","Epoch 00270: val_accuracy did not improve from 0.92118\n","Epoch 271/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5205 - val_accuracy: 0.8990\n","\n","Epoch 00271: val_accuracy did not improve from 0.92118\n","Epoch 272/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 1.2123 - val_accuracy: 0.8473\n","\n","Epoch 00272: val_accuracy did not improve from 0.92118\n","Epoch 273/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0649 - accuracy: 0.9842 - val_loss: 1.0157 - val_accuracy: 0.8448\n","\n","Epoch 00273: val_accuracy did not improve from 0.92118\n","Epoch 274/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.9708 - val_accuracy: 0.8399\n","\n","Epoch 00274: val_accuracy did not improve from 0.92118\n","Epoch 275/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.5210 - val_accuracy: 0.9015\n","\n","Epoch 00275: val_accuracy did not improve from 0.92118\n","Epoch 276/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.4938 - val_accuracy: 0.9015\n","\n","Epoch 00276: val_accuracy did not improve from 0.92118\n","Epoch 277/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5971 - val_accuracy: 0.8867\n","\n","Epoch 00277: val_accuracy did not improve from 0.92118\n","Epoch 278/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.5074 - val_accuracy: 0.9015\n","\n","Epoch 00278: val_accuracy did not improve from 0.92118\n","Epoch 279/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.9039\n","\n","Epoch 00279: val_accuracy did not improve from 0.92118\n","Epoch 280/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4404 - val_accuracy: 0.8916\n","\n","Epoch 00280: val_accuracy did not improve from 0.92118\n","Epoch 281/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.5325 - val_accuracy: 0.8916\n","\n","Epoch 00281: val_accuracy did not improve from 0.92118\n","Epoch 282/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5278 - val_accuracy: 0.8892\n","\n","Epoch 00282: val_accuracy did not improve from 0.92118\n","Epoch 283/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.6901 - val_accuracy: 0.8596\n","\n","Epoch 00283: val_accuracy did not improve from 0.92118\n","Epoch 284/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5815 - val_accuracy: 0.8645\n","\n","Epoch 00284: val_accuracy did not improve from 0.92118\n","Epoch 285/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9113\n","\n","Epoch 00285: val_accuracy did not improve from 0.92118\n","Epoch 286/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5487 - val_accuracy: 0.8966\n","\n","Epoch 00286: val_accuracy did not improve from 0.92118\n","Epoch 287/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9039\n","\n","Epoch 00287: val_accuracy did not improve from 0.92118\n","Epoch 288/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.6917e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9187\n","\n","Epoch 00288: val_accuracy did not improve from 0.92118\n","Epoch 289/500\n","52/52 [==============================] - 11s 220ms/step - loss: 8.3212e-04 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9236\n","\n","Epoch 00289: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 290/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4488 - val_accuracy: 0.9138\n","\n","Epoch 00290: val_accuracy did not improve from 0.92365\n","Epoch 291/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4479 - val_accuracy: 0.9089\n","\n","Epoch 00291: val_accuracy did not improve from 0.92365\n","Epoch 292/500\n","52/52 [==============================] - 11s 218ms/step - loss: 5.9449e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9089\n","\n","Epoch 00292: val_accuracy did not improve from 0.92365\n","Epoch 293/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.7821 - val_accuracy: 0.8300\n","\n","Epoch 00293: val_accuracy did not improve from 0.92365\n","Epoch 294/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6335 - val_accuracy: 0.8645\n","\n","Epoch 00294: val_accuracy did not improve from 0.92365\n","Epoch 295/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 1.0758 - val_accuracy: 0.7365\n","\n","Epoch 00295: val_accuracy did not improve from 0.92365\n","Epoch 296/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.8415 - val_accuracy: 0.8571\n","\n","Epoch 00296: val_accuracy did not improve from 0.92365\n","Epoch 297/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5729 - val_accuracy: 0.8867\n","\n","Epoch 00297: val_accuracy did not improve from 0.92365\n","Epoch 298/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.7929 - val_accuracy: 0.8276\n","\n","Epoch 00298: val_accuracy did not improve from 0.92365\n","Epoch 299/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.7225 - val_accuracy: 0.8645\n","\n","Epoch 00299: val_accuracy did not improve from 0.92365\n","Epoch 300/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0289 - accuracy: 0.9890 - val_loss: 0.8324 - val_accuracy: 0.8818\n","\n","Epoch 00300: val_accuracy did not improve from 0.92365\n","Epoch 301/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.9052 - val_accuracy: 0.8276\n","\n","Epoch 00301: val_accuracy did not improve from 0.92365\n","Epoch 302/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.7412 - val_accuracy: 0.8522\n","\n","Epoch 00302: val_accuracy did not improve from 0.92365\n","Epoch 303/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0319 - accuracy: 0.9915 - val_loss: 0.6493 - val_accuracy: 0.8695\n","\n","Epoch 00303: val_accuracy did not improve from 0.92365\n","Epoch 304/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5749 - val_accuracy: 0.8818\n","\n","Epoch 00304: val_accuracy did not improve from 0.92365\n","Epoch 305/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.5789 - val_accuracy: 0.8522\n","\n","Epoch 00305: val_accuracy did not improve from 0.92365\n","Epoch 306/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.4878 - val_accuracy: 0.8966\n","\n","Epoch 00306: val_accuracy did not improve from 0.92365\n","Epoch 307/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.6376 - val_accuracy: 0.8547\n","\n","Epoch 00307: val_accuracy did not improve from 0.92365\n","Epoch 308/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 1.1600 - val_accuracy: 0.8128\n","\n","Epoch 00308: val_accuracy did not improve from 0.92365\n","Epoch 309/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.7309 - val_accuracy: 0.8596\n","\n","Epoch 00309: val_accuracy did not improve from 0.92365\n","Epoch 310/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.6182 - val_accuracy: 0.8744\n","\n","Epoch 00310: val_accuracy did not improve from 0.92365\n","Epoch 311/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.6230 - val_accuracy: 0.8818\n","\n","Epoch 00311: val_accuracy did not improve from 0.92365\n","Epoch 312/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.4963 - val_accuracy: 0.8990\n","\n","Epoch 00312: val_accuracy did not improve from 0.92365\n","Epoch 313/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5923 - val_accuracy: 0.8719\n","\n","Epoch 00313: val_accuracy did not improve from 0.92365\n","Epoch 314/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4332 - val_accuracy: 0.9064\n","\n","Epoch 00314: val_accuracy did not improve from 0.92365\n","Epoch 315/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4959 - val_accuracy: 0.8867\n","\n","Epoch 00315: val_accuracy did not improve from 0.92365\n","Epoch 316/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9089\n","\n","Epoch 00316: val_accuracy did not improve from 0.92365\n","Epoch 317/500\n","52/52 [==============================] - 11s 219ms/step - loss: 4.4929e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9089\n","\n","Epoch 00317: val_accuracy did not improve from 0.92365\n","Epoch 318/500\n","52/52 [==============================] - 11s 219ms/step - loss: 7.1001e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9064\n","\n","Epoch 00318: val_accuracy did not improve from 0.92365\n","Epoch 319/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.0457e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9138\n","\n","Epoch 00319: val_accuracy did not improve from 0.92365\n","Epoch 320/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.7250e-04 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9187\n","\n","Epoch 00320: val_accuracy did not improve from 0.92365\n","Epoch 321/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.9039\n","\n","Epoch 00321: val_accuracy did not improve from 0.92365\n","Epoch 322/500\n","52/52 [==============================] - 11s 220ms/step - loss: 3.9425e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9064\n","\n","Epoch 00322: val_accuracy did not improve from 0.92365\n","Epoch 323/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.4966e-04 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9064\n","\n","Epoch 00323: val_accuracy did not improve from 0.92365\n","Epoch 324/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.2142e-04 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9064\n","\n","Epoch 00324: val_accuracy did not improve from 0.92365\n","Epoch 325/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.0490e-04 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9138\n","\n","Epoch 00325: val_accuracy did not improve from 0.92365\n","Epoch 326/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.2623e-04 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9039\n","\n","Epoch 00326: val_accuracy did not improve from 0.92365\n","Epoch 327/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.9860e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9163\n","\n","Epoch 00327: val_accuracy did not improve from 0.92365\n","Epoch 328/500\n","52/52 [==============================] - 11s 219ms/step - loss: 1.5397e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9163\n","\n","Epoch 00328: val_accuracy did not improve from 0.92365\n","Epoch 329/500\n","52/52 [==============================] - 12s 220ms/step - loss: 2.8566e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9236\n","\n","Epoch 00329: val_accuracy did not improve from 0.92365\n","Epoch 330/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.8135e-04 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9089\n","\n","Epoch 00330: val_accuracy did not improve from 0.92365\n","Epoch 331/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.1037e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9064\n","\n","Epoch 00331: val_accuracy did not improve from 0.92365\n","Epoch 332/500\n","52/52 [==============================] - 11s 220ms/step - loss: 1.1351e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9113\n","\n","Epoch 00332: val_accuracy did not improve from 0.92365\n","Epoch 333/500\n","52/52 [==============================] - 11s 220ms/step - loss: 1.6535e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9212\n","\n","Epoch 00333: val_accuracy did not improve from 0.92365\n","Epoch 334/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.8902e-05 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9089\n","\n","Epoch 00334: val_accuracy did not improve from 0.92365\n","Epoch 335/500\n","52/52 [==============================] - 12s 220ms/step - loss: 1.9159e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9187\n","\n","Epoch 00335: val_accuracy did not improve from 0.92365\n","Epoch 336/500\n","52/52 [==============================] - 12s 221ms/step - loss: 8.9888e-05 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9113\n","\n","Epoch 00336: val_accuracy did not improve from 0.92365\n","Epoch 337/500\n","52/52 [==============================] - 11s 218ms/step - loss: 9.0328e-05 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9236\n","\n","Epoch 00337: val_accuracy did not improve from 0.92365\n","Epoch 338/500\n","52/52 [==============================] - 11s 219ms/step - loss: 2.8035e-04 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9212\n","\n","Epoch 00338: val_accuracy did not improve from 0.92365\n","Epoch 339/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.7929e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9261\n","\n","Epoch 00339: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 340/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.0317e-04 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9310\n","\n","Epoch 00340: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5\n","Epoch 341/500\n","52/52 [==============================] - 12s 224ms/step - loss: 3.1562e-04 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9310\n","\n","Epoch 00341: val_accuracy did not improve from 0.93103\n","Epoch 342/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.5379 - val_accuracy: 0.9015\n","\n","Epoch 00342: val_accuracy did not improve from 0.93103\n","Epoch 343/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0541 - accuracy: 0.9878 - val_loss: 2.6953 - val_accuracy: 0.6626\n","\n","Epoch 00343: val_accuracy did not improve from 0.93103\n","Epoch 344/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1183 - accuracy: 0.9635 - val_loss: 3.4674 - val_accuracy: 0.6552\n","\n","Epoch 00344: val_accuracy did not improve from 0.93103\n","Epoch 345/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1273 - accuracy: 0.9708 - val_loss: 1.4429 - val_accuracy: 0.7783\n","\n","Epoch 00345: val_accuracy did not improve from 0.93103\n","Epoch 346/500\n","52/52 [==============================] - 11s 222ms/step - loss: 0.0694 - accuracy: 0.9714 - val_loss: 0.7999 - val_accuracy: 0.8424\n","\n","Epoch 00346: val_accuracy did not improve from 0.93103\n","Epoch 347/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.8371 - val_accuracy: 0.8498\n","\n","Epoch 00347: val_accuracy did not improve from 0.93103\n","Epoch 348/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.5199 - val_accuracy: 0.8990\n","\n","Epoch 00348: val_accuracy did not improve from 0.93103\n","Epoch 349/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4446 - val_accuracy: 0.9015\n","\n","Epoch 00349: val_accuracy did not improve from 0.93103\n","Epoch 350/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4217 - val_accuracy: 0.8966\n","\n","Epoch 00350: val_accuracy did not improve from 0.93103\n","Epoch 351/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.5070 - val_accuracy: 0.8892\n","\n","Epoch 00351: val_accuracy did not improve from 0.93103\n","Epoch 352/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4459 - val_accuracy: 0.8990\n","\n","Epoch 00352: val_accuracy did not improve from 0.93103\n","Epoch 353/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.9039\n","\n","Epoch 00353: val_accuracy did not improve from 0.93103\n","Epoch 354/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.8605e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9015\n","\n","Epoch 00354: val_accuracy did not improve from 0.93103\n","Epoch 355/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8941\n","\n","Epoch 00355: val_accuracy did not improve from 0.93103\n","Epoch 356/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.8871e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.8990\n","\n","Epoch 00356: val_accuracy did not improve from 0.93103\n","Epoch 357/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4027 - val_accuracy: 0.9113\n","\n","Epoch 00357: val_accuracy did not improve from 0.93103\n","Epoch 358/500\n","52/52 [==============================] - 11s 219ms/step - loss: 5.9977e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9138\n","\n","Epoch 00358: val_accuracy did not improve from 0.93103\n","Epoch 359/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.2817e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9039\n","\n","Epoch 00359: val_accuracy did not improve from 0.93103\n","Epoch 360/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.5378 - val_accuracy: 0.8916\n","\n","Epoch 00360: val_accuracy did not improve from 0.93103\n","Epoch 361/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.7329 - val_accuracy: 0.8670\n","\n","Epoch 00361: val_accuracy did not improve from 0.93103\n","Epoch 362/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0097 - accuracy: 0.9951 - val_loss: 0.5261 - val_accuracy: 0.9015\n","\n","Epoch 00362: val_accuracy did not improve from 0.93103\n","Epoch 363/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4440 - val_accuracy: 0.9039\n","\n","Epoch 00363: val_accuracy did not improve from 0.93103\n","Epoch 364/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 1.0513 - val_accuracy: 0.7635\n","\n","Epoch 00364: val_accuracy did not improve from 0.93103\n","Epoch 365/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5737 - val_accuracy: 0.8744\n","\n","Epoch 00365: val_accuracy did not improve from 0.93103\n","Epoch 366/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4477 - val_accuracy: 0.8990\n","\n","Epoch 00366: val_accuracy did not improve from 0.93103\n","Epoch 367/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4812 - val_accuracy: 0.8966\n","\n","Epoch 00367: val_accuracy did not improve from 0.93103\n","Epoch 368/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0528 - accuracy: 0.9890 - val_loss: 5.2994 - val_accuracy: 0.4335\n","\n","Epoch 00368: val_accuracy did not improve from 0.93103\n","Epoch 369/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.5683 - val_accuracy: 0.8966\n","\n","Epoch 00369: val_accuracy did not improve from 0.93103\n","Epoch 370/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.7349 - val_accuracy: 0.8448\n","\n","Epoch 00370: val_accuracy did not improve from 0.93103\n","Epoch 371/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.8768\n","\n","Epoch 00371: val_accuracy did not improve from 0.93103\n","Epoch 372/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5195 - val_accuracy: 0.8941\n","\n","Epoch 00372: val_accuracy did not improve from 0.93103\n","Epoch 373/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9039\n","\n","Epoch 00373: val_accuracy did not improve from 0.93103\n","Epoch 374/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4731 - val_accuracy: 0.8892\n","\n","Epoch 00374: val_accuracy did not improve from 0.93103\n","Epoch 375/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.6440 - val_accuracy: 0.8448\n","\n","Epoch 00375: val_accuracy did not improve from 0.93103\n","Epoch 376/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5865 - val_accuracy: 0.8768\n","\n","Epoch 00376: val_accuracy did not improve from 0.93103\n","Epoch 377/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8842\n","\n","Epoch 00377: val_accuracy did not improve from 0.93103\n","Epoch 378/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4953 - val_accuracy: 0.9039\n","\n","Epoch 00378: val_accuracy did not improve from 0.93103\n","Epoch 379/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5865 - val_accuracy: 0.8966\n","\n","Epoch 00379: val_accuracy did not improve from 0.93103\n","Epoch 380/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.7251 - val_accuracy: 0.8768\n","\n","Epoch 00380: val_accuracy did not improve from 0.93103\n","Epoch 381/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.8959 - val_accuracy: 0.8522\n","\n","Epoch 00381: val_accuracy did not improve from 0.93103\n","Epoch 382/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.9595 - val_accuracy: 0.8300\n","\n","Epoch 00382: val_accuracy did not improve from 0.93103\n","Epoch 383/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0780 - accuracy: 0.9793 - val_loss: 2.9551 - val_accuracy: 0.5788\n","\n","Epoch 00383: val_accuracy did not improve from 0.93103\n","Epoch 384/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0531 - accuracy: 0.9817 - val_loss: 0.6832 - val_accuracy: 0.8867\n","\n","Epoch 00384: val_accuracy did not improve from 0.93103\n","Epoch 385/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.9110 - val_accuracy: 0.8128\n","\n","Epoch 00385: val_accuracy did not improve from 0.93103\n","Epoch 386/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.6024 - val_accuracy: 0.8793\n","\n","Epoch 00386: val_accuracy did not improve from 0.93103\n","Epoch 387/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.5490 - val_accuracy: 0.8966\n","\n","Epoch 00387: val_accuracy did not improve from 0.93103\n","Epoch 388/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.7354 - val_accuracy: 0.8744\n","\n","Epoch 00388: val_accuracy did not improve from 0.93103\n","Epoch 389/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5781 - val_accuracy: 0.8990\n","\n","Epoch 00389: val_accuracy did not improve from 0.93103\n","Epoch 390/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9015\n","\n","Epoch 00390: val_accuracy did not improve from 0.93103\n","Epoch 391/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9138\n","\n","Epoch 00391: val_accuracy did not improve from 0.93103\n","Epoch 392/500\n","52/52 [==============================] - 11s 219ms/step - loss: 9.0287e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9064\n","\n","Epoch 00392: val_accuracy did not improve from 0.93103\n","Epoch 393/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9163\n","\n","Epoch 00393: val_accuracy did not improve from 0.93103\n","Epoch 394/500\n","52/52 [==============================] - 11s 220ms/step - loss: 8.5796e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9089\n","\n","Epoch 00394: val_accuracy did not improve from 0.93103\n","Epoch 395/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 1.0445 - val_accuracy: 0.8005\n","\n","Epoch 00395: val_accuracy did not improve from 0.93103\n","Epoch 396/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.6389 - val_accuracy: 0.8645\n","\n","Epoch 00396: val_accuracy did not improve from 0.93103\n","Epoch 397/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.6431 - val_accuracy: 0.8916\n","\n","Epoch 00397: val_accuracy did not improve from 0.93103\n","Epoch 398/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5496 - val_accuracy: 0.9039\n","\n","Epoch 00398: val_accuracy did not improve from 0.93103\n","Epoch 399/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5018 - val_accuracy: 0.8941\n","\n","Epoch 00399: val_accuracy did not improve from 0.93103\n","Epoch 400/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4625 - val_accuracy: 0.9089\n","\n","Epoch 00400: val_accuracy did not improve from 0.93103\n","Epoch 401/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5823 - val_accuracy: 0.8768\n","\n","Epoch 00401: val_accuracy did not improve from 0.93103\n","Epoch 402/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4734 - val_accuracy: 0.8916\n","\n","Epoch 00402: val_accuracy did not improve from 0.93103\n","Epoch 403/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.8842\n","\n","Epoch 00403: val_accuracy did not improve from 0.93103\n","Epoch 404/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.5709e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8941\n","\n","Epoch 00404: val_accuracy did not improve from 0.93103\n","Epoch 405/500\n","52/52 [==============================] - 12s 220ms/step - loss: 3.2423e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9064\n","\n","Epoch 00405: val_accuracy did not improve from 0.93103\n","Epoch 406/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.3439e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9039\n","\n","Epoch 00406: val_accuracy did not improve from 0.93103\n","Epoch 407/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.8166e-04 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9064\n","\n","Epoch 00407: val_accuracy did not improve from 0.93103\n","Epoch 408/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5065 - val_accuracy: 0.8966\n","\n","Epoch 00408: val_accuracy did not improve from 0.93103\n","Epoch 409/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4668 - val_accuracy: 0.9113\n","\n","Epoch 00409: val_accuracy did not improve from 0.93103\n","Epoch 410/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4778 - val_accuracy: 0.9015\n","\n","Epoch 00410: val_accuracy did not improve from 0.93103\n","Epoch 411/500\n","52/52 [==============================] - 12s 221ms/step - loss: 8.2445e-04 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9236\n","\n","Epoch 00411: val_accuracy did not improve from 0.93103\n","Epoch 412/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8892\n","\n","Epoch 00412: val_accuracy did not improve from 0.93103\n","Epoch 413/500\n","52/52 [==============================] - 12s 222ms/step - loss: 6.2557e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9089\n","\n","Epoch 00413: val_accuracy did not improve from 0.93103\n","Epoch 414/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.9113\n","\n","Epoch 00414: val_accuracy did not improve from 0.93103\n","Epoch 415/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5664 - val_accuracy: 0.9236\n","\n","Epoch 00415: val_accuracy did not improve from 0.93103\n","Epoch 416/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 0.6624 - val_accuracy: 0.8842\n","\n","Epoch 00416: val_accuracy did not improve from 0.93103\n","Epoch 417/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4802 - val_accuracy: 0.9015\n","\n","Epoch 00417: val_accuracy did not improve from 0.93103\n","Epoch 418/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5429 - val_accuracy: 0.8645\n","\n","Epoch 00418: val_accuracy did not improve from 0.93103\n","Epoch 419/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8892\n","\n","Epoch 00419: val_accuracy did not improve from 0.93103\n","Epoch 420/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5811 - val_accuracy: 0.8768\n","\n","Epoch 00420: val_accuracy did not improve from 0.93103\n","Epoch 421/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4267 - val_accuracy: 0.9089\n","\n","Epoch 00421: val_accuracy did not improve from 0.93103\n","Epoch 422/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4912 - val_accuracy: 0.8916\n","\n","Epoch 00422: val_accuracy did not improve from 0.93103\n","Epoch 423/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5606 - val_accuracy: 0.8768\n","\n","Epoch 00423: val_accuracy did not improve from 0.93103\n","Epoch 424/500\n","52/52 [==============================] - 12s 220ms/step - loss: 4.2350e-04 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8892\n","\n","Epoch 00424: val_accuracy did not improve from 0.93103\n","Epoch 425/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.3094e-04 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8990\n","\n","Epoch 00425: val_accuracy did not improve from 0.93103\n","Epoch 426/500\n","52/52 [==============================] - 12s 220ms/step - loss: 5.8798e-04 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9138\n","\n","Epoch 00426: val_accuracy did not improve from 0.93103\n","Epoch 427/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0626 - accuracy: 0.9823 - val_loss: 1.5505 - val_accuracy: 0.7931\n","\n","Epoch 00427: val_accuracy did not improve from 0.93103\n","Epoch 428/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0586 - accuracy: 0.9836 - val_loss: 1.7651 - val_accuracy: 0.6847\n","\n","Epoch 00428: val_accuracy did not improve from 0.93103\n","Epoch 429/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.9014 - val_accuracy: 0.8153\n","\n","Epoch 00429: val_accuracy did not improve from 0.93103\n","Epoch 430/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.6267 - val_accuracy: 0.8990\n","\n","Epoch 00430: val_accuracy did not improve from 0.93103\n","Epoch 431/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.8472 - val_accuracy: 0.8695\n","\n","Epoch 00431: val_accuracy did not improve from 0.93103\n","Epoch 432/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.7362 - val_accuracy: 0.8941\n","\n","Epoch 00432: val_accuracy did not improve from 0.93103\n","Epoch 433/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 3.4593 - val_accuracy: 0.6552\n","\n","Epoch 00433: val_accuracy did not improve from 0.93103\n","Epoch 434/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5824 - val_accuracy: 0.9089\n","\n","Epoch 00434: val_accuracy did not improve from 0.93103\n","Epoch 435/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5495 - val_accuracy: 0.8892\n","\n","Epoch 00435: val_accuracy did not improve from 0.93103\n","Epoch 436/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.93103\n","Epoch 437/500\n","52/52 [==============================] - 11s 220ms/step - loss: 7.1405e-04 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9089\n","\n","Epoch 00437: val_accuracy did not improve from 0.93103\n","Epoch 438/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.6160 - val_accuracy: 0.9138\n","\n","Epoch 00438: val_accuracy did not improve from 0.93103\n","Epoch 439/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4187 - val_accuracy: 0.9163\n","\n","Epoch 00439: val_accuracy did not improve from 0.93103\n","Epoch 440/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.3766e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9236\n","\n","Epoch 00440: val_accuracy did not improve from 0.93103\n","Epoch 441/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.9664e-04 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9138\n","\n","Epoch 00441: val_accuracy did not improve from 0.93103\n","Epoch 442/500\n","52/52 [==============================] - 12s 222ms/step - loss: 8.3869e-04 - accuracy: 0.9994 - val_loss: 0.4897 - val_accuracy: 0.9089\n","\n","Epoch 00442: val_accuracy did not improve from 0.93103\n","Epoch 443/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4530 - val_accuracy: 0.9113\n","\n","Epoch 00443: val_accuracy did not improve from 0.93103\n","Epoch 444/500\n","52/52 [==============================] - 12s 220ms/step - loss: 8.9450e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9064\n","\n","Epoch 00444: val_accuracy did not improve from 0.93103\n","Epoch 445/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.4910e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9064\n","\n","Epoch 00445: val_accuracy did not improve from 0.93103\n","Epoch 446/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.7071e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.93103\n","Epoch 447/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.5798e-04 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.9113\n","\n","Epoch 00447: val_accuracy did not improve from 0.93103\n","Epoch 448/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.2702e-04 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9064\n","\n","Epoch 00448: val_accuracy did not improve from 0.93103\n","Epoch 449/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.2518e-04 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9261\n","\n","Epoch 00449: val_accuracy did not improve from 0.93103\n","Epoch 450/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.7994e-04 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9064\n","\n","Epoch 00450: val_accuracy did not improve from 0.93103\n","Epoch 451/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.1966e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9212\n","\n","Epoch 00451: val_accuracy did not improve from 0.93103\n","Epoch 452/500\n","52/52 [==============================] - 12s 221ms/step - loss: 5.9591e-04 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9015\n","\n","Epoch 00452: val_accuracy did not improve from 0.93103\n","Epoch 453/500\n","52/52 [==============================] - 12s 222ms/step - loss: 1.7715e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9089\n","\n","Epoch 00453: val_accuracy did not improve from 0.93103\n","Epoch 454/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4877 - val_accuracy: 0.9015\n","\n","Epoch 00454: val_accuracy did not improve from 0.93103\n","Epoch 455/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.5635 - val_accuracy: 0.8916\n","\n","Epoch 00455: val_accuracy did not improve from 0.93103\n","Epoch 456/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.8399 - val_accuracy: 0.8030\n","\n","Epoch 00456: val_accuracy did not improve from 0.93103\n","Epoch 457/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 1.4008 - val_accuracy: 0.8251\n","\n","Epoch 00457: val_accuracy did not improve from 0.93103\n","Epoch 458/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 1.0231 - val_accuracy: 0.8300\n","\n","Epoch 00458: val_accuracy did not improve from 0.93103\n","Epoch 459/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 1.0771 - val_accuracy: 0.8399\n","\n","Epoch 00459: val_accuracy did not improve from 0.93103\n","Epoch 460/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.7168 - val_accuracy: 0.8571\n","\n","Epoch 00460: val_accuracy did not improve from 0.93103\n","Epoch 461/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6871 - val_accuracy: 0.8547\n","\n","Epoch 00461: val_accuracy did not improve from 0.93103\n","Epoch 462/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.6922 - val_accuracy: 0.8941\n","\n","Epoch 00462: val_accuracy did not improve from 0.93103\n","Epoch 463/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0399 - accuracy: 0.9836 - val_loss: 0.8078 - val_accuracy: 0.8202\n","\n","Epoch 00463: val_accuracy did not improve from 0.93103\n","Epoch 464/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0168 - accuracy: 0.9927 - val_loss: 0.5995 - val_accuracy: 0.8793\n","\n","Epoch 00464: val_accuracy did not improve from 0.93103\n","Epoch 465/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.6886 - val_accuracy: 0.8645\n","\n","Epoch 00465: val_accuracy did not improve from 0.93103\n","Epoch 466/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.7087 - val_accuracy: 0.8448\n","\n","Epoch 00466: val_accuracy did not improve from 0.93103\n","Epoch 467/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 1.7572 - val_accuracy: 0.6182\n","\n","Epoch 00467: val_accuracy did not improve from 0.93103\n","Epoch 468/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.7980\n","\n","Epoch 00468: val_accuracy did not improve from 0.93103\n","Epoch 469/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.8571\n","\n","Epoch 00469: val_accuracy did not improve from 0.93103\n","Epoch 470/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.5974 - val_accuracy: 0.8744\n","\n","Epoch 00470: val_accuracy did not improve from 0.93103\n","Epoch 471/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.7632 - val_accuracy: 0.8916\n","\n","Epoch 00471: val_accuracy did not improve from 0.93103\n","Epoch 472/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0162 - accuracy: 0.9921 - val_loss: 1.2796 - val_accuracy: 0.7709\n","\n","Epoch 00472: val_accuracy did not improve from 0.93103\n","Epoch 473/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.5523 - val_accuracy: 0.8867\n","\n","Epoch 00473: val_accuracy did not improve from 0.93103\n","Epoch 474/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5047 - val_accuracy: 0.8966\n","\n","Epoch 00474: val_accuracy did not improve from 0.93103\n","Epoch 475/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.6126 - val_accuracy: 0.9039\n","\n","Epoch 00475: val_accuracy did not improve from 0.93103\n","Epoch 476/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5352 - val_accuracy: 0.9015\n","\n","Epoch 00476: val_accuracy did not improve from 0.93103\n","Epoch 477/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5937 - val_accuracy: 0.8966\n","\n","Epoch 00477: val_accuracy did not improve from 0.93103\n","Epoch 478/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8941\n","\n","Epoch 00478: val_accuracy did not improve from 0.93103\n","Epoch 479/500\n","52/52 [==============================] - 12s 222ms/step - loss: 3.2131e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.8966\n","\n","Epoch 00479: val_accuracy did not improve from 0.93103\n","Epoch 480/500\n","52/52 [==============================] - 12s 221ms/step - loss: 4.6323e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.93103\n","Epoch 481/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9039\n","\n","Epoch 00481: val_accuracy did not improve from 0.93103\n","Epoch 482/500\n","52/52 [==============================] - 12s 223ms/step - loss: 5.4976e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9015\n","\n","Epoch 00482: val_accuracy did not improve from 0.93103\n","Epoch 483/500\n","52/52 [==============================] - 12s 221ms/step - loss: 3.6285e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9261\n","\n","Epoch 00483: val_accuracy did not improve from 0.93103\n","Epoch 484/500\n","52/52 [==============================] - 11s 220ms/step - loss: 3.8505e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9089\n","\n","Epoch 00484: val_accuracy did not improve from 0.93103\n","Epoch 485/500\n","52/52 [==============================] - 12s 221ms/step - loss: 1.1844e-04 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9113\n","\n","Epoch 00485: val_accuracy did not improve from 0.93103\n","Epoch 486/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9039\n","\n","Epoch 00486: val_accuracy did not improve from 0.93103\n","Epoch 487/500\n","52/52 [==============================] - 12s 222ms/step - loss: 2.5177e-04 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9015\n","\n","Epoch 00487: val_accuracy did not improve from 0.93103\n","Epoch 488/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.5670 - val_accuracy: 0.8941\n","\n","Epoch 00488: val_accuracy did not improve from 0.93103\n","Epoch 489/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.5352 - val_accuracy: 0.8867\n","\n","Epoch 00489: val_accuracy did not improve from 0.93103\n","Epoch 490/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.6814 - val_accuracy: 0.8522\n","\n","Epoch 00490: val_accuracy did not improve from 0.93103\n","Epoch 491/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.7556 - val_accuracy: 0.7808\n","\n","Epoch 00491: val_accuracy did not improve from 0.93103\n","Epoch 492/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.7649 - val_accuracy: 0.8030\n","\n","Epoch 00492: val_accuracy did not improve from 0.93103\n","Epoch 493/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.8687 - val_accuracy: 0.8596\n","\n","Epoch 00493: val_accuracy did not improve from 0.93103\n","Epoch 494/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.6686 - val_accuracy: 0.8473\n","\n","Epoch 00494: val_accuracy did not improve from 0.93103\n","Epoch 495/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.6923 - val_accuracy: 0.8793\n","\n","Epoch 00495: val_accuracy did not improve from 0.93103\n","Epoch 496/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5848 - val_accuracy: 0.8645\n","\n","Epoch 00496: val_accuracy did not improve from 0.93103\n","Epoch 497/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6560 - val_accuracy: 0.8966\n","\n","Epoch 00497: val_accuracy did not improve from 0.93103\n","Epoch 498/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.3342e-04 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.9039\n","\n","Epoch 00498: val_accuracy did not improve from 0.93103\n","Epoch 499/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.0190e-04 - accuracy: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.8966\n","\n","Epoch 00499: val_accuracy did not improve from 0.93103\n","Epoch 500/500\n","52/52 [==============================] - 12s 221ms/step - loss: 2.9473e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9039\n","\n","Epoch 00500: val_accuracy did not improve from 0.93103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8bd4441ad0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629737460744,"user_tz":-540,"elapsed":40,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6fc9d4e9-e2dc-4e8b-9d0a-f11938c34c50"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629737475662,"user_tz":-540,"elapsed":14946,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_1_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629737476083,"user_tz":-540,"elapsed":430,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629737476823,"user_tz":-540,"elapsed":758,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8f909708-44b6-466b-9097-5d300e92c576"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629737507488,"user_tz":-540,"elapsed":30672,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e2bcb6b4-386d-4879-8961-12da48646bb3"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629737507489,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629737507492,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629737508663,"user_tz":-540,"elapsed":1190,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629737508664,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629737519882,"user_tz":-540,"elapsed":11223,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629737519883,"user_tz":-540,"elapsed":22,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"a31e60a1-d4b1-4f54-b6b0-e067551504df"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629737519884,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1af67a5e-6bc3-4ed7-c41c-f2239e760648"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.200_1_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.200_1_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_c2b519e8-e15b-4c0e-a109-bfb57b530b5f\", \"Validation_split_0.200_1_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}