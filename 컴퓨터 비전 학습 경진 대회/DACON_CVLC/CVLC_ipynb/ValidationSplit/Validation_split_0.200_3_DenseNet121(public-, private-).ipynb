{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Validation_split_0.200_3_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyM03oLdjZCBXPjJ8UB3Zta+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629774179565,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"24953ec5-8c8c-452b-9847-855634e5bf91"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Aug 24 03:02:59 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629774196375,"user_tz":-540,"elapsed":16815,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"109bd4ab-1c07-45cb-a4e1-37b09cdbac18"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1629774199484,"user_tz":-540,"elapsed":3113,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1629774200600,"user_tz":-540,"elapsed":1120,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1629774203076,"user_tz":-540,"elapsed":2480,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1629774220460,"user_tz":-540,"elapsed":17387,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1629774227735,"user_tz":-540,"elapsed":7278,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629774227736,"user_tz":-540,"elapsed":13,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"37cb995c-7507-4090-faba-bcd92bb3815a"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629774228134,"user_tz":-540,"elapsed":403,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f3891948-f6ef-428b-92dc-824a61fbd831"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1629774228135,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629780895826,"user_tz":-540,"elapsed":6667701,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"cbc55a68-5982-4898-e9a7-fc73d5c0c8a3"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/500\n","52/52 [==============================] - 40s 280ms/step - loss: 1.8827 - accuracy: 0.3410 - val_loss: 21.8703 - val_accuracy: 0.0936\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 12s 223ms/step - loss: 1.2724 - accuracy: 0.5676 - val_loss: 45.3606 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy improved from 0.09360 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.9376 - accuracy: 0.6821 - val_loss: 20.6178 - val_accuracy: 0.1010\n","\n","Epoch 00003: val_accuracy did not improve from 0.10099\n","Epoch 4/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.7609 - accuracy: 0.7546 - val_loss: 17.2252 - val_accuracy: 0.1502\n","\n","Epoch 00004: val_accuracy improved from 0.10099 to 0.15025, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 5/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.7068 - accuracy: 0.7588 - val_loss: 12.8172 - val_accuracy: 0.1207\n","\n","Epoch 00005: val_accuracy did not improve from 0.15025\n","Epoch 6/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.6075 - accuracy: 0.7996 - val_loss: 8.4535 - val_accuracy: 0.1650\n","\n","Epoch 00006: val_accuracy improved from 0.15025 to 0.16502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.5229 - accuracy: 0.8210 - val_loss: 4.4793 - val_accuracy: 0.3202\n","\n","Epoch 00007: val_accuracy improved from 0.16502 to 0.32020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.5596 - accuracy: 0.8118 - val_loss: 4.4552 - val_accuracy: 0.3227\n","\n","Epoch 00008: val_accuracy improved from 0.32020 to 0.32266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.4645 - accuracy: 0.8386 - val_loss: 1.9821 - val_accuracy: 0.5246\n","\n","Epoch 00009: val_accuracy improved from 0.32266 to 0.52463, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.4086 - accuracy: 0.8587 - val_loss: 1.3962 - val_accuracy: 0.6823\n","\n","Epoch 00010: val_accuracy improved from 0.52463 to 0.68227, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.4220 - accuracy: 0.8605 - val_loss: 1.4029 - val_accuracy: 0.7094\n","\n","Epoch 00011: val_accuracy improved from 0.68227 to 0.70936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 12/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.3650 - accuracy: 0.8788 - val_loss: 0.7768 - val_accuracy: 0.7635\n","\n","Epoch 00012: val_accuracy improved from 0.70936 to 0.76355, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 13/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.3938 - accuracy: 0.8654 - val_loss: 0.7701 - val_accuracy: 0.8005\n","\n","Epoch 00013: val_accuracy improved from 0.76355 to 0.80049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.3368 - accuracy: 0.8855 - val_loss: 1.1940 - val_accuracy: 0.6724\n","\n","Epoch 00014: val_accuracy did not improve from 0.80049\n","Epoch 15/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.3517 - accuracy: 0.8764 - val_loss: 0.8614 - val_accuracy: 0.7611\n","\n","Epoch 00015: val_accuracy did not improve from 0.80049\n","Epoch 16/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2953 - accuracy: 0.8971 - val_loss: 0.8602 - val_accuracy: 0.7488\n","\n","Epoch 00016: val_accuracy did not improve from 0.80049\n","Epoch 17/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2562 - accuracy: 0.9129 - val_loss: 0.5555 - val_accuracy: 0.8325\n","\n","Epoch 00017: val_accuracy improved from 0.80049 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 18/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.2998 - accuracy: 0.8886 - val_loss: 0.8830 - val_accuracy: 0.7537\n","\n","Epoch 00018: val_accuracy did not improve from 0.83251\n","Epoch 19/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2926 - accuracy: 0.9007 - val_loss: 0.6036 - val_accuracy: 0.8251\n","\n","Epoch 00019: val_accuracy did not improve from 0.83251\n","Epoch 20/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.2401 - accuracy: 0.9184 - val_loss: 3.3222 - val_accuracy: 0.4483\n","\n","Epoch 00020: val_accuracy did not improve from 0.83251\n","Epoch 21/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2700 - accuracy: 0.9044 - val_loss: 1.0018 - val_accuracy: 0.7488\n","\n","Epoch 00021: val_accuracy did not improve from 0.83251\n","Epoch 22/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2039 - accuracy: 0.9379 - val_loss: 0.5047 - val_accuracy: 0.8424\n","\n","Epoch 00022: val_accuracy improved from 0.83251 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 23/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2430 - accuracy: 0.9172 - val_loss: 0.4974 - val_accuracy: 0.8448\n","\n","Epoch 00023: val_accuracy improved from 0.84236 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 24/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.1770 - accuracy: 0.9379 - val_loss: 0.5059 - val_accuracy: 0.8522\n","\n","Epoch 00024: val_accuracy improved from 0.84483 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 25/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.2059 - accuracy: 0.9312 - val_loss: 1.4667 - val_accuracy: 0.6601\n","\n","Epoch 00025: val_accuracy did not improve from 0.85222\n","Epoch 26/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2131 - accuracy: 0.9354 - val_loss: 0.5154 - val_accuracy: 0.8596\n","\n","Epoch 00026: val_accuracy improved from 0.85222 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1760 - accuracy: 0.9458 - val_loss: 0.6493 - val_accuracy: 0.8276\n","\n","Epoch 00027: val_accuracy did not improve from 0.85961\n","Epoch 28/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1326 - accuracy: 0.9525 - val_loss: 0.7711 - val_accuracy: 0.8128\n","\n","Epoch 00028: val_accuracy did not improve from 0.85961\n","Epoch 29/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1657 - accuracy: 0.9446 - val_loss: 0.6669 - val_accuracy: 0.8079\n","\n","Epoch 00029: val_accuracy did not improve from 0.85961\n","Epoch 30/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1674 - accuracy: 0.9458 - val_loss: 0.6583 - val_accuracy: 0.8325\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1473 - accuracy: 0.9470 - val_loss: 0.6607 - val_accuracy: 0.8227\n","\n","Epoch 00031: val_accuracy did not improve from 0.85961\n","Epoch 32/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1159 - accuracy: 0.9647 - val_loss: 0.5440 - val_accuracy: 0.8498\n","\n","Epoch 00032: val_accuracy did not improve from 0.85961\n","Epoch 33/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1653 - accuracy: 0.9464 - val_loss: 0.7247 - val_accuracy: 0.8054\n","\n","Epoch 00033: val_accuracy did not improve from 0.85961\n","Epoch 34/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1327 - accuracy: 0.9531 - val_loss: 0.4174 - val_accuracy: 0.8916\n","\n","Epoch 00034: val_accuracy improved from 0.85961 to 0.89163, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 35/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 0.4133 - val_accuracy: 0.8670\n","\n","Epoch 00035: val_accuracy did not improve from 0.89163\n","Epoch 36/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 0.4596 - val_accuracy: 0.8818\n","\n","Epoch 00036: val_accuracy did not improve from 0.89163\n","Epoch 37/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0927 - accuracy: 0.9708 - val_loss: 0.5762 - val_accuracy: 0.8448\n","\n","Epoch 00037: val_accuracy did not improve from 0.89163\n","Epoch 38/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1093 - accuracy: 0.9622 - val_loss: 0.5333 - val_accuracy: 0.8596\n","\n","Epoch 00038: val_accuracy did not improve from 0.89163\n","Epoch 39/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.2266 - accuracy: 0.9184 - val_loss: 0.8364 - val_accuracy: 0.8079\n","\n","Epoch 00039: val_accuracy did not improve from 0.89163\n","Epoch 40/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1288 - accuracy: 0.9519 - val_loss: 0.6077 - val_accuracy: 0.8424\n","\n","Epoch 00040: val_accuracy did not improve from 0.89163\n","Epoch 41/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1030 - accuracy: 0.9695 - val_loss: 0.5875 - val_accuracy: 0.8645\n","\n","Epoch 00041: val_accuracy did not improve from 0.89163\n","Epoch 42/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.1298 - accuracy: 0.9598 - val_loss: 0.5751 - val_accuracy: 0.8473\n","\n","Epoch 00042: val_accuracy did not improve from 0.89163\n","Epoch 43/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0785 - accuracy: 0.9756 - val_loss: 0.6788 - val_accuracy: 0.8325\n","\n","Epoch 00043: val_accuracy did not improve from 0.89163\n","Epoch 44/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.4163 - val_accuracy: 0.8818\n","\n","Epoch 00044: val_accuracy did not improve from 0.89163\n","Epoch 45/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0986 - accuracy: 0.9708 - val_loss: 0.8007 - val_accuracy: 0.8276\n","\n","Epoch 00045: val_accuracy did not improve from 0.89163\n","Epoch 46/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1092 - accuracy: 0.9604 - val_loss: 0.7792 - val_accuracy: 0.8128\n","\n","Epoch 00046: val_accuracy did not improve from 0.89163\n","Epoch 47/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1176 - accuracy: 0.9683 - val_loss: 0.7241 - val_accuracy: 0.8128\n","\n","Epoch 00047: val_accuracy did not improve from 0.89163\n","Epoch 48/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0732 - accuracy: 0.9744 - val_loss: 0.4375 - val_accuracy: 0.8842\n","\n","Epoch 00048: val_accuracy did not improve from 0.89163\n","Epoch 49/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0649 - accuracy: 0.9787 - val_loss: 0.4207 - val_accuracy: 0.8867\n","\n","Epoch 00049: val_accuracy did not improve from 0.89163\n","Epoch 50/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0601 - accuracy: 0.9781 - val_loss: 0.6965 - val_accuracy: 0.8473\n","\n","Epoch 00050: val_accuracy did not improve from 0.89163\n","Epoch 51/500\n","52/52 [==============================] - 11s 217ms/step - loss: 0.1101 - accuracy: 0.9604 - val_loss: 0.5071 - val_accuracy: 0.8793\n","\n","Epoch 00051: val_accuracy did not improve from 0.89163\n","Epoch 52/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0987 - accuracy: 0.9695 - val_loss: 0.4981 - val_accuracy: 0.8768\n","\n","Epoch 00052: val_accuracy did not improve from 0.89163\n","Epoch 53/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0778 - accuracy: 0.9775 - val_loss: 0.5498 - val_accuracy: 0.8645\n","\n","Epoch 00053: val_accuracy did not improve from 0.89163\n","Epoch 54/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0749 - accuracy: 0.9756 - val_loss: 0.6549 - val_accuracy: 0.8645\n","\n","Epoch 00054: val_accuracy did not improve from 0.89163\n","Epoch 55/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0892 - accuracy: 0.9726 - val_loss: 0.5478 - val_accuracy: 0.8818\n","\n","Epoch 00055: val_accuracy did not improve from 0.89163\n","Epoch 56/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 0.5867 - val_accuracy: 0.8645\n","\n","Epoch 00056: val_accuracy did not improve from 0.89163\n","Epoch 57/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 0.4783 - val_accuracy: 0.8941\n","\n","Epoch 00057: val_accuracy improved from 0.89163 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 58/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 1.7325 - val_accuracy: 0.7438\n","\n","Epoch 00058: val_accuracy did not improve from 0.89409\n","Epoch 59/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0611 - accuracy: 0.9775 - val_loss: 0.7506 - val_accuracy: 0.8522\n","\n","Epoch 00059: val_accuracy did not improve from 0.89409\n","Epoch 60/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0485 - accuracy: 0.9848 - val_loss: 0.4698 - val_accuracy: 0.8941\n","\n","Epoch 00060: val_accuracy did not improve from 0.89409\n","Epoch 61/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0745 - accuracy: 0.9738 - val_loss: 0.6977 - val_accuracy: 0.8596\n","\n","Epoch 00061: val_accuracy did not improve from 0.89409\n","Epoch 62/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0993 - accuracy: 0.9641 - val_loss: 1.1501 - val_accuracy: 0.7685\n","\n","Epoch 00062: val_accuracy did not improve from 0.89409\n","Epoch 63/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1440 - accuracy: 0.9501 - val_loss: 0.7131 - val_accuracy: 0.8448\n","\n","Epoch 00063: val_accuracy did not improve from 0.89409\n","Epoch 64/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0917 - accuracy: 0.9702 - val_loss: 0.5637 - val_accuracy: 0.8670\n","\n","Epoch 00064: val_accuracy did not improve from 0.89409\n","Epoch 65/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.4495 - val_accuracy: 0.8966\n","\n","Epoch 00065: val_accuracy improved from 0.89409 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 66/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.5986 - val_accuracy: 0.8719\n","\n","Epoch 00066: val_accuracy did not improve from 0.89655\n","Epoch 67/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0445 - accuracy: 0.9836 - val_loss: 0.9174 - val_accuracy: 0.8030\n","\n","Epoch 00067: val_accuracy did not improve from 0.89655\n","Epoch 68/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.3780 - val_accuracy: 0.8941\n","\n","Epoch 00068: val_accuracy did not improve from 0.89655\n","Epoch 69/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.6540 - val_accuracy: 0.8596\n","\n","Epoch 00069: val_accuracy did not improve from 0.89655\n","Epoch 70/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0778 - accuracy: 0.9744 - val_loss: 0.9170 - val_accuracy: 0.8079\n","\n","Epoch 00070: val_accuracy did not improve from 0.89655\n","Epoch 71/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0484 - accuracy: 0.9872 - val_loss: 0.7540 - val_accuracy: 0.8448\n","\n","Epoch 00071: val_accuracy did not improve from 0.89655\n","Epoch 72/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 0.7042 - val_accuracy: 0.8571\n","\n","Epoch 00072: val_accuracy did not improve from 0.89655\n","Epoch 73/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.5248 - val_accuracy: 0.8966\n","\n","Epoch 00073: val_accuracy did not improve from 0.89655\n","Epoch 74/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.3541 - val_accuracy: 0.9187\n","\n","Epoch 00074: val_accuracy improved from 0.89655 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.7807 - val_accuracy: 0.7709\n","\n","Epoch 00075: val_accuracy did not improve from 0.91872\n","Epoch 76/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0699 - accuracy: 0.9750 - val_loss: 0.6969 - val_accuracy: 0.8424\n","\n","Epoch 00076: val_accuracy did not improve from 0.91872\n","Epoch 77/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 0.7204 - val_accuracy: 0.8399\n","\n","Epoch 00077: val_accuracy did not improve from 0.91872\n","Epoch 78/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.1055 - accuracy: 0.9641 - val_loss: 0.9852 - val_accuracy: 0.8227\n","\n","Epoch 00078: val_accuracy did not improve from 0.91872\n","Epoch 79/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0627 - accuracy: 0.9756 - val_loss: 0.6381 - val_accuracy: 0.8522\n","\n","Epoch 00079: val_accuracy did not improve from 0.91872\n","Epoch 80/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.4395 - val_accuracy: 0.8941\n","\n","Epoch 00080: val_accuracy did not improve from 0.91872\n","Epoch 81/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 0.6487 - val_accuracy: 0.8645\n","\n","Epoch 00081: val_accuracy did not improve from 0.91872\n","Epoch 82/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.5101 - val_accuracy: 0.8719\n","\n","Epoch 00082: val_accuracy did not improve from 0.91872\n","Epoch 83/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.5116 - val_accuracy: 0.8793\n","\n","Epoch 00083: val_accuracy did not improve from 0.91872\n","Epoch 84/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.5547 - val_accuracy: 0.8670\n","\n","Epoch 00084: val_accuracy did not improve from 0.91872\n","Epoch 85/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0873 - accuracy: 0.9720 - val_loss: 0.9188 - val_accuracy: 0.7857\n","\n","Epoch 00085: val_accuracy did not improve from 0.91872\n","Epoch 86/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.2146 - accuracy: 0.9379 - val_loss: 0.8143 - val_accuracy: 0.8424\n","\n","Epoch 00086: val_accuracy did not improve from 0.91872\n","Epoch 87/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1000 - accuracy: 0.9689 - val_loss: 0.4738 - val_accuracy: 0.8793\n","\n","Epoch 00087: val_accuracy did not improve from 0.91872\n","Epoch 88/500\n","52/52 [==============================] - 12s 219ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 0.3836 - val_accuracy: 0.8916\n","\n","Epoch 00088: val_accuracy did not improve from 0.91872\n","Epoch 89/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.3128 - val_accuracy: 0.9187\n","\n","Epoch 00089: val_accuracy did not improve from 0.91872\n","Epoch 90/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.3784 - val_accuracy: 0.8966\n","\n","Epoch 00090: val_accuracy did not improve from 0.91872\n","Epoch 91/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.3526 - val_accuracy: 0.9064\n","\n","Epoch 00091: val_accuracy did not improve from 0.91872\n","Epoch 92/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.4078 - val_accuracy: 0.9039\n","\n","Epoch 00092: val_accuracy did not improve from 0.91872\n","Epoch 93/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 1.6342 - val_accuracy: 0.7167\n","\n","Epoch 00093: val_accuracy did not improve from 0.91872\n","Epoch 94/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1126 - accuracy: 0.9592 - val_loss: 0.9306 - val_accuracy: 0.8300\n","\n","Epoch 00094: val_accuracy did not improve from 0.91872\n","Epoch 95/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0590 - accuracy: 0.9775 - val_loss: 0.5203 - val_accuracy: 0.8916\n","\n","Epoch 00095: val_accuracy did not improve from 0.91872\n","Epoch 96/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0572 - accuracy: 0.9848 - val_loss: 0.6385 - val_accuracy: 0.8719\n","\n","Epoch 00096: val_accuracy did not improve from 0.91872\n","Epoch 97/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.6620 - val_accuracy: 0.8547\n","\n","Epoch 00097: val_accuracy did not improve from 0.91872\n","Epoch 98/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.3899 - val_accuracy: 0.8941\n","\n","Epoch 00098: val_accuracy did not improve from 0.91872\n","Epoch 99/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0213 - accuracy: 0.9921 - val_loss: 0.4411 - val_accuracy: 0.8744\n","\n","Epoch 00099: val_accuracy did not improve from 0.91872\n","Epoch 100/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.3379 - val_accuracy: 0.8966\n","\n","Epoch 00100: val_accuracy did not improve from 0.91872\n","Epoch 101/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.3284 - val_accuracy: 0.9163\n","\n","Epoch 00101: val_accuracy did not improve from 0.91872\n","Epoch 102/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.5991 - val_accuracy: 0.8867\n","\n","Epoch 00102: val_accuracy did not improve from 0.91872\n","Epoch 103/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.4723 - val_accuracy: 0.8892\n","\n","Epoch 00103: val_accuracy did not improve from 0.91872\n","Epoch 104/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.7659 - val_accuracy: 0.8695\n","\n","Epoch 00104: val_accuracy did not improve from 0.91872\n","Epoch 105/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.4542 - val_accuracy: 0.8892\n","\n","Epoch 00105: val_accuracy did not improve from 0.91872\n","Epoch 106/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 1.2836 - val_accuracy: 0.7488\n","\n","Epoch 00106: val_accuracy did not improve from 0.91872\n","Epoch 107/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0388 - accuracy: 0.9848 - val_loss: 0.5113 - val_accuracy: 0.8768\n","\n","Epoch 00107: val_accuracy did not improve from 0.91872\n","Epoch 108/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.6473 - val_accuracy: 0.8768\n","\n","Epoch 00108: val_accuracy did not improve from 0.91872\n","Epoch 109/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.5411 - val_accuracy: 0.8670\n","\n","Epoch 00109: val_accuracy did not improve from 0.91872\n","Epoch 110/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.5191 - val_accuracy: 0.8867\n","\n","Epoch 00110: val_accuracy did not improve from 0.91872\n","Epoch 111/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.4859 - val_accuracy: 0.8645\n","\n","Epoch 00111: val_accuracy did not improve from 0.91872\n","Epoch 112/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 1.0118 - val_accuracy: 0.8177\n","\n","Epoch 00112: val_accuracy did not improve from 0.91872\n","Epoch 113/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.4508 - val_accuracy: 0.8818\n","\n","Epoch 00113: val_accuracy did not improve from 0.91872\n","Epoch 114/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.9827 - val_accuracy: 0.8276\n","\n","Epoch 00114: val_accuracy did not improve from 0.91872\n","Epoch 115/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.5521 - val_accuracy: 0.8818\n","\n","Epoch 00115: val_accuracy did not improve from 0.91872\n","Epoch 116/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.6636 - val_accuracy: 0.8793\n","\n","Epoch 00116: val_accuracy did not improve from 0.91872\n","Epoch 117/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.7342 - val_accuracy: 0.8227\n","\n","Epoch 00117: val_accuracy did not improve from 0.91872\n","Epoch 118/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0419 - accuracy: 0.9854 - val_loss: 0.6731 - val_accuracy: 0.8621\n","\n","Epoch 00118: val_accuracy did not improve from 0.91872\n","Epoch 119/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0513 - accuracy: 0.9805 - val_loss: 0.6621 - val_accuracy: 0.8596\n","\n","Epoch 00119: val_accuracy did not improve from 0.91872\n","Epoch 120/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.6418 - val_accuracy: 0.8744\n","\n","Epoch 00120: val_accuracy did not improve from 0.91872\n","Epoch 121/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0473 - accuracy: 0.9829 - val_loss: 1.5891 - val_accuracy: 0.6995\n","\n","Epoch 00121: val_accuracy did not improve from 0.91872\n","Epoch 122/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0944 - accuracy: 0.9702 - val_loss: 0.7582 - val_accuracy: 0.8448\n","\n","Epoch 00122: val_accuracy did not improve from 0.91872\n","Epoch 123/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0784 - accuracy: 0.9769 - val_loss: 0.6742 - val_accuracy: 0.8448\n","\n","Epoch 00123: val_accuracy did not improve from 0.91872\n","Epoch 124/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 0.9827 - val_accuracy: 0.8350\n","\n","Epoch 00124: val_accuracy did not improve from 0.91872\n","Epoch 125/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.4679 - val_accuracy: 0.8867\n","\n","Epoch 00125: val_accuracy did not improve from 0.91872\n","Epoch 126/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.5391 - val_accuracy: 0.8670\n","\n","Epoch 00126: val_accuracy did not improve from 0.91872\n","Epoch 127/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.5704 - val_accuracy: 0.8670\n","\n","Epoch 00127: val_accuracy did not improve from 0.91872\n","Epoch 128/500\n","52/52 [==============================] - 11s 221ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5982 - val_accuracy: 0.8719\n","\n","Epoch 00128: val_accuracy did not improve from 0.91872\n","Epoch 129/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.6221 - val_accuracy: 0.8670\n","\n","Epoch 00129: val_accuracy did not improve from 0.91872\n","Epoch 130/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.3793 - val_accuracy: 0.8990\n","\n","Epoch 00130: val_accuracy did not improve from 0.91872\n","Epoch 131/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.3431 - val_accuracy: 0.9212\n","\n","Epoch 00131: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 132/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.3902 - val_accuracy: 0.9039\n","\n","Epoch 00132: val_accuracy did not improve from 0.92118\n","Epoch 133/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0130 - accuracy: 0.9939 - val_loss: 0.4250 - val_accuracy: 0.8941\n","\n","Epoch 00133: val_accuracy did not improve from 0.92118\n","Epoch 134/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.7144 - val_accuracy: 0.8202\n","\n","Epoch 00134: val_accuracy did not improve from 0.92118\n","Epoch 135/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.8195 - val_accuracy: 0.8325\n","\n","Epoch 00135: val_accuracy did not improve from 0.92118\n","Epoch 136/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0386 - accuracy: 0.9872 - val_loss: 0.6113 - val_accuracy: 0.8818\n","\n","Epoch 00136: val_accuracy did not improve from 0.92118\n","Epoch 137/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.6155 - val_accuracy: 0.8596\n","\n","Epoch 00137: val_accuracy did not improve from 0.92118\n","Epoch 138/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0367 - accuracy: 0.9842 - val_loss: 0.5464 - val_accuracy: 0.8842\n","\n","Epoch 00138: val_accuracy did not improve from 0.92118\n","Epoch 139/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.7159 - val_accuracy: 0.8522\n","\n","Epoch 00139: val_accuracy did not improve from 0.92118\n","Epoch 140/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0492 - accuracy: 0.9829 - val_loss: 0.6547 - val_accuracy: 0.8670\n","\n","Epoch 00140: val_accuracy did not improve from 0.92118\n","Epoch 141/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0513 - accuracy: 0.9793 - val_loss: 0.7977 - val_accuracy: 0.8473\n","\n","Epoch 00141: val_accuracy did not improve from 0.92118\n","Epoch 142/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.5734 - val_accuracy: 0.8867\n","\n","Epoch 00142: val_accuracy did not improve from 0.92118\n","Epoch 143/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.6531 - val_accuracy: 0.8695\n","\n","Epoch 00143: val_accuracy did not improve from 0.92118\n","Epoch 144/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.1190 - accuracy: 0.9629 - val_loss: 3.4104 - val_accuracy: 0.6182\n","\n","Epoch 00144: val_accuracy did not improve from 0.92118\n","Epoch 145/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.5227 - val_accuracy: 0.8867\n","\n","Epoch 00145: val_accuracy did not improve from 0.92118\n","Epoch 146/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.9822 - val_accuracy: 0.8251\n","\n","Epoch 00146: val_accuracy did not improve from 0.92118\n","Epoch 147/500\n","52/52 [==============================] - 11s 218ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.3509 - val_accuracy: 0.9212\n","\n","Epoch 00147: val_accuracy did not improve from 0.92118\n","Epoch 148/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.3655 - val_accuracy: 0.9212\n","\n","Epoch 00148: val_accuracy did not improve from 0.92118\n","Epoch 149/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.3456 - val_accuracy: 0.9163\n","\n","Epoch 00149: val_accuracy did not improve from 0.92118\n","Epoch 150/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.3536 - val_accuracy: 0.9212\n","\n","Epoch 00150: val_accuracy did not improve from 0.92118\n","Epoch 151/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.3561 - val_accuracy: 0.9261\n","\n","Epoch 00151: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 152/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.3864 - val_accuracy: 0.9187\n","\n","Epoch 00152: val_accuracy did not improve from 0.92611\n","Epoch 153/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.3648 - val_accuracy: 0.9212\n","\n","Epoch 00153: val_accuracy did not improve from 0.92611\n","Epoch 154/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.3144 - val_accuracy: 0.9163\n","\n","Epoch 00154: val_accuracy did not improve from 0.92611\n","Epoch 155/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9163\n","\n","Epoch 00155: val_accuracy did not improve from 0.92611\n","Epoch 156/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3585 - val_accuracy: 0.9138\n","\n","Epoch 00156: val_accuracy did not improve from 0.92611\n","Epoch 157/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9212\n","\n","Epoch 00157: val_accuracy did not improve from 0.92611\n","Epoch 158/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.3874 - val_accuracy: 0.9089\n","\n","Epoch 00158: val_accuracy did not improve from 0.92611\n","Epoch 159/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.7153 - val_accuracy: 0.8744\n","\n","Epoch 00159: val_accuracy did not improve from 0.92611\n","Epoch 160/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.4544 - val_accuracy: 0.9113\n","\n","Epoch 00160: val_accuracy did not improve from 0.92611\n","Epoch 161/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.7309 - val_accuracy: 0.8670\n","\n","Epoch 00161: val_accuracy did not improve from 0.92611\n","Epoch 162/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5190 - val_accuracy: 0.8892\n","\n","Epoch 00162: val_accuracy did not improve from 0.92611\n","Epoch 163/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4219 - val_accuracy: 0.9089\n","\n","Epoch 00163: val_accuracy did not improve from 0.92611\n","Epoch 164/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5988 - val_accuracy: 0.8892\n","\n","Epoch 00164: val_accuracy did not improve from 0.92611\n","Epoch 165/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.5356 - val_accuracy: 0.9015\n","\n","Epoch 00165: val_accuracy did not improve from 0.92611\n","Epoch 166/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.6477 - val_accuracy: 0.8768\n","\n","Epoch 00166: val_accuracy did not improve from 0.92611\n","Epoch 167/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 1.2842 - val_accuracy: 0.7365\n","\n","Epoch 00167: val_accuracy did not improve from 0.92611\n","Epoch 168/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.9360 - val_accuracy: 0.8374\n","\n","Epoch 00168: val_accuracy did not improve from 0.92611\n","Epoch 169/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 2.1798 - val_accuracy: 0.5764\n","\n","Epoch 00169: val_accuracy did not improve from 0.92611\n","Epoch 170/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.7569 - val_accuracy: 0.8153\n","\n","Epoch 00170: val_accuracy did not improve from 0.92611\n","Epoch 171/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0790 - accuracy: 0.9793 - val_loss: 0.7606 - val_accuracy: 0.8473\n","\n","Epoch 00171: val_accuracy did not improve from 0.92611\n","Epoch 172/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0383 - accuracy: 0.9903 - val_loss: 0.8215 - val_accuracy: 0.8473\n","\n","Epoch 00172: val_accuracy did not improve from 0.92611\n","Epoch 173/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0377 - accuracy: 0.9903 - val_loss: 0.5151 - val_accuracy: 0.8916\n","\n","Epoch 00173: val_accuracy did not improve from 0.92611\n","Epoch 174/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.6021 - val_accuracy: 0.8916\n","\n","Epoch 00174: val_accuracy did not improve from 0.92611\n","Epoch 175/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.5756 - val_accuracy: 0.8892\n","\n","Epoch 00175: val_accuracy did not improve from 0.92611\n","Epoch 176/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 2.1447 - val_accuracy: 0.5714\n","\n","Epoch 00176: val_accuracy did not improve from 0.92611\n","Epoch 177/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.1081 - accuracy: 0.9671 - val_loss: 1.9344 - val_accuracy: 0.6798\n","\n","Epoch 00177: val_accuracy did not improve from 0.92611\n","Epoch 178/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.8573 - val_accuracy: 0.8448\n","\n","Epoch 00178: val_accuracy did not improve from 0.92611\n","Epoch 179/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 0.4624 - val_accuracy: 0.9089\n","\n","Epoch 00179: val_accuracy did not improve from 0.92611\n","Epoch 180/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.4548 - val_accuracy: 0.8916\n","\n","Epoch 00180: val_accuracy did not improve from 0.92611\n","Epoch 181/500\n","52/52 [==============================] - 11s 220ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.4093 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.92611\n","Epoch 182/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.5105 - val_accuracy: 0.8818\n","\n","Epoch 00182: val_accuracy did not improve from 0.92611\n","Epoch 183/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4497 - val_accuracy: 0.8867\n","\n","Epoch 00183: val_accuracy did not improve from 0.92611\n","Epoch 184/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8842\n","\n","Epoch 00184: val_accuracy did not improve from 0.92611\n","Epoch 185/500\n","52/52 [==============================] - 11s 219ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3715 - val_accuracy: 0.9138\n","\n","Epoch 00185: val_accuracy did not improve from 0.92611\n","Epoch 186/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3894 - val_accuracy: 0.9212\n","\n","Epoch 00186: val_accuracy did not improve from 0.92611\n","Epoch 187/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0474 - accuracy: 0.9909 - val_loss: 4.4864 - val_accuracy: 0.4187\n","\n","Epoch 00187: val_accuracy did not improve from 0.92611\n","Epoch 188/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.1144 - accuracy: 0.9641 - val_loss: 2.5699 - val_accuracy: 0.5837\n","\n","Epoch 00188: val_accuracy did not improve from 0.92611\n","Epoch 189/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.6236 - val_accuracy: 0.8374\n","\n","Epoch 00189: val_accuracy did not improve from 0.92611\n","Epoch 190/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.5245 - val_accuracy: 0.8818\n","\n","Epoch 00190: val_accuracy did not improve from 0.92611\n","Epoch 191/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.6235 - val_accuracy: 0.8596\n","\n","Epoch 00191: val_accuracy did not improve from 0.92611\n","Epoch 192/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.5215 - val_accuracy: 0.8744\n","\n","Epoch 00192: val_accuracy did not improve from 0.92611\n","Epoch 193/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5267 - val_accuracy: 0.9039\n","\n","Epoch 00193: val_accuracy did not improve from 0.92611\n","Epoch 194/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4155 - val_accuracy: 0.8990\n","\n","Epoch 00194: val_accuracy did not improve from 0.92611\n","Epoch 195/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4346 - val_accuracy: 0.9138\n","\n","Epoch 00195: val_accuracy did not improve from 0.92611\n","Epoch 196/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.3840 - val_accuracy: 0.9187\n","\n","Epoch 00196: val_accuracy did not improve from 0.92611\n","Epoch 197/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.6669e-04 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9113\n","\n","Epoch 00197: val_accuracy did not improve from 0.92611\n","Epoch 198/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9138\n","\n","Epoch 00198: val_accuracy did not improve from 0.92611\n","Epoch 199/500\n","52/52 [==============================] - 12s 223ms/step - loss: 6.4383e-04 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9163\n","\n","Epoch 00199: val_accuracy did not improve from 0.92611\n","Epoch 200/500\n","52/52 [==============================] - 12s 222ms/step - loss: 4.4912e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9261\n","\n","Epoch 00200: val_accuracy did not improve from 0.92611\n","Epoch 201/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4179 - val_accuracy: 0.9064\n","\n","Epoch 00201: val_accuracy did not improve from 0.92611\n","Epoch 202/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4043 - val_accuracy: 0.9138\n","\n","Epoch 00202: val_accuracy did not improve from 0.92611\n","Epoch 203/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9286\n","\n","Epoch 00203: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 204/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9286\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5253 - val_accuracy: 0.8768\n","\n","Epoch 00205: val_accuracy did not improve from 0.92857\n","Epoch 206/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.5827 - val_accuracy: 0.8719\n","\n","Epoch 00206: val_accuracy did not improve from 0.92857\n","Epoch 207/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 1.2012 - val_accuracy: 0.7980\n","\n","Epoch 00207: val_accuracy did not improve from 0.92857\n","Epoch 208/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6945 - val_accuracy: 0.8818\n","\n","Epoch 00208: val_accuracy did not improve from 0.92857\n","Epoch 209/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6414 - val_accuracy: 0.8793\n","\n","Epoch 00209: val_accuracy did not improve from 0.92857\n","Epoch 210/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0221 - accuracy: 0.9909 - val_loss: 1.6952 - val_accuracy: 0.6872\n","\n","Epoch 00210: val_accuracy did not improve from 0.92857\n","Epoch 211/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0367 - accuracy: 0.9854 - val_loss: 0.7008 - val_accuracy: 0.8892\n","\n","Epoch 00211: val_accuracy did not improve from 0.92857\n","Epoch 212/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.9477 - val_accuracy: 0.8473\n","\n","Epoch 00212: val_accuracy did not improve from 0.92857\n","Epoch 213/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.9854 - val_accuracy: 0.8448\n","\n","Epoch 00213: val_accuracy did not improve from 0.92857\n","Epoch 214/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.5643 - val_accuracy: 0.9039\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.5102 - val_accuracy: 0.9039\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4459 - val_accuracy: 0.9015\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0385 - accuracy: 0.9915 - val_loss: 0.9421 - val_accuracy: 0.8448\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.6060 - val_accuracy: 0.8916\n","\n","Epoch 00218: val_accuracy did not improve from 0.92857\n","Epoch 219/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0243 - accuracy: 0.9890 - val_loss: 0.8368 - val_accuracy: 0.8621\n","\n","Epoch 00219: val_accuracy did not improve from 0.92857\n","Epoch 220/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.4945 - val_accuracy: 0.8818\n","\n","Epoch 00220: val_accuracy did not improve from 0.92857\n","Epoch 221/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.5184 - val_accuracy: 0.8892\n","\n","Epoch 00221: val_accuracy did not improve from 0.92857\n","Epoch 222/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4537 - val_accuracy: 0.8892\n","\n","Epoch 00222: val_accuracy did not improve from 0.92857\n","Epoch 223/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9187\n","\n","Epoch 00223: val_accuracy did not improve from 0.92857\n","Epoch 224/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3749 - val_accuracy: 0.9286\n","\n","Epoch 00224: val_accuracy did not improve from 0.92857\n","Epoch 225/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4157 - val_accuracy: 0.9163\n","\n","Epoch 00225: val_accuracy did not improve from 0.92857\n","Epoch 226/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.3778 - val_accuracy: 0.9113\n","\n","Epoch 00226: val_accuracy did not improve from 0.92857\n","Epoch 227/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0321 - accuracy: 0.9878 - val_loss: 0.9979 - val_accuracy: 0.8030\n","\n","Epoch 00227: val_accuracy did not improve from 0.92857\n","Epoch 228/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.6147 - val_accuracy: 0.8744\n","\n","Epoch 00228: val_accuracy did not improve from 0.92857\n","Epoch 229/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.5855 - val_accuracy: 0.8941\n","\n","Epoch 00229: val_accuracy did not improve from 0.92857\n","Epoch 230/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.8479 - val_accuracy: 0.8251\n","\n","Epoch 00230: val_accuracy did not improve from 0.92857\n","Epoch 231/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0163 - accuracy: 0.9927 - val_loss: 0.6151 - val_accuracy: 0.9015\n","\n","Epoch 00231: val_accuracy did not improve from 0.92857\n","Epoch 232/500\n","52/52 [==============================] - 13s 240ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 0.8471 - val_accuracy: 0.8251\n","\n","Epoch 00232: val_accuracy did not improve from 0.92857\n","Epoch 233/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0188 - accuracy: 0.9921 - val_loss: 0.7805 - val_accuracy: 0.8719\n","\n","Epoch 00233: val_accuracy did not improve from 0.92857\n","Epoch 234/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.6525 - val_accuracy: 0.8916\n","\n","Epoch 00234: val_accuracy did not improve from 0.92857\n","Epoch 235/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4179 - val_accuracy: 0.9163\n","\n","Epoch 00235: val_accuracy did not improve from 0.92857\n","Epoch 236/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.6687 - val_accuracy: 0.8744\n","\n","Epoch 00236: val_accuracy did not improve from 0.92857\n","Epoch 237/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.4510 - val_accuracy: 0.9113\n","\n","Epoch 00237: val_accuracy did not improve from 0.92857\n","Epoch 238/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9113\n","\n","Epoch 00238: val_accuracy did not improve from 0.92857\n","Epoch 239/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4283 - val_accuracy: 0.9163\n","\n","Epoch 00239: val_accuracy did not improve from 0.92857\n","Epoch 240/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.4714 - val_accuracy: 0.9089\n","\n","Epoch 00240: val_accuracy did not improve from 0.92857\n","Epoch 241/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.9113\n","\n","Epoch 00241: val_accuracy did not improve from 0.92857\n","Epoch 242/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4528 - val_accuracy: 0.9261\n","\n","Epoch 00242: val_accuracy did not improve from 0.92857\n","Epoch 243/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4585 - val_accuracy: 0.9236\n","\n","Epoch 00243: val_accuracy did not improve from 0.92857\n","Epoch 244/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.2672e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9310\n","\n","Epoch 00244: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 245/500\n","52/52 [==============================] - 12s 225ms/step - loss: 3.0616e-04 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9335\n","\n","Epoch 00245: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 246/500\n","52/52 [==============================] - 12s 225ms/step - loss: 5.5461e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9236\n","\n","Epoch 00246: val_accuracy did not improve from 0.93350\n","Epoch 247/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4849 - val_accuracy: 0.9089\n","\n","Epoch 00247: val_accuracy did not improve from 0.93350\n","Epoch 248/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5410 - val_accuracy: 0.8892\n","\n","Epoch 00248: val_accuracy did not improve from 0.93350\n","Epoch 249/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.7145 - val_accuracy: 0.8818\n","\n","Epoch 00249: val_accuracy did not improve from 0.93350\n","Epoch 250/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.8386 - val_accuracy: 0.8300\n","\n","Epoch 00250: val_accuracy did not improve from 0.93350\n","Epoch 251/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.6871 - val_accuracy: 0.8645\n","\n","Epoch 00251: val_accuracy did not improve from 0.93350\n","Epoch 252/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0808 - accuracy: 0.9805 - val_loss: 1.0870 - val_accuracy: 0.8079\n","\n","Epoch 00252: val_accuracy did not improve from 0.93350\n","Epoch 253/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0606 - accuracy: 0.9738 - val_loss: 1.0464 - val_accuracy: 0.8325\n","\n","Epoch 00253: val_accuracy did not improve from 0.93350\n","Epoch 254/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 1.9194 - val_accuracy: 0.6626\n","\n","Epoch 00254: val_accuracy did not improve from 0.93350\n","Epoch 255/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.6490 - val_accuracy: 0.8916\n","\n","Epoch 00255: val_accuracy did not improve from 0.93350\n","Epoch 256/500\n","52/52 [==============================] - 12s 220ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6062 - val_accuracy: 0.8818\n","\n","Epoch 00256: val_accuracy did not improve from 0.93350\n","Epoch 257/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4699 - val_accuracy: 0.8941\n","\n","Epoch 00257: val_accuracy did not improve from 0.93350\n","Epoch 258/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.4182 - val_accuracy: 0.8966\n","\n","Epoch 00258: val_accuracy did not improve from 0.93350\n","Epoch 259/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.3476 - val_accuracy: 0.9089\n","\n","Epoch 00259: val_accuracy did not improve from 0.93350\n","Epoch 260/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3666 - val_accuracy: 0.9163\n","\n","Epoch 00260: val_accuracy did not improve from 0.93350\n","Epoch 261/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3441 - val_accuracy: 0.9286\n","\n","Epoch 00261: val_accuracy did not improve from 0.93350\n","Epoch 262/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4128 - val_accuracy: 0.9039\n","\n","Epoch 00262: val_accuracy did not improve from 0.93350\n","Epoch 263/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4233 - val_accuracy: 0.8966\n","\n","Epoch 00263: val_accuracy did not improve from 0.93350\n","Epoch 264/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9089\n","\n","Epoch 00264: val_accuracy did not improve from 0.93350\n","Epoch 265/500\n","52/52 [==============================] - 12s 222ms/step - loss: 7.6824e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9286\n","\n","Epoch 00265: val_accuracy did not improve from 0.93350\n","Epoch 266/500\n","52/52 [==============================] - 12s 222ms/step - loss: 9.3642e-04 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9187\n","\n","Epoch 00266: val_accuracy did not improve from 0.93350\n","Epoch 267/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3791 - val_accuracy: 0.9187\n","\n","Epoch 00267: val_accuracy did not improve from 0.93350\n","Epoch 268/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3894 - val_accuracy: 0.9212\n","\n","Epoch 00268: val_accuracy did not improve from 0.93350\n","Epoch 269/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.4999 - val_accuracy: 0.8966\n","\n","Epoch 00269: val_accuracy did not improve from 0.93350\n","Epoch 270/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.4737 - val_accuracy: 0.9138\n","\n","Epoch 00270: val_accuracy did not improve from 0.93350\n","Epoch 271/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.4029 - val_accuracy: 0.9138\n","\n","Epoch 00271: val_accuracy did not improve from 0.93350\n","Epoch 272/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.5136 - val_accuracy: 0.9015\n","\n","Epoch 00272: val_accuracy did not improve from 0.93350\n","Epoch 273/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9113\n","\n","Epoch 00273: val_accuracy did not improve from 0.93350\n","Epoch 274/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9360\n","\n","Epoch 00274: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5\n","Epoch 275/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.8193 - val_accuracy: 0.8448\n","\n","Epoch 00275: val_accuracy did not improve from 0.93596\n","Epoch 276/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0350 - accuracy: 0.9866 - val_loss: 0.6556 - val_accuracy: 0.8818\n","\n","Epoch 00276: val_accuracy did not improve from 0.93596\n","Epoch 277/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.6091 - val_accuracy: 0.9039\n","\n","Epoch 00277: val_accuracy did not improve from 0.93596\n","Epoch 278/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 1.1384 - val_accuracy: 0.8227\n","\n","Epoch 00278: val_accuracy did not improve from 0.93596\n","Epoch 279/500\n","52/52 [==============================] - 12s 221ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 1.2093 - val_accuracy: 0.7833\n","\n","Epoch 00279: val_accuracy did not improve from 0.93596\n","Epoch 280/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0134 - accuracy: 0.9927 - val_loss: 0.5984 - val_accuracy: 0.8867\n","\n","Epoch 00280: val_accuracy did not improve from 0.93596\n","Epoch 281/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.6254 - val_accuracy: 0.8571\n","\n","Epoch 00281: val_accuracy did not improve from 0.93596\n","Epoch 282/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 0.4662 - val_accuracy: 0.8695\n","\n","Epoch 00282: val_accuracy did not improve from 0.93596\n","Epoch 283/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4524 - val_accuracy: 0.8990\n","\n","Epoch 00283: val_accuracy did not improve from 0.93596\n","Epoch 284/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.4969 - val_accuracy: 0.9039\n","\n","Epoch 00284: val_accuracy did not improve from 0.93596\n","Epoch 285/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.7036 - val_accuracy: 0.8645\n","\n","Epoch 00285: val_accuracy did not improve from 0.93596\n","Epoch 286/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 1.0513 - val_accuracy: 0.8547\n","\n","Epoch 00286: val_accuracy did not improve from 0.93596\n","Epoch 287/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.2476 - val_accuracy: 0.7635\n","\n","Epoch 00287: val_accuracy did not improve from 0.93596\n","Epoch 288/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 1.2192 - val_accuracy: 0.7315\n","\n","Epoch 00288: val_accuracy did not improve from 0.93596\n","Epoch 289/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.7739 - val_accuracy: 0.8300\n","\n","Epoch 00289: val_accuracy did not improve from 0.93596\n","Epoch 290/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5007 - val_accuracy: 0.8916\n","\n","Epoch 00290: val_accuracy did not improve from 0.93596\n","Epoch 291/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9187\n","\n","Epoch 00291: val_accuracy did not improve from 0.93596\n","Epoch 292/500\n","52/52 [==============================] - 12s 221ms/step - loss: 7.8023e-04 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9236\n","\n","Epoch 00292: val_accuracy did not improve from 0.93596\n","Epoch 293/500\n","52/52 [==============================] - 12s 223ms/step - loss: 3.6275e-04 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9113\n","\n","Epoch 00293: val_accuracy did not improve from 0.93596\n","Epoch 294/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3988 - val_accuracy: 0.9261\n","\n","Epoch 00294: val_accuracy did not improve from 0.93596\n","Epoch 295/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9310\n","\n","Epoch 00295: val_accuracy did not improve from 0.93596\n","Epoch 296/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.6618 - val_accuracy: 0.8818\n","\n","Epoch 00296: val_accuracy did not improve from 0.93596\n","Epoch 297/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 1.3268 - val_accuracy: 0.8300\n","\n","Epoch 00297: val_accuracy did not improve from 0.93596\n","Epoch 298/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.7313 - val_accuracy: 0.8768\n","\n","Epoch 00298: val_accuracy did not improve from 0.93596\n","Epoch 299/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.7407 - val_accuracy: 0.9015\n","\n","Epoch 00299: val_accuracy did not improve from 0.93596\n","Epoch 300/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 1.1743 - val_accuracy: 0.7931\n","\n","Epoch 00300: val_accuracy did not improve from 0.93596\n","Epoch 301/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.8902 - val_accuracy: 0.8448\n","\n","Epoch 00301: val_accuracy did not improve from 0.93596\n","Epoch 302/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 0.6320 - val_accuracy: 0.8916\n","\n","Epoch 00302: val_accuracy did not improve from 0.93596\n","Epoch 303/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 1.0183 - val_accuracy: 0.8424\n","\n","Epoch 00303: val_accuracy did not improve from 0.93596\n","Epoch 304/500\n","52/52 [==============================] - 12s 222ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.5979 - val_accuracy: 0.8744\n","\n","Epoch 00304: val_accuracy did not improve from 0.93596\n","Epoch 305/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4730 - val_accuracy: 0.9039\n","\n","Epoch 00305: val_accuracy did not improve from 0.93596\n","Epoch 306/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.3580 - val_accuracy: 0.9113\n","\n","Epoch 00306: val_accuracy did not improve from 0.93596\n","Epoch 307/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9335\n","\n","Epoch 00307: val_accuracy did not improve from 0.93596\n","Epoch 308/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9212\n","\n","Epoch 00308: val_accuracy did not improve from 0.93596\n","Epoch 309/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3789 - val_accuracy: 0.9138\n","\n","Epoch 00309: val_accuracy did not improve from 0.93596\n","Epoch 310/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0248 - accuracy: 0.9945 - val_loss: 2.1062 - val_accuracy: 0.6749\n","\n","Epoch 00310: val_accuracy did not improve from 0.93596\n","Epoch 311/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0174 - accuracy: 0.9957 - val_loss: 4.4022 - val_accuracy: 0.6379\n","\n","Epoch 00311: val_accuracy did not improve from 0.93596\n","Epoch 312/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 0.7953 - val_accuracy: 0.8498\n","\n","Epoch 00312: val_accuracy did not improve from 0.93596\n","Epoch 313/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.7596 - val_accuracy: 0.8818\n","\n","Epoch 00313: val_accuracy did not improve from 0.93596\n","Epoch 314/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.5226 - val_accuracy: 0.8966\n","\n","Epoch 00314: val_accuracy did not improve from 0.93596\n","Epoch 315/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5529 - val_accuracy: 0.9089\n","\n","Epoch 00315: val_accuracy did not improve from 0.93596\n","Epoch 316/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4706 - val_accuracy: 0.9089\n","\n","Epoch 00316: val_accuracy did not improve from 0.93596\n","Epoch 317/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.7820 - val_accuracy: 0.8424\n","\n","Epoch 00317: val_accuracy did not improve from 0.93596\n","Epoch 318/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4974 - val_accuracy: 0.8916\n","\n","Epoch 00318: val_accuracy did not improve from 0.93596\n","Epoch 319/500\n","52/52 [==============================] - 12s 226ms/step - loss: 4.4420e-04 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9089\n","\n","Epoch 00319: val_accuracy did not improve from 0.93596\n","Epoch 320/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.9451e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.93596\n","Epoch 321/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0389 - accuracy: 0.9915 - val_loss: 6.8750 - val_accuracy: 0.3842\n","\n","Epoch 00321: val_accuracy did not improve from 0.93596\n","Epoch 322/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 1.0512 - val_accuracy: 0.8128\n","\n","Epoch 00322: val_accuracy did not improve from 0.93596\n","Epoch 323/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.5720 - val_accuracy: 0.8793\n","\n","Epoch 00323: val_accuracy did not improve from 0.93596\n","Epoch 324/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.3784 - val_accuracy: 0.9187\n","\n","Epoch 00324: val_accuracy did not improve from 0.93596\n","Epoch 325/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.9113\n","\n","Epoch 00325: val_accuracy did not improve from 0.93596\n","Epoch 326/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4037 - val_accuracy: 0.9089\n","\n","Epoch 00326: val_accuracy did not improve from 0.93596\n","Epoch 327/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9089\n","\n","Epoch 00327: val_accuracy did not improve from 0.93596\n","Epoch 328/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6856 - val_accuracy: 0.8719\n","\n","Epoch 00328: val_accuracy did not improve from 0.93596\n","Epoch 329/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.3930 - val_accuracy: 0.9261\n","\n","Epoch 00329: val_accuracy did not improve from 0.93596\n","Epoch 330/500\n","52/52 [==============================] - 12s 226ms/step - loss: 6.6260e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9089\n","\n","Epoch 00330: val_accuracy did not improve from 0.93596\n","Epoch 331/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9138\n","\n","Epoch 00331: val_accuracy did not improve from 0.93596\n","Epoch 332/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4461 - val_accuracy: 0.9064\n","\n","Epoch 00332: val_accuracy did not improve from 0.93596\n","Epoch 333/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9310\n","\n","Epoch 00333: val_accuracy did not improve from 0.93596\n","Epoch 334/500\n","52/52 [==============================] - 12s 226ms/step - loss: 1.9324e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9335\n","\n","Epoch 00334: val_accuracy did not improve from 0.93596\n","Epoch 335/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3832 - val_accuracy: 0.9335\n","\n","Epoch 00335: val_accuracy did not improve from 0.93596\n","Epoch 336/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5078 - val_accuracy: 0.9163\n","\n","Epoch 00336: val_accuracy did not improve from 0.93596\n","Epoch 337/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0401 - accuracy: 0.9933 - val_loss: 0.6783 - val_accuracy: 0.8596\n","\n","Epoch 00337: val_accuracy did not improve from 0.93596\n","Epoch 338/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.6537 - val_accuracy: 0.8842\n","\n","Epoch 00338: val_accuracy did not improve from 0.93596\n","Epoch 339/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.7754 - val_accuracy: 0.8522\n","\n","Epoch 00339: val_accuracy did not improve from 0.93596\n","Epoch 340/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.7077 - val_accuracy: 0.8695\n","\n","Epoch 00340: val_accuracy did not improve from 0.93596\n","Epoch 341/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4754 - val_accuracy: 0.9015\n","\n","Epoch 00341: val_accuracy did not improve from 0.93596\n","Epoch 342/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.5515 - val_accuracy: 0.8744\n","\n","Epoch 00342: val_accuracy did not improve from 0.93596\n","Epoch 343/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.5967 - val_accuracy: 0.8842\n","\n","Epoch 00343: val_accuracy did not improve from 0.93596\n","Epoch 344/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5424 - val_accuracy: 0.9089\n","\n","Epoch 00344: val_accuracy did not improve from 0.93596\n","Epoch 345/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.6873 - val_accuracy: 0.8818\n","\n","Epoch 00345: val_accuracy did not improve from 0.93596\n","Epoch 346/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4937 - val_accuracy: 0.8966\n","\n","Epoch 00346: val_accuracy did not improve from 0.93596\n","Epoch 347/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4806 - val_accuracy: 0.9236\n","\n","Epoch 00347: val_accuracy did not improve from 0.93596\n","Epoch 348/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4069 - val_accuracy: 0.9286\n","\n","Epoch 00348: val_accuracy did not improve from 0.93596\n","Epoch 349/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5228 - val_accuracy: 0.9064\n","\n","Epoch 00349: val_accuracy did not improve from 0.93596\n","Epoch 350/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5363 - val_accuracy: 0.8990\n","\n","Epoch 00350: val_accuracy did not improve from 0.93596\n","Epoch 351/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9015\n","\n","Epoch 00351: val_accuracy did not improve from 0.93596\n","Epoch 352/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9113\n","\n","Epoch 00352: val_accuracy did not improve from 0.93596\n","Epoch 353/500\n","52/52 [==============================] - 12s 225ms/step - loss: 5.4273e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9187\n","\n","Epoch 00353: val_accuracy did not improve from 0.93596\n","Epoch 354/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4499 - val_accuracy: 0.9187\n","\n","Epoch 00354: val_accuracy did not improve from 0.93596\n","Epoch 355/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4878 - val_accuracy: 0.8990\n","\n","Epoch 00355: val_accuracy did not improve from 0.93596\n","Epoch 356/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6681 - val_accuracy: 0.8842\n","\n","Epoch 00356: val_accuracy did not improve from 0.93596\n","Epoch 357/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.7789 - val_accuracy: 0.8842\n","\n","Epoch 00357: val_accuracy did not improve from 0.93596\n","Epoch 358/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6220 - val_accuracy: 0.8916\n","\n","Epoch 00358: val_accuracy did not improve from 0.93596\n","Epoch 359/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5993 - val_accuracy: 0.9113\n","\n","Epoch 00359: val_accuracy did not improve from 0.93596\n","Epoch 360/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.6749 - val_accuracy: 0.9039\n","\n","Epoch 00360: val_accuracy did not improve from 0.93596\n","Epoch 361/500\n","52/52 [==============================] - 13s 241ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.5223 - val_accuracy: 0.9039\n","\n","Epoch 00361: val_accuracy did not improve from 0.93596\n","Epoch 362/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4991 - val_accuracy: 0.8916\n","\n","Epoch 00362: val_accuracy did not improve from 0.93596\n","Epoch 363/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.5965 - val_accuracy: 0.8990\n","\n","Epoch 00363: val_accuracy did not improve from 0.93596\n","Epoch 364/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.7747 - val_accuracy: 0.8818\n","\n","Epoch 00364: val_accuracy did not improve from 0.93596\n","Epoch 365/500\n","52/52 [==============================] - 12s 223ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.6358 - val_accuracy: 0.8842\n","\n","Epoch 00365: val_accuracy did not improve from 0.93596\n","Epoch 366/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.8503 - val_accuracy: 0.8670\n","\n","Epoch 00366: val_accuracy did not improve from 0.93596\n","Epoch 367/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0545 - accuracy: 0.9829 - val_loss: 0.7196 - val_accuracy: 0.8892\n","\n","Epoch 00367: val_accuracy did not improve from 0.93596\n","Epoch 368/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.6588 - val_accuracy: 0.8596\n","\n","Epoch 00368: val_accuracy did not improve from 0.93596\n","Epoch 369/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5539 - val_accuracy: 0.8892\n","\n","Epoch 00369: val_accuracy did not improve from 0.93596\n","Epoch 370/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4363 - val_accuracy: 0.8990\n","\n","Epoch 00370: val_accuracy did not improve from 0.93596\n","Epoch 371/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4437 - val_accuracy: 0.9089\n","\n","Epoch 00371: val_accuracy did not improve from 0.93596\n","Epoch 372/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9187\n","\n","Epoch 00372: val_accuracy did not improve from 0.93596\n","Epoch 373/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6256 - val_accuracy: 0.8571\n","\n","Epoch 00373: val_accuracy did not improve from 0.93596\n","Epoch 374/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.5872 - val_accuracy: 0.8621\n","\n","Epoch 00374: val_accuracy did not improve from 0.93596\n","Epoch 375/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6497 - val_accuracy: 0.8596\n","\n","Epoch 00375: val_accuracy did not improve from 0.93596\n","Epoch 376/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5176 - val_accuracy: 0.8990\n","\n","Epoch 00376: val_accuracy did not improve from 0.93596\n","Epoch 377/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3258 - val_accuracy: 0.9236\n","\n","Epoch 00377: val_accuracy did not improve from 0.93596\n","Epoch 378/500\n","52/52 [==============================] - 12s 225ms/step - loss: 2.2125e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9187\n","\n","Epoch 00378: val_accuracy did not improve from 0.93596\n","Epoch 379/500\n","52/52 [==============================] - 12s 226ms/step - loss: 8.2244e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9286\n","\n","Epoch 00379: val_accuracy did not improve from 0.93596\n","Epoch 380/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4389 - val_accuracy: 0.9138\n","\n","Epoch 00380: val_accuracy did not improve from 0.93596\n","Epoch 381/500\n","52/52 [==============================] - 12s 226ms/step - loss: 7.2985e-04 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.9113\n","\n","Epoch 00381: val_accuracy did not improve from 0.93596\n","Epoch 382/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6010 - val_accuracy: 0.8892\n","\n","Epoch 00382: val_accuracy did not improve from 0.93596\n","Epoch 383/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.7179 - val_accuracy: 0.8473\n","\n","Epoch 00383: val_accuracy did not improve from 0.93596\n","Epoch 384/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5819 - val_accuracy: 0.9015\n","\n","Epoch 00384: val_accuracy did not improve from 0.93596\n","Epoch 385/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.7772 - val_accuracy: 0.8867\n","\n","Epoch 00385: val_accuracy did not improve from 0.93596\n","Epoch 386/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.6256 - val_accuracy: 0.9064\n","\n","Epoch 00386: val_accuracy did not improve from 0.93596\n","Epoch 387/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6116 - val_accuracy: 0.8941\n","\n","Epoch 00387: val_accuracy did not improve from 0.93596\n","Epoch 388/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.9848 - val_accuracy: 0.8030\n","\n","Epoch 00388: val_accuracy did not improve from 0.93596\n","Epoch 389/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.9800 - val_accuracy: 0.8498\n","\n","Epoch 00389: val_accuracy did not improve from 0.93596\n","Epoch 390/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.0427 - val_accuracy: 0.8054\n","\n","Epoch 00390: val_accuracy did not improve from 0.93596\n","Epoch 391/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0548 - accuracy: 0.9854 - val_loss: 2.1692 - val_accuracy: 0.6650\n","\n","Epoch 00391: val_accuracy did not improve from 0.93596\n","Epoch 392/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.7509 - val_accuracy: 0.8695\n","\n","Epoch 00392: val_accuracy did not improve from 0.93596\n","Epoch 393/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8793\n","\n","Epoch 00393: val_accuracy did not improve from 0.93596\n","Epoch 394/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.7830 - val_accuracy: 0.8768\n","\n","Epoch 00394: val_accuracy did not improve from 0.93596\n","Epoch 395/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 1.0954 - val_accuracy: 0.7980\n","\n","Epoch 00395: val_accuracy did not improve from 0.93596\n","Epoch 396/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.7514 - val_accuracy: 0.8941\n","\n","Epoch 00396: val_accuracy did not improve from 0.93596\n","Epoch 397/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.6656 - val_accuracy: 0.8744\n","\n","Epoch 00397: val_accuracy did not improve from 0.93596\n","Epoch 398/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5712 - val_accuracy: 0.8892\n","\n","Epoch 00398: val_accuracy did not improve from 0.93596\n","Epoch 399/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4406 - val_accuracy: 0.8966\n","\n","Epoch 00399: val_accuracy did not improve from 0.93596\n","Epoch 400/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9286\n","\n","Epoch 00400: val_accuracy did not improve from 0.93596\n","Epoch 401/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4528 - val_accuracy: 0.9261\n","\n","Epoch 00401: val_accuracy did not improve from 0.93596\n","Epoch 402/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4963 - val_accuracy: 0.9039\n","\n","Epoch 00402: val_accuracy did not improve from 0.93596\n","Epoch 403/500\n","52/52 [==============================] - 12s 224ms/step - loss: 8.8848e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9310\n","\n","Epoch 00403: val_accuracy did not improve from 0.93596\n","Epoch 404/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6123 - val_accuracy: 0.8670\n","\n","Epoch 00404: val_accuracy did not improve from 0.93596\n","Epoch 405/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.4996e-04 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9163\n","\n","Epoch 00405: val_accuracy did not improve from 0.93596\n","Epoch 406/500\n","52/52 [==============================] - 12s 226ms/step - loss: 3.4902e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9212\n","\n","Epoch 00406: val_accuracy did not improve from 0.93596\n","Epoch 407/500\n","52/52 [==============================] - 12s 226ms/step - loss: 7.2651e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9335\n","\n","Epoch 00407: val_accuracy did not improve from 0.93596\n","Epoch 408/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5371 - val_accuracy: 0.8966\n","\n","Epoch 00408: val_accuracy did not improve from 0.93596\n","Epoch 409/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6070 - val_accuracy: 0.8916\n","\n","Epoch 00409: val_accuracy did not improve from 0.93596\n","Epoch 410/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4422 - val_accuracy: 0.9163\n","\n","Epoch 00410: val_accuracy did not improve from 0.93596\n","Epoch 411/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.8476e-04 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9163\n","\n","Epoch 00411: val_accuracy did not improve from 0.93596\n","Epoch 412/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.6998 - val_accuracy: 0.9015\n","\n","Epoch 00412: val_accuracy did not improve from 0.93596\n","Epoch 413/500\n","52/52 [==============================] - 12s 227ms/step - loss: 8.0322e-04 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9261\n","\n","Epoch 00413: val_accuracy did not improve from 0.93596\n","Epoch 414/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3929 - val_accuracy: 0.9236\n","\n","Epoch 00414: val_accuracy did not improve from 0.93596\n","Epoch 415/500\n","52/52 [==============================] - 12s 226ms/step - loss: 9.4679e-04 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9236\n","\n","Epoch 00415: val_accuracy did not improve from 0.93596\n","Epoch 416/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4594 - val_accuracy: 0.9286\n","\n","Epoch 00416: val_accuracy did not improve from 0.93596\n","Epoch 417/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.5486 - val_accuracy: 0.9138\n","\n","Epoch 00417: val_accuracy did not improve from 0.93596\n","Epoch 418/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 4.6173 - val_accuracy: 0.3768\n","\n","Epoch 00418: val_accuracy did not improve from 0.93596\n","Epoch 419/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0579 - accuracy: 0.9817 - val_loss: 1.1763 - val_accuracy: 0.7635\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 1.4639 - val_accuracy: 0.7192\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 0.8782 - val_accuracy: 0.8571\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4629 - val_accuracy: 0.8941\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4920 - val_accuracy: 0.8793\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","52/52 [==============================] - 12s 226ms/step - loss: 8.1149e-04 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8892\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5068 - val_accuracy: 0.8842\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8916\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4276 - val_accuracy: 0.9138\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9236\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4097 - val_accuracy: 0.9138\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5078 - val_accuracy: 0.9015\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","52/52 [==============================] - 12s 227ms/step - loss: 5.1717e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9236\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.0036e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9236\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 12s 225ms/step - loss: 8.6674e-04 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9187\n","\n","Epoch 00433: val_accuracy did not improve from 0.93596\n","Epoch 434/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.4554 - val_accuracy: 0.9187\n","\n","Epoch 00434: val_accuracy did not improve from 0.93596\n","Epoch 435/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.5779 - val_accuracy: 0.8990\n","\n","Epoch 00435: val_accuracy did not improve from 0.93596\n","Epoch 436/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9089\n","\n","Epoch 00436: val_accuracy did not improve from 0.93596\n","Epoch 437/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6443 - val_accuracy: 0.8547\n","\n","Epoch 00437: val_accuracy did not improve from 0.93596\n","Epoch 438/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 1.4165 - val_accuracy: 0.6872\n","\n","Epoch 00438: val_accuracy did not improve from 0.93596\n","Epoch 439/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.7428 - val_accuracy: 0.8300\n","\n","Epoch 00439: val_accuracy did not improve from 0.93596\n","Epoch 440/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0086 - accuracy: 0.9957 - val_loss: 0.9154 - val_accuracy: 0.7783\n","\n","Epoch 00440: val_accuracy did not improve from 0.93596\n","Epoch 441/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.5751 - val_accuracy: 0.8818\n","\n","Epoch 00441: val_accuracy did not improve from 0.93596\n","Epoch 442/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.8849 - val_accuracy: 0.8153\n","\n","Epoch 00442: val_accuracy did not improve from 0.93596\n","Epoch 443/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0575 - accuracy: 0.9872 - val_loss: 0.8559 - val_accuracy: 0.8596\n","\n","Epoch 00443: val_accuracy did not improve from 0.93596\n","Epoch 444/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6671 - val_accuracy: 0.8867\n","\n","Epoch 00444: val_accuracy did not improve from 0.93596\n","Epoch 445/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4933 - val_accuracy: 0.9015\n","\n","Epoch 00445: val_accuracy did not improve from 0.93596\n","Epoch 446/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.6642 - val_accuracy: 0.8867\n","\n","Epoch 00446: val_accuracy did not improve from 0.93596\n","Epoch 447/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.5573 - val_accuracy: 0.8990\n","\n","Epoch 00447: val_accuracy did not improve from 0.93596\n","Epoch 448/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.6707 - val_accuracy: 0.9015\n","\n","Epoch 00448: val_accuracy did not improve from 0.93596\n","Epoch 449/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.5320 - val_accuracy: 0.8867\n","\n","Epoch 00449: val_accuracy did not improve from 0.93596\n","Epoch 450/500\n","52/52 [==============================] - 12s 225ms/step - loss: 7.4395e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9039\n","\n","Epoch 00450: val_accuracy did not improve from 0.93596\n","Epoch 451/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.4157 - val_accuracy: 0.9236\n","\n","Epoch 00451: val_accuracy did not improve from 0.93596\n","Epoch 452/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5763 - val_accuracy: 0.8916\n","\n","Epoch 00452: val_accuracy did not improve from 0.93596\n","Epoch 453/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.5148 - val_accuracy: 0.9113\n","\n","Epoch 00453: val_accuracy did not improve from 0.93596\n","Epoch 454/500\n","52/52 [==============================] - 12s 224ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.5489 - val_accuracy: 0.9064\n","\n","Epoch 00454: val_accuracy did not improve from 0.93596\n","Epoch 455/500\n","52/52 [==============================] - 12s 225ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.4522 - val_accuracy: 0.9113\n","\n","Epoch 00455: val_accuracy did not improve from 0.93596\n","Epoch 456/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4761 - val_accuracy: 0.9187\n","\n","Epoch 00456: val_accuracy did not improve from 0.93596\n","Epoch 457/500\n","52/52 [==============================] - 12s 226ms/step - loss: 5.2997e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9236\n","\n","Epoch 00457: val_accuracy did not improve from 0.93596\n","Epoch 458/500\n","52/52 [==============================] - 12s 227ms/step - loss: 8.7232e-04 - accuracy: 0.9994 - val_loss: 0.5121 - val_accuracy: 0.9089\n","\n","Epoch 00458: val_accuracy did not improve from 0.93596\n","Epoch 459/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5081 - val_accuracy: 0.9089\n","\n","Epoch 00459: val_accuracy did not improve from 0.93596\n","Epoch 460/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4200 - val_accuracy: 0.9187\n","\n","Epoch 00460: val_accuracy did not improve from 0.93596\n","Epoch 461/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5442 - val_accuracy: 0.9187\n","\n","Epoch 00461: val_accuracy did not improve from 0.93596\n","Epoch 462/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.4524 - val_accuracy: 0.9138\n","\n","Epoch 00462: val_accuracy did not improve from 0.93596\n","Epoch 463/500\n","52/52 [==============================] - 12s 227ms/step - loss: 8.8496e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9138\n","\n","Epoch 00463: val_accuracy did not improve from 0.93596\n","Epoch 464/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.4844 - val_accuracy: 0.9039\n","\n","Epoch 00464: val_accuracy did not improve from 0.93596\n","Epoch 465/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5468 - val_accuracy: 0.8966\n","\n","Epoch 00465: val_accuracy did not improve from 0.93596\n","Epoch 466/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.7128 - val_accuracy: 0.8719\n","\n","Epoch 00466: val_accuracy did not improve from 0.93596\n","Epoch 467/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.6936 - val_accuracy: 0.8892\n","\n","Epoch 00467: val_accuracy did not improve from 0.93596\n","Epoch 468/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.5966 - val_accuracy: 0.9039\n","\n","Epoch 00468: val_accuracy did not improve from 0.93596\n","Epoch 469/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.7860 - val_accuracy: 0.8670\n","\n","Epoch 00469: val_accuracy did not improve from 0.93596\n","Epoch 470/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.5484 - val_accuracy: 0.9089\n","\n","Epoch 00470: val_accuracy did not improve from 0.93596\n","Epoch 471/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4685 - val_accuracy: 0.9138\n","\n","Epoch 00471: val_accuracy did not improve from 0.93596\n","Epoch 472/500\n","52/52 [==============================] - 12s 228ms/step - loss: 8.8397e-04 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9212\n","\n","Epoch 00472: val_accuracy did not improve from 0.93596\n","Epoch 473/500\n","52/52 [==============================] - 12s 229ms/step - loss: 8.3767e-04 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9064\n","\n","Epoch 00473: val_accuracy did not improve from 0.93596\n","Epoch 474/500\n","52/52 [==============================] - 12s 227ms/step - loss: 5.9291e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9138\n","\n","Epoch 00474: val_accuracy did not improve from 0.93596\n","Epoch 475/500\n","52/52 [==============================] - 12s 230ms/step - loss: 2.3853e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9089\n","\n","Epoch 00475: val_accuracy did not improve from 0.93596\n","Epoch 476/500\n","52/52 [==============================] - 12s 229ms/step - loss: 6.1590e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9089\n","\n","Epoch 00476: val_accuracy did not improve from 0.93596\n","Epoch 477/500\n","52/52 [==============================] - 12s 230ms/step - loss: 2.9375e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9015\n","\n","Epoch 00477: val_accuracy did not improve from 0.93596\n","Epoch 478/500\n","52/52 [==============================] - 12s 230ms/step - loss: 6.2870e-04 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9039\n","\n","Epoch 00478: val_accuracy did not improve from 0.93596\n","Epoch 479/500\n","52/52 [==============================] - 12s 230ms/step - loss: 8.3003e-05 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9212\n","\n","Epoch 00479: val_accuracy did not improve from 0.93596\n","Epoch 480/500\n","52/52 [==============================] - 12s 228ms/step - loss: 1.8411e-04 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9089\n","\n","Epoch 00480: val_accuracy did not improve from 0.93596\n","Epoch 481/500\n","52/52 [==============================] - 12s 228ms/step - loss: 1.7200e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9212\n","\n","Epoch 00481: val_accuracy did not improve from 0.93596\n","Epoch 482/500\n","52/52 [==============================] - 12s 227ms/step - loss: 3.6818e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9187\n","\n","Epoch 00482: val_accuracy did not improve from 0.93596\n","Epoch 483/500\n","52/52 [==============================] - 12s 228ms/step - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9064\n","\n","Epoch 00483: val_accuracy did not improve from 0.93596\n","Epoch 484/500\n","52/52 [==============================] - 12s 226ms/step - loss: 8.5236e-05 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9236\n","\n","Epoch 00484: val_accuracy did not improve from 0.93596\n","Epoch 485/500\n","52/52 [==============================] - 12s 227ms/step - loss: 2.0595e-04 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9039\n","\n","Epoch 00485: val_accuracy did not improve from 0.93596\n","Epoch 486/500\n","52/52 [==============================] - 12s 227ms/step - loss: 1.1438e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9163\n","\n","Epoch 00486: val_accuracy did not improve from 0.93596\n","Epoch 487/500\n","52/52 [==============================] - 12s 229ms/step - loss: 9.5833e-05 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9187\n","\n","Epoch 00487: val_accuracy did not improve from 0.93596\n","Epoch 488/500\n","52/52 [==============================] - 12s 228ms/step - loss: 3.0490e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9212\n","\n","Epoch 00488: val_accuracy did not improve from 0.93596\n","Epoch 489/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.6074 - val_accuracy: 0.8966\n","\n","Epoch 00489: val_accuracy did not improve from 0.93596\n","Epoch 490/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 1.2952 - val_accuracy: 0.7857\n","\n","Epoch 00490: val_accuracy did not improve from 0.93596\n","Epoch 491/500\n","52/52 [==============================] - 12s 229ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.9616 - val_accuracy: 0.8079\n","\n","Epoch 00491: val_accuracy did not improve from 0.93596\n","Epoch 492/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0352 - accuracy: 0.9860 - val_loss: 1.1294 - val_accuracy: 0.8030\n","\n","Epoch 00492: val_accuracy did not improve from 0.93596\n","Epoch 493/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 0.8012 - val_accuracy: 0.8621\n","\n","Epoch 00493: val_accuracy did not improve from 0.93596\n","Epoch 494/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.7996 - val_accuracy: 0.8424\n","\n","Epoch 00494: val_accuracy did not improve from 0.93596\n","Epoch 495/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.6412 - val_accuracy: 0.8892\n","\n","Epoch 00495: val_accuracy did not improve from 0.93596\n","Epoch 496/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5574 - val_accuracy: 0.9064\n","\n","Epoch 00496: val_accuracy did not improve from 0.93596\n","Epoch 497/500\n","52/52 [==============================] - 12s 227ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5437 - val_accuracy: 0.9039\n","\n","Epoch 00497: val_accuracy did not improve from 0.93596\n","Epoch 498/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.5150 - val_accuracy: 0.9064\n","\n","Epoch 00498: val_accuracy did not improve from 0.93596\n","Epoch 499/500\n","52/52 [==============================] - 12s 226ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4601 - val_accuracy: 0.9113\n","\n","Epoch 00499: val_accuracy did not improve from 0.93596\n","Epoch 500/500\n","52/52 [==============================] - 12s 228ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6154 - val_accuracy: 0.8498\n","\n","Epoch 00500: val_accuracy did not improve from 0.93596\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f35f4013390>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1629780895829,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"40bcd933-7624-499a-ae11-8f7ac07711b3"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1629780904874,"user_tz":-540,"elapsed":9059,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/VS_0200_3_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1629780905526,"user_tz":-540,"elapsed":670,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629780905939,"user_tz":-540,"elapsed":418,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f2986572-2de0-43a4-86ea-ac01d49a68fe"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 20480 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629780937067,"user_tz":-540,"elapsed":31136,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c605e649-453f-4bc0-8c95-4c692ce25d52"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1629780937069,"user_tz":-540,"elapsed":17,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1629780937070,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1629780938321,"user_tz":-540,"elapsed":1266,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1629780938324,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1629780950269,"user_tz":-540,"elapsed":11949,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629780950270,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"801c02a1-b6a0-4437-b8fc-33ff01e08676"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629780950271,"user_tz":-540,"elapsed":21,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dd190035-3e43-4f7a-c6ed-b2d8d7be231c"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.200_3_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Validation_split_0.200_3_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_8de4ddcf-288e-43f7-85cd-e57ccb9cbb98\", \"Validation_split_0.200_3_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}