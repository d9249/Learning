{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WidthShiftRange_010_2_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyNn//vg3EMcUyYjMx5tMVh/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630388819315,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b36cac52-e669-42ec-ff58-c9009e6c92be"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 31 05:46:59 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630388836724,"user_tz":-540,"elapsed":17412,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"e1598c64-8512-48ac-a151-271688794625"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630388840126,"user_tz":-540,"elapsed":3408,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630388841308,"user_tz":-540,"elapsed":1187,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630388843672,"user_tz":-540,"elapsed":2369,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630388860677,"user_tz":-540,"elapsed":17009,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630388867444,"user_tz":-540,"elapsed":6780,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630388867452,"user_tz":-540,"elapsed":16,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"17a00797-a337-453f-d67b-d2a71513ad8d"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630388867453,"user_tz":-540,"elapsed":15,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"1d090c4b-9dd6-4c8c-a498-285264ccc9cb"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.1,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630388867453,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630399165674,"user_tz":-540,"elapsed":10298231,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"c5420fb0-a848-4cb1-dfb0-ec7ebef5f29d"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 53s 467ms/step - loss: 1.8121 - accuracy: 0.3471 - val_loss: 12.3321 - val_accuracy: 0.0985\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 366ms/step - loss: 1.1881 - accuracy: 0.5993 - val_loss: 8.7958 - val_accuracy: 0.1034\n","\n","Epoch 00002: val_accuracy improved from 0.09852 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 3/500\n","52/52 [==============================] - 19s 369ms/step - loss: 0.9711 - accuracy: 0.6736 - val_loss: 18.5655 - val_accuracy: 0.0961\n","\n","Epoch 00003: val_accuracy did not improve from 0.10345\n","Epoch 4/500\n","52/52 [==============================] - 19s 369ms/step - loss: 0.7893 - accuracy: 0.7278 - val_loss: 9.8659 - val_accuracy: 0.0813\n","\n","Epoch 00004: val_accuracy did not improve from 0.10345\n","Epoch 5/500\n","52/52 [==============================] - 19s 373ms/step - loss: 0.7062 - accuracy: 0.7722 - val_loss: 4.1676 - val_accuracy: 0.1084\n","\n","Epoch 00005: val_accuracy improved from 0.10345 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 374ms/step - loss: 0.6293 - accuracy: 0.8021 - val_loss: 9.7670 - val_accuracy: 0.1010\n","\n","Epoch 00006: val_accuracy did not improve from 0.10837\n","Epoch 7/500\n","52/52 [==============================] - 20s 375ms/step - loss: 0.5886 - accuracy: 0.8027 - val_loss: 9.6959 - val_accuracy: 0.1429\n","\n","Epoch 00007: val_accuracy improved from 0.10837 to 0.14286, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.5528 - accuracy: 0.8130 - val_loss: 3.0069 - val_accuracy: 0.2857\n","\n","Epoch 00008: val_accuracy improved from 0.14286 to 0.28571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.5100 - accuracy: 0.8350 - val_loss: 1.8391 - val_accuracy: 0.5911\n","\n","Epoch 00009: val_accuracy improved from 0.28571 to 0.59113, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.4982 - accuracy: 0.8368 - val_loss: 0.7415 - val_accuracy: 0.7906\n","\n","Epoch 00010: val_accuracy improved from 0.59113 to 0.79064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.4268 - accuracy: 0.8520 - val_loss: 1.2085 - val_accuracy: 0.6552\n","\n","Epoch 00011: val_accuracy did not improve from 0.79064\n","Epoch 12/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.4082 - accuracy: 0.8538 - val_loss: 1.7395 - val_accuracy: 0.6429\n","\n","Epoch 00012: val_accuracy did not improve from 0.79064\n","Epoch 13/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.4226 - accuracy: 0.8453 - val_loss: 0.7683 - val_accuracy: 0.7685\n","\n","Epoch 00013: val_accuracy did not improve from 0.79064\n","Epoch 14/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.3236 - accuracy: 0.8916 - val_loss: 0.7539 - val_accuracy: 0.7956\n","\n","Epoch 00014: val_accuracy improved from 0.79064 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.3431 - accuracy: 0.8812 - val_loss: 0.7809 - val_accuracy: 0.7389\n","\n","Epoch 00015: val_accuracy did not improve from 0.79557\n","Epoch 16/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.2737 - accuracy: 0.9080 - val_loss: 1.5426 - val_accuracy: 0.6232\n","\n","Epoch 00016: val_accuracy did not improve from 0.79557\n","Epoch 17/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2651 - accuracy: 0.9105 - val_loss: 0.9565 - val_accuracy: 0.7291\n","\n","Epoch 00017: val_accuracy did not improve from 0.79557\n","Epoch 18/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2597 - accuracy: 0.9129 - val_loss: 0.6143 - val_accuracy: 0.8202\n","\n","Epoch 00018: val_accuracy improved from 0.79557 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.2495 - accuracy: 0.9099 - val_loss: 1.3754 - val_accuracy: 0.6700\n","\n","Epoch 00019: val_accuracy did not improve from 0.82020\n","Epoch 20/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.2755 - accuracy: 0.9105 - val_loss: 1.1393 - val_accuracy: 0.6970\n","\n","Epoch 00020: val_accuracy did not improve from 0.82020\n","Epoch 21/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2054 - accuracy: 0.9312 - val_loss: 0.7449 - val_accuracy: 0.7931\n","\n","Epoch 00021: val_accuracy did not improve from 0.82020\n","Epoch 22/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2191 - accuracy: 0.9251 - val_loss: 0.6664 - val_accuracy: 0.8005\n","\n","Epoch 00022: val_accuracy did not improve from 0.82020\n","Epoch 23/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2083 - accuracy: 0.9208 - val_loss: 1.0292 - val_accuracy: 0.7241\n","\n","Epoch 00023: val_accuracy did not improve from 0.82020\n","Epoch 24/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2109 - accuracy: 0.9281 - val_loss: 0.6856 - val_accuracy: 0.8128\n","\n","Epoch 00024: val_accuracy did not improve from 0.82020\n","Epoch 25/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1799 - accuracy: 0.9312 - val_loss: 0.5160 - val_accuracy: 0.8596\n","\n","Epoch 00025: val_accuracy improved from 0.82020 to 0.85961, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2310 - accuracy: 0.9178 - val_loss: 0.6245 - val_accuracy: 0.8374\n","\n","Epoch 00026: val_accuracy did not improve from 0.85961\n","Epoch 27/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.2080 - accuracy: 0.9263 - val_loss: 0.9684 - val_accuracy: 0.7586\n","\n","Epoch 00027: val_accuracy did not improve from 0.85961\n","Epoch 28/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2098 - accuracy: 0.9245 - val_loss: 0.5810 - val_accuracy: 0.8473\n","\n","Epoch 00028: val_accuracy did not improve from 0.85961\n","Epoch 29/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2049 - accuracy: 0.9227 - val_loss: 0.6041 - val_accuracy: 0.8251\n","\n","Epoch 00029: val_accuracy did not improve from 0.85961\n","Epoch 30/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1688 - accuracy: 0.9440 - val_loss: 0.6284 - val_accuracy: 0.8251\n","\n","Epoch 00030: val_accuracy did not improve from 0.85961\n","Epoch 31/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1483 - accuracy: 0.9495 - val_loss: 1.0940 - val_accuracy: 0.7340\n","\n","Epoch 00031: val_accuracy did not improve from 0.85961\n","Epoch 32/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1479 - accuracy: 0.9495 - val_loss: 0.6266 - val_accuracy: 0.8276\n","\n","Epoch 00032: val_accuracy did not improve from 0.85961\n","Epoch 33/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1918 - accuracy: 0.9385 - val_loss: 1.6281 - val_accuracy: 0.6847\n","\n","Epoch 00033: val_accuracy did not improve from 0.85961\n","Epoch 34/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2221 - accuracy: 0.9269 - val_loss: 0.8290 - val_accuracy: 0.7660\n","\n","Epoch 00034: val_accuracy did not improve from 0.85961\n","Epoch 35/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1340 - accuracy: 0.9531 - val_loss: 0.5985 - val_accuracy: 0.8596\n","\n","Epoch 00035: val_accuracy did not improve from 0.85961\n","Epoch 36/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1236 - accuracy: 0.9592 - val_loss: 0.3323 - val_accuracy: 0.8719\n","\n","Epoch 00036: val_accuracy improved from 0.85961 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 37/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1054 - accuracy: 0.9665 - val_loss: 0.5488 - val_accuracy: 0.8522\n","\n","Epoch 00037: val_accuracy did not improve from 0.87192\n","Epoch 38/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1068 - accuracy: 0.9598 - val_loss: 0.5854 - val_accuracy: 0.8621\n","\n","Epoch 00038: val_accuracy did not improve from 0.87192\n","Epoch 39/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1231 - accuracy: 0.9555 - val_loss: 0.6369 - val_accuracy: 0.8300\n","\n","Epoch 00039: val_accuracy did not improve from 0.87192\n","Epoch 40/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0980 - accuracy: 0.9659 - val_loss: 0.5430 - val_accuracy: 0.8571\n","\n","Epoch 00040: val_accuracy did not improve from 0.87192\n","Epoch 41/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0907 - accuracy: 0.9641 - val_loss: 0.6467 - val_accuracy: 0.8227\n","\n","Epoch 00041: val_accuracy did not improve from 0.87192\n","Epoch 42/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1016 - accuracy: 0.9683 - val_loss: 0.4028 - val_accuracy: 0.8768\n","\n","Epoch 00042: val_accuracy improved from 0.87192 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 43/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.5115 - val_accuracy: 0.8744\n","\n","Epoch 00043: val_accuracy did not improve from 0.87685\n","Epoch 44/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 0.6930 - val_accuracy: 0.8079\n","\n","Epoch 00044: val_accuracy did not improve from 0.87685\n","Epoch 45/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 0.6521 - val_accuracy: 0.8276\n","\n","Epoch 00045: val_accuracy did not improve from 0.87685\n","Epoch 46/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1599 - accuracy: 0.9470 - val_loss: 0.8214 - val_accuracy: 0.8325\n","\n","Epoch 00046: val_accuracy did not improve from 0.87685\n","Epoch 47/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1601 - accuracy: 0.9488 - val_loss: 0.5537 - val_accuracy: 0.8374\n","\n","Epoch 00047: val_accuracy did not improve from 0.87685\n","Epoch 48/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.6281 - val_accuracy: 0.8350\n","\n","Epoch 00048: val_accuracy did not improve from 0.87685\n","Epoch 49/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.4216 - val_accuracy: 0.8842\n","\n","Epoch 00049: val_accuracy improved from 0.87685 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 50/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0897 - accuracy: 0.9671 - val_loss: 0.5667 - val_accuracy: 0.8571\n","\n","Epoch 00050: val_accuracy did not improve from 0.88424\n","Epoch 51/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0650 - accuracy: 0.9793 - val_loss: 0.8088 - val_accuracy: 0.8177\n","\n","Epoch 00051: val_accuracy did not improve from 0.88424\n","Epoch 52/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1159 - accuracy: 0.9574 - val_loss: 0.3960 - val_accuracy: 0.9039\n","\n","Epoch 00052: val_accuracy improved from 0.88424 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 53/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1277 - accuracy: 0.9513 - val_loss: 0.3826 - val_accuracy: 0.9089\n","\n","Epoch 00053: val_accuracy improved from 0.90394 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 54/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.4709 - val_accuracy: 0.8768\n","\n","Epoch 00054: val_accuracy did not improve from 0.90887\n","Epoch 55/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0733 - accuracy: 0.9781 - val_loss: 0.6145 - val_accuracy: 0.8842\n","\n","Epoch 00055: val_accuracy did not improve from 0.90887\n","Epoch 56/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.3764 - val_accuracy: 0.9113\n","\n","Epoch 00056: val_accuracy improved from 0.90887 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 57/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 0.3810 - val_accuracy: 0.9039\n","\n","Epoch 00057: val_accuracy did not improve from 0.91133\n","Epoch 58/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0825 - accuracy: 0.9720 - val_loss: 0.4497 - val_accuracy: 0.8793\n","\n","Epoch 00058: val_accuracy did not improve from 0.91133\n","Epoch 59/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0655 - accuracy: 0.9793 - val_loss: 0.5657 - val_accuracy: 0.8645\n","\n","Epoch 00059: val_accuracy did not improve from 0.91133\n","Epoch 60/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0728 - accuracy: 0.9769 - val_loss: 0.6217 - val_accuracy: 0.8498\n","\n","Epoch 00060: val_accuracy did not improve from 0.91133\n","Epoch 61/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0816 - accuracy: 0.9714 - val_loss: 0.4885 - val_accuracy: 0.8695\n","\n","Epoch 00061: val_accuracy did not improve from 0.91133\n","Epoch 62/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0441 - accuracy: 0.9829 - val_loss: 0.5651 - val_accuracy: 0.8719\n","\n","Epoch 00062: val_accuracy did not improve from 0.91133\n","Epoch 63/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 0.5249 - val_accuracy: 0.8645\n","\n","Epoch 00063: val_accuracy did not improve from 0.91133\n","Epoch 64/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0613 - accuracy: 0.9756 - val_loss: 0.7269 - val_accuracy: 0.8498\n","\n","Epoch 00064: val_accuracy did not improve from 0.91133\n","Epoch 65/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0509 - accuracy: 0.9829 - val_loss: 0.5521 - val_accuracy: 0.8547\n","\n","Epoch 00065: val_accuracy did not improve from 0.91133\n","Epoch 66/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 0.4485 - val_accuracy: 0.8768\n","\n","Epoch 00066: val_accuracy did not improve from 0.91133\n","Epoch 67/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.3652 - val_accuracy: 0.9064\n","\n","Epoch 00067: val_accuracy did not improve from 0.91133\n","Epoch 68/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0671 - accuracy: 0.9781 - val_loss: 1.6076 - val_accuracy: 0.7365\n","\n","Epoch 00068: val_accuracy did not improve from 0.91133\n","Epoch 69/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1108 - accuracy: 0.9641 - val_loss: 0.4850 - val_accuracy: 0.8719\n","\n","Epoch 00069: val_accuracy did not improve from 0.91133\n","Epoch 70/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0831 - accuracy: 0.9683 - val_loss: 1.0317 - val_accuracy: 0.7882\n","\n","Epoch 00070: val_accuracy did not improve from 0.91133\n","Epoch 71/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1577 - accuracy: 0.9434 - val_loss: 0.5832 - val_accuracy: 0.8842\n","\n","Epoch 00071: val_accuracy did not improve from 0.91133\n","Epoch 72/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0740 - accuracy: 0.9732 - val_loss: 0.4834 - val_accuracy: 0.8768\n","\n","Epoch 00072: val_accuracy did not improve from 0.91133\n","Epoch 73/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0369 - accuracy: 0.9866 - val_loss: 0.4067 - val_accuracy: 0.9113\n","\n","Epoch 00073: val_accuracy did not improve from 0.91133\n","Epoch 74/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0269 - accuracy: 0.9878 - val_loss: 0.3590 - val_accuracy: 0.9015\n","\n","Epoch 00074: val_accuracy did not improve from 0.91133\n","Epoch 75/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.4700 - val_accuracy: 0.8941\n","\n","Epoch 00075: val_accuracy did not improve from 0.91133\n","Epoch 76/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.5263 - val_accuracy: 0.8695\n","\n","Epoch 00076: val_accuracy did not improve from 0.91133\n","Epoch 77/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0358 - accuracy: 0.9860 - val_loss: 0.5656 - val_accuracy: 0.8695\n","\n","Epoch 00077: val_accuracy did not improve from 0.91133\n","Epoch 78/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0722 - accuracy: 0.9756 - val_loss: 0.9317 - val_accuracy: 0.8227\n","\n","Epoch 00078: val_accuracy did not improve from 0.91133\n","Epoch 79/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0963 - accuracy: 0.9671 - val_loss: 0.8624 - val_accuracy: 0.8202\n","\n","Epoch 00079: val_accuracy did not improve from 0.91133\n","Epoch 80/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0559 - accuracy: 0.9793 - val_loss: 0.4958 - val_accuracy: 0.8793\n","\n","Epoch 00080: val_accuracy did not improve from 0.91133\n","Epoch 81/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0748 - accuracy: 0.9744 - val_loss: 0.7716 - val_accuracy: 0.8424\n","\n","Epoch 00081: val_accuracy did not improve from 0.91133\n","Epoch 82/500\n","52/52 [==============================] - 21s 397ms/step - loss: 0.0966 - accuracy: 0.9689 - val_loss: 0.7022 - val_accuracy: 0.8399\n","\n","Epoch 00082: val_accuracy did not improve from 0.91133\n","Epoch 83/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0687 - accuracy: 0.9781 - val_loss: 0.5643 - val_accuracy: 0.8571\n","\n","Epoch 00083: val_accuracy did not improve from 0.91133\n","Epoch 84/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0605 - accuracy: 0.9793 - val_loss: 0.4850 - val_accuracy: 0.8966\n","\n","Epoch 00084: val_accuracy did not improve from 0.91133\n","Epoch 85/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0645 - accuracy: 0.9817 - val_loss: 0.5358 - val_accuracy: 0.8719\n","\n","Epoch 00085: val_accuracy did not improve from 0.91133\n","Epoch 86/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.5503 - val_accuracy: 0.8670\n","\n","Epoch 00086: val_accuracy did not improve from 0.91133\n","Epoch 87/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0254 - accuracy: 0.9890 - val_loss: 0.4416 - val_accuracy: 0.8990\n","\n","Epoch 00087: val_accuracy did not improve from 0.91133\n","Epoch 88/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.3951 - val_accuracy: 0.9089\n","\n","Epoch 00088: val_accuracy did not improve from 0.91133\n","Epoch 89/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.3540 - val_accuracy: 0.9089\n","\n","Epoch 00089: val_accuracy did not improve from 0.91133\n","Epoch 90/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.4237 - val_accuracy: 0.9064\n","\n","Epoch 00090: val_accuracy did not improve from 0.91133\n","Epoch 91/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.3710 - val_accuracy: 0.9113\n","\n","Epoch 00091: val_accuracy did not improve from 0.91133\n","Epoch 92/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.7419 - val_accuracy: 0.8276\n","\n","Epoch 00092: val_accuracy did not improve from 0.91133\n","Epoch 93/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.5831 - val_accuracy: 0.8596\n","\n","Epoch 00093: val_accuracy did not improve from 0.91133\n","Epoch 94/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.5416 - val_accuracy: 0.8695\n","\n","Epoch 00094: val_accuracy did not improve from 0.91133\n","Epoch 95/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.4743 - val_accuracy: 0.8842\n","\n","Epoch 00095: val_accuracy did not improve from 0.91133\n","Epoch 96/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.5942 - val_accuracy: 0.8818\n","\n","Epoch 00096: val_accuracy did not improve from 0.91133\n","Epoch 97/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.4731 - val_accuracy: 0.9113\n","\n","Epoch 00097: val_accuracy did not improve from 0.91133\n","Epoch 98/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1245 - accuracy: 0.9622 - val_loss: 0.8657 - val_accuracy: 0.8350\n","\n","Epoch 00098: val_accuracy did not improve from 0.91133\n","Epoch 99/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.5926 - val_accuracy: 0.8744\n","\n","Epoch 00099: val_accuracy did not improve from 0.91133\n","Epoch 100/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0361 - accuracy: 0.9854 - val_loss: 0.8986 - val_accuracy: 0.8374\n","\n","Epoch 00100: val_accuracy did not improve from 0.91133\n","Epoch 101/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1056 - accuracy: 0.9665 - val_loss: 0.6569 - val_accuracy: 0.8571\n","\n","Epoch 00101: val_accuracy did not improve from 0.91133\n","Epoch 102/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0580 - accuracy: 0.9799 - val_loss: 0.6618 - val_accuracy: 0.8596\n","\n","Epoch 00102: val_accuracy did not improve from 0.91133\n","Epoch 103/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0311 - accuracy: 0.9866 - val_loss: 0.4169 - val_accuracy: 0.8966\n","\n","Epoch 00103: val_accuracy did not improve from 0.91133\n","Epoch 104/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.5059 - val_accuracy: 0.9064\n","\n","Epoch 00104: val_accuracy did not improve from 0.91133\n","Epoch 105/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 0.4796 - val_accuracy: 0.8892\n","\n","Epoch 00105: val_accuracy did not improve from 0.91133\n","Epoch 106/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0188 - accuracy: 0.9915 - val_loss: 0.4952 - val_accuracy: 0.8966\n","\n","Epoch 00106: val_accuracy did not improve from 0.91133\n","Epoch 107/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.4284 - val_accuracy: 0.9113\n","\n","Epoch 00107: val_accuracy did not improve from 0.91133\n","Epoch 108/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.4182 - val_accuracy: 0.8966\n","\n","Epoch 00108: val_accuracy did not improve from 0.91133\n","Epoch 109/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.6031 - val_accuracy: 0.8695\n","\n","Epoch 00109: val_accuracy did not improve from 0.91133\n","Epoch 110/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.5163 - val_accuracy: 0.8867\n","\n","Epoch 00110: val_accuracy did not improve from 0.91133\n","Epoch 111/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.1157 - accuracy: 0.9598 - val_loss: 0.6227 - val_accuracy: 0.8571\n","\n","Epoch 00111: val_accuracy did not improve from 0.91133\n","Epoch 112/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0518 - accuracy: 0.9805 - val_loss: 0.5278 - val_accuracy: 0.8966\n","\n","Epoch 00112: val_accuracy did not improve from 0.91133\n","Epoch 113/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.5333 - val_accuracy: 0.8768\n","\n","Epoch 00113: val_accuracy did not improve from 0.91133\n","Epoch 114/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.5286 - val_accuracy: 0.8744\n","\n","Epoch 00114: val_accuracy did not improve from 0.91133\n","Epoch 115/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0585 - accuracy: 0.9854 - val_loss: 0.6939 - val_accuracy: 0.8621\n","\n","Epoch 00115: val_accuracy did not improve from 0.91133\n","Epoch 116/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0583 - accuracy: 0.9854 - val_loss: 0.7574 - val_accuracy: 0.8645\n","\n","Epoch 00116: val_accuracy did not improve from 0.91133\n","Epoch 117/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.6683 - val_accuracy: 0.8571\n","\n","Epoch 00117: val_accuracy did not improve from 0.91133\n","Epoch 118/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.6085 - val_accuracy: 0.8818\n","\n","Epoch 00118: val_accuracy did not improve from 0.91133\n","Epoch 119/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 0.4540 - val_accuracy: 0.8916\n","\n","Epoch 00119: val_accuracy did not improve from 0.91133\n","Epoch 120/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0515 - accuracy: 0.9860 - val_loss: 0.6424 - val_accuracy: 0.8768\n","\n","Epoch 00120: val_accuracy did not improve from 0.91133\n","Epoch 121/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.4277 - val_accuracy: 0.9064\n","\n","Epoch 00121: val_accuracy did not improve from 0.91133\n","Epoch 122/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.5467 - val_accuracy: 0.8768\n","\n","Epoch 00122: val_accuracy did not improve from 0.91133\n","Epoch 123/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.4297 - val_accuracy: 0.8990\n","\n","Epoch 00123: val_accuracy did not improve from 0.91133\n","Epoch 124/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.4520 - val_accuracy: 0.8941\n","\n","Epoch 00124: val_accuracy did not improve from 0.91133\n","Epoch 125/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 0.5340 - val_accuracy: 0.8867\n","\n","Epoch 00125: val_accuracy did not improve from 0.91133\n","Epoch 126/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.4724 - val_accuracy: 0.9064\n","\n","Epoch 00126: val_accuracy did not improve from 0.91133\n","Epoch 127/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.4421 - val_accuracy: 0.8892\n","\n","Epoch 00127: val_accuracy did not improve from 0.91133\n","Epoch 128/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.3918 - val_accuracy: 0.9015\n","\n","Epoch 00128: val_accuracy did not improve from 0.91133\n","Epoch 129/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4044 - val_accuracy: 0.9163\n","\n","Epoch 00129: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 130/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4121 - val_accuracy: 0.8966\n","\n","Epoch 00130: val_accuracy did not improve from 0.91626\n","Epoch 131/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0404 - accuracy: 0.9884 - val_loss: 0.6347 - val_accuracy: 0.8670\n","\n","Epoch 00131: val_accuracy did not improve from 0.91626\n","Epoch 132/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 1.1025 - val_accuracy: 0.8276\n","\n","Epoch 00132: val_accuracy did not improve from 0.91626\n","Epoch 133/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 1.0020 - val_accuracy: 0.8177\n","\n","Epoch 00133: val_accuracy did not improve from 0.91626\n","Epoch 134/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.6071 - val_accuracy: 0.8842\n","\n","Epoch 00134: val_accuracy did not improve from 0.91626\n","Epoch 135/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0893 - accuracy: 0.9726 - val_loss: 0.7635 - val_accuracy: 0.8547\n","\n","Epoch 00135: val_accuracy did not improve from 0.91626\n","Epoch 136/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0668 - accuracy: 0.9805 - val_loss: 0.6975 - val_accuracy: 0.8424\n","\n","Epoch 00136: val_accuracy did not improve from 0.91626\n","Epoch 137/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.4624 - val_accuracy: 0.9039\n","\n","Epoch 00137: val_accuracy did not improve from 0.91626\n","Epoch 138/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.7446 - val_accuracy: 0.8448\n","\n","Epoch 00138: val_accuracy did not improve from 0.91626\n","Epoch 139/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.6946 - val_accuracy: 0.8596\n","\n","Epoch 00139: val_accuracy did not improve from 0.91626\n","Epoch 140/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.6984 - val_accuracy: 0.8374\n","\n","Epoch 00140: val_accuracy did not improve from 0.91626\n","Epoch 141/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.6611 - val_accuracy: 0.8621\n","\n","Epoch 00141: val_accuracy did not improve from 0.91626\n","Epoch 142/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.5442 - val_accuracy: 0.8818\n","\n","Epoch 00142: val_accuracy did not improve from 0.91626\n","Epoch 143/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0263 - accuracy: 0.9890 - val_loss: 0.6556 - val_accuracy: 0.8916\n","\n","Epoch 00143: val_accuracy did not improve from 0.91626\n","Epoch 144/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0168 - accuracy: 0.9970 - val_loss: 0.4587 - val_accuracy: 0.9113\n","\n","Epoch 00144: val_accuracy did not improve from 0.91626\n","Epoch 145/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.8637 - val_accuracy: 0.8424\n","\n","Epoch 00145: val_accuracy did not improve from 0.91626\n","Epoch 146/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.5923 - val_accuracy: 0.8892\n","\n","Epoch 00146: val_accuracy did not improve from 0.91626\n","Epoch 147/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.6098 - val_accuracy: 0.8990\n","\n","Epoch 00147: val_accuracy did not improve from 0.91626\n","Epoch 148/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.4502 - val_accuracy: 0.8990\n","\n","Epoch 00148: val_accuracy did not improve from 0.91626\n","Epoch 149/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.4696 - val_accuracy: 0.9039\n","\n","Epoch 00149: val_accuracy did not improve from 0.91626\n","Epoch 150/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4534 - val_accuracy: 0.9138\n","\n","Epoch 00150: val_accuracy did not improve from 0.91626\n","Epoch 151/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4612 - val_accuracy: 0.9187\n","\n","Epoch 00151: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 152/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4675 - val_accuracy: 0.9015\n","\n","Epoch 00152: val_accuracy did not improve from 0.91872\n","Epoch 153/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.4785 - val_accuracy: 0.9163\n","\n","Epoch 00153: val_accuracy did not improve from 0.91872\n","Epoch 154/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.4938 - val_accuracy: 0.9163\n","\n","Epoch 00154: val_accuracy did not improve from 0.91872\n","Epoch 155/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4300 - val_accuracy: 0.9163\n","\n","Epoch 00155: val_accuracy did not improve from 0.91872\n","Epoch 156/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4031 - val_accuracy: 0.9187\n","\n","Epoch 00156: val_accuracy did not improve from 0.91872\n","Epoch 157/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9212\n","\n","Epoch 00157: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 158/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.4163 - val_accuracy: 0.9138\n","\n","Epoch 00158: val_accuracy did not improve from 0.92118\n","Epoch 159/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.4886 - val_accuracy: 0.8966\n","\n","Epoch 00159: val_accuracy did not improve from 0.92118\n","Epoch 160/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.5293 - val_accuracy: 0.8892\n","\n","Epoch 00160: val_accuracy did not improve from 0.92118\n","Epoch 161/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0539 - accuracy: 0.9854 - val_loss: 0.6671 - val_accuracy: 0.8547\n","\n","Epoch 00161: val_accuracy did not improve from 0.92118\n","Epoch 162/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 0.8575 - val_accuracy: 0.8399\n","\n","Epoch 00162: val_accuracy did not improve from 0.92118\n","Epoch 163/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.1157 - accuracy: 0.9714 - val_loss: 0.6937 - val_accuracy: 0.8621\n","\n","Epoch 00163: val_accuracy did not improve from 0.92118\n","Epoch 164/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.4785 - val_accuracy: 0.9015\n","\n","Epoch 00164: val_accuracy did not improve from 0.92118\n","Epoch 165/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.5762 - val_accuracy: 0.8670\n","\n","Epoch 00165: val_accuracy did not improve from 0.92118\n","Epoch 166/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.9282 - val_accuracy: 0.8276\n","\n","Epoch 00166: val_accuracy did not improve from 0.92118\n","Epoch 167/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.5353 - val_accuracy: 0.8990\n","\n","Epoch 00167: val_accuracy did not improve from 0.92118\n","Epoch 168/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.5028 - val_accuracy: 0.8892\n","\n","Epoch 00168: val_accuracy did not improve from 0.92118\n","Epoch 169/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 0.3979 - val_accuracy: 0.9113\n","\n","Epoch 00169: val_accuracy did not improve from 0.92118\n","Epoch 170/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.5039 - val_accuracy: 0.9015\n","\n","Epoch 00170: val_accuracy did not improve from 0.92118\n","Epoch 171/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4527 - val_accuracy: 0.9064\n","\n","Epoch 00171: val_accuracy did not improve from 0.92118\n","Epoch 172/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.5410 - val_accuracy: 0.8966\n","\n","Epoch 00172: val_accuracy did not improve from 0.92118\n","Epoch 173/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.7032 - val_accuracy: 0.8719\n","\n","Epoch 00173: val_accuracy did not improve from 0.92118\n","Epoch 174/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.5076 - val_accuracy: 0.8916\n","\n","Epoch 00174: val_accuracy did not improve from 0.92118\n","Epoch 175/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.7613 - val_accuracy: 0.8374\n","\n","Epoch 00175: val_accuracy did not improve from 0.92118\n","Epoch 176/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.5902 - val_accuracy: 0.8793\n","\n","Epoch 00176: val_accuracy did not improve from 0.92118\n","Epoch 177/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.8386 - val_accuracy: 0.8768\n","\n","Epoch 00177: val_accuracy did not improve from 0.92118\n","Epoch 178/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 1.3816 - val_accuracy: 0.7759\n","\n","Epoch 00178: val_accuracy did not improve from 0.92118\n","Epoch 179/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.6002 - val_accuracy: 0.8916\n","\n","Epoch 00179: val_accuracy did not improve from 0.92118\n","Epoch 180/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.4014 - val_accuracy: 0.8990\n","\n","Epoch 00180: val_accuracy did not improve from 0.92118\n","Epoch 181/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.3751 - val_accuracy: 0.9039\n","\n","Epoch 00181: val_accuracy did not improve from 0.92118\n","Epoch 182/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9113\n","\n","Epoch 00182: val_accuracy did not improve from 0.92118\n","Epoch 183/500\n","52/52 [==============================] - 20s 383ms/step - loss: 8.0277e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9163\n","\n","Epoch 00183: val_accuracy did not improve from 0.92118\n","Epoch 184/500\n","52/52 [==============================] - 20s 384ms/step - loss: 9.2363e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9113\n","\n","Epoch 00184: val_accuracy did not improve from 0.92118\n","Epoch 185/500\n","52/52 [==============================] - 20s 383ms/step - loss: 6.4783e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9236\n","\n","Epoch 00185: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 186/500\n","52/52 [==============================] - 20s 383ms/step - loss: 2.7046e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9212\n","\n","Epoch 00186: val_accuracy did not improve from 0.92365\n","Epoch 187/500\n","52/52 [==============================] - 20s 384ms/step - loss: 5.2662e-04 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9286\n","\n","Epoch 00187: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 188/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3966 - val_accuracy: 0.9015\n","\n","Epoch 00188: val_accuracy did not improve from 0.92857\n","Epoch 189/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.6193 - val_accuracy: 0.8793\n","\n","Epoch 00189: val_accuracy did not improve from 0.92857\n","Epoch 190/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.7644 - val_accuracy: 0.8744\n","\n","Epoch 00190: val_accuracy did not improve from 0.92857\n","Epoch 191/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0161 - accuracy: 0.9927 - val_loss: 0.8271 - val_accuracy: 0.8571\n","\n","Epoch 00191: val_accuracy did not improve from 0.92857\n","Epoch 192/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.7726 - val_accuracy: 0.8547\n","\n","Epoch 00192: val_accuracy did not improve from 0.92857\n","Epoch 193/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 1.6165 - val_accuracy: 0.8079\n","\n","Epoch 00193: val_accuracy did not improve from 0.92857\n","Epoch 194/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0529 - accuracy: 0.9793 - val_loss: 0.8745 - val_accuracy: 0.8350\n","\n","Epoch 00194: val_accuracy did not improve from 0.92857\n","Epoch 195/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0508 - accuracy: 0.9872 - val_loss: 0.7905 - val_accuracy: 0.8571\n","\n","Epoch 00195: val_accuracy did not improve from 0.92857\n","Epoch 196/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0528 - accuracy: 0.9799 - val_loss: 0.8067 - val_accuracy: 0.8498\n","\n","Epoch 00196: val_accuracy did not improve from 0.92857\n","Epoch 197/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.6262 - val_accuracy: 0.8768\n","\n","Epoch 00197: val_accuracy did not improve from 0.92857\n","Epoch 198/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 0.9865 - val_accuracy: 0.7660\n","\n","Epoch 00198: val_accuracy did not improve from 0.92857\n","Epoch 199/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.5051 - val_accuracy: 0.9064\n","\n","Epoch 00199: val_accuracy did not improve from 0.92857\n","Epoch 200/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.5542 - val_accuracy: 0.8966\n","\n","Epoch 00200: val_accuracy did not improve from 0.92857\n","Epoch 201/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.5040 - val_accuracy: 0.8867\n","\n","Epoch 00201: val_accuracy did not improve from 0.92857\n","Epoch 202/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.4780 - val_accuracy: 0.9015\n","\n","Epoch 00202: val_accuracy did not improve from 0.92857\n","Epoch 203/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4828 - val_accuracy: 0.9138\n","\n","Epoch 00203: val_accuracy did not improve from 0.92857\n","Epoch 204/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5094 - val_accuracy: 0.9064\n","\n","Epoch 00204: val_accuracy did not improve from 0.92857\n","Epoch 205/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5664 - val_accuracy: 0.8818\n","\n","Epoch 00205: val_accuracy did not improve from 0.92857\n","Epoch 206/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.6114 - val_accuracy: 0.8867\n","\n","Epoch 00206: val_accuracy did not improve from 0.92857\n","Epoch 207/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5939 - val_accuracy: 0.8842\n","\n","Epoch 00207: val_accuracy did not improve from 0.92857\n","Epoch 208/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5531 - val_accuracy: 0.9015\n","\n","Epoch 00208: val_accuracy did not improve from 0.92857\n","Epoch 209/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.5966 - val_accuracy: 0.8768\n","\n","Epoch 00209: val_accuracy did not improve from 0.92857\n","Epoch 210/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5098 - val_accuracy: 0.8916\n","\n","Epoch 00210: val_accuracy did not improve from 0.92857\n","Epoch 211/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4518 - val_accuracy: 0.9064\n","\n","Epoch 00211: val_accuracy did not improve from 0.92857\n","Epoch 212/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5213 - val_accuracy: 0.9113\n","\n","Epoch 00212: val_accuracy did not improve from 0.92857\n","Epoch 213/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5424 - val_accuracy: 0.8966\n","\n","Epoch 00213: val_accuracy did not improve from 0.92857\n","Epoch 214/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9236\n","\n","Epoch 00214: val_accuracy did not improve from 0.92857\n","Epoch 215/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5591 - val_accuracy: 0.8990\n","\n","Epoch 00215: val_accuracy did not improve from 0.92857\n","Epoch 216/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.6405e-04 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9015\n","\n","Epoch 00216: val_accuracy did not improve from 0.92857\n","Epoch 217/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.7321 - val_accuracy: 0.8892\n","\n","Epoch 00217: val_accuracy did not improve from 0.92857\n","Epoch 218/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5837 - val_accuracy: 0.8768\n","\n","Epoch 00218: val_accuracy did not improve from 0.92857\n","Epoch 219/500\n","52/52 [==============================] - 21s 398ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.7085 - val_accuracy: 0.8867\n","\n","Epoch 00219: val_accuracy did not improve from 0.92857\n","Epoch 220/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.6401 - val_accuracy: 0.8916\n","\n","Epoch 00220: val_accuracy did not improve from 0.92857\n","Epoch 221/500\n","52/52 [==============================] - 21s 399ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6928 - val_accuracy: 0.8842\n","\n","Epoch 00221: val_accuracy did not improve from 0.92857\n","Epoch 222/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.8322 - val_accuracy: 0.8645\n","\n","Epoch 00222: val_accuracy did not improve from 0.92857\n","Epoch 223/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0568 - accuracy: 0.9848 - val_loss: 0.9857 - val_accuracy: 0.8374\n","\n","Epoch 00223: val_accuracy did not improve from 0.92857\n","Epoch 224/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.6091 - val_accuracy: 0.8793\n","\n","Epoch 00224: val_accuracy did not improve from 0.92857\n","Epoch 225/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.5216 - val_accuracy: 0.9015\n","\n","Epoch 00225: val_accuracy did not improve from 0.92857\n","Epoch 226/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5091 - val_accuracy: 0.9015\n","\n","Epoch 00226: val_accuracy did not improve from 0.92857\n","Epoch 227/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5782 - val_accuracy: 0.9064\n","\n","Epoch 00227: val_accuracy did not improve from 0.92857\n","Epoch 228/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.6186 - val_accuracy: 0.8941\n","\n","Epoch 00228: val_accuracy did not improve from 0.92857\n","Epoch 229/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.5726 - val_accuracy: 0.8842\n","\n","Epoch 00229: val_accuracy did not improve from 0.92857\n","Epoch 230/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 3.1110 - val_accuracy: 0.6379\n","\n","Epoch 00230: val_accuracy did not improve from 0.92857\n","Epoch 231/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0495 - accuracy: 0.9860 - val_loss: 0.7630 - val_accuracy: 0.8522\n","\n","Epoch 00231: val_accuracy did not improve from 0.92857\n","Epoch 232/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0432 - accuracy: 0.9848 - val_loss: 0.9194 - val_accuracy: 0.8424\n","\n","Epoch 00232: val_accuracy did not improve from 0.92857\n","Epoch 233/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.7066 - val_accuracy: 0.8744\n","\n","Epoch 00233: val_accuracy did not improve from 0.92857\n","Epoch 234/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0314 - accuracy: 0.9878 - val_loss: 0.7357 - val_accuracy: 0.8498\n","\n","Epoch 00234: val_accuracy did not improve from 0.92857\n","Epoch 235/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.7667 - val_accuracy: 0.8498\n","\n","Epoch 00235: val_accuracy did not improve from 0.92857\n","Epoch 236/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0200 - accuracy: 0.9921 - val_loss: 0.6683 - val_accuracy: 0.8793\n","\n","Epoch 00236: val_accuracy did not improve from 0.92857\n","Epoch 237/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.5690 - val_accuracy: 0.9089\n","\n","Epoch 00237: val_accuracy did not improve from 0.92857\n","Epoch 238/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.5675 - val_accuracy: 0.8842\n","\n","Epoch 00238: val_accuracy did not improve from 0.92857\n","Epoch 239/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4878 - val_accuracy: 0.9113\n","\n","Epoch 00239: val_accuracy did not improve from 0.92857\n","Epoch 240/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5123 - val_accuracy: 0.9113\n","\n","Epoch 00240: val_accuracy did not improve from 0.92857\n","Epoch 241/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4217 - val_accuracy: 0.9212\n","\n","Epoch 00241: val_accuracy did not improve from 0.92857\n","Epoch 242/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5091 - val_accuracy: 0.8818\n","\n","Epoch 00242: val_accuracy did not improve from 0.92857\n","Epoch 243/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.7971 - val_accuracy: 0.8719\n","\n","Epoch 00243: val_accuracy did not improve from 0.92857\n","Epoch 244/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.7489 - val_accuracy: 0.8596\n","\n","Epoch 00244: val_accuracy did not improve from 0.92857\n","Epoch 245/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.6366 - val_accuracy: 0.9039\n","\n","Epoch 00245: val_accuracy did not improve from 0.92857\n","Epoch 246/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5025 - val_accuracy: 0.9015\n","\n","Epoch 00246: val_accuracy did not improve from 0.92857\n","Epoch 247/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.8569 - val_accuracy: 0.8645\n","\n","Epoch 00247: val_accuracy did not improve from 0.92857\n","Epoch 248/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5965 - val_accuracy: 0.8645\n","\n","Epoch 00248: val_accuracy did not improve from 0.92857\n","Epoch 249/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0130 - accuracy: 0.9945 - val_loss: 0.5404 - val_accuracy: 0.8842\n","\n","Epoch 00249: val_accuracy did not improve from 0.92857\n","Epoch 250/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 1.0632 - val_accuracy: 0.8202\n","\n","Epoch 00250: val_accuracy did not improve from 0.92857\n","Epoch 251/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1270 - accuracy: 0.9677 - val_loss: 4.0686 - val_accuracy: 0.5394\n","\n","Epoch 00251: val_accuracy did not improve from 0.92857\n","Epoch 252/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1140 - accuracy: 0.9659 - val_loss: 1.6405 - val_accuracy: 0.7685\n","\n","Epoch 00252: val_accuracy did not improve from 0.92857\n","Epoch 253/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 1.0809 - val_accuracy: 0.8547\n","\n","Epoch 00253: val_accuracy did not improve from 0.92857\n","Epoch 254/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 0.4780 - val_accuracy: 0.9089\n","\n","Epoch 00254: val_accuracy did not improve from 0.92857\n","Epoch 255/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.5101 - val_accuracy: 0.8818\n","\n","Epoch 00255: val_accuracy did not improve from 0.92857\n","Epoch 256/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.4515 - val_accuracy: 0.8966\n","\n","Epoch 00256: val_accuracy did not improve from 0.92857\n","Epoch 257/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4764 - val_accuracy: 0.9015\n","\n","Epoch 00257: val_accuracy did not improve from 0.92857\n","Epoch 258/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4387 - val_accuracy: 0.9138\n","\n","Epoch 00258: val_accuracy did not improve from 0.92857\n","Epoch 259/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4917 - val_accuracy: 0.9064\n","\n","Epoch 00259: val_accuracy did not improve from 0.92857\n","Epoch 260/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9187\n","\n","Epoch 00260: val_accuracy did not improve from 0.92857\n","Epoch 261/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3858 - val_accuracy: 0.9212\n","\n","Epoch 00261: val_accuracy did not improve from 0.92857\n","Epoch 262/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5406 - val_accuracy: 0.8990\n","\n","Epoch 00262: val_accuracy did not improve from 0.92857\n","Epoch 263/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9015\n","\n","Epoch 00263: val_accuracy did not improve from 0.92857\n","Epoch 264/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4333 - val_accuracy: 0.9261\n","\n","Epoch 00264: val_accuracy did not improve from 0.92857\n","Epoch 265/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.4229e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9187\n","\n","Epoch 00265: val_accuracy did not improve from 0.92857\n","Epoch 266/500\n","52/52 [==============================] - 20s 383ms/step - loss: 9.3162e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9113\n","\n","Epoch 00266: val_accuracy did not improve from 0.92857\n","Epoch 267/500\n","52/52 [==============================] - 20s 383ms/step - loss: 3.4905e-04 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9039\n","\n","Epoch 00267: val_accuracy did not improve from 0.92857\n","Epoch 268/500\n","52/52 [==============================] - 20s 383ms/step - loss: 3.0407e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9212\n","\n","Epoch 00268: val_accuracy did not improve from 0.92857\n","Epoch 269/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.2322e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9187\n","\n","Epoch 00269: val_accuracy did not improve from 0.92857\n","Epoch 270/500\n","52/52 [==============================] - 20s 383ms/step - loss: 5.1546e-04 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9187\n","\n","Epoch 00270: val_accuracy did not improve from 0.92857\n","Epoch 271/500\n","52/52 [==============================] - 20s 384ms/step - loss: 3.4129e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9163\n","\n","Epoch 00271: val_accuracy did not improve from 0.92857\n","Epoch 272/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.2615e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9113\n","\n","Epoch 00272: val_accuracy did not improve from 0.92857\n","Epoch 273/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.7175 - val_accuracy: 0.8744\n","\n","Epoch 00273: val_accuracy did not improve from 0.92857\n","Epoch 274/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0313 - accuracy: 0.9921 - val_loss: 1.0420 - val_accuracy: 0.7833\n","\n","Epoch 00274: val_accuracy did not improve from 0.92857\n","Epoch 275/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.5897 - val_accuracy: 0.8867\n","\n","Epoch 00275: val_accuracy did not improve from 0.92857\n","Epoch 276/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.4948 - val_accuracy: 0.9015\n","\n","Epoch 00276: val_accuracy did not improve from 0.92857\n","Epoch 277/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5169 - val_accuracy: 0.9015\n","\n","Epoch 00277: val_accuracy did not improve from 0.92857\n","Epoch 278/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6196 - val_accuracy: 0.9064\n","\n","Epoch 00278: val_accuracy did not improve from 0.92857\n","Epoch 279/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.6204 - val_accuracy: 0.8916\n","\n","Epoch 00279: val_accuracy did not improve from 0.92857\n","Epoch 280/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9236\n","\n","Epoch 00280: val_accuracy did not improve from 0.92857\n","Epoch 281/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5838 - val_accuracy: 0.8990\n","\n","Epoch 00281: val_accuracy did not improve from 0.92857\n","Epoch 282/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 0.8195 - val_accuracy: 0.8867\n","\n","Epoch 00282: val_accuracy did not improve from 0.92857\n","Epoch 283/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0553 - accuracy: 0.9854 - val_loss: 0.9347 - val_accuracy: 0.8596\n","\n","Epoch 00283: val_accuracy did not improve from 0.92857\n","Epoch 284/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.4728 - val_accuracy: 0.9015\n","\n","Epoch 00284: val_accuracy did not improve from 0.92857\n","Epoch 285/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.6427 - val_accuracy: 0.8941\n","\n","Epoch 00285: val_accuracy did not improve from 0.92857\n","Epoch 286/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0411 - accuracy: 0.9823 - val_loss: 0.6662 - val_accuracy: 0.8695\n","\n","Epoch 00286: val_accuracy did not improve from 0.92857\n","Epoch 287/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.4103 - val_accuracy: 0.9015\n","\n","Epoch 00287: val_accuracy did not improve from 0.92857\n","Epoch 288/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.5369 - val_accuracy: 0.8990\n","\n","Epoch 00288: val_accuracy did not improve from 0.92857\n","Epoch 289/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4246 - val_accuracy: 0.9261\n","\n","Epoch 00289: val_accuracy did not improve from 0.92857\n","Epoch 290/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5385 - val_accuracy: 0.8990\n","\n","Epoch 00290: val_accuracy did not improve from 0.92857\n","Epoch 291/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5665 - val_accuracy: 0.8842\n","\n","Epoch 00291: val_accuracy did not improve from 0.92857\n","Epoch 292/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.4540 - val_accuracy: 0.9212\n","\n","Epoch 00292: val_accuracy did not improve from 0.92857\n","Epoch 293/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.6814 - val_accuracy: 0.8793\n","\n","Epoch 00293: val_accuracy did not improve from 0.92857\n","Epoch 294/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3827 - val_accuracy: 0.9261\n","\n","Epoch 00294: val_accuracy did not improve from 0.92857\n","Epoch 295/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9236\n","\n","Epoch 00295: val_accuracy did not improve from 0.92857\n","Epoch 296/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9236\n","\n","Epoch 00296: val_accuracy did not improve from 0.92857\n","Epoch 297/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.8372e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9261\n","\n","Epoch 00297: val_accuracy did not improve from 0.92857\n","Epoch 298/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4542 - val_accuracy: 0.9138\n","\n","Epoch 00298: val_accuracy did not improve from 0.92857\n","Epoch 299/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4475 - val_accuracy: 0.9187\n","\n","Epoch 00299: val_accuracy did not improve from 0.92857\n","Epoch 300/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5298 - val_accuracy: 0.9039\n","\n","Epoch 00300: val_accuracy did not improve from 0.92857\n","Epoch 301/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0406 - accuracy: 0.9909 - val_loss: 0.9707 - val_accuracy: 0.7980\n","\n","Epoch 00301: val_accuracy did not improve from 0.92857\n","Epoch 302/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6246 - val_accuracy: 0.9015\n","\n","Epoch 00302: val_accuracy did not improve from 0.92857\n","Epoch 303/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9212\n","\n","Epoch 00303: val_accuracy did not improve from 0.92857\n","Epoch 304/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4501 - val_accuracy: 0.9138\n","\n","Epoch 00304: val_accuracy did not improve from 0.92857\n","Epoch 305/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.4809 - val_accuracy: 0.9064\n","\n","Epoch 00305: val_accuracy did not improve from 0.92857\n","Epoch 306/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4482 - val_accuracy: 0.9187\n","\n","Epoch 00306: val_accuracy did not improve from 0.92857\n","Epoch 307/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6563 - val_accuracy: 0.8990\n","\n","Epoch 00307: val_accuracy did not improve from 0.92857\n","Epoch 308/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0329 - accuracy: 0.9927 - val_loss: 0.8623 - val_accuracy: 0.8719\n","\n","Epoch 00308: val_accuracy did not improve from 0.92857\n","Epoch 309/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.7087 - val_accuracy: 0.8522\n","\n","Epoch 00309: val_accuracy did not improve from 0.92857\n","Epoch 310/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.5613 - val_accuracy: 0.8744\n","\n","Epoch 00310: val_accuracy did not improve from 0.92857\n","Epoch 311/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0496 - accuracy: 0.9854 - val_loss: 0.8541 - val_accuracy: 0.8202\n","\n","Epoch 00311: val_accuracy did not improve from 0.92857\n","Epoch 312/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 1.0465 - val_accuracy: 0.8300\n","\n","Epoch 00312: val_accuracy did not improve from 0.92857\n","Epoch 313/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.6982 - val_accuracy: 0.8892\n","\n","Epoch 00313: val_accuracy did not improve from 0.92857\n","Epoch 314/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.5094 - val_accuracy: 0.9015\n","\n","Epoch 00314: val_accuracy did not improve from 0.92857\n","Epoch 315/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0510 - accuracy: 0.9878 - val_loss: 0.5027 - val_accuracy: 0.9113\n","\n","Epoch 00315: val_accuracy did not improve from 0.92857\n","Epoch 316/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.4764 - val_accuracy: 0.9138\n","\n","Epoch 00316: val_accuracy did not improve from 0.92857\n","Epoch 317/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4886 - val_accuracy: 0.8941\n","\n","Epoch 00317: val_accuracy did not improve from 0.92857\n","Epoch 318/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4498 - val_accuracy: 0.9212\n","\n","Epoch 00318: val_accuracy did not improve from 0.92857\n","Epoch 319/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4668 - val_accuracy: 0.9187\n","\n","Epoch 00319: val_accuracy did not improve from 0.92857\n","Epoch 320/500\n","52/52 [==============================] - 20s 384ms/step - loss: 9.9606e-04 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9138\n","\n","Epoch 00320: val_accuracy did not improve from 0.92857\n","Epoch 321/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9236\n","\n","Epoch 00321: val_accuracy did not improve from 0.92857\n","Epoch 322/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.6285 - val_accuracy: 0.8818\n","\n","Epoch 00322: val_accuracy did not improve from 0.92857\n","Epoch 323/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6111 - val_accuracy: 0.8966\n","\n","Epoch 00323: val_accuracy did not improve from 0.92857\n","Epoch 324/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.6103 - val_accuracy: 0.8916\n","\n","Epoch 00324: val_accuracy did not improve from 0.92857\n","Epoch 325/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4869 - val_accuracy: 0.9138\n","\n","Epoch 00325: val_accuracy did not improve from 0.92857\n","Epoch 326/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4008 - val_accuracy: 0.9138\n","\n","Epoch 00326: val_accuracy did not improve from 0.92857\n","Epoch 327/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.6185 - val_accuracy: 0.8867\n","\n","Epoch 00327: val_accuracy did not improve from 0.92857\n","Epoch 328/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5503 - val_accuracy: 0.9089\n","\n","Epoch 00328: val_accuracy did not improve from 0.92857\n","Epoch 329/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.6141 - val_accuracy: 0.8966\n","\n","Epoch 00329: val_accuracy did not improve from 0.92857\n","Epoch 330/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5449 - val_accuracy: 0.9039\n","\n","Epoch 00330: val_accuracy did not improve from 0.92857\n","Epoch 331/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5602 - val_accuracy: 0.9039\n","\n","Epoch 00331: val_accuracy did not improve from 0.92857\n","Epoch 332/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9335\n","\n","Epoch 00332: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 333/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5695 - val_accuracy: 0.8892\n","\n","Epoch 00333: val_accuracy did not improve from 0.93350\n","Epoch 334/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5219 - val_accuracy: 0.8916\n","\n","Epoch 00334: val_accuracy did not improve from 0.93350\n","Epoch 335/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5954 - val_accuracy: 0.8941\n","\n","Epoch 00335: val_accuracy did not improve from 0.93350\n","Epoch 336/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5772 - val_accuracy: 0.8916\n","\n","Epoch 00336: val_accuracy did not improve from 0.93350\n","Epoch 337/500\n","52/52 [==============================] - 20s 383ms/step - loss: 8.8878e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9089\n","\n","Epoch 00337: val_accuracy did not improve from 0.93350\n","Epoch 338/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9212\n","\n","Epoch 00338: val_accuracy did not improve from 0.93350\n","Epoch 339/500\n","52/52 [==============================] - 20s 384ms/step - loss: 4.5280e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9236\n","\n","Epoch 00339: val_accuracy did not improve from 0.93350\n","Epoch 340/500\n","52/52 [==============================] - 20s 383ms/step - loss: 5.5511e-04 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9138\n","\n","Epoch 00340: val_accuracy did not improve from 0.93350\n","Epoch 341/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.2677e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9039\n","\n","Epoch 00341: val_accuracy did not improve from 0.93350\n","Epoch 342/500\n","52/52 [==============================] - 20s 384ms/step - loss: 4.0690e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9163\n","\n","Epoch 00342: val_accuracy did not improve from 0.93350\n","Epoch 343/500\n","52/52 [==============================] - 20s 384ms/step - loss: 5.6552e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9163\n","\n","Epoch 00343: val_accuracy did not improve from 0.93350\n","Epoch 344/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.7475e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9236\n","\n","Epoch 00344: val_accuracy did not improve from 0.93350\n","Epoch 345/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.0031e-04 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9212\n","\n","Epoch 00345: val_accuracy did not improve from 0.93350\n","Epoch 346/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.9127e-04 - accuracy: 0.9994 - val_loss: 0.4898 - val_accuracy: 0.9212\n","\n","Epoch 00346: val_accuracy did not improve from 0.93350\n","Epoch 347/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6566 - val_accuracy: 0.8941\n","\n","Epoch 00347: val_accuracy did not improve from 0.93350\n","Epoch 348/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4706 - val_accuracy: 0.9163\n","\n","Epoch 00348: val_accuracy did not improve from 0.93350\n","Epoch 349/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.9862 - val_accuracy: 0.8424\n","\n","Epoch 00349: val_accuracy did not improve from 0.93350\n","Epoch 350/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0850 - accuracy: 0.9769 - val_loss: 0.9629 - val_accuracy: 0.8227\n","\n","Epoch 00350: val_accuracy did not improve from 0.93350\n","Epoch 351/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 1.7312 - val_accuracy: 0.7340\n","\n","Epoch 00351: val_accuracy did not improve from 0.93350\n","Epoch 352/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 1.0496 - val_accuracy: 0.8547\n","\n","Epoch 00352: val_accuracy did not improve from 0.93350\n","Epoch 353/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.7537 - val_accuracy: 0.8473\n","\n","Epoch 00353: val_accuracy did not improve from 0.93350\n","Epoch 354/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4850 - val_accuracy: 0.9113\n","\n","Epoch 00354: val_accuracy did not improve from 0.93350\n","Epoch 355/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.6661 - val_accuracy: 0.8744\n","\n","Epoch 00355: val_accuracy did not improve from 0.93350\n","Epoch 356/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.4911 - val_accuracy: 0.8867\n","\n","Epoch 00356: val_accuracy did not improve from 0.93350\n","Epoch 357/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4713 - val_accuracy: 0.9039\n","\n","Epoch 00357: val_accuracy did not improve from 0.93350\n","Epoch 358/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9310\n","\n","Epoch 00358: val_accuracy did not improve from 0.93350\n","Epoch 359/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9212\n","\n","Epoch 00359: val_accuracy did not improve from 0.93350\n","Epoch 360/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9335\n","\n","Epoch 00360: val_accuracy did not improve from 0.93350\n","Epoch 361/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4062 - val_accuracy: 0.9212\n","\n","Epoch 00361: val_accuracy did not improve from 0.93350\n","Epoch 362/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.5267 - val_accuracy: 0.9113\n","\n","Epoch 00362: val_accuracy did not improve from 0.93350\n","Epoch 363/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.4650 - val_accuracy: 0.9212\n","\n","Epoch 00363: val_accuracy did not improve from 0.93350\n","Epoch 364/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9163\n","\n","Epoch 00364: val_accuracy did not improve from 0.93350\n","Epoch 365/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.9266e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9138\n","\n","Epoch 00365: val_accuracy did not improve from 0.93350\n","Epoch 366/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.3065e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9089\n","\n","Epoch 00366: val_accuracy did not improve from 0.93350\n","Epoch 367/500\n","52/52 [==============================] - 20s 385ms/step - loss: 5.0842e-04 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9187\n","\n","Epoch 00367: val_accuracy did not improve from 0.93350\n","Epoch 368/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.6433e-04 - accuracy: 1.0000 - val_loss: 0.5693 - val_accuracy: 0.8990\n","\n","Epoch 00368: val_accuracy did not improve from 0.93350\n","Epoch 369/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4742 - val_accuracy: 0.9113\n","\n","Epoch 00369: val_accuracy did not improve from 0.93350\n","Epoch 370/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.5061e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9138\n","\n","Epoch 00370: val_accuracy did not improve from 0.93350\n","Epoch 371/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.1707e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9089\n","\n","Epoch 00371: val_accuracy did not improve from 0.93350\n","Epoch 372/500\n","52/52 [==============================] - 20s 385ms/step - loss: 3.4902e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.9089\n","\n","Epoch 00372: val_accuracy did not improve from 0.93350\n","Epoch 373/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0246 - accuracy: 0.9957 - val_loss: 1.0540 - val_accuracy: 0.8695\n","\n","Epoch 00373: val_accuracy did not improve from 0.93350\n","Epoch 374/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.9573 - val_accuracy: 0.8399\n","\n","Epoch 00374: val_accuracy did not improve from 0.93350\n","Epoch 375/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0255 - accuracy: 0.9890 - val_loss: 0.6572 - val_accuracy: 0.8818\n","\n","Epoch 00375: val_accuracy did not improve from 0.93350\n","Epoch 376/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6287 - val_accuracy: 0.8842\n","\n","Epoch 00376: val_accuracy did not improve from 0.93350\n","Epoch 377/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 1.2884 - val_accuracy: 0.8473\n","\n","Epoch 00377: val_accuracy did not improve from 0.93350\n","Epoch 378/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.8678 - val_accuracy: 0.8473\n","\n","Epoch 00378: val_accuracy did not improve from 0.93350\n","Epoch 379/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0185 - accuracy: 0.9921 - val_loss: 0.6485 - val_accuracy: 0.8867\n","\n","Epoch 00379: val_accuracy did not improve from 0.93350\n","Epoch 380/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4756 - val_accuracy: 0.9138\n","\n","Epoch 00380: val_accuracy did not improve from 0.93350\n","Epoch 381/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.5928 - val_accuracy: 0.9015\n","\n","Epoch 00381: val_accuracy did not improve from 0.93350\n","Epoch 382/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6927 - val_accuracy: 0.8621\n","\n","Epoch 00382: val_accuracy did not improve from 0.93350\n","Epoch 383/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4457 - val_accuracy: 0.9113\n","\n","Epoch 00383: val_accuracy did not improve from 0.93350\n","Epoch 384/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3910 - val_accuracy: 0.9261\n","\n","Epoch 00384: val_accuracy did not improve from 0.93350\n","Epoch 385/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5633 - val_accuracy: 0.9163\n","\n","Epoch 00385: val_accuracy did not improve from 0.93350\n","Epoch 386/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5419 - val_accuracy: 0.9113\n","\n","Epoch 00386: val_accuracy did not improve from 0.93350\n","Epoch 387/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5958 - val_accuracy: 0.8768\n","\n","Epoch 00387: val_accuracy did not improve from 0.93350\n","Epoch 388/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.6776 - val_accuracy: 0.8719\n","\n","Epoch 00388: val_accuracy did not improve from 0.93350\n","Epoch 389/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.6133 - val_accuracy: 0.9163\n","\n","Epoch 00389: val_accuracy did not improve from 0.93350\n","Epoch 390/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9310\n","\n","Epoch 00390: val_accuracy did not improve from 0.93350\n","Epoch 391/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.3410e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9113\n","\n","Epoch 00391: val_accuracy did not improve from 0.93350\n","Epoch 392/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.5230 - val_accuracy: 0.8966\n","\n","Epoch 00392: val_accuracy did not improve from 0.93350\n","Epoch 393/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.8999e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9261\n","\n","Epoch 00393: val_accuracy did not improve from 0.93350\n","Epoch 394/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9113\n","\n","Epoch 00394: val_accuracy did not improve from 0.93350\n","Epoch 395/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0153 - accuracy: 0.9976 - val_loss: 1.1244 - val_accuracy: 0.8350\n","\n","Epoch 00395: val_accuracy did not improve from 0.93350\n","Epoch 396/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 1.1349 - val_accuracy: 0.8251\n","\n","Epoch 00396: val_accuracy did not improve from 0.93350\n","Epoch 397/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.2681 - val_accuracy: 0.7635\n","\n","Epoch 00397: val_accuracy did not improve from 0.93350\n","Epoch 398/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.7142 - val_accuracy: 0.8473\n","\n","Epoch 00398: val_accuracy did not improve from 0.93350\n","Epoch 399/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0664 - accuracy: 0.9823 - val_loss: 0.7714 - val_accuracy: 0.8448\n","\n","Epoch 00399: val_accuracy did not improve from 0.93350\n","Epoch 400/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5261 - val_accuracy: 0.8941\n","\n","Epoch 00400: val_accuracy did not improve from 0.93350\n","Epoch 401/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6042 - val_accuracy: 0.8990\n","\n","Epoch 00401: val_accuracy did not improve from 0.93350\n","Epoch 402/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.4135 - val_accuracy: 0.9064\n","\n","Epoch 00402: val_accuracy did not improve from 0.93350\n","Epoch 403/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5224 - val_accuracy: 0.9064\n","\n","Epoch 00403: val_accuracy did not improve from 0.93350\n","Epoch 404/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.6030 - val_accuracy: 0.9039\n","\n","Epoch 00404: val_accuracy did not improve from 0.93350\n","Epoch 405/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.6091 - val_accuracy: 0.8867\n","\n","Epoch 00405: val_accuracy did not improve from 0.93350\n","Epoch 406/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9015\n","\n","Epoch 00406: val_accuracy did not improve from 0.93350\n","Epoch 407/500\n","52/52 [==============================] - 20s 386ms/step - loss: 8.6317e-04 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.8966\n","\n","Epoch 00407: val_accuracy did not improve from 0.93350\n","Epoch 408/500\n","52/52 [==============================] - 20s 385ms/step - loss: 7.9785e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9113\n","\n","Epoch 00408: val_accuracy did not improve from 0.93350\n","Epoch 409/500\n","52/52 [==============================] - 20s 385ms/step - loss: 8.2251e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9015\n","\n","Epoch 00409: val_accuracy did not improve from 0.93350\n","Epoch 410/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4445 - val_accuracy: 0.8990\n","\n","Epoch 00410: val_accuracy did not improve from 0.93350\n","Epoch 411/500\n","52/52 [==============================] - 20s 385ms/step - loss: 6.8832e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9064\n","\n","Epoch 00411: val_accuracy did not improve from 0.93350\n","Epoch 412/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.8678e-04 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9187\n","\n","Epoch 00412: val_accuracy did not improve from 0.93350\n","Epoch 413/500\n","52/52 [==============================] - 20s 387ms/step - loss: 9.7965e-04 - accuracy: 0.9994 - val_loss: 0.3688 - val_accuracy: 0.9310\n","\n","Epoch 00413: val_accuracy did not improve from 0.93350\n","Epoch 414/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4881 - val_accuracy: 0.9138\n","\n","Epoch 00414: val_accuracy did not improve from 0.93350\n","Epoch 415/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9335\n","\n","Epoch 00415: val_accuracy did not improve from 0.93350\n","Epoch 416/500\n","52/52 [==============================] - 20s 386ms/step - loss: 8.0041e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9261\n","\n","Epoch 00416: val_accuracy did not improve from 0.93350\n","Epoch 417/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.9488e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9163\n","\n","Epoch 00417: val_accuracy did not improve from 0.93350\n","Epoch 418/500\n","52/52 [==============================] - 20s 386ms/step - loss: 2.8480e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9360\n","\n","Epoch 00418: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 419/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5103 - val_accuracy: 0.9163\n","\n","Epoch 00419: val_accuracy did not improve from 0.93596\n","Epoch 420/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4586 - val_accuracy: 0.9138\n","\n","Epoch 00420: val_accuracy did not improve from 0.93596\n","Epoch 421/500\n","52/52 [==============================] - 20s 385ms/step - loss: 8.0925e-04 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9113\n","\n","Epoch 00421: val_accuracy did not improve from 0.93596\n","Epoch 422/500\n","52/52 [==============================] - 20s 385ms/step - loss: 3.0012e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9163\n","\n","Epoch 00422: val_accuracy did not improve from 0.93596\n","Epoch 423/500\n","52/52 [==============================] - 20s 386ms/step - loss: 5.3473e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9236\n","\n","Epoch 00423: val_accuracy did not improve from 0.93596\n","Epoch 424/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9089\n","\n","Epoch 00424: val_accuracy did not improve from 0.93596\n","Epoch 425/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.5777e-04 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9236\n","\n","Epoch 00425: val_accuracy did not improve from 0.93596\n","Epoch 426/500\n","52/52 [==============================] - 20s 385ms/step - loss: 1.3262e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9261\n","\n","Epoch 00426: val_accuracy did not improve from 0.93596\n","Epoch 427/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.9331e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9187\n","\n","Epoch 00427: val_accuracy did not improve from 0.93596\n","Epoch 428/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.4802e-04 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9335\n","\n","Epoch 00428: val_accuracy did not improve from 0.93596\n","Epoch 429/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.0305e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9187\n","\n","Epoch 00429: val_accuracy did not improve from 0.93596\n","Epoch 430/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.5298e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9212\n","\n","Epoch 00430: val_accuracy did not improve from 0.93596\n","Epoch 431/500\n","52/52 [==============================] - 20s 386ms/step - loss: 1.1893e-04 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9310\n","\n","Epoch 00431: val_accuracy did not improve from 0.93596\n","Epoch 432/500\n","52/52 [==============================] - 20s 387ms/step - loss: 8.4611e-05 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9360\n","\n","Epoch 00432: val_accuracy did not improve from 0.93596\n","Epoch 433/500\n","52/52 [==============================] - 20s 386ms/step - loss: 3.3411e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9409\n","\n","Epoch 00433: val_accuracy improved from 0.93596 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5\n","Epoch 434/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0191 - accuracy: 0.9976 - val_loss: 0.6155 - val_accuracy: 0.8990\n","\n","Epoch 00434: val_accuracy did not improve from 0.94089\n","Epoch 435/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 1.4272 - val_accuracy: 0.7291\n","\n","Epoch 00435: val_accuracy did not improve from 0.94089\n","Epoch 436/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.1254 - accuracy: 0.9708 - val_loss: 1.4684 - val_accuracy: 0.6798\n","\n","Epoch 00436: val_accuracy did not improve from 0.94089\n","Epoch 437/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 1.1033 - val_accuracy: 0.7118\n","\n","Epoch 00437: val_accuracy did not improve from 0.94089\n","Epoch 438/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.5096 - val_accuracy: 0.8916\n","\n","Epoch 00438: val_accuracy did not improve from 0.94089\n","Epoch 439/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4690 - val_accuracy: 0.9138\n","\n","Epoch 00439: val_accuracy did not improve from 0.94089\n","Epoch 440/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9113\n","\n","Epoch 00440: val_accuracy did not improve from 0.94089\n","Epoch 441/500\n","52/52 [==============================] - 20s 385ms/step - loss: 9.5019e-04 - accuracy: 0.9994 - val_loss: 0.4295 - val_accuracy: 0.9089\n","\n","Epoch 00441: val_accuracy did not improve from 0.94089\n","Epoch 442/500\n","52/52 [==============================] - 20s 384ms/step - loss: 9.2334e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8941\n","\n","Epoch 00442: val_accuracy did not improve from 0.94089\n","Epoch 443/500\n","52/52 [==============================] - 20s 384ms/step - loss: 8.1420e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9163\n","\n","Epoch 00443: val_accuracy did not improve from 0.94089\n","Epoch 444/500\n","52/52 [==============================] - 20s 384ms/step - loss: 6.1557e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9212\n","\n","Epoch 00444: val_accuracy did not improve from 0.94089\n","Epoch 445/500\n","52/52 [==============================] - 20s 385ms/step - loss: 2.0102e-04 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9212\n","\n","Epoch 00445: val_accuracy did not improve from 0.94089\n","Epoch 446/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4579 - val_accuracy: 0.9015\n","\n","Epoch 00446: val_accuracy did not improve from 0.94089\n","Epoch 447/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4280 - val_accuracy: 0.8990\n","\n","Epoch 00447: val_accuracy did not improve from 0.94089\n","Epoch 448/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6541 - val_accuracy: 0.8719\n","\n","Epoch 00448: val_accuracy did not improve from 0.94089\n","Epoch 449/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4633 - val_accuracy: 0.9163\n","\n","Epoch 00449: val_accuracy did not improve from 0.94089\n","Epoch 450/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6284 - val_accuracy: 0.8818\n","\n","Epoch 00450: val_accuracy did not improve from 0.94089\n","Epoch 451/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.6495 - val_accuracy: 0.8596\n","\n","Epoch 00451: val_accuracy did not improve from 0.94089\n","Epoch 452/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0209 - accuracy: 0.9903 - val_loss: 0.7399 - val_accuracy: 0.8670\n","\n","Epoch 00452: val_accuracy did not improve from 0.94089\n","Epoch 453/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5250 - val_accuracy: 0.9064\n","\n","Epoch 00453: val_accuracy did not improve from 0.94089\n","Epoch 454/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.6488 - val_accuracy: 0.8941\n","\n","Epoch 00454: val_accuracy did not improve from 0.94089\n","Epoch 455/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.5345 - val_accuracy: 0.8966\n","\n","Epoch 00455: val_accuracy did not improve from 0.94089\n","Epoch 456/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5230 - val_accuracy: 0.9089\n","\n","Epoch 00456: val_accuracy did not improve from 0.94089\n","Epoch 457/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.5359 - val_accuracy: 0.9064\n","\n","Epoch 00457: val_accuracy did not improve from 0.94089\n","Epoch 458/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.6563 - val_accuracy: 0.8768\n","\n","Epoch 00458: val_accuracy did not improve from 0.94089\n","Epoch 459/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.7108 - val_accuracy: 0.8621\n","\n","Epoch 00459: val_accuracy did not improve from 0.94089\n","Epoch 460/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.5303 - val_accuracy: 0.8941\n","\n","Epoch 00460: val_accuracy did not improve from 0.94089\n","Epoch 461/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0118 - accuracy: 0.9945 - val_loss: 0.6434 - val_accuracy: 0.8793\n","\n","Epoch 00461: val_accuracy did not improve from 0.94089\n","Epoch 462/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.3022 - val_accuracy: 0.9384\n","\n","Epoch 00462: val_accuracy did not improve from 0.94089\n","Epoch 463/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9187\n","\n","Epoch 00463: val_accuracy did not improve from 0.94089\n","Epoch 464/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.8251 - val_accuracy: 0.8670\n","\n","Epoch 00464: val_accuracy did not improve from 0.94089\n","Epoch 465/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.5522 - val_accuracy: 0.8719\n","\n","Epoch 00465: val_accuracy did not improve from 0.94089\n","Epoch 466/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4303 - val_accuracy: 0.9261\n","\n","Epoch 00466: val_accuracy did not improve from 0.94089\n","Epoch 467/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4837 - val_accuracy: 0.9187\n","\n","Epoch 00467: val_accuracy did not improve from 0.94089\n","Epoch 468/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 0.8156 - val_accuracy: 0.8079\n","\n","Epoch 00468: val_accuracy did not improve from 0.94089\n","Epoch 469/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5440 - val_accuracy: 0.8842\n","\n","Epoch 00469: val_accuracy did not improve from 0.94089\n","Epoch 470/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.6506 - val_accuracy: 0.8892\n","\n","Epoch 00470: val_accuracy did not improve from 0.94089\n","Epoch 471/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5956 - val_accuracy: 0.9015\n","\n","Epoch 00471: val_accuracy did not improve from 0.94089\n","Epoch 472/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4861 - val_accuracy: 0.9015\n","\n","Epoch 00472: val_accuracy did not improve from 0.94089\n","Epoch 473/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9113\n","\n","Epoch 00473: val_accuracy did not improve from 0.94089\n","Epoch 474/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.8843 - val_accuracy: 0.8473\n","\n","Epoch 00474: val_accuracy did not improve from 0.94089\n","Epoch 475/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.6707 - val_accuracy: 0.8645\n","\n","Epoch 00475: val_accuracy did not improve from 0.94089\n","Epoch 476/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.4478 - val_accuracy: 0.9015\n","\n","Epoch 00476: val_accuracy did not improve from 0.94089\n","Epoch 477/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.5960 - val_accuracy: 0.8842\n","\n","Epoch 00477: val_accuracy did not improve from 0.94089\n","Epoch 478/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4984 - val_accuracy: 0.8867\n","\n","Epoch 00478: val_accuracy did not improve from 0.94089\n","Epoch 479/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.7025 - val_accuracy: 0.8424\n","\n","Epoch 00479: val_accuracy did not improve from 0.94089\n","Epoch 480/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.5053 - val_accuracy: 0.8966\n","\n","Epoch 00480: val_accuracy did not improve from 0.94089\n","Epoch 481/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4370 - val_accuracy: 0.9039\n","\n","Epoch 00481: val_accuracy did not improve from 0.94089\n","Epoch 482/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.9802 - val_accuracy: 0.8325\n","\n","Epoch 00482: val_accuracy did not improve from 0.94089\n","Epoch 483/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.7101 - val_accuracy: 0.8670\n","\n","Epoch 00483: val_accuracy did not improve from 0.94089\n","Epoch 484/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5041 - val_accuracy: 0.8990\n","\n","Epoch 00484: val_accuracy did not improve from 0.94089\n","Epoch 485/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.8990\n","\n","Epoch 00485: val_accuracy did not improve from 0.94089\n","Epoch 486/500\n","52/52 [==============================] - 20s 383ms/step - loss: 9.9604e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9113\n","\n","Epoch 00486: val_accuracy did not improve from 0.94089\n","Epoch 487/500\n","52/52 [==============================] - 20s 385ms/step - loss: 5.4016e-04 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9113\n","\n","Epoch 00487: val_accuracy did not improve from 0.94089\n","Epoch 488/500\n","52/52 [==============================] - 20s 385ms/step - loss: 7.2461e-04 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.9015\n","\n","Epoch 00488: val_accuracy did not improve from 0.94089\n","Epoch 489/500\n","52/52 [==============================] - 20s 382ms/step - loss: 3.4151e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9089\n","\n","Epoch 00489: val_accuracy did not improve from 0.94089\n","Epoch 490/500\n","52/52 [==============================] - 20s 385ms/step - loss: 4.6275e-04 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9261\n","\n","Epoch 00490: val_accuracy did not improve from 0.94089\n","Epoch 491/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.2158e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9212\n","\n","Epoch 00491: val_accuracy did not improve from 0.94089\n","Epoch 492/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.7250e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9138\n","\n","Epoch 00492: val_accuracy did not improve from 0.94089\n","Epoch 493/500\n","52/52 [==============================] - 20s 384ms/step - loss: 1.6746e-04 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9261\n","\n","Epoch 00493: val_accuracy did not improve from 0.94089\n","Epoch 494/500\n","52/52 [==============================] - 20s 386ms/step - loss: 1.1374e-04 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9138\n","\n","Epoch 00494: val_accuracy did not improve from 0.94089\n","Epoch 495/500\n","52/52 [==============================] - 20s 383ms/step - loss: 4.7474e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9212\n","\n","Epoch 00495: val_accuracy did not improve from 0.94089\n","Epoch 496/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5237 - val_accuracy: 0.9138\n","\n","Epoch 00496: val_accuracy did not improve from 0.94089\n","Epoch 497/500\n","52/52 [==============================] - 20s 384ms/step - loss: 2.6325e-04 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.9113\n","\n","Epoch 00497: val_accuracy did not improve from 0.94089\n","Epoch 498/500\n","52/52 [==============================] - 20s 383ms/step - loss: 2.9131e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9236\n","\n","Epoch 00498: val_accuracy did not improve from 0.94089\n","Epoch 499/500\n","52/52 [==============================] - 20s 384ms/step - loss: 7.0822e-04 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9261\n","\n","Epoch 00499: val_accuracy did not improve from 0.94089\n","Epoch 500/500\n","52/52 [==============================] - 20s 383ms/step - loss: 7.2854e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9163\n","\n","Epoch 00500: val_accuracy did not improve from 0.94089\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0d7877bd50>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630399166096,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"14122e8b-2d5d-42de-b0d7-887db3c2ad00"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630399185310,"user_tz":-540,"elapsed":18831,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_010_2_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630399186042,"user_tz":-540,"elapsed":737,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630399186428,"user_tz":-540,"elapsed":389,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b5e3fb9b-085e-4ad8-e99f-f8510fc459fe"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630399241335,"user_tz":-540,"elapsed":54909,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"dbc7bf17-694a-4bd1-a552-884a4af0f6d4"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630399241839,"user_tz":-540,"elapsed":517,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630399241840,"user_tz":-540,"elapsed":4,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630399242593,"user_tz":-540,"elapsed":756,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630399242594,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630399253792,"user_tz":-540,"elapsed":11203,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630399253793,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"71712c9d-a6d4-449e-bd35-65db52258b30"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630399255500,"user_tz":-540,"elapsed":1716,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"146e1705-bcb6-4fe1-c47d-22a210a98c09"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_010_2_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_010_2_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ab60de96-f907-460e-a200-3c6d0cc3228d\", \"WidthShiftRange_010_2_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}