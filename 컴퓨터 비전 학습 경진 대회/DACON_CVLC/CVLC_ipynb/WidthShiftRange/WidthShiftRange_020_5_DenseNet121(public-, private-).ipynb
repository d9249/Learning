{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WidthShiftRange_020_5_DenseNet121(public-, private-).ipynb","provenance":[{"file_id":"1O4p5sORV6DLudBSH7sV5nxc_U1X27lUZ","timestamp":1630418523750},{"file_id":"15VXtcGnPaUJnLd_nPIm4aJS9sTqfhcd4","timestamp":1630418496779},{"file_id":"1zESw2NSh732ywzcq-o4GrKdtq5pYJDyl","timestamp":1630415524120},{"file_id":"1AQ3lCJpNGG-pcm9kv5d9baWYvTBHKFEk","timestamp":1630415344189},{"file_id":"11AxMhgU3sYVSXZPQy5eSH54jKa3_uz8Z","timestamp":1630415264634},{"file_id":"1b13kRp0GfJQt6OWjsaqxovvpb_jfXS8o","timestamp":1630401428894},{"file_id":"1twlAI6CK-6CpHrBpu3_0nFtxVnwFZe5L","timestamp":1630399653251},{"file_id":"1p0RO4vLW2iNm5EolNIeAqmY_QtASQzIa","timestamp":1630399628758},{"file_id":"116cIWnRhowEaFMUyNkIeRIk2Lp1MKkU5","timestamp":1630399598636},{"file_id":"1VKIqlqqKc-A4vYqSsW_JUeSK_N1y2xml","timestamp":1630397601024},{"file_id":"1zglsqNkWY_tOoJptdF8X3mTGsu7h6Bwz","timestamp":1630389141056},{"file_id":"1iKFQJmNJ5CQD-AugmIjtaXRZM9HP5uqz","timestamp":1630388959469},{"file_id":"1T6Dq_galPaWk9t4pLkN8nhKLQUEOjHJ7","timestamp":1630381812370},{"file_id":"1Ly1AS8898mvipysBYrU3q8iiLASPUEJF","timestamp":1630381785409},{"file_id":"1KSSOlRb7UcsevhJritnzzhtyEZKMzJAe","timestamp":1629934152693},{"file_id":"1ajKePeW-DYAjB9sSmnoaK51pMz2Fa9Sl","timestamp":1629934129003},{"file_id":"1wStY7zoH0wKdwYkopHVivYR41ZSHQXS0","timestamp":1629934100919},{"file_id":"1l7ce0_Ey48SOHGtYsTBR7jpHXzJUP9ue","timestamp":1629934072691},{"file_id":"1P_krP115VpkAnlGzBGdhlCDdliPnck4S","timestamp":1629930401248},{"file_id":"1tjObWJ1mSAj3uTagmoSjSHE4kXx1rO7i","timestamp":1629930350078},{"file_id":"1Rl2mXgWKUFBDDiGbS6zqfyqNCsmgYynT","timestamp":1629930309637},{"file_id":"17NpfuP6bzFvGgEWm76315CyuSce1j-nI","timestamp":1629930239013},{"file_id":"1Jh81MWVOQgKqdffbvx28QO3jlWDkuuEy","timestamp":1629921823577},{"file_id":"1MLMlLWKXXZLLgaIwniQnr_lZFDA1Ms8X","timestamp":1629921759135},{"file_id":"1Y1upTrq-Q1ouuCozckYRXPVmxrADZmfU","timestamp":1629905290443},{"file_id":"1cPeef80S40tec8hPAWS30wPlD9DLTdql","timestamp":1629905226097},{"file_id":"1BInjzkOWv4MzETmZxtD52hqvUP6r9xpW","timestamp":1629905201842},{"file_id":"1UbYKBN3yAUX4a6b5Y6TAl_ckyXwPJN3n","timestamp":1629905178459},{"file_id":"1s2rc6YfkF2sllYF0QkhrllA9y-ApLABf","timestamp":1629905152234},{"file_id":"1YpMtBbq37PcZFXF4Nv70e1jSj9mQ00At","timestamp":1629887248762},{"file_id":"1cZHETntsYraMYh4K5gG0MuXheE_7E8LY","timestamp":1629887208340},{"file_id":"1HrkG_DgJMWpZpqfP9JjRU6pOqASAgx_A","timestamp":1629887181496},{"file_id":"1vTf5DATPshqE-PuJlGwEKrH6aZVvOaMe","timestamp":1629887153449},{"file_id":"1wrd8U3UmcBOS0oHH9u1rknjvPt0qn0ue","timestamp":1629879827259},{"file_id":"1Rv7tEa_aRgrPJ4n7neFVzFJyFQQJHLBY","timestamp":1629879776253},{"file_id":"10xcw6CtTb9HHBApnI9Q9bS_v62DV2IuR","timestamp":1629879746323},{"file_id":"1lc5cUyUmrm7AuL05doOtOch2f4lQWs54","timestamp":1629842744896},{"file_id":"178r4Tqo4iAYDB4Oo_enkB_gPeUngK1cT","timestamp":1629842718146},{"file_id":"1DyoSI9ZXVtqhUeTXTI-VP3Nea4rmIKuj","timestamp":1629842690476},{"file_id":"1BKVbO7YpF70hxnD0vTyYn3TQyYAYFCbK","timestamp":1629840868493},{"file_id":"10cv_oWU-D-RJl-ohjJDK79FUK9g-2CG2","timestamp":1629840806319},{"file_id":"1OAheFmC5_2j2cszcONa2wJpU-PMMfjBD","timestamp":1629830648273},{"file_id":"18x0c0f7SyHup_iF5nT8xZNiCuvPWjPsV","timestamp":1629830624531},{"file_id":"1DRdeC1ciU3hCvKq2nggivhquIx9oGiek","timestamp":1629830592512},{"file_id":"1JJ7KVdbER6GotFj_2ONc8A0NfXPBDn6Z","timestamp":1629830560265},{"file_id":"12uEm4XnG0iteqzxURnigxDUXQ2czFPhU","timestamp":1629819860110},{"file_id":"1--bizXJYt9sMdeui0dm7tRkRtXFKs6QE","timestamp":1629819834736},{"file_id":"1wCmd2Bv_35pubIcMC35_0y9wMZS6-onp","timestamp":1629819811172},{"file_id":"1h8LqgxMamE2ABZ3gXpjtXDX9nuMOVGNW","timestamp":1629819775394},{"file_id":"1smC9sXhwdZVF8jrwtMqEerUOPmnz_rkZ","timestamp":1629819705119},{"file_id":"1EM8gXwBtpHUUlgSh1S2227RUphu2dP9y","timestamp":1629809833175},{"file_id":"1dMrgQmGFrnt6MGeQzfCE8A_AO-EAx66T","timestamp":1629809808472},{"file_id":"1o-FGmF8TZy1xxyrjObHIwZpvYquXGQSo","timestamp":1629809782839},{"file_id":"1LKQATNLnUZqp0VY8f-DqSFsreRlBtR_g","timestamp":1629809752559},{"file_id":"1-1_Bd33ITxhUhYZPXVlarlXpbviZfKfH","timestamp":1629809688730},{"file_id":"12Le2l7ByMOGLC1-TQGlQ7ujiAtY4zLCD","timestamp":1629807271343},{"file_id":"1D0bBklmeyYrgQs1jbv5K72j23GcFMOL2","timestamp":1629795101988},{"file_id":"17jryMpsTONvRVq8z0JNREvhjNdYJaL4Z","timestamp":1629795046063},{"file_id":"15D_YDPGphS_M3gZfWnkEV-ORFSq1ybVO","timestamp":1629795016046},{"file_id":"151vxCgtpEUCpfYKv5HGK0VvjyzQ-vPN3","timestamp":1629794907548},{"file_id":"1u5guGiXpzdUivBm2_YemyK5sg7Ll4ebW","timestamp":1629794329875},{"file_id":"1k6Mnpo6-Wh-6A8cQXXPUEdkdDRyhSKQ_","timestamp":1629794274104},{"file_id":"15uETeEvej7wBTXB1sPpuUT5mhvIyVACs","timestamp":1629774528384},{"file_id":"1HU-2leUR3vh5_7o05kDcLtS98pruVW5H","timestamp":1629774499231},{"file_id":"1r6EY2-13yzcR1s0ZoklC_rTGW0BY29Ct","timestamp":1629774403193},{"file_id":"12F2UjKnHrSeoLoEqeXOYpm1szAiLDrKP","timestamp":1629732670497},{"file_id":"1Ouake2JvyocAkVZeauXpI0DHrj9wmRhP","timestamp":1629732645276},{"file_id":"1otHJ9uhttanGHHd0a6b6X8zZMm7JGQ1M","timestamp":1629732614192},{"file_id":"1ezLXcoPm4fN9t5_1zTC8QkD2LpbAKHl5","timestamp":1629730858808},{"file_id":"1hr63pFTCkr3ObU1fYeYcLUkc2WM_s8Tm","timestamp":1629685399142},{"file_id":"1EAdTffTXvJNBZIobMiTZcrRL_mlb2du3","timestamp":1629685277874},{"file_id":"1Sk8UXtqXhSb37VRzUwFFM-BGZdc0h4e2","timestamp":1629685250698},{"file_id":"197EYXNFW_ygohfTvydvMqDJ36AX4ZfDc","timestamp":1629685227448},{"file_id":"1NWHlhrgtsSDi9y22igED4vzdDbXBsVxR","timestamp":1629685140526},{"file_id":"1qiQ5JFJlpNstqUlh9u3g5xAYrXML3qMy","timestamp":1629667753837},{"file_id":"17JJEIAnAfUlUvas8PqiHWS8Htqq3Xz_-","timestamp":1629666957933},{"file_id":"1HjRQ71ZH0rP-QOc1nKvfeJxA6s-xiyiI","timestamp":1629666934807},{"file_id":"1-ARfvjfuTAWYZQu1hnJwzUoPYAkkMeop","timestamp":1629666912415},{"file_id":"1Fipi12zMsz8stjgStMFrs--KGXVkIly9","timestamp":1629666887018},{"file_id":"1JbsXwkV5cwLU3EfR8W1txPjrbMKSbmYX","timestamp":1629666841636},{"file_id":"1SqMX8fiUvGqPeBlww4LMInubgBSeBHaO","timestamp":1629646750556},{"file_id":"14-ZkuSzXen5ePE4jAUCVlz-ENq2drJCF","timestamp":1629646714631},{"file_id":"1m-jt-oBSHLElfCTPOHOm_XXeB1Cl5iRI","timestamp":1629646659574},{"file_id":"1ZSsyWUt5_nB_2Pphtm5pZN7_btFxJ3ey","timestamp":1629646626568},{"file_id":"19EXi1j0m1K19vieo-MkMbMR_PMqLhISZ","timestamp":1629646549672},{"file_id":"1Ca7ueqwh34kMJS18unlKskW6b6Ak4aB_","timestamp":1629646514253},{"file_id":"1cB0MKwol17Kue0n8nSN3UWXfthPwp-kr","timestamp":1629646408830},{"file_id":"1T7cuUXYXgmLRgWuQPEOH_jXuh_4IeDp3","timestamp":1629646280479},{"file_id":"13WRpbQUZoF_A0qkn8V7zrUsi3ucrD_lo","timestamp":1629646250444},{"file_id":"1l23K3aYucFT1ZMVlBoVoihZoVBYFpC_x","timestamp":1629646041940}],"collapsed_sections":[],"authorship_tag":"ABX9TyNlHgnlJhWIlW+51v+fTXfL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bMLx8uC2eHeP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630426914310,"user_tz":-540,"elapsed":34,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"0dc6c821-5a49-49a2-ecb8-a2c167e412eb"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 31 16:21:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630426931470,"user_tz":-540,"elapsed":17184,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"19b7ede1-24af-422a-fa9e-670bc4da8d17"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1630426934781,"user_tz":-540,"elapsed":3315,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1630426936160,"user_tz":-540,"elapsed":1383,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1630426938154,"user_tz":-540,"elapsed":1998,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1630426955485,"user_tz":-540,"elapsed":17338,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import cv2\n","\n","for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1630426962257,"user_tz":-540,"elapsed":6775,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import tensorflow as tf\n","DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630426962264,"user_tz":-540,"elapsed":25,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"d786416c-aa87-427f-cd28-671bcf18d28c"},"source":["from tensorflow.keras.optimizers import Adam\n","DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630426962265,"user_tz":-540,"elapsed":22,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"f0833ee5-846a-4534-92b5-a73160701c72"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","                             rescale=1./255, \n","                             validation_split=0.2,\n","                             rotation_range=10,\n","                             width_shift_range=0.2,\n","                             height_shift_range=0.1)\n","\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1642 images belonging to 10 classes.\n","Found 406 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1630426962266,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630437662448,"user_tz":-540,"elapsed":10700201,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"716fa87f-c84b-4e12-fd57-d09d21bde20d"},"source":["DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","52/52 [==============================] - 53s 469ms/step - loss: 1.9419 - accuracy: 0.2996 - val_loss: 6.6104 - val_accuracy: 0.1453\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.14532, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 2/500\n","52/52 [==============================] - 19s 367ms/step - loss: 1.2444 - accuracy: 0.5719 - val_loss: 19.3391 - val_accuracy: 0.1010\n","\n","Epoch 00002: val_accuracy did not improve from 0.14532\n","Epoch 3/500\n","52/52 [==============================] - 19s 369ms/step - loss: 0.9639 - accuracy: 0.6742 - val_loss: 13.0426 - val_accuracy: 0.1133\n","\n","Epoch 00003: val_accuracy did not improve from 0.14532\n","Epoch 4/500\n","52/52 [==============================] - 19s 371ms/step - loss: 0.8204 - accuracy: 0.7229 - val_loss: 8.7828 - val_accuracy: 0.0985\n","\n","Epoch 00004: val_accuracy did not improve from 0.14532\n","Epoch 5/500\n","52/52 [==============================] - 20s 374ms/step - loss: 0.7898 - accuracy: 0.7400 - val_loss: 6.4909 - val_accuracy: 0.2069\n","\n","Epoch 00005: val_accuracy improved from 0.14532 to 0.20690, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 6/500\n","52/52 [==============================] - 20s 375ms/step - loss: 0.6678 - accuracy: 0.7674 - val_loss: 5.2312 - val_accuracy: 0.2217\n","\n","Epoch 00006: val_accuracy improved from 0.20690 to 0.22167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 7/500\n","52/52 [==============================] - 20s 376ms/step - loss: 0.6166 - accuracy: 0.7862 - val_loss: 6.0590 - val_accuracy: 0.2857\n","\n","Epoch 00007: val_accuracy improved from 0.22167 to 0.28571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 8/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.5545 - accuracy: 0.8136 - val_loss: 5.4239 - val_accuracy: 0.2931\n","\n","Epoch 00008: val_accuracy improved from 0.28571 to 0.29310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 9/500\n","52/52 [==============================] - 20s 377ms/step - loss: 0.5477 - accuracy: 0.8143 - val_loss: 1.2370 - val_accuracy: 0.6601\n","\n","Epoch 00009: val_accuracy improved from 0.29310 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 10/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.5042 - accuracy: 0.8368 - val_loss: 1.1680 - val_accuracy: 0.6724\n","\n","Epoch 00010: val_accuracy improved from 0.66010 to 0.67241, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 11/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.4204 - accuracy: 0.8520 - val_loss: 1.7538 - val_accuracy: 0.5468\n","\n","Epoch 00011: val_accuracy did not improve from 0.67241\n","Epoch 12/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.4330 - accuracy: 0.8581 - val_loss: 2.9844 - val_accuracy: 0.4507\n","\n","Epoch 00012: val_accuracy did not improve from 0.67241\n","Epoch 13/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3868 - accuracy: 0.8618 - val_loss: 1.1981 - val_accuracy: 0.7365\n","\n","Epoch 00013: val_accuracy improved from 0.67241 to 0.73645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 14/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.3673 - accuracy: 0.8782 - val_loss: 0.6998 - val_accuracy: 0.7956\n","\n","Epoch 00014: val_accuracy improved from 0.73645 to 0.79557, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 15/500\n","52/52 [==============================] - 20s 378ms/step - loss: 0.3589 - accuracy: 0.8812 - val_loss: 0.6531 - val_accuracy: 0.8103\n","\n","Epoch 00015: val_accuracy improved from 0.79557 to 0.81034, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 16/500\n","52/52 [==============================] - 20s 380ms/step - loss: 0.2579 - accuracy: 0.9086 - val_loss: 0.7068 - val_accuracy: 0.7882\n","\n","Epoch 00016: val_accuracy did not improve from 0.81034\n","Epoch 17/500\n","52/52 [==============================] - 20s 381ms/step - loss: 0.3245 - accuracy: 0.8819 - val_loss: 1.4896 - val_accuracy: 0.6404\n","\n","Epoch 00017: val_accuracy did not improve from 0.81034\n","Epoch 18/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.2768 - accuracy: 0.9038 - val_loss: 0.6931 - val_accuracy: 0.8128\n","\n","Epoch 00018: val_accuracy improved from 0.81034 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 19/500\n","52/52 [==============================] - 20s 379ms/step - loss: 0.2318 - accuracy: 0.9220 - val_loss: 0.9492 - val_accuracy: 0.7635\n","\n","Epoch 00019: val_accuracy did not improve from 0.81281\n","Epoch 20/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2911 - accuracy: 0.9050 - val_loss: 0.5612 - val_accuracy: 0.8399\n","\n","Epoch 00020: val_accuracy improved from 0.81281 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 21/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2616 - accuracy: 0.9141 - val_loss: 0.5923 - val_accuracy: 0.7857\n","\n","Epoch 00021: val_accuracy did not improve from 0.83990\n","Epoch 22/500\n","52/52 [==============================] - 20s 382ms/step - loss: 0.2762 - accuracy: 0.9099 - val_loss: 0.7930 - val_accuracy: 0.7759\n","\n","Epoch 00022: val_accuracy did not improve from 0.83990\n","Epoch 23/500\n","52/52 [==============================] - 20s 383ms/step - loss: 0.2296 - accuracy: 0.9178 - val_loss: 0.6206 - val_accuracy: 0.8374\n","\n","Epoch 00023: val_accuracy did not improve from 0.83990\n","Epoch 24/500\n","52/52 [==============================] - 20s 384ms/step - loss: 0.2126 - accuracy: 0.9245 - val_loss: 0.5947 - val_accuracy: 0.8399\n","\n","Epoch 00024: val_accuracy did not improve from 0.83990\n","Epoch 25/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.2178 - accuracy: 0.9287 - val_loss: 0.4818 - val_accuracy: 0.8448\n","\n","Epoch 00025: val_accuracy improved from 0.83990 to 0.84483, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 26/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.5332 - val_accuracy: 0.8522\n","\n","Epoch 00026: val_accuracy improved from 0.84483 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 27/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1835 - accuracy: 0.9409 - val_loss: 0.5401 - val_accuracy: 0.8547\n","\n","Epoch 00027: val_accuracy improved from 0.85222 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 28/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.1556 - accuracy: 0.9476 - val_loss: 0.5695 - val_accuracy: 0.8276\n","\n","Epoch 00028: val_accuracy did not improve from 0.85468\n","Epoch 29/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1689 - accuracy: 0.9452 - val_loss: 0.7167 - val_accuracy: 0.7857\n","\n","Epoch 00029: val_accuracy did not improve from 0.85468\n","Epoch 30/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1949 - accuracy: 0.9300 - val_loss: 0.7803 - val_accuracy: 0.8103\n","\n","Epoch 00030: val_accuracy did not improve from 0.85468\n","Epoch 31/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1245 - accuracy: 0.9543 - val_loss: 0.5506 - val_accuracy: 0.8473\n","\n","Epoch 00031: val_accuracy did not improve from 0.85468\n","Epoch 32/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1739 - accuracy: 0.9391 - val_loss: 1.2179 - val_accuracy: 0.7365\n","\n","Epoch 00032: val_accuracy did not improve from 0.85468\n","Epoch 33/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.2235 - accuracy: 0.9257 - val_loss: 0.7569 - val_accuracy: 0.8300\n","\n","Epoch 00033: val_accuracy did not improve from 0.85468\n","Epoch 34/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1413 - accuracy: 0.9495 - val_loss: 1.4579 - val_accuracy: 0.6724\n","\n","Epoch 00034: val_accuracy did not improve from 0.85468\n","Epoch 35/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1347 - accuracy: 0.9531 - val_loss: 0.4370 - val_accuracy: 0.8719\n","\n","Epoch 00035: val_accuracy improved from 0.85468 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 36/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.1471 - accuracy: 0.9476 - val_loss: 0.5341 - val_accuracy: 0.8547\n","\n","Epoch 00036: val_accuracy did not improve from 0.87192\n","Epoch 37/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1351 - accuracy: 0.9513 - val_loss: 0.5915 - val_accuracy: 0.8153\n","\n","Epoch 00037: val_accuracy did not improve from 0.87192\n","Epoch 38/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1230 - accuracy: 0.9568 - val_loss: 0.5192 - val_accuracy: 0.8695\n","\n","Epoch 00038: val_accuracy did not improve from 0.87192\n","Epoch 39/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0895 - accuracy: 0.9714 - val_loss: 0.4418 - val_accuracy: 0.8818\n","\n","Epoch 00039: val_accuracy improved from 0.87192 to 0.88177, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 40/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.1078 - accuracy: 0.9622 - val_loss: 0.6693 - val_accuracy: 0.8571\n","\n","Epoch 00040: val_accuracy did not improve from 0.88177\n","Epoch 41/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1864 - accuracy: 0.9391 - val_loss: 0.6971 - val_accuracy: 0.8424\n","\n","Epoch 00041: val_accuracy did not improve from 0.88177\n","Epoch 42/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1619 - accuracy: 0.9458 - val_loss: 0.7623 - val_accuracy: 0.7857\n","\n","Epoch 00042: val_accuracy did not improve from 0.88177\n","Epoch 43/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.5591 - val_accuracy: 0.8621\n","\n","Epoch 00043: val_accuracy did not improve from 0.88177\n","Epoch 44/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0924 - accuracy: 0.9647 - val_loss: 0.5034 - val_accuracy: 0.8596\n","\n","Epoch 00044: val_accuracy did not improve from 0.88177\n","Epoch 45/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.1482 - accuracy: 0.9470 - val_loss: 1.0182 - val_accuracy: 0.7857\n","\n","Epoch 00045: val_accuracy did not improve from 0.88177\n","Epoch 46/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1238 - accuracy: 0.9586 - val_loss: 0.7478 - val_accuracy: 0.8177\n","\n","Epoch 00046: val_accuracy did not improve from 0.88177\n","Epoch 47/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1052 - accuracy: 0.9622 - val_loss: 1.1522 - val_accuracy: 0.7734\n","\n","Epoch 00047: val_accuracy did not improve from 0.88177\n","Epoch 48/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.3884 - val_accuracy: 0.8966\n","\n","Epoch 00048: val_accuracy improved from 0.88177 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 49/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1101 - accuracy: 0.9622 - val_loss: 0.5749 - val_accuracy: 0.8424\n","\n","Epoch 00049: val_accuracy did not improve from 0.89655\n","Epoch 50/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0809 - accuracy: 0.9762 - val_loss: 0.6291 - val_accuracy: 0.8473\n","\n","Epoch 00050: val_accuracy did not improve from 0.89655\n","Epoch 51/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0849 - accuracy: 0.9683 - val_loss: 0.6098 - val_accuracy: 0.8498\n","\n","Epoch 00051: val_accuracy did not improve from 0.89655\n","Epoch 52/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1020 - accuracy: 0.9616 - val_loss: 1.7050 - val_accuracy: 0.6872\n","\n","Epoch 00052: val_accuracy did not improve from 0.89655\n","Epoch 53/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1136 - accuracy: 0.9622 - val_loss: 0.9773 - val_accuracy: 0.8005\n","\n","Epoch 00053: val_accuracy did not improve from 0.89655\n","Epoch 54/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1030 - accuracy: 0.9659 - val_loss: 0.6703 - val_accuracy: 0.8498\n","\n","Epoch 00054: val_accuracy did not improve from 0.89655\n","Epoch 55/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.4538 - val_accuracy: 0.8990\n","\n","Epoch 00055: val_accuracy improved from 0.89655 to 0.89901, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 56/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0683 - accuracy: 0.9799 - val_loss: 0.7793 - val_accuracy: 0.8177\n","\n","Epoch 00056: val_accuracy did not improve from 0.89901\n","Epoch 57/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1359 - accuracy: 0.9531 - val_loss: 0.6110 - val_accuracy: 0.8695\n","\n","Epoch 00057: val_accuracy did not improve from 0.89901\n","Epoch 58/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1882 - accuracy: 0.9373 - val_loss: 0.7656 - val_accuracy: 0.8399\n","\n","Epoch 00058: val_accuracy did not improve from 0.89901\n","Epoch 59/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0961 - accuracy: 0.9671 - val_loss: 0.7825 - val_accuracy: 0.8300\n","\n","Epoch 00059: val_accuracy did not improve from 0.89901\n","Epoch 60/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0754 - accuracy: 0.9756 - val_loss: 0.6858 - val_accuracy: 0.8276\n","\n","Epoch 00060: val_accuracy did not improve from 0.89901\n","Epoch 61/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0724 - accuracy: 0.9732 - val_loss: 0.4650 - val_accuracy: 0.8670\n","\n","Epoch 00061: val_accuracy did not improve from 0.89901\n","Epoch 62/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.5569 - val_accuracy: 0.8645\n","\n","Epoch 00062: val_accuracy did not improve from 0.89901\n","Epoch 63/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.4027 - val_accuracy: 0.8867\n","\n","Epoch 00063: val_accuracy did not improve from 0.89901\n","Epoch 64/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.4072 - val_accuracy: 0.8793\n","\n","Epoch 00064: val_accuracy did not improve from 0.89901\n","Epoch 65/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.5502 - val_accuracy: 0.8842\n","\n","Epoch 00065: val_accuracy did not improve from 0.89901\n","Epoch 66/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0542 - accuracy: 0.9799 - val_loss: 0.6482 - val_accuracy: 0.8448\n","\n","Epoch 00066: val_accuracy did not improve from 0.89901\n","Epoch 67/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.6769 - val_accuracy: 0.8522\n","\n","Epoch 00067: val_accuracy did not improve from 0.89901\n","Epoch 68/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0921 - accuracy: 0.9695 - val_loss: 0.6990 - val_accuracy: 0.8473\n","\n","Epoch 00068: val_accuracy did not improve from 0.89901\n","Epoch 69/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0864 - accuracy: 0.9689 - val_loss: 0.9808 - val_accuracy: 0.8128\n","\n","Epoch 00069: val_accuracy did not improve from 0.89901\n","Epoch 70/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0851 - accuracy: 0.9750 - val_loss: 0.5856 - val_accuracy: 0.8768\n","\n","Epoch 00070: val_accuracy did not improve from 0.89901\n","Epoch 71/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.4677 - val_accuracy: 0.8842\n","\n","Epoch 00071: val_accuracy did not improve from 0.89901\n","Epoch 72/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.6416 - val_accuracy: 0.8596\n","\n","Epoch 00072: val_accuracy did not improve from 0.89901\n","Epoch 73/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.5492 - val_accuracy: 0.8768\n","\n","Epoch 00073: val_accuracy did not improve from 0.89901\n","Epoch 74/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.3661 - val_accuracy: 0.9163\n","\n","Epoch 00074: val_accuracy improved from 0.89901 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 75/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0508 - accuracy: 0.9787 - val_loss: 0.5995 - val_accuracy: 0.8768\n","\n","Epoch 00075: val_accuracy did not improve from 0.91626\n","Epoch 76/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1155 - accuracy: 0.9695 - val_loss: 0.7367 - val_accuracy: 0.8424\n","\n","Epoch 00076: val_accuracy did not improve from 0.91626\n","Epoch 77/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0764 - accuracy: 0.9781 - val_loss: 0.4906 - val_accuracy: 0.8892\n","\n","Epoch 00077: val_accuracy did not improve from 0.91626\n","Epoch 78/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.5261 - val_accuracy: 0.8966\n","\n","Epoch 00078: val_accuracy did not improve from 0.91626\n","Epoch 79/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4971 - val_accuracy: 0.8966\n","\n","Epoch 00079: val_accuracy did not improve from 0.91626\n","Epoch 80/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.8962 - val_accuracy: 0.8448\n","\n","Epoch 00080: val_accuracy did not improve from 0.91626\n","Epoch 81/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0617 - accuracy: 0.9762 - val_loss: 0.6328 - val_accuracy: 0.8621\n","\n","Epoch 00081: val_accuracy did not improve from 0.91626\n","Epoch 82/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0717 - accuracy: 0.9738 - val_loss: 0.6775 - val_accuracy: 0.8251\n","\n","Epoch 00082: val_accuracy did not improve from 0.91626\n","Epoch 83/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0659 - accuracy: 0.9836 - val_loss: 0.8951 - val_accuracy: 0.8374\n","\n","Epoch 00083: val_accuracy did not improve from 0.91626\n","Epoch 84/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0856 - accuracy: 0.9702 - val_loss: 0.5021 - val_accuracy: 0.8842\n","\n","Epoch 00084: val_accuracy did not improve from 0.91626\n","Epoch 85/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0625 - accuracy: 0.9787 - val_loss: 0.8907 - val_accuracy: 0.8448\n","\n","Epoch 00085: val_accuracy did not improve from 0.91626\n","Epoch 86/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0628 - accuracy: 0.9769 - val_loss: 0.6067 - val_accuracy: 0.8596\n","\n","Epoch 00086: val_accuracy did not improve from 0.91626\n","Epoch 87/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.8506 - val_accuracy: 0.8448\n","\n","Epoch 00087: val_accuracy did not improve from 0.91626\n","Epoch 88/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0563 - accuracy: 0.9799 - val_loss: 0.8365 - val_accuracy: 0.8103\n","\n","Epoch 00088: val_accuracy did not improve from 0.91626\n","Epoch 89/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0557 - accuracy: 0.9817 - val_loss: 0.4355 - val_accuracy: 0.8990\n","\n","Epoch 00089: val_accuracy did not improve from 0.91626\n","Epoch 90/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.5175 - val_accuracy: 0.8867\n","\n","Epoch 00090: val_accuracy did not improve from 0.91626\n","Epoch 91/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.1039 - accuracy: 0.9702 - val_loss: 0.8377 - val_accuracy: 0.8399\n","\n","Epoch 00091: val_accuracy did not improve from 0.91626\n","Epoch 92/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0926 - accuracy: 0.9683 - val_loss: 0.7403 - val_accuracy: 0.7882\n","\n","Epoch 00092: val_accuracy did not improve from 0.91626\n","Epoch 93/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.7695 - val_accuracy: 0.8424\n","\n","Epoch 00093: val_accuracy did not improve from 0.91626\n","Epoch 94/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.7217 - val_accuracy: 0.8448\n","\n","Epoch 00094: val_accuracy did not improve from 0.91626\n","Epoch 95/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 0.9077 - val_accuracy: 0.8399\n","\n","Epoch 00095: val_accuracy did not improve from 0.91626\n","Epoch 96/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0460 - accuracy: 0.9836 - val_loss: 0.6259 - val_accuracy: 0.8744\n","\n","Epoch 00096: val_accuracy did not improve from 0.91626\n","Epoch 97/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.6552 - val_accuracy: 0.8498\n","\n","Epoch 00097: val_accuracy did not improve from 0.91626\n","Epoch 98/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.4788 - val_accuracy: 0.8842\n","\n","Epoch 00098: val_accuracy did not improve from 0.91626\n","Epoch 99/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0394 - accuracy: 0.9866 - val_loss: 0.5845 - val_accuracy: 0.8867\n","\n","Epoch 00099: val_accuracy did not improve from 0.91626\n","Epoch 100/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0238 - accuracy: 0.9939 - val_loss: 0.4257 - val_accuracy: 0.8990\n","\n","Epoch 00100: val_accuracy did not improve from 0.91626\n","Epoch 101/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.4703 - val_accuracy: 0.9064\n","\n","Epoch 00101: val_accuracy did not improve from 0.91626\n","Epoch 102/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.7117 - val_accuracy: 0.8547\n","\n","Epoch 00102: val_accuracy did not improve from 0.91626\n","Epoch 103/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0280 - accuracy: 0.9890 - val_loss: 1.3569 - val_accuracy: 0.7734\n","\n","Epoch 00103: val_accuracy did not improve from 0.91626\n","Epoch 104/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.6703 - val_accuracy: 0.8744\n","\n","Epoch 00104: val_accuracy did not improve from 0.91626\n","Epoch 105/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 0.6020 - val_accuracy: 0.8842\n","\n","Epoch 00105: val_accuracy did not improve from 0.91626\n","Epoch 106/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.4429 - val_accuracy: 0.8941\n","\n","Epoch 00106: val_accuracy did not improve from 0.91626\n","Epoch 107/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.5298 - val_accuracy: 0.8916\n","\n","Epoch 00107: val_accuracy did not improve from 0.91626\n","Epoch 108/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.4581 - val_accuracy: 0.9113\n","\n","Epoch 00108: val_accuracy did not improve from 0.91626\n","Epoch 109/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 0.6470 - val_accuracy: 0.8522\n","\n","Epoch 00109: val_accuracy did not improve from 0.91626\n","Epoch 110/500\n","52/52 [==============================] - 21s 409ms/step - loss: 0.0423 - accuracy: 0.9884 - val_loss: 0.5063 - val_accuracy: 0.8719\n","\n","Epoch 00110: val_accuracy did not improve from 0.91626\n","Epoch 111/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 0.8514 - val_accuracy: 0.8251\n","\n","Epoch 00111: val_accuracy did not improve from 0.91626\n","Epoch 112/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0914 - accuracy: 0.9665 - val_loss: 0.7316 - val_accuracy: 0.8695\n","\n","Epoch 00112: val_accuracy did not improve from 0.91626\n","Epoch 113/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.5410 - val_accuracy: 0.8966\n","\n","Epoch 00113: val_accuracy did not improve from 0.91626\n","Epoch 114/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0257 - accuracy: 0.9903 - val_loss: 0.4119 - val_accuracy: 0.9138\n","\n","Epoch 00114: val_accuracy did not improve from 0.91626\n","Epoch 115/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.6241 - val_accuracy: 0.8571\n","\n","Epoch 00115: val_accuracy did not improve from 0.91626\n","Epoch 116/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0184 - accuracy: 0.9976 - val_loss: 0.4892 - val_accuracy: 0.8990\n","\n","Epoch 00116: val_accuracy did not improve from 0.91626\n","Epoch 117/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.3889 - val_accuracy: 0.9113\n","\n","Epoch 00117: val_accuracy did not improve from 0.91626\n","Epoch 118/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.7762 - val_accuracy: 0.8621\n","\n","Epoch 00118: val_accuracy did not improve from 0.91626\n","Epoch 119/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0287 - accuracy: 0.9878 - val_loss: 0.5804 - val_accuracy: 0.8768\n","\n","Epoch 00119: val_accuracy did not improve from 0.91626\n","Epoch 120/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.6940 - val_accuracy: 0.8571\n","\n","Epoch 00120: val_accuracy did not improve from 0.91626\n","Epoch 121/500\n","52/52 [==============================] - 21s 404ms/step - loss: 0.0400 - accuracy: 0.9866 - val_loss: 0.5624 - val_accuracy: 0.8916\n","\n","Epoch 00121: val_accuracy did not improve from 0.91626\n","Epoch 122/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0448 - accuracy: 0.9890 - val_loss: 0.6713 - val_accuracy: 0.8842\n","\n","Epoch 00122: val_accuracy did not improve from 0.91626\n","Epoch 123/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0376 - accuracy: 0.9854 - val_loss: 0.6220 - val_accuracy: 0.8695\n","\n","Epoch 00123: val_accuracy did not improve from 0.91626\n","Epoch 124/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4712 - val_accuracy: 0.9015\n","\n","Epoch 00124: val_accuracy did not improve from 0.91626\n","Epoch 125/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.5228 - val_accuracy: 0.8916\n","\n","Epoch 00125: val_accuracy did not improve from 0.91626\n","Epoch 126/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0308 - accuracy: 0.9860 - val_loss: 0.5559 - val_accuracy: 0.8768\n","\n","Epoch 00126: val_accuracy did not improve from 0.91626\n","Epoch 127/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.4108 - val_accuracy: 0.9015\n","\n","Epoch 00127: val_accuracy did not improve from 0.91626\n","Epoch 128/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.5594 - val_accuracy: 0.9015\n","\n","Epoch 00128: val_accuracy did not improve from 0.91626\n","Epoch 129/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 1.0340 - val_accuracy: 0.8300\n","\n","Epoch 00129: val_accuracy did not improve from 0.91626\n","Epoch 130/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.8267 - val_accuracy: 0.8522\n","\n","Epoch 00130: val_accuracy did not improve from 0.91626\n","Epoch 131/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0869 - accuracy: 0.9689 - val_loss: 0.9948 - val_accuracy: 0.8177\n","\n","Epoch 00131: val_accuracy did not improve from 0.91626\n","Epoch 132/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0559 - accuracy: 0.9793 - val_loss: 0.4894 - val_accuracy: 0.8842\n","\n","Epoch 00132: val_accuracy did not improve from 0.91626\n","Epoch 133/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0440 - accuracy: 0.9896 - val_loss: 0.6143 - val_accuracy: 0.8571\n","\n","Epoch 00133: val_accuracy did not improve from 0.91626\n","Epoch 134/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0641 - accuracy: 0.9799 - val_loss: 0.6204 - val_accuracy: 0.8793\n","\n","Epoch 00134: val_accuracy did not improve from 0.91626\n","Epoch 135/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 0.5633 - val_accuracy: 0.8941\n","\n","Epoch 00135: val_accuracy did not improve from 0.91626\n","Epoch 136/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.3875 - val_accuracy: 0.8941\n","\n","Epoch 00136: val_accuracy did not improve from 0.91626\n","Epoch 137/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.4480 - val_accuracy: 0.8867\n","\n","Epoch 00137: val_accuracy did not improve from 0.91626\n","Epoch 138/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.4585 - val_accuracy: 0.8892\n","\n","Epoch 00138: val_accuracy did not improve from 0.91626\n","Epoch 139/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.5434 - val_accuracy: 0.8793\n","\n","Epoch 00139: val_accuracy did not improve from 0.91626\n","Epoch 140/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5456 - val_accuracy: 0.8892\n","\n","Epoch 00140: val_accuracy did not improve from 0.91626\n","Epoch 141/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5332 - val_accuracy: 0.8867\n","\n","Epoch 00141: val_accuracy did not improve from 0.91626\n","Epoch 142/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.5799 - val_accuracy: 0.8892\n","\n","Epoch 00142: val_accuracy did not improve from 0.91626\n","Epoch 143/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.5726 - val_accuracy: 0.8867\n","\n","Epoch 00143: val_accuracy did not improve from 0.91626\n","Epoch 144/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.6304 - val_accuracy: 0.8621\n","\n","Epoch 00144: val_accuracy did not improve from 0.91626\n","Epoch 145/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.4184 - val_accuracy: 0.8941\n","\n","Epoch 00145: val_accuracy did not improve from 0.91626\n","Epoch 146/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.5469 - val_accuracy: 0.8571\n","\n","Epoch 00146: val_accuracy did not improve from 0.91626\n","Epoch 147/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4832 - val_accuracy: 0.9064\n","\n","Epoch 00147: val_accuracy did not improve from 0.91626\n","Epoch 148/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.8892\n","\n","Epoch 00148: val_accuracy did not improve from 0.91626\n","Epoch 149/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5191 - val_accuracy: 0.9187\n","\n","Epoch 00149: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 150/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.5754 - val_accuracy: 0.8793\n","\n","Epoch 00150: val_accuracy did not improve from 0.91872\n","Epoch 151/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0474 - accuracy: 0.9860 - val_loss: 1.0185 - val_accuracy: 0.8128\n","\n","Epoch 00151: val_accuracy did not improve from 0.91872\n","Epoch 152/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.1345 - accuracy: 0.9580 - val_loss: 1.2712 - val_accuracy: 0.7956\n","\n","Epoch 00152: val_accuracy did not improve from 0.91872\n","Epoch 153/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1564 - accuracy: 0.9537 - val_loss: 0.9530 - val_accuracy: 0.8350\n","\n","Epoch 00153: val_accuracy did not improve from 0.91872\n","Epoch 154/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.5554 - val_accuracy: 0.8842\n","\n","Epoch 00154: val_accuracy did not improve from 0.91872\n","Epoch 155/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.4459 - val_accuracy: 0.8990\n","\n","Epoch 00155: val_accuracy did not improve from 0.91872\n","Epoch 156/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.4813 - val_accuracy: 0.9015\n","\n","Epoch 00156: val_accuracy did not improve from 0.91872\n","Epoch 157/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.7038 - val_accuracy: 0.8621\n","\n","Epoch 00157: val_accuracy did not improve from 0.91872\n","Epoch 158/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.5115 - val_accuracy: 0.8916\n","\n","Epoch 00158: val_accuracy did not improve from 0.91872\n","Epoch 159/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5381 - val_accuracy: 0.8966\n","\n","Epoch 00159: val_accuracy did not improve from 0.91872\n","Epoch 160/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.8749 - val_accuracy: 0.8128\n","\n","Epoch 00160: val_accuracy did not improve from 0.91872\n","Epoch 161/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.6206 - val_accuracy: 0.8867\n","\n","Epoch 00161: val_accuracy did not improve from 0.91872\n","Epoch 162/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.6633 - val_accuracy: 0.8571\n","\n","Epoch 00162: val_accuracy did not improve from 0.91872\n","Epoch 163/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.5556 - val_accuracy: 0.8768\n","\n","Epoch 00163: val_accuracy did not improve from 0.91872\n","Epoch 164/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4878 - val_accuracy: 0.8990\n","\n","Epoch 00164: val_accuracy did not improve from 0.91872\n","Epoch 165/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.5328 - val_accuracy: 0.9015\n","\n","Epoch 00165: val_accuracy did not improve from 0.91872\n","Epoch 166/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.4608 - val_accuracy: 0.9113\n","\n","Epoch 00166: val_accuracy did not improve from 0.91872\n","Epoch 167/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9138\n","\n","Epoch 00167: val_accuracy did not improve from 0.91872\n","Epoch 168/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4498 - val_accuracy: 0.9212\n","\n","Epoch 00168: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 169/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9261\n","\n","Epoch 00169: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 170/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.5935 - val_accuracy: 0.8966\n","\n","Epoch 00170: val_accuracy did not improve from 0.92611\n","Epoch 171/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.8563 - val_accuracy: 0.8695\n","\n","Epoch 00171: val_accuracy did not improve from 0.92611\n","Epoch 172/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.6995 - val_accuracy: 0.8645\n","\n","Epoch 00172: val_accuracy did not improve from 0.92611\n","Epoch 173/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0602 - accuracy: 0.9836 - val_loss: 0.9494 - val_accuracy: 0.8177\n","\n","Epoch 00173: val_accuracy did not improve from 0.92611\n","Epoch 174/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.9785 - val_accuracy: 0.8227\n","\n","Epoch 00174: val_accuracy did not improve from 0.92611\n","Epoch 175/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.6095 - val_accuracy: 0.8941\n","\n","Epoch 00175: val_accuracy did not improve from 0.92611\n","Epoch 176/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.5108 - val_accuracy: 0.9138\n","\n","Epoch 00176: val_accuracy did not improve from 0.92611\n","Epoch 177/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6268 - val_accuracy: 0.8621\n","\n","Epoch 00177: val_accuracy did not improve from 0.92611\n","Epoch 178/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.3911 - val_accuracy: 0.9089\n","\n","Epoch 00178: val_accuracy did not improve from 0.92611\n","Epoch 179/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.5027 - val_accuracy: 0.8768\n","\n","Epoch 00179: val_accuracy did not improve from 0.92611\n","Epoch 180/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 0.5025 - val_accuracy: 0.8990\n","\n","Epoch 00180: val_accuracy did not improve from 0.92611\n","Epoch 181/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.5152 - val_accuracy: 0.9064\n","\n","Epoch 00181: val_accuracy did not improve from 0.92611\n","Epoch 182/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0755 - accuracy: 0.9769 - val_loss: 0.7620 - val_accuracy: 0.8744\n","\n","Epoch 00182: val_accuracy did not improve from 0.92611\n","Epoch 183/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0671 - accuracy: 0.9817 - val_loss: 0.7517 - val_accuracy: 0.8744\n","\n","Epoch 00183: val_accuracy did not improve from 0.92611\n","Epoch 184/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.6882 - val_accuracy: 0.8719\n","\n","Epoch 00184: val_accuracy did not improve from 0.92611\n","Epoch 185/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0261 - accuracy: 0.9890 - val_loss: 0.5761 - val_accuracy: 0.8793\n","\n","Epoch 00185: val_accuracy did not improve from 0.92611\n","Epoch 186/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.5166 - val_accuracy: 0.8916\n","\n","Epoch 00186: val_accuracy did not improve from 0.92611\n","Epoch 187/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.5115 - val_accuracy: 0.8966\n","\n","Epoch 00187: val_accuracy did not improve from 0.92611\n","Epoch 188/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.6813 - val_accuracy: 0.8744\n","\n","Epoch 00188: val_accuracy did not improve from 0.92611\n","Epoch 189/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5145 - val_accuracy: 0.8892\n","\n","Epoch 00189: val_accuracy did not improve from 0.92611\n","Epoch 190/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.4838 - val_accuracy: 0.9039\n","\n","Epoch 00190: val_accuracy did not improve from 0.92611\n","Epoch 191/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5022 - val_accuracy: 0.9039\n","\n","Epoch 00191: val_accuracy did not improve from 0.92611\n","Epoch 192/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4594 - val_accuracy: 0.9015\n","\n","Epoch 00192: val_accuracy did not improve from 0.92611\n","Epoch 193/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5177 - val_accuracy: 0.8941\n","\n","Epoch 00193: val_accuracy did not improve from 0.92611\n","Epoch 194/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.9163\n","\n","Epoch 00194: val_accuracy did not improve from 0.92611\n","Epoch 195/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.4742 - val_accuracy: 0.8941\n","\n","Epoch 00195: val_accuracy did not improve from 0.92611\n","Epoch 196/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.3551 - val_accuracy: 0.9310\n","\n","Epoch 00196: val_accuracy improved from 0.92611 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5\n","Epoch 197/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4532 - val_accuracy: 0.9187\n","\n","Epoch 00197: val_accuracy did not improve from 0.93103\n","Epoch 198/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.5514 - val_accuracy: 0.8966\n","\n","Epoch 00198: val_accuracy did not improve from 0.93103\n","Epoch 199/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.5068 - val_accuracy: 0.9015\n","\n","Epoch 00199: val_accuracy did not improve from 0.93103\n","Epoch 200/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.6999 - val_accuracy: 0.8744\n","\n","Epoch 00200: val_accuracy did not improve from 0.93103\n","Epoch 201/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5202 - val_accuracy: 0.8916\n","\n","Epoch 00201: val_accuracy did not improve from 0.93103\n","Epoch 202/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.5074 - val_accuracy: 0.9089\n","\n","Epoch 00202: val_accuracy did not improve from 0.93103\n","Epoch 203/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.5464 - val_accuracy: 0.8990\n","\n","Epoch 00203: val_accuracy did not improve from 0.93103\n","Epoch 204/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.6578 - val_accuracy: 0.8916\n","\n","Epoch 00204: val_accuracy did not improve from 0.93103\n","Epoch 205/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0309 - accuracy: 0.9909 - val_loss: 0.8720 - val_accuracy: 0.8768\n","\n","Epoch 00205: val_accuracy did not improve from 0.93103\n","Epoch 206/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.6373 - val_accuracy: 0.8793\n","\n","Epoch 00206: val_accuracy did not improve from 0.93103\n","Epoch 207/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.7994 - val_accuracy: 0.8596\n","\n","Epoch 00207: val_accuracy did not improve from 0.93103\n","Epoch 208/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.6504 - val_accuracy: 0.8966\n","\n","Epoch 00208: val_accuracy did not improve from 0.93103\n","Epoch 209/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.6201 - val_accuracy: 0.8818\n","\n","Epoch 00209: val_accuracy did not improve from 0.93103\n","Epoch 210/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.5428 - val_accuracy: 0.8916\n","\n","Epoch 00210: val_accuracy did not improve from 0.93103\n","Epoch 211/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.6371 - val_accuracy: 0.8768\n","\n","Epoch 00211: val_accuracy did not improve from 0.93103\n","Epoch 212/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.6672 - val_accuracy: 0.8892\n","\n","Epoch 00212: val_accuracy did not improve from 0.93103\n","Epoch 213/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 1.1924 - val_accuracy: 0.8227\n","\n","Epoch 00213: val_accuracy did not improve from 0.93103\n","Epoch 214/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.5524 - val_accuracy: 0.8892\n","\n","Epoch 00214: val_accuracy did not improve from 0.93103\n","Epoch 215/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.9913 - val_accuracy: 0.8276\n","\n","Epoch 00215: val_accuracy did not improve from 0.93103\n","Epoch 216/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0501 - accuracy: 0.9872 - val_loss: 0.9208 - val_accuracy: 0.8498\n","\n","Epoch 00216: val_accuracy did not improve from 0.93103\n","Epoch 217/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 0.9128 - val_accuracy: 0.8498\n","\n","Epoch 00217: val_accuracy did not improve from 0.93103\n","Epoch 218/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.6649 - val_accuracy: 0.8818\n","\n","Epoch 00218: val_accuracy did not improve from 0.93103\n","Epoch 219/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6426 - val_accuracy: 0.8867\n","\n","Epoch 00219: val_accuracy did not improve from 0.93103\n","Epoch 220/500\n","52/52 [==============================] - 20s 396ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.5068 - val_accuracy: 0.8892\n","\n","Epoch 00220: val_accuracy did not improve from 0.93103\n","Epoch 221/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.8768 - val_accuracy: 0.8744\n","\n","Epoch 00221: val_accuracy did not improve from 0.93103\n","Epoch 222/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.7093 - val_accuracy: 0.8695\n","\n","Epoch 00222: val_accuracy did not improve from 0.93103\n","Epoch 223/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.6642 - val_accuracy: 0.8941\n","\n","Epoch 00223: val_accuracy did not improve from 0.93103\n","Epoch 224/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.6814 - val_accuracy: 0.8768\n","\n","Epoch 00224: val_accuracy did not improve from 0.93103\n","Epoch 225/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0194 - accuracy: 0.9915 - val_loss: 0.6181 - val_accuracy: 0.9015\n","\n","Epoch 00225: val_accuracy did not improve from 0.93103\n","Epoch 226/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 0.6190 - val_accuracy: 0.8744\n","\n","Epoch 00226: val_accuracy did not improve from 0.93103\n","Epoch 227/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0124 - accuracy: 0.9939 - val_loss: 0.6391 - val_accuracy: 0.8818\n","\n","Epoch 00227: val_accuracy did not improve from 0.93103\n","Epoch 228/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5258 - val_accuracy: 0.9039\n","\n","Epoch 00228: val_accuracy did not improve from 0.93103\n","Epoch 229/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6505 - val_accuracy: 0.9015\n","\n","Epoch 00229: val_accuracy did not improve from 0.93103\n","Epoch 230/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4852 - val_accuracy: 0.9138\n","\n","Epoch 00230: val_accuracy did not improve from 0.93103\n","Epoch 231/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4724 - val_accuracy: 0.9064\n","\n","Epoch 00231: val_accuracy did not improve from 0.93103\n","Epoch 232/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4829 - val_accuracy: 0.9187\n","\n","Epoch 00232: val_accuracy did not improve from 0.93103\n","Epoch 233/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6967 - val_accuracy: 0.8892\n","\n","Epoch 00233: val_accuracy did not improve from 0.93103\n","Epoch 234/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.9138\n","\n","Epoch 00234: val_accuracy did not improve from 0.93103\n","Epoch 235/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0545 - accuracy: 0.9909 - val_loss: 1.5973 - val_accuracy: 0.7759\n","\n","Epoch 00235: val_accuracy did not improve from 0.93103\n","Epoch 236/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 0.9841 - val_accuracy: 0.8522\n","\n","Epoch 00236: val_accuracy did not improve from 0.93103\n","Epoch 237/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.7307 - val_accuracy: 0.8596\n","\n","Epoch 00237: val_accuracy did not improve from 0.93103\n","Epoch 238/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0518 - accuracy: 0.9787 - val_loss: 0.6720 - val_accuracy: 0.8670\n","\n","Epoch 00238: val_accuracy did not improve from 0.93103\n","Epoch 239/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.7227 - val_accuracy: 0.8670\n","\n","Epoch 00239: val_accuracy did not improve from 0.93103\n","Epoch 240/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5885 - val_accuracy: 0.9015\n","\n","Epoch 00240: val_accuracy did not improve from 0.93103\n","Epoch 241/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.5322 - val_accuracy: 0.8892\n","\n","Epoch 00241: val_accuracy did not improve from 0.93103\n","Epoch 242/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5062 - val_accuracy: 0.8916\n","\n","Epoch 00242: val_accuracy did not improve from 0.93103\n","Epoch 243/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 0.6957 - val_accuracy: 0.8744\n","\n","Epoch 00243: val_accuracy did not improve from 0.93103\n","Epoch 244/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.5552 - val_accuracy: 0.8916\n","\n","Epoch 00244: val_accuracy did not improve from 0.93103\n","Epoch 245/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.6039 - val_accuracy: 0.8842\n","\n","Epoch 00245: val_accuracy did not improve from 0.93103\n","Epoch 246/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.6379 - val_accuracy: 0.8719\n","\n","Epoch 00246: val_accuracy did not improve from 0.93103\n","Epoch 247/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0112 - accuracy: 0.9951 - val_loss: 0.5567 - val_accuracy: 0.8867\n","\n","Epoch 00247: val_accuracy did not improve from 0.93103\n","Epoch 248/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.6210 - val_accuracy: 0.8695\n","\n","Epoch 00248: val_accuracy did not improve from 0.93103\n","Epoch 249/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.5217 - val_accuracy: 0.9015\n","\n","Epoch 00249: val_accuracy did not improve from 0.93103\n","Epoch 250/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6740 - val_accuracy: 0.8941\n","\n","Epoch 00250: val_accuracy did not improve from 0.93103\n","Epoch 251/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.6615 - val_accuracy: 0.8990\n","\n","Epoch 00251: val_accuracy did not improve from 0.93103\n","Epoch 252/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0697 - accuracy: 0.9805 - val_loss: 0.9072 - val_accuracy: 0.8621\n","\n","Epoch 00252: val_accuracy did not improve from 0.93103\n","Epoch 253/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 1.1061 - val_accuracy: 0.8596\n","\n","Epoch 00253: val_accuracy did not improve from 0.93103\n","Epoch 254/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.7650 - val_accuracy: 0.8842\n","\n","Epoch 00254: val_accuracy did not improve from 0.93103\n","Epoch 255/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.6225 - val_accuracy: 0.8793\n","\n","Epoch 00255: val_accuracy did not improve from 0.93103\n","Epoch 256/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.6378 - val_accuracy: 0.8892\n","\n","Epoch 00256: val_accuracy did not improve from 0.93103\n","Epoch 257/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.5988 - val_accuracy: 0.9064\n","\n","Epoch 00257: val_accuracy did not improve from 0.93103\n","Epoch 258/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5577 - val_accuracy: 0.9039\n","\n","Epoch 00258: val_accuracy did not improve from 0.93103\n","Epoch 259/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.4513 - val_accuracy: 0.9113\n","\n","Epoch 00259: val_accuracy did not improve from 0.93103\n","Epoch 260/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.6042 - val_accuracy: 0.8867\n","\n","Epoch 00260: val_accuracy did not improve from 0.93103\n","Epoch 261/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.5220 - val_accuracy: 0.8990\n","\n","Epoch 00261: val_accuracy did not improve from 0.93103\n","Epoch 262/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.6620 - val_accuracy: 0.8695\n","\n","Epoch 00262: val_accuracy did not improve from 0.93103\n","Epoch 263/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.6083 - val_accuracy: 0.8645\n","\n","Epoch 00263: val_accuracy did not improve from 0.93103\n","Epoch 264/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.5141 - val_accuracy: 0.8793\n","\n","Epoch 00264: val_accuracy did not improve from 0.93103\n","Epoch 265/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4961 - val_accuracy: 0.8941\n","\n","Epoch 00265: val_accuracy did not improve from 0.93103\n","Epoch 266/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4031 - val_accuracy: 0.9187\n","\n","Epoch 00266: val_accuracy did not improve from 0.93103\n","Epoch 267/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.4554 - val_accuracy: 0.9089\n","\n","Epoch 00267: val_accuracy did not improve from 0.93103\n","Epoch 268/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4519 - val_accuracy: 0.9064\n","\n","Epoch 00268: val_accuracy did not improve from 0.93103\n","Epoch 269/500\n","52/52 [==============================] - 21s 404ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9064\n","\n","Epoch 00269: val_accuracy did not improve from 0.93103\n","Epoch 270/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4435 - val_accuracy: 0.9310\n","\n","Epoch 00270: val_accuracy did not improve from 0.93103\n","Epoch 271/500\n","52/52 [==============================] - 20s 390ms/step - loss: 9.8896e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9163\n","\n","Epoch 00271: val_accuracy did not improve from 0.93103\n","Epoch 272/500\n","52/52 [==============================] - 20s 392ms/step - loss: 9.6483e-04 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9113\n","\n","Epoch 00272: val_accuracy did not improve from 0.93103\n","Epoch 273/500\n","52/52 [==============================] - 20s 392ms/step - loss: 8.0820e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9113\n","\n","Epoch 00273: val_accuracy did not improve from 0.93103\n","Epoch 274/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4669 - val_accuracy: 0.9089\n","\n","Epoch 00274: val_accuracy did not improve from 0.93103\n","Epoch 275/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5384 - val_accuracy: 0.9039\n","\n","Epoch 00275: val_accuracy did not improve from 0.93103\n","Epoch 276/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4528 - val_accuracy: 0.9286\n","\n","Epoch 00276: val_accuracy did not improve from 0.93103\n","Epoch 277/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.7441 - val_accuracy: 0.8867\n","\n","Epoch 00277: val_accuracy did not improve from 0.93103\n","Epoch 278/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.7233 - val_accuracy: 0.9039\n","\n","Epoch 00278: val_accuracy did not improve from 0.93103\n","Epoch 279/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.7466 - val_accuracy: 0.8719\n","\n","Epoch 00279: val_accuracy did not improve from 0.93103\n","Epoch 280/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0483 - accuracy: 0.9860 - val_loss: 0.9873 - val_accuracy: 0.8276\n","\n","Epoch 00280: val_accuracy did not improve from 0.93103\n","Epoch 281/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.7087 - val_accuracy: 0.8695\n","\n","Epoch 00281: val_accuracy did not improve from 0.93103\n","Epoch 282/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.6417 - val_accuracy: 0.9089\n","\n","Epoch 00282: val_accuracy did not improve from 0.93103\n","Epoch 283/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0709 - accuracy: 0.9787 - val_loss: 0.7061 - val_accuracy: 0.8695\n","\n","Epoch 00283: val_accuracy did not improve from 0.93103\n","Epoch 284/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.6096 - val_accuracy: 0.8916\n","\n","Epoch 00284: val_accuracy did not improve from 0.93103\n","Epoch 285/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.5815 - val_accuracy: 0.8966\n","\n","Epoch 00285: val_accuracy did not improve from 0.93103\n","Epoch 286/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.5761 - val_accuracy: 0.9015\n","\n","Epoch 00286: val_accuracy did not improve from 0.93103\n","Epoch 287/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.9053 - val_accuracy: 0.8645\n","\n","Epoch 00287: val_accuracy did not improve from 0.93103\n","Epoch 288/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.1029 - accuracy: 0.9726 - val_loss: 0.7713 - val_accuracy: 0.8547\n","\n","Epoch 00288: val_accuracy did not improve from 0.93103\n","Epoch 289/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.4294 - val_accuracy: 0.8966\n","\n","Epoch 00289: val_accuracy did not improve from 0.93103\n","Epoch 290/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.4455 - val_accuracy: 0.9113\n","\n","Epoch 00290: val_accuracy did not improve from 0.93103\n","Epoch 291/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4386 - val_accuracy: 0.8941\n","\n","Epoch 00291: val_accuracy did not improve from 0.93103\n","Epoch 292/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4863 - val_accuracy: 0.8990\n","\n","Epoch 00292: val_accuracy did not improve from 0.93103\n","Epoch 293/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.4176 - val_accuracy: 0.8941\n","\n","Epoch 00293: val_accuracy did not improve from 0.93103\n","Epoch 294/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3949 - val_accuracy: 0.9187\n","\n","Epoch 00294: val_accuracy did not improve from 0.93103\n","Epoch 295/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4647 - val_accuracy: 0.8990\n","\n","Epoch 00295: val_accuracy did not improve from 0.93103\n","Epoch 296/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4409 - val_accuracy: 0.8966\n","\n","Epoch 00296: val_accuracy did not improve from 0.93103\n","Epoch 297/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3792 - val_accuracy: 0.9089\n","\n","Epoch 00297: val_accuracy did not improve from 0.93103\n","Epoch 298/500\n","52/52 [==============================] - 20s 391ms/step - loss: 7.8017e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9163\n","\n","Epoch 00298: val_accuracy did not improve from 0.93103\n","Epoch 299/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4680 - val_accuracy: 0.9089\n","\n","Epoch 00299: val_accuracy did not improve from 0.93103\n","Epoch 300/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4926 - val_accuracy: 0.8990\n","\n","Epoch 00300: val_accuracy did not improve from 0.93103\n","Epoch 301/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9163\n","\n","Epoch 00301: val_accuracy did not improve from 0.93103\n","Epoch 302/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5565 - val_accuracy: 0.8941\n","\n","Epoch 00302: val_accuracy did not improve from 0.93103\n","Epoch 303/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.5058 - val_accuracy: 0.9064\n","\n","Epoch 00303: val_accuracy did not improve from 0.93103\n","Epoch 304/500\n","52/52 [==============================] - 20s 396ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4606 - val_accuracy: 0.9236\n","\n","Epoch 00304: val_accuracy did not improve from 0.93103\n","Epoch 305/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5576 - val_accuracy: 0.8892\n","\n","Epoch 00305: val_accuracy did not improve from 0.93103\n","Epoch 306/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3817 - val_accuracy: 0.9138\n","\n","Epoch 00306: val_accuracy did not improve from 0.93103\n","Epoch 307/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.9163\n","\n","Epoch 00307: val_accuracy did not improve from 0.93103\n","Epoch 308/500\n","52/52 [==============================] - 20s 391ms/step - loss: 6.8408e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9261\n","\n","Epoch 00308: val_accuracy did not improve from 0.93103\n","Epoch 309/500\n","52/52 [==============================] - 20s 391ms/step - loss: 4.3619e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9310\n","\n","Epoch 00309: val_accuracy did not improve from 0.93103\n","Epoch 310/500\n","52/52 [==============================] - 20s 394ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.6520 - val_accuracy: 0.8966\n","\n","Epoch 00310: val_accuracy did not improve from 0.93103\n","Epoch 311/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6461 - val_accuracy: 0.9039\n","\n","Epoch 00311: val_accuracy did not improve from 0.93103\n","Epoch 312/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.6174 - val_accuracy: 0.8842\n","\n","Epoch 00312: val_accuracy did not improve from 0.93103\n","Epoch 313/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.8044 - val_accuracy: 0.8473\n","\n","Epoch 00313: val_accuracy did not improve from 0.93103\n","Epoch 314/500\n","52/52 [==============================] - 20s 395ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 0.5439 - val_accuracy: 0.9039\n","\n","Epoch 00314: val_accuracy did not improve from 0.93103\n","Epoch 315/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5424 - val_accuracy: 0.9039\n","\n","Epoch 00315: val_accuracy did not improve from 0.93103\n","Epoch 316/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.4474 - val_accuracy: 0.9212\n","\n","Epoch 00316: val_accuracy did not improve from 0.93103\n","Epoch 317/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.7495 - val_accuracy: 0.8768\n","\n","Epoch 00317: val_accuracy did not improve from 0.93103\n","Epoch 318/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0964 - accuracy: 0.9714 - val_loss: 0.9323 - val_accuracy: 0.8498\n","\n","Epoch 00318: val_accuracy did not improve from 0.93103\n","Epoch 319/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.6316 - val_accuracy: 0.8867\n","\n","Epoch 00319: val_accuracy did not improve from 0.93103\n","Epoch 320/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.6800 - val_accuracy: 0.8793\n","\n","Epoch 00320: val_accuracy did not improve from 0.93103\n","Epoch 321/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0478 - accuracy: 0.9866 - val_loss: 0.5941 - val_accuracy: 0.8892\n","\n","Epoch 00321: val_accuracy did not improve from 0.93103\n","Epoch 322/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.6864 - val_accuracy: 0.8818\n","\n","Epoch 00322: val_accuracy did not improve from 0.93103\n","Epoch 323/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.5161 - val_accuracy: 0.9163\n","\n","Epoch 00323: val_accuracy did not improve from 0.93103\n","Epoch 324/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.4396 - val_accuracy: 0.9064\n","\n","Epoch 00324: val_accuracy did not improve from 0.93103\n","Epoch 325/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5031 - val_accuracy: 0.9138\n","\n","Epoch 00325: val_accuracy did not improve from 0.93103\n","Epoch 326/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5074 - val_accuracy: 0.9138\n","\n","Epoch 00326: val_accuracy did not improve from 0.93103\n","Epoch 327/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9015\n","\n","Epoch 00327: val_accuracy did not improve from 0.93103\n","Epoch 328/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9113\n","\n","Epoch 00328: val_accuracy did not improve from 0.93103\n","Epoch 329/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9236\n","\n","Epoch 00329: val_accuracy did not improve from 0.93103\n","Epoch 330/500\n","52/52 [==============================] - 20s 390ms/step - loss: 9.8407e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9163\n","\n","Epoch 00330: val_accuracy did not improve from 0.93103\n","Epoch 331/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4864 - val_accuracy: 0.9138\n","\n","Epoch 00331: val_accuracy did not improve from 0.93103\n","Epoch 332/500\n","52/52 [==============================] - 20s 391ms/step - loss: 9.8176e-04 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9163\n","\n","Epoch 00332: val_accuracy did not improve from 0.93103\n","Epoch 333/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4413 - val_accuracy: 0.9163\n","\n","Epoch 00333: val_accuracy did not improve from 0.93103\n","Epoch 334/500\n","52/52 [==============================] - 20s 391ms/step - loss: 9.3654e-04 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9212\n","\n","Epoch 00334: val_accuracy did not improve from 0.93103\n","Epoch 335/500\n","52/52 [==============================] - 21s 393ms/step - loss: 7.8621e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9113\n","\n","Epoch 00335: val_accuracy did not improve from 0.93103\n","Epoch 336/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5504 - val_accuracy: 0.9089\n","\n","Epoch 00336: val_accuracy did not improve from 0.93103\n","Epoch 337/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.7467 - val_accuracy: 0.8990\n","\n","Epoch 00337: val_accuracy did not improve from 0.93103\n","Epoch 338/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.6141 - val_accuracy: 0.9015\n","\n","Epoch 00338: val_accuracy did not improve from 0.93103\n","Epoch 339/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 1.1688 - val_accuracy: 0.8103\n","\n","Epoch 00339: val_accuracy did not improve from 0.93103\n","Epoch 340/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.9688 - val_accuracy: 0.8276\n","\n","Epoch 00340: val_accuracy did not improve from 0.93103\n","Epoch 341/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 1.1060 - val_accuracy: 0.8448\n","\n","Epoch 00341: val_accuracy did not improve from 0.93103\n","Epoch 342/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.5895 - val_accuracy: 0.8867\n","\n","Epoch 00342: val_accuracy did not improve from 0.93103\n","Epoch 343/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.5503 - val_accuracy: 0.8990\n","\n","Epoch 00343: val_accuracy did not improve from 0.93103\n","Epoch 344/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.5247 - val_accuracy: 0.9064\n","\n","Epoch 00344: val_accuracy did not improve from 0.93103\n","Epoch 345/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.4516 - val_accuracy: 0.9089\n","\n","Epoch 00345: val_accuracy did not improve from 0.93103\n","Epoch 346/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4958 - val_accuracy: 0.9236\n","\n","Epoch 00346: val_accuracy did not improve from 0.93103\n","Epoch 347/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9138\n","\n","Epoch 00347: val_accuracy did not improve from 0.93103\n","Epoch 348/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4758 - val_accuracy: 0.8916\n","\n","Epoch 00348: val_accuracy did not improve from 0.93103\n","Epoch 349/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.7481 - val_accuracy: 0.8695\n","\n","Epoch 00349: val_accuracy did not improve from 0.93103\n","Epoch 350/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.6367 - val_accuracy: 0.8867\n","\n","Epoch 00350: val_accuracy did not improve from 0.93103\n","Epoch 351/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5156 - val_accuracy: 0.9089\n","\n","Epoch 00351: val_accuracy did not improve from 0.93103\n","Epoch 352/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4808 - val_accuracy: 0.9064\n","\n","Epoch 00352: val_accuracy did not improve from 0.93103\n","Epoch 353/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5746 - val_accuracy: 0.9039\n","\n","Epoch 00353: val_accuracy did not improve from 0.93103\n","Epoch 354/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9015\n","\n","Epoch 00354: val_accuracy did not improve from 0.93103\n","Epoch 355/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5361 - val_accuracy: 0.9138\n","\n","Epoch 00355: val_accuracy did not improve from 0.93103\n","Epoch 356/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4507 - val_accuracy: 0.9187\n","\n","Epoch 00356: val_accuracy did not improve from 0.93103\n","Epoch 357/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9310\n","\n","Epoch 00357: val_accuracy did not improve from 0.93103\n","Epoch 358/500\n","52/52 [==============================] - 20s 389ms/step - loss: 9.3792e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9187\n","\n","Epoch 00358: val_accuracy did not improve from 0.93103\n","Epoch 359/500\n","52/52 [==============================] - 21s 403ms/step - loss: 8.5988e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9187\n","\n","Epoch 00359: val_accuracy did not improve from 0.93103\n","Epoch 360/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.1421e-04 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9187\n","\n","Epoch 00360: val_accuracy did not improve from 0.93103\n","Epoch 361/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.3964 - val_accuracy: 0.9236\n","\n","Epoch 00361: val_accuracy did not improve from 0.93103\n","Epoch 362/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.5257 - val_accuracy: 0.8892\n","\n","Epoch 00362: val_accuracy did not improve from 0.93103\n","Epoch 363/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.6379 - val_accuracy: 0.8768\n","\n","Epoch 00363: val_accuracy did not improve from 0.93103\n","Epoch 364/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6191 - val_accuracy: 0.8966\n","\n","Epoch 00364: val_accuracy did not improve from 0.93103\n","Epoch 365/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.5419 - val_accuracy: 0.9064\n","\n","Epoch 00365: val_accuracy did not improve from 0.93103\n","Epoch 366/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5048 - val_accuracy: 0.9163\n","\n","Epoch 00366: val_accuracy did not improve from 0.93103\n","Epoch 367/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5314 - val_accuracy: 0.9261\n","\n","Epoch 00367: val_accuracy did not improve from 0.93103\n","Epoch 368/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 1.1571 - val_accuracy: 0.8325\n","\n","Epoch 00368: val_accuracy did not improve from 0.93103\n","Epoch 369/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0714 - accuracy: 0.9817 - val_loss: 1.3430 - val_accuracy: 0.8251\n","\n","Epoch 00369: val_accuracy did not improve from 0.93103\n","Epoch 370/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.8955 - val_accuracy: 0.8768\n","\n","Epoch 00370: val_accuracy did not improve from 0.93103\n","Epoch 371/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0102 - accuracy: 0.9988 - val_loss: 0.8627 - val_accuracy: 0.8596\n","\n","Epoch 00371: val_accuracy did not improve from 0.93103\n","Epoch 372/500\n","52/52 [==============================] - 21s 403ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.7484 - val_accuracy: 0.8719\n","\n","Epoch 00372: val_accuracy did not improve from 0.93103\n","Epoch 373/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0346 - accuracy: 0.9921 - val_loss: 0.7583 - val_accuracy: 0.8966\n","\n","Epoch 00373: val_accuracy did not improve from 0.93103\n","Epoch 374/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.5257 - val_accuracy: 0.8990\n","\n","Epoch 00374: val_accuracy did not improve from 0.93103\n","Epoch 375/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4944 - val_accuracy: 0.8941\n","\n","Epoch 00375: val_accuracy did not improve from 0.93103\n","Epoch 376/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4163 - val_accuracy: 0.9212\n","\n","Epoch 00376: val_accuracy did not improve from 0.93103\n","Epoch 377/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8990\n","\n","Epoch 00377: val_accuracy did not improve from 0.93103\n","Epoch 378/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.6007 - val_accuracy: 0.8892\n","\n","Epoch 00378: val_accuracy did not improve from 0.93103\n","Epoch 379/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.6163 - val_accuracy: 0.8966\n","\n","Epoch 00379: val_accuracy did not improve from 0.93103\n","Epoch 380/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.5509 - val_accuracy: 0.8990\n","\n","Epoch 00380: val_accuracy did not improve from 0.93103\n","Epoch 381/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.6625 - val_accuracy: 0.8793\n","\n","Epoch 00381: val_accuracy did not improve from 0.93103\n","Epoch 382/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9064\n","\n","Epoch 00382: val_accuracy did not improve from 0.93103\n","Epoch 383/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9212\n","\n","Epoch 00383: val_accuracy did not improve from 0.93103\n","Epoch 384/500\n","52/52 [==============================] - 20s 392ms/step - loss: 5.4387e-04 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9138\n","\n","Epoch 00384: val_accuracy did not improve from 0.93103\n","Epoch 385/500\n","52/52 [==============================] - 21s 393ms/step - loss: 2.7498e-04 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9089\n","\n","Epoch 00385: val_accuracy did not improve from 0.93103\n","Epoch 386/500\n","52/52 [==============================] - 20s 392ms/step - loss: 2.7308e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9261\n","\n","Epoch 00386: val_accuracy did not improve from 0.93103\n","Epoch 387/500\n","52/52 [==============================] - 20s 390ms/step - loss: 7.6404e-04 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9187\n","\n","Epoch 00387: val_accuracy did not improve from 0.93103\n","Epoch 388/500\n","52/52 [==============================] - 20s 390ms/step - loss: 3.8910e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9212\n","\n","Epoch 00388: val_accuracy did not improve from 0.93103\n","Epoch 389/500\n","52/52 [==============================] - 20s 392ms/step - loss: 3.4109e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9187\n","\n","Epoch 00389: val_accuracy did not improve from 0.93103\n","Epoch 390/500\n","52/52 [==============================] - 20s 391ms/step - loss: 2.7152e-04 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9286\n","\n","Epoch 00390: val_accuracy did not improve from 0.93103\n","Epoch 391/500\n","52/52 [==============================] - 20s 392ms/step - loss: 1.4572e-04 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9212\n","\n","Epoch 00391: val_accuracy did not improve from 0.93103\n","Epoch 392/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4963 - val_accuracy: 0.9187\n","\n","Epoch 00392: val_accuracy did not improve from 0.93103\n","Epoch 393/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5228 - val_accuracy: 0.9113\n","\n","Epoch 00393: val_accuracy did not improve from 0.93103\n","Epoch 394/500\n","52/52 [==============================] - 20s 389ms/step - loss: 7.3844e-04 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.9039\n","\n","Epoch 00394: val_accuracy did not improve from 0.93103\n","Epoch 395/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.9138 - val_accuracy: 0.8522\n","\n","Epoch 00395: val_accuracy did not improve from 0.93103\n","Epoch 396/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0859 - accuracy: 0.9793 - val_loss: 2.1122 - val_accuracy: 0.7291\n","\n","Epoch 00396: val_accuracy did not improve from 0.93103\n","Epoch 397/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 0.8475 - val_accuracy: 0.8793\n","\n","Epoch 00397: val_accuracy did not improve from 0.93103\n","Epoch 398/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.6689 - val_accuracy: 0.8768\n","\n","Epoch 00398: val_accuracy did not improve from 0.93103\n","Epoch 399/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.5129 - val_accuracy: 0.8867\n","\n","Epoch 00399: val_accuracy did not improve from 0.93103\n","Epoch 400/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.4581 - val_accuracy: 0.9039\n","\n","Epoch 00400: val_accuracy did not improve from 0.93103\n","Epoch 401/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7171 - val_accuracy: 0.8670\n","\n","Epoch 00401: val_accuracy did not improve from 0.93103\n","Epoch 402/500\n","52/52 [==============================] - 20s 396ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.4813 - val_accuracy: 0.8916\n","\n","Epoch 00402: val_accuracy did not improve from 0.93103\n","Epoch 403/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.5803 - val_accuracy: 0.8892\n","\n","Epoch 00403: val_accuracy did not improve from 0.93103\n","Epoch 404/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4839 - val_accuracy: 0.8892\n","\n","Epoch 00404: val_accuracy did not improve from 0.93103\n","Epoch 405/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9138\n","\n","Epoch 00405: val_accuracy did not improve from 0.93103\n","Epoch 406/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6041 - val_accuracy: 0.9015\n","\n","Epoch 00406: val_accuracy did not improve from 0.93103\n","Epoch 407/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6022 - val_accuracy: 0.8941\n","\n","Epoch 00407: val_accuracy did not improve from 0.93103\n","Epoch 408/500\n","52/52 [==============================] - 20s 388ms/step - loss: 9.2717e-04 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8990\n","\n","Epoch 00408: val_accuracy did not improve from 0.93103\n","Epoch 409/500\n","52/52 [==============================] - 20s 391ms/step - loss: 6.7166e-04 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.9113\n","\n","Epoch 00409: val_accuracy did not improve from 0.93103\n","Epoch 410/500\n","52/52 [==============================] - 20s 390ms/step - loss: 9.3394e-04 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.9039\n","\n","Epoch 00410: val_accuracy did not improve from 0.93103\n","Epoch 411/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 0.8235 - val_accuracy: 0.8768\n","\n","Epoch 00411: val_accuracy did not improve from 0.93103\n","Epoch 412/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.7872 - val_accuracy: 0.8670\n","\n","Epoch 00412: val_accuracy did not improve from 0.93103\n","Epoch 413/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.5468 - val_accuracy: 0.8941\n","\n","Epoch 00413: val_accuracy did not improve from 0.93103\n","Epoch 414/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5961 - val_accuracy: 0.8719\n","\n","Epoch 00414: val_accuracy did not improve from 0.93103\n","Epoch 415/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.5339 - val_accuracy: 0.8892\n","\n","Epoch 00415: val_accuracy did not improve from 0.93103\n","Epoch 416/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9138\n","\n","Epoch 00416: val_accuracy did not improve from 0.93103\n","Epoch 417/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4536 - val_accuracy: 0.9039\n","\n","Epoch 00417: val_accuracy did not improve from 0.93103\n","Epoch 418/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.7591 - val_accuracy: 0.8867\n","\n","Epoch 00418: val_accuracy did not improve from 0.93103\n","Epoch 419/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.9089\n","\n","Epoch 00419: val_accuracy did not improve from 0.93103\n","Epoch 420/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.6695 - val_accuracy: 0.8818\n","\n","Epoch 00420: val_accuracy did not improve from 0.93103\n","Epoch 421/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.8040 - val_accuracy: 0.8719\n","\n","Epoch 00421: val_accuracy did not improve from 0.93103\n","Epoch 422/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6810 - val_accuracy: 0.8892\n","\n","Epoch 00422: val_accuracy did not improve from 0.93103\n","Epoch 423/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.5761 - val_accuracy: 0.9163\n","\n","Epoch 00423: val_accuracy did not improve from 0.93103\n","Epoch 424/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.4940 - val_accuracy: 0.9039\n","\n","Epoch 00424: val_accuracy did not improve from 0.93103\n","Epoch 425/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5219 - val_accuracy: 0.9138\n","\n","Epoch 00425: val_accuracy did not improve from 0.93103\n","Epoch 426/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6685 - val_accuracy: 0.8842\n","\n","Epoch 00426: val_accuracy did not improve from 0.93103\n","Epoch 427/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.5665 - val_accuracy: 0.8916\n","\n","Epoch 00427: val_accuracy did not improve from 0.93103\n","Epoch 428/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5648 - val_accuracy: 0.8966\n","\n","Epoch 00428: val_accuracy did not improve from 0.93103\n","Epoch 429/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.8990\n","\n","Epoch 00429: val_accuracy did not improve from 0.93103\n","Epoch 430/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.9211 - val_accuracy: 0.8818\n","\n","Epoch 00430: val_accuracy did not improve from 0.93103\n","Epoch 431/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 1.0781 - val_accuracy: 0.8153\n","\n","Epoch 00431: val_accuracy did not improve from 0.93103\n","Epoch 432/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0268 - accuracy: 0.9884 - val_loss: 0.6449 - val_accuracy: 0.8842\n","\n","Epoch 00432: val_accuracy did not improve from 0.93103\n","Epoch 433/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.7294 - val_accuracy: 0.8966\n","\n","Epoch 00433: val_accuracy did not improve from 0.93103\n","Epoch 434/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.6187 - val_accuracy: 0.8916\n","\n","Epoch 00434: val_accuracy did not improve from 0.93103\n","Epoch 435/500\n","52/52 [==============================] - 21s 394ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.6197 - val_accuracy: 0.8892\n","\n","Epoch 00435: val_accuracy did not improve from 0.93103\n","Epoch 436/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5242 - val_accuracy: 0.9138\n","\n","Epoch 00436: val_accuracy did not improve from 0.93103\n","Epoch 437/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.5562 - val_accuracy: 0.9064\n","\n","Epoch 00437: val_accuracy did not improve from 0.93103\n","Epoch 438/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5096 - val_accuracy: 0.9113\n","\n","Epoch 00438: val_accuracy did not improve from 0.93103\n","Epoch 439/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5100 - val_accuracy: 0.8966\n","\n","Epoch 00439: val_accuracy did not improve from 0.93103\n","Epoch 440/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.7093 - val_accuracy: 0.9089\n","\n","Epoch 00440: val_accuracy did not improve from 0.93103\n","Epoch 441/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.6254 - val_accuracy: 0.9039\n","\n","Epoch 00441: val_accuracy did not improve from 0.93103\n","Epoch 442/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9039\n","\n","Epoch 00442: val_accuracy did not improve from 0.93103\n","Epoch 443/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.7921 - val_accuracy: 0.8842\n","\n","Epoch 00443: val_accuracy did not improve from 0.93103\n","Epoch 444/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.5679 - val_accuracy: 0.9089\n","\n","Epoch 00444: val_accuracy did not improve from 0.93103\n","Epoch 445/500\n","52/52 [==============================] - 20s 391ms/step - loss: 5.4194e-04 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.9039\n","\n","Epoch 00445: val_accuracy did not improve from 0.93103\n","Epoch 446/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4962 - val_accuracy: 0.9163\n","\n","Epoch 00446: val_accuracy did not improve from 0.93103\n","Epoch 447/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4956 - val_accuracy: 0.9064\n","\n","Epoch 00447: val_accuracy did not improve from 0.93103\n","Epoch 448/500\n","52/52 [==============================] - 20s 395ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.9163\n","\n","Epoch 00448: val_accuracy did not improve from 0.93103\n","Epoch 449/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9015\n","\n","Epoch 00449: val_accuracy did not improve from 0.93103\n","Epoch 450/500\n","52/52 [==============================] - 20s 391ms/step - loss: 3.6116e-04 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 0.9039\n","\n","Epoch 00450: val_accuracy did not improve from 0.93103\n","Epoch 451/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5743 - val_accuracy: 0.9064\n","\n","Epoch 00451: val_accuracy did not improve from 0.93103\n","Epoch 452/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.6517 - val_accuracy: 0.8916\n","\n","Epoch 00452: val_accuracy did not improve from 0.93103\n","Epoch 453/500\n","52/52 [==============================] - 21s 393ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.6210 - val_accuracy: 0.9039\n","\n","Epoch 00453: val_accuracy did not improve from 0.93103\n","Epoch 454/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6593 - val_accuracy: 0.8867\n","\n","Epoch 00454: val_accuracy did not improve from 0.93103\n","Epoch 455/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.7647 - val_accuracy: 0.8916\n","\n","Epoch 00455: val_accuracy did not improve from 0.93103\n","Epoch 456/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.5602 - val_accuracy: 0.9064\n","\n","Epoch 00456: val_accuracy did not improve from 0.93103\n","Epoch 457/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.5906 - val_accuracy: 0.9187\n","\n","Epoch 00457: val_accuracy did not improve from 0.93103\n","Epoch 458/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.6527 - val_accuracy: 0.9113\n","\n","Epoch 00458: val_accuracy did not improve from 0.93103\n","Epoch 459/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6231 - val_accuracy: 0.9015\n","\n","Epoch 00459: val_accuracy did not improve from 0.93103\n","Epoch 460/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.6382 - val_accuracy: 0.8966\n","\n","Epoch 00460: val_accuracy did not improve from 0.93103\n","Epoch 461/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 1.4445 - val_accuracy: 0.8202\n","\n","Epoch 00461: val_accuracy did not improve from 0.93103\n","Epoch 462/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 1.1651 - val_accuracy: 0.8473\n","\n","Epoch 00462: val_accuracy did not improve from 0.93103\n","Epoch 463/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.7676 - val_accuracy: 0.8842\n","\n","Epoch 00463: val_accuracy did not improve from 0.93103\n","Epoch 464/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.6286 - val_accuracy: 0.8966\n","\n","Epoch 00464: val_accuracy did not improve from 0.93103\n","Epoch 465/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5912 - val_accuracy: 0.8966\n","\n","Epoch 00465: val_accuracy did not improve from 0.93103\n","Epoch 466/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4685 - val_accuracy: 0.9113\n","\n","Epoch 00466: val_accuracy did not improve from 0.93103\n","Epoch 467/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6247 - val_accuracy: 0.8867\n","\n","Epoch 00467: val_accuracy did not improve from 0.93103\n","Epoch 468/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5977 - val_accuracy: 0.9015\n","\n","Epoch 00468: val_accuracy did not improve from 0.93103\n","Epoch 469/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6053 - val_accuracy: 0.9015\n","\n","Epoch 00469: val_accuracy did not improve from 0.93103\n","Epoch 470/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5697 - val_accuracy: 0.8941\n","\n","Epoch 00470: val_accuracy did not improve from 0.93103\n","Epoch 471/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.6236 - val_accuracy: 0.9039\n","\n","Epoch 00471: val_accuracy did not improve from 0.93103\n","Epoch 472/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.7641 - val_accuracy: 0.8670\n","\n","Epoch 00472: val_accuracy did not improve from 0.93103\n","Epoch 473/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6269 - val_accuracy: 0.8892\n","\n","Epoch 00473: val_accuracy did not improve from 0.93103\n","Epoch 474/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.6590 - val_accuracy: 0.8941\n","\n","Epoch 00474: val_accuracy did not improve from 0.93103\n","Epoch 475/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8941\n","\n","Epoch 00475: val_accuracy did not improve from 0.93103\n","Epoch 476/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.5860 - val_accuracy: 0.9138\n","\n","Epoch 00476: val_accuracy did not improve from 0.93103\n","Epoch 477/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5715 - val_accuracy: 0.9113\n","\n","Epoch 00477: val_accuracy did not improve from 0.93103\n","Epoch 478/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.9653 - val_accuracy: 0.8966\n","\n","Epoch 00478: val_accuracy did not improve from 0.93103\n","Epoch 479/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.8189 - val_accuracy: 0.8768\n","\n","Epoch 00479: val_accuracy did not improve from 0.93103\n","Epoch 480/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.5154 - val_accuracy: 0.9039\n","\n","Epoch 00480: val_accuracy did not improve from 0.93103\n","Epoch 481/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4612 - val_accuracy: 0.8867\n","\n","Epoch 00481: val_accuracy did not improve from 0.93103\n","Epoch 482/500\n","52/52 [==============================] - 20s 390ms/step - loss: 4.3015e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9113\n","\n","Epoch 00482: val_accuracy did not improve from 0.93103\n","Epoch 483/500\n","52/52 [==============================] - 20s 391ms/step - loss: 6.0745e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.8966\n","\n","Epoch 00483: val_accuracy did not improve from 0.93103\n","Epoch 484/500\n","52/52 [==============================] - 20s 391ms/step - loss: 7.4234e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9212\n","\n","Epoch 00484: val_accuracy did not improve from 0.93103\n","Epoch 485/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5207 - val_accuracy: 0.9039\n","\n","Epoch 00485: val_accuracy did not improve from 0.93103\n","Epoch 486/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5681 - val_accuracy: 0.8966\n","\n","Epoch 00486: val_accuracy did not improve from 0.93103\n","Epoch 487/500\n","52/52 [==============================] - 20s 385ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.6052 - val_accuracy: 0.8941\n","\n","Epoch 00487: val_accuracy did not improve from 0.93103\n","Epoch 488/500\n","52/52 [==============================] - 20s 388ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.5095 - val_accuracy: 0.9163\n","\n","Epoch 00488: val_accuracy did not improve from 0.93103\n","Epoch 489/500\n","52/52 [==============================] - 20s 387ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5712 - val_accuracy: 0.9089\n","\n","Epoch 00489: val_accuracy did not improve from 0.93103\n","Epoch 490/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.5077 - val_accuracy: 0.9138\n","\n","Epoch 00490: val_accuracy did not improve from 0.93103\n","Epoch 491/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4339 - val_accuracy: 0.9212\n","\n","Epoch 00491: val_accuracy did not improve from 0.93103\n","Epoch 492/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4920 - val_accuracy: 0.9039\n","\n","Epoch 00492: val_accuracy did not improve from 0.93103\n","Epoch 493/500\n","52/52 [==============================] - 20s 391ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.8211 - val_accuracy: 0.8892\n","\n","Epoch 00493: val_accuracy did not improve from 0.93103\n","Epoch 494/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4988 - val_accuracy: 0.9113\n","\n","Epoch 00494: val_accuracy did not improve from 0.93103\n","Epoch 495/500\n","52/52 [==============================] - 20s 390ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.8204 - val_accuracy: 0.8719\n","\n","Epoch 00495: val_accuracy did not improve from 0.93103\n","Epoch 496/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.8271 - val_accuracy: 0.8818\n","\n","Epoch 00496: val_accuracy did not improve from 0.93103\n","Epoch 497/500\n","52/52 [==============================] - 20s 392ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.9139 - val_accuracy: 0.8374\n","\n","Epoch 00497: val_accuracy did not improve from 0.93103\n","Epoch 498/500\n","52/52 [==============================] - 20s 393ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.7218 - val_accuracy: 0.8719\n","\n","Epoch 00498: val_accuracy did not improve from 0.93103\n","Epoch 499/500\n","52/52 [==============================] - 20s 386ms/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.6810 - val_accuracy: 0.9039\n","\n","Epoch 00499: val_accuracy did not improve from 0.93103\n","Epoch 500/500\n","52/52 [==============================] - 20s 389ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6021 - val_accuracy: 0.9015\n","\n","Epoch 00500: val_accuracy did not improve from 0.93103\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f135826ad90>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1630437663030,"user_tz":-540,"elapsed":592,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"8b520b8b-849a-49c2-9475-27009ef77eaa"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n","plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n","\n","plt.legend()\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1630437679487,"user_tz":-540,"elapsed":16102,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_020_5_DN121.h5', compile=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1630437680258,"user_tz":-540,"elapsed":786,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630437680634,"user_tz":-540,"elapsed":393,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"38ff77eb-3b0d-48be-d04e-cb853c886bd6"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630437736014,"user_tz":-540,"elapsed":55382,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"6a31b374-c5be-4ca1-bc83-a1712f651c1d"},"source":["DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1630437736015,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1630437736015,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1630437737035,"user_tz":-540,"elapsed":1026,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1630437737036,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["submission[\"DenseNet121_predict\"] = DenseNet121_predict"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1630437749241,"user_tz":-540,"elapsed":12210,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['DenseNet121_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1630437749242,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"19fd1a4b-fa8f-45c4-8d52-2922f23f40d7"},"source":["submission = submission[['id', 'digit']]\n","submission.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  digit\n","0  10000      4\n","1  10001      4\n","2  10002      6\n","3  10003      9\n","4  10004      5"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1630437750953,"user_tz":-540,"elapsed":1717,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwWA7JKqOrAuJreghl2Xa5oY8W9qpi7rlSayx_AsU=s64","userId":"07266262195408457313"}},"outputId":"b4d2028a-dd0f-4fbd-a908-0a3cf96de429"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_020_5_DenseNet121_model.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_020_5_DenseNet121_model.csv')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b797fd48-1957-49db-bddd-f38571d241e2\", \"WidthShiftRange_020_5_DenseNet121_model.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}