{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Xception_1_(public-, private-).ipynb","provenance":[{"file_id":"1M8OJEV_AT9MOCy7JGAaVl1j_VfABfzuE","timestamp":1632775493726},{"file_id":"1tLm7xKEM0NUAtTz8MetJXTPqs1Vr30rT","timestamp":1632775476672},{"file_id":"1cQ9_pnDLKsxM2cvx0IWbLgjkO3Cepyu-","timestamp":1632775461739},{"file_id":"1wP4iB5o6DM91rslno_OvktLGjLoIpAes","timestamp":1632775444303},{"file_id":"1dp46txQYj-TzLA1Gc54Q8rt5HLq0q6Ya","timestamp":1632775427818},{"file_id":"1aTR2tEWrt0W_t7v1aT5sEWrY2fB8Vbwk","timestamp":1632775384268},{"file_id":"1OK3Q_uTJHKxOBU9a9LjMw8MZY9-m_qax","timestamp":1632775365110},{"file_id":"12rbPEBCBS4GLkAocXVKMeBFRx23lD26Y","timestamp":1632775350191},{"file_id":"13xRLFQ8Hipz_BgwiFlaogXJZjqYLclRl","timestamp":1632774878702},{"file_id":"1luopodme_2PAosMrjbeJFrjr8TTmUyyi","timestamp":1632774856109},{"file_id":"1_KfZfBkcDbe5bnFU5VAUULs4qEtYpZc2","timestamp":1632773239935},{"file_id":"1ks7cPy6YRHRAmKY092ZBPxiPfOiHr5Dw","timestamp":1632773090135},{"file_id":"1DX-VAkigMOMI4H8Tym6SDeRIC846UJKl","timestamp":1632766435368},{"file_id":"1MiY3-NuosQH2lOSwZs4hXFDVSdCU0ucv","timestamp":1632766287071},{"file_id":"1CQOhgM_f1bTX8impB1c4QEcVlmSxl3Rz","timestamp":1632766225629},{"file_id":"1NxaJdPz5D7xHXti1IodBLxTyurilAYey","timestamp":1632764873900},{"file_id":"18TpM-aeHM3jrQ21NpPhQJXyu9Kkddi1z","timestamp":1632757533244},{"file_id":"1ru3oFw4R5jlAbvt6XFdYZNHbr13fm76L","timestamp":1632757500318},{"file_id":"11bKdbU5uhsA-AQ6rltMfGFGkKz00AQzM","timestamp":1632757434832},{"file_id":"1iT1DpUTybBnG79zJOIqNnn_lqKynaZso","timestamp":1632745793318},{"file_id":"1M_c2tK-OSq0Sf0EkgPYrIVj_UFxyDhLa","timestamp":1632722288709},{"file_id":"1Ks4BnsIQVSo6nrDm_GCFLP-tUWbMF7fV","timestamp":1632675649149},{"file_id":"1CqtLKNQRRuC325QEoXZHskfQDXw-hybx","timestamp":1632675617704},{"file_id":"12JaYWavZfXc3mxowUEN1hmoDHEhLE9kD","timestamp":1632669857913},{"file_id":"1mRQmgFDcxuga37ytSbeksdBDV8lXPuP_","timestamp":1632669810228},{"file_id":"1hSseuq321IM3Xw9iARWzPOzaWFGuSYps","timestamp":1632659933103},{"file_id":"1i84kOIoNMg1SDAOmCAl-iREVAA8REpRl","timestamp":1632659111522},{"file_id":"1aWKemyOVH_XXsufg6PEqpNJHCIODEQDQ","timestamp":1632658287256},{"file_id":"1ZUL9g9uU5gE9mjrGyZ_ZE6_ZMwE69CPb","timestamp":1632657078244},{"file_id":"1Xq9yUa0JgnqQUKKTfy3z54fip8tHOUVO","timestamp":1632649657584},{"file_id":"1g107jAyKQClzEQj_DMR2xU4rZ9qbJH5e","timestamp":1632649536640},{"file_id":"1Z6kuupfDyi8FoEAzxFaCF1zxYVFMOZLV","timestamp":1632555432723},{"file_id":"1EbR-z2BYoOKWzYoeQoCF6HChJXoczWOg","timestamp":1632529654720},{"file_id":"19UhJoIWtCbGyO-f3O4Ejh3cQm9HsELdp","timestamp":1632508748323},{"file_id":"1P94NU6OoLRtS_ewl8Rb7NPZqKyl6ScPt","timestamp":1632508239637},{"file_id":"1oYHEjU-CSdxlLxyB6mhRRnSPmxfEbe9-","timestamp":1632483693856},{"file_id":"1tY8RF_0awL36zd9hQqUN3JK-9i7JjSCs","timestamp":1632483672985},{"file_id":"1hfaa8YJTlfEKZL9us0XaxbDFzEg6QlrT","timestamp":1632483587193},{"file_id":"1ar0JVhm118hpsiDCU0yS0Ty83Lr95cSu","timestamp":1632438063611},{"file_id":"1ISSiU2DrdSTDMVmbAxc8Ql72Bwult8wi","timestamp":1632382754243},{"file_id":"1cmBIBf0Y6KY5nFGyXFWuz9pe-V3QXe84","timestamp":1632382703200},{"file_id":"1NmDQbVBw3bmj4dkYxCWjOgHGEPxn2knZ","timestamp":1632382649241},{"file_id":"1h-FhrHH66IwjTlqiffpUdtWJZ47_06LZ","timestamp":1632332735991},{"file_id":"174isfXxsoXsuFjV-4wlPn8FyvhQelSZa","timestamp":1632264352072},{"file_id":"1rvvO3AZYRa3O0L25N-Kx2tXg3SO3ZLMb","timestamp":1632207962186},{"file_id":"10a77ENeqwaxgwFA_yCVpQBXkA9Fdts6t","timestamp":1632177040567},{"file_id":"1FLQ4OWmjzgDT_6nR4k61mlxJ0RbQfLbW","timestamp":1632127337902},{"file_id":"1L21WYacshipXDSgj75p87xRajwZ-yYEf","timestamp":1632125266824},{"file_id":"1gXw-oagzF1c49Ds2rFNXBNA-Jjj0YTGM","timestamp":1632125231955},{"file_id":"1odc6VzTolz3PuXSezCpAr8zqRhjlzJFc","timestamp":1632032770915},{"file_id":"1MLPQlf1Ig6rev94yP2Zy_hjHPEwnJWKr","timestamp":1631962707157},{"file_id":"1RFXq_y4na26GX1TMhOCKZvjIKxWZgQei","timestamp":1631894145495},{"file_id":"1j4_hnK2KjlLPPPkDR5LUdjrgcl7E5VJ2","timestamp":1631892272403},{"file_id":"1p_d4XYROzKVVUxBHxjuVx1gTinsguwp8","timestamp":1631892211512},{"file_id":"1qviqzhy3AgjpFc3P2QLjjqfHnbk3izT5","timestamp":1631892086873},{"file_id":"1rE8G1jItkQTqd3bvVGDHTrM9ONajBm2k","timestamp":1631891790249},{"file_id":"https://github.com/d9249/DACON/blob/main/CVLC_05_No_Data_Argmentation(public_0_81862_private_0_76593).ipynb","timestamp":1627056180265}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"g0yI4jO4W5lx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633027221025,"user_tz":-540,"elapsed":395,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"c703bf26-f356-4ba7-9c14-681cc10d3596"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep 30 18:40:27 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"LmEaPJckuX-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633027237036,"user_tz":-540,"elapsed":15628,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"46d74b8d-a7f1-4222-da0b-58f9324f7dc6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"88GAtllsufPj","executionInfo":{"status":"ok","timestamp":1633027240261,"user_tz":-540,"elapsed":2587,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import pandas as pd\n","train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qBWziyZrqBo","executionInfo":{"status":"ok","timestamp":1633027241461,"user_tz":-540,"elapsed":1206,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["!mkdir images_train\n","!mkdir images_train/0\n","!mkdir images_train/1\n","!mkdir images_train/2\n","!mkdir images_train/3\n","!mkdir images_train/4\n","!mkdir images_train/5\n","!mkdir images_train/6\n","!mkdir images_train/7\n","!mkdir images_train/8\n","!mkdir images_train/9\n","!mkdir images_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fjN8mIDrazg","executionInfo":{"status":"ok","timestamp":1633027243541,"user_tz":-540,"elapsed":2083,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import cv2\n","\n","for idx in range(len(train)) :\n","    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    digit = train.loc[idx, 'digit']\n","    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4P9AD1gyotc","executionInfo":{"status":"ok","timestamp":1633027259659,"user_tz":-540,"elapsed":16121,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["for idx in range(len(test)) :\n","    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n","    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTkw3fo6icZm","executionInfo":{"status":"ok","timestamp":1633027259660,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["model_save = 'Xception_1'\n","Target_model = 'Xception_model'\n","Target_predict = 'Xception_predict'\n","Target_acc = 'Xception_acc'\n","Target_val = 'Xception_val'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUJTlJ6GxNmK","executionInfo":{"status":"ok","timestamp":1633027265763,"user_tz":-540,"elapsed":6109,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import tensorflow as tf\n","Target_model =  tf.keras.applications.Xception(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlVMd30ZxUMQ","executionInfo":{"status":"ok","timestamp":1633027265764,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1haI0Zjxa74","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633027265764,"user_tz":-540,"elapsed":19,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"92a61abd-a37e-41b9-bee7-15450495eae8"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator (\n","    rescale = 1./255, \n","    validation_split = 0.075,\n","    rotation_range = 15,\n","    width_shift_range = 0.00,\n","    height_shift_range = 0.05 )\n","\n","batch_size = 8\n","train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n","val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1900 images belonging to 10 classes.\n","Found 148 images belonging to 10 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"SRP2R9hdxsyY","executionInfo":{"status":"ok","timestamp":1633027265765,"user_tz":-540,"elapsed":9,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKMJhbFnxotA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633041526954,"user_tz":-540,"elapsed":14261196,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"c30c81e1-d25d-4e73-9b6e-bff5e51966b5"},"source":["Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","238/238 [==============================] - 50s 123ms/step - loss: 1.7022 - accuracy: 0.4221 - val_loss: 2.3405 - val_accuracy: 0.1014\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.0305 - accuracy: 0.6458 - val_loss: 2.8293 - val_accuracy: 0.1081\n","\n","Epoch 00002: val_accuracy improved from 0.10135 to 0.10811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 3/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.8597 - accuracy: 0.7153 - val_loss: 2.2537 - val_accuracy: 0.4797\n","\n","Epoch 00003: val_accuracy improved from 0.10811 to 0.47973, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 4/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.6779 - accuracy: 0.7763 - val_loss: 2.5741 - val_accuracy: 0.4324\n","\n","Epoch 00004: val_accuracy did not improve from 0.47973\n","Epoch 5/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.6349 - accuracy: 0.7879 - val_loss: 1.7040 - val_accuracy: 0.5743\n","\n","Epoch 00005: val_accuracy improved from 0.47973 to 0.57432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 6/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.5618 - accuracy: 0.8211 - val_loss: 0.7997 - val_accuracy: 0.7635\n","\n","Epoch 00006: val_accuracy improved from 0.57432 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 7/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.4941 - accuracy: 0.8358 - val_loss: 1.0620 - val_accuracy: 0.7635\n","\n","Epoch 00007: val_accuracy did not improve from 0.76351\n","Epoch 8/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.4604 - accuracy: 0.8537 - val_loss: 0.9031 - val_accuracy: 0.7230\n","\n","Epoch 00008: val_accuracy did not improve from 0.76351\n","Epoch 9/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.4448 - accuracy: 0.8647 - val_loss: 1.5251 - val_accuracy: 0.6081\n","\n","Epoch 00009: val_accuracy did not improve from 0.76351\n","Epoch 10/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.4190 - accuracy: 0.8721 - val_loss: 1.0278 - val_accuracy: 0.7432\n","\n","Epoch 00010: val_accuracy did not improve from 0.76351\n","Epoch 11/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3889 - accuracy: 0.8811 - val_loss: 0.4777 - val_accuracy: 0.8581\n","\n","Epoch 00011: val_accuracy improved from 0.76351 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 12/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3651 - accuracy: 0.8858 - val_loss: 0.6072 - val_accuracy: 0.8378\n","\n","Epoch 00012: val_accuracy did not improve from 0.85811\n","Epoch 13/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3397 - accuracy: 0.8795 - val_loss: 0.6012 - val_accuracy: 0.8176\n","\n","Epoch 00013: val_accuracy did not improve from 0.85811\n","Epoch 14/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3319 - accuracy: 0.8874 - val_loss: 0.8222 - val_accuracy: 0.7432\n","\n","Epoch 00014: val_accuracy did not improve from 0.85811\n","Epoch 15/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.3121 - accuracy: 0.8921 - val_loss: 1.0275 - val_accuracy: 0.7635\n","\n","Epoch 00015: val_accuracy did not improve from 0.85811\n","Epoch 16/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2834 - accuracy: 0.9047 - val_loss: 1.8553 - val_accuracy: 0.6554\n","\n","Epoch 00016: val_accuracy did not improve from 0.85811\n","Epoch 17/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2763 - accuracy: 0.9163 - val_loss: 0.6051 - val_accuracy: 0.8243\n","\n","Epoch 00017: val_accuracy did not improve from 0.85811\n","Epoch 18/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2767 - accuracy: 0.9079 - val_loss: 0.4810 - val_accuracy: 0.8446\n","\n","Epoch 00018: val_accuracy did not improve from 0.85811\n","Epoch 19/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2619 - accuracy: 0.9137 - val_loss: 0.4164 - val_accuracy: 0.8919\n","\n","Epoch 00019: val_accuracy improved from 0.85811 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 20/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1884 - accuracy: 0.9389 - val_loss: 0.3780 - val_accuracy: 0.8716\n","\n","Epoch 00020: val_accuracy did not improve from 0.89189\n","Epoch 21/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2132 - accuracy: 0.9258 - val_loss: 1.5972 - val_accuracy: 0.7365\n","\n","Epoch 00021: val_accuracy did not improve from 0.89189\n","Epoch 22/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2325 - accuracy: 0.9168 - val_loss: 0.6084 - val_accuracy: 0.8311\n","\n","Epoch 00022: val_accuracy did not improve from 0.89189\n","Epoch 23/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2075 - accuracy: 0.9311 - val_loss: 0.5798 - val_accuracy: 0.8243\n","\n","Epoch 00023: val_accuracy did not improve from 0.89189\n","Epoch 24/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1784 - accuracy: 0.9468 - val_loss: 0.4131 - val_accuracy: 0.8919\n","\n","Epoch 00024: val_accuracy did not improve from 0.89189\n","Epoch 25/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1631 - accuracy: 0.9416 - val_loss: 0.5739 - val_accuracy: 0.8446\n","\n","Epoch 00025: val_accuracy did not improve from 0.89189\n","Epoch 26/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1609 - accuracy: 0.9458 - val_loss: 0.5777 - val_accuracy: 0.8243\n","\n","Epoch 00026: val_accuracy did not improve from 0.89189\n","Epoch 27/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.1812 - accuracy: 0.9374 - val_loss: 0.6452 - val_accuracy: 0.8446\n","\n","Epoch 00027: val_accuracy did not improve from 0.89189\n","Epoch 28/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1844 - accuracy: 0.9332 - val_loss: 0.9537 - val_accuracy: 0.7770\n","\n","Epoch 00028: val_accuracy did not improve from 0.89189\n","Epoch 29/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1421 - accuracy: 0.9553 - val_loss: 0.5483 - val_accuracy: 0.8784\n","\n","Epoch 00029: val_accuracy did not improve from 0.89189\n","Epoch 30/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1384 - accuracy: 0.9547 - val_loss: 0.8924 - val_accuracy: 0.7973\n","\n","Epoch 00030: val_accuracy did not improve from 0.89189\n","Epoch 31/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.2106 - accuracy: 0.9258 - val_loss: 0.9064 - val_accuracy: 0.7905\n","\n","Epoch 00031: val_accuracy did not improve from 0.89189\n","Epoch 32/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1619 - accuracy: 0.9479 - val_loss: 0.5823 - val_accuracy: 0.8446\n","\n","Epoch 00032: val_accuracy did not improve from 0.89189\n","Epoch 33/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1245 - accuracy: 0.9647 - val_loss: 0.4415 - val_accuracy: 0.8581\n","\n","Epoch 00033: val_accuracy did not improve from 0.89189\n","Epoch 34/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.1259 - accuracy: 0.9621 - val_loss: 0.5265 - val_accuracy: 0.8176\n","\n","Epoch 00034: val_accuracy did not improve from 0.89189\n","Epoch 35/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.1141 - accuracy: 0.9589 - val_loss: 0.5615 - val_accuracy: 0.8514\n","\n","Epoch 00035: val_accuracy did not improve from 0.89189\n","Epoch 36/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1295 - accuracy: 0.9532 - val_loss: 0.7313 - val_accuracy: 0.8378\n","\n","Epoch 00036: val_accuracy did not improve from 0.89189\n","Epoch 37/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0711 - accuracy: 0.9784 - val_loss: 0.3734 - val_accuracy: 0.8919\n","\n","Epoch 00037: val_accuracy did not improve from 0.89189\n","Epoch 38/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 0.4481 - val_accuracy: 0.8851\n","\n","Epoch 00038: val_accuracy did not improve from 0.89189\n","Epoch 39/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1354 - accuracy: 0.9563 - val_loss: 0.6675 - val_accuracy: 0.8378\n","\n","Epoch 00039: val_accuracy did not improve from 0.89189\n","Epoch 40/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0948 - accuracy: 0.9679 - val_loss: 1.4595 - val_accuracy: 0.7365\n","\n","Epoch 00040: val_accuracy did not improve from 0.89189\n","Epoch 41/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1399 - accuracy: 0.9558 - val_loss: 0.6019 - val_accuracy: 0.8851\n","\n","Epoch 00041: val_accuracy did not improve from 0.89189\n","Epoch 42/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 0.5350 - val_accuracy: 0.8784\n","\n","Epoch 00042: val_accuracy did not improve from 0.89189\n","Epoch 43/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0902 - accuracy: 0.9732 - val_loss: 0.5407 - val_accuracy: 0.8986\n","\n","Epoch 00043: val_accuracy improved from 0.89189 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 44/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.3770 - val_accuracy: 0.8986\n","\n","Epoch 00044: val_accuracy did not improve from 0.89865\n","Epoch 45/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1466 - accuracy: 0.9526 - val_loss: 0.7573 - val_accuracy: 0.8108\n","\n","Epoch 00045: val_accuracy did not improve from 0.89865\n","Epoch 46/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1037 - accuracy: 0.9653 - val_loss: 0.4072 - val_accuracy: 0.8784\n","\n","Epoch 00046: val_accuracy did not improve from 0.89865\n","Epoch 47/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.6332 - val_accuracy: 0.8581\n","\n","Epoch 00047: val_accuracy did not improve from 0.89865\n","Epoch 48/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0709 - accuracy: 0.9732 - val_loss: 0.6522 - val_accuracy: 0.8716\n","\n","Epoch 00048: val_accuracy did not improve from 0.89865\n","Epoch 49/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0823 - accuracy: 0.9768 - val_loss: 0.9768 - val_accuracy: 0.8176\n","\n","Epoch 00049: val_accuracy did not improve from 0.89865\n","Epoch 50/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.5585 - val_accuracy: 0.8784\n","\n","Epoch 00050: val_accuracy did not improve from 0.89865\n","Epoch 51/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0926 - accuracy: 0.9684 - val_loss: 0.8963 - val_accuracy: 0.8243\n","\n","Epoch 00051: val_accuracy did not improve from 0.89865\n","Epoch 52/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1142 - accuracy: 0.9589 - val_loss: 0.4298 - val_accuracy: 0.8716\n","\n","Epoch 00052: val_accuracy did not improve from 0.89865\n","Epoch 53/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0871 - accuracy: 0.9705 - val_loss: 0.5043 - val_accuracy: 0.8986\n","\n","Epoch 00053: val_accuracy did not improve from 0.89865\n","Epoch 54/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.3505 - val_accuracy: 0.8919\n","\n","Epoch 00054: val_accuracy did not improve from 0.89865\n","Epoch 55/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0964 - accuracy: 0.9721 - val_loss: 0.5695 - val_accuracy: 0.9054\n","\n","Epoch 00055: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 56/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.5955 - val_accuracy: 0.8851\n","\n","Epoch 00056: val_accuracy did not improve from 0.90541\n","Epoch 57/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.5019 - val_accuracy: 0.8851\n","\n","Epoch 00057: val_accuracy did not improve from 0.90541\n","Epoch 58/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0902 - accuracy: 0.9721 - val_loss: 0.9186 - val_accuracy: 0.8581\n","\n","Epoch 00058: val_accuracy did not improve from 0.90541\n","Epoch 59/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0755 - accuracy: 0.9737 - val_loss: 0.4068 - val_accuracy: 0.8851\n","\n","Epoch 00059: val_accuracy did not improve from 0.90541\n","Epoch 60/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0723 - accuracy: 0.9763 - val_loss: 0.5352 - val_accuracy: 0.8581\n","\n","Epoch 00060: val_accuracy did not improve from 0.90541\n","Epoch 61/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0517 - accuracy: 0.9842 - val_loss: 0.3346 - val_accuracy: 0.9122\n","\n","Epoch 00061: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 62/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.4267 - val_accuracy: 0.8919\n","\n","Epoch 00062: val_accuracy did not improve from 0.91216\n","Epoch 63/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0341 - accuracy: 0.9889 - val_loss: 0.5315 - val_accuracy: 0.8784\n","\n","Epoch 00063: val_accuracy did not improve from 0.91216\n","Epoch 64/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0483 - accuracy: 0.9889 - val_loss: 2.1907 - val_accuracy: 0.7095\n","\n","Epoch 00064: val_accuracy did not improve from 0.91216\n","Epoch 65/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.1244 - accuracy: 0.9584 - val_loss: 0.5263 - val_accuracy: 0.9189\n","\n","Epoch 00065: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 66/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.5243 - val_accuracy: 0.8446\n","\n","Epoch 00066: val_accuracy did not improve from 0.91892\n","Epoch 67/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0615 - accuracy: 0.9837 - val_loss: 0.3711 - val_accuracy: 0.9189\n","\n","Epoch 00067: val_accuracy did not improve from 0.91892\n","Epoch 68/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.2944 - val_accuracy: 0.9122\n","\n","Epoch 00068: val_accuracy did not improve from 0.91892\n","Epoch 69/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.3500 - val_accuracy: 0.8986\n","\n","Epoch 00069: val_accuracy did not improve from 0.91892\n","Epoch 70/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.5153 - val_accuracy: 0.8716\n","\n","Epoch 00070: val_accuracy did not improve from 0.91892\n","Epoch 71/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0710 - accuracy: 0.9758 - val_loss: 0.8703 - val_accuracy: 0.8243\n","\n","Epoch 00071: val_accuracy did not improve from 0.91892\n","Epoch 72/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.6251 - val_accuracy: 0.8649\n","\n","Epoch 00072: val_accuracy did not improve from 0.91892\n","Epoch 73/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.3560 - val_accuracy: 0.9122\n","\n","Epoch 00073: val_accuracy did not improve from 0.91892\n","Epoch 74/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.6022 - val_accuracy: 0.9054\n","\n","Epoch 00074: val_accuracy did not improve from 0.91892\n","Epoch 75/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.3114 - val_accuracy: 0.9122\n","\n","Epoch 00075: val_accuracy did not improve from 0.91892\n","Epoch 76/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 2.0967 - val_accuracy: 0.6419\n","\n","Epoch 00076: val_accuracy did not improve from 0.91892\n","Epoch 77/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.5778 - val_accuracy: 0.8784\n","\n","Epoch 00077: val_accuracy did not improve from 0.91892\n","Epoch 78/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.3261 - val_accuracy: 0.9054\n","\n","Epoch 00078: val_accuracy did not improve from 0.91892\n","Epoch 79/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.3323 - val_accuracy: 0.9054\n","\n","Epoch 00079: val_accuracy did not improve from 0.91892\n","Epoch 80/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.3036 - val_accuracy: 0.9189\n","\n","Epoch 00080: val_accuracy did not improve from 0.91892\n","Epoch 81/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 0.5166 - val_accuracy: 0.8581\n","\n","Epoch 00081: val_accuracy did not improve from 0.91892\n","Epoch 82/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.7136 - val_accuracy: 0.8784\n","\n","Epoch 00082: val_accuracy did not improve from 0.91892\n","Epoch 83/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 0.4610 - val_accuracy: 0.8919\n","\n","Epoch 00083: val_accuracy did not improve from 0.91892\n","Epoch 84/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.3859 - val_accuracy: 0.8851\n","\n","Epoch 00084: val_accuracy did not improve from 0.91892\n","Epoch 85/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.5104 - val_accuracy: 0.8581\n","\n","Epoch 00085: val_accuracy did not improve from 0.91892\n","Epoch 86/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 0.2854 - val_accuracy: 0.9054\n","\n","Epoch 00086: val_accuracy did not improve from 0.91892\n","Epoch 87/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0237 - accuracy: 0.9900 - val_loss: 1.0464 - val_accuracy: 0.8176\n","\n","Epoch 00087: val_accuracy did not improve from 0.91892\n","Epoch 88/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.4440 - val_accuracy: 0.8919\n","\n","Epoch 00088: val_accuracy did not improve from 0.91892\n","Epoch 89/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0480 - accuracy: 0.9826 - val_loss: 0.5246 - val_accuracy: 0.8784\n","\n","Epoch 00089: val_accuracy did not improve from 0.91892\n","Epoch 90/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.5098 - val_accuracy: 0.8919\n","\n","Epoch 00090: val_accuracy did not improve from 0.91892\n","Epoch 91/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0220 - accuracy: 0.9905 - val_loss: 0.7120 - val_accuracy: 0.8649\n","\n","Epoch 00091: val_accuracy did not improve from 0.91892\n","Epoch 92/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.3994 - val_accuracy: 0.8851\n","\n","Epoch 00092: val_accuracy did not improve from 0.91892\n","Epoch 93/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.6289 - val_accuracy: 0.8784\n","\n","Epoch 00093: val_accuracy did not improve from 0.91892\n","Epoch 94/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0691 - accuracy: 0.9779 - val_loss: 0.5779 - val_accuracy: 0.8649\n","\n","Epoch 00094: val_accuracy did not improve from 0.91892\n","Epoch 95/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0183 - accuracy: 0.9911 - val_loss: 0.4896 - val_accuracy: 0.8716\n","\n","Epoch 00095: val_accuracy did not improve from 0.91892\n","Epoch 96/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.4229 - val_accuracy: 0.8919\n","\n","Epoch 00096: val_accuracy did not improve from 0.91892\n","Epoch 97/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0434 - accuracy: 0.9889 - val_loss: 1.0438 - val_accuracy: 0.7905\n","\n","Epoch 00097: val_accuracy did not improve from 0.91892\n","Epoch 98/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.4037 - val_accuracy: 0.8986\n","\n","Epoch 00098: val_accuracy did not improve from 0.91892\n","Epoch 99/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.6867 - val_accuracy: 0.8716\n","\n","Epoch 00099: val_accuracy did not improve from 0.91892\n","Epoch 100/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0311 - accuracy: 0.9874 - val_loss: 1.3442 - val_accuracy: 0.7703\n","\n","Epoch 00100: val_accuracy did not improve from 0.91892\n","Epoch 101/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0482 - accuracy: 0.9821 - val_loss: 0.7307 - val_accuracy: 0.8716\n","\n","Epoch 00101: val_accuracy did not improve from 0.91892\n","Epoch 102/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.4900 - val_accuracy: 0.8851\n","\n","Epoch 00102: val_accuracy did not improve from 0.91892\n","Epoch 103/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.5954 - val_accuracy: 0.8649\n","\n","Epoch 00103: val_accuracy did not improve from 0.91892\n","Epoch 104/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0270 - accuracy: 0.9942 - val_loss: 0.5276 - val_accuracy: 0.9459\n","\n","Epoch 00104: val_accuracy improved from 0.91892 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 105/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.4541 - val_accuracy: 0.8919\n","\n","Epoch 00105: val_accuracy did not improve from 0.94595\n","Epoch 106/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.6054 - val_accuracy: 0.8851\n","\n","Epoch 00106: val_accuracy did not improve from 0.94595\n","Epoch 107/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.4001 - val_accuracy: 0.8851\n","\n","Epoch 00107: val_accuracy did not improve from 0.94595\n","Epoch 108/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.3798 - val_accuracy: 0.8986\n","\n","Epoch 00108: val_accuracy did not improve from 0.94595\n","Epoch 109/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.3274 - val_accuracy: 0.9122\n","\n","Epoch 00109: val_accuracy did not improve from 0.94595\n","Epoch 110/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.5665 - val_accuracy: 0.8311\n","\n","Epoch 00110: val_accuracy did not improve from 0.94595\n","Epoch 111/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.4103 - val_accuracy: 0.9122\n","\n","Epoch 00111: val_accuracy did not improve from 0.94595\n","Epoch 112/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.4850 - val_accuracy: 0.8986\n","\n","Epoch 00112: val_accuracy did not improve from 0.94595\n","Epoch 113/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0166 - accuracy: 0.9932 - val_loss: 0.4331 - val_accuracy: 0.8986\n","\n","Epoch 00113: val_accuracy did not improve from 0.94595\n","Epoch 114/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.3687 - val_accuracy: 0.8784\n","\n","Epoch 00114: val_accuracy did not improve from 0.94595\n","Epoch 115/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.5589 - val_accuracy: 0.9054\n","\n","Epoch 00115: val_accuracy did not improve from 0.94595\n","Epoch 116/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.4068 - val_accuracy: 0.9189\n","\n","Epoch 00116: val_accuracy did not improve from 0.94595\n","Epoch 117/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.3451 - val_accuracy: 0.9054\n","\n","Epoch 00117: val_accuracy did not improve from 0.94595\n","Epoch 118/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.4934 - val_accuracy: 0.8649\n","\n","Epoch 00118: val_accuracy did not improve from 0.94595\n","Epoch 119/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5307 - val_accuracy: 0.9122\n","\n","Epoch 00119: val_accuracy did not improve from 0.94595\n","Epoch 120/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.4661 - val_accuracy: 0.8851\n","\n","Epoch 00120: val_accuracy did not improve from 0.94595\n","Epoch 121/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 0.7010 - val_accuracy: 0.8851\n","\n","Epoch 00121: val_accuracy did not improve from 0.94595\n","Epoch 122/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0312 - accuracy: 0.9879 - val_loss: 0.7021 - val_accuracy: 0.8514\n","\n","Epoch 00122: val_accuracy did not improve from 0.94595\n","Epoch 123/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.6323 - val_accuracy: 0.8716\n","\n","Epoch 00123: val_accuracy did not improve from 0.94595\n","Epoch 124/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.6872 - val_accuracy: 0.8784\n","\n","Epoch 00124: val_accuracy did not improve from 0.94595\n","Epoch 125/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.4215 - val_accuracy: 0.8986\n","\n","Epoch 00125: val_accuracy did not improve from 0.94595\n","Epoch 126/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 0.4351 - val_accuracy: 0.9054\n","\n","Epoch 00126: val_accuracy did not improve from 0.94595\n","Epoch 127/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.5061 - val_accuracy: 0.9122\n","\n","Epoch 00127: val_accuracy did not improve from 0.94595\n","Epoch 128/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.8089 - val_accuracy: 0.8851\n","\n","Epoch 00128: val_accuracy did not improve from 0.94595\n","Epoch 129/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0295 - accuracy: 0.9895 - val_loss: 0.3822 - val_accuracy: 0.9054\n","\n","Epoch 00129: val_accuracy did not improve from 0.94595\n","Epoch 130/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0518 - accuracy: 0.9863 - val_loss: 0.7940 - val_accuracy: 0.8581\n","\n","Epoch 00130: val_accuracy did not improve from 0.94595\n","Epoch 131/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5993 - val_accuracy: 0.8986\n","\n","Epoch 00131: val_accuracy did not improve from 0.94595\n","Epoch 132/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5813 - val_accuracy: 0.8784\n","\n","Epoch 00132: val_accuracy did not improve from 0.94595\n","Epoch 133/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0080 - accuracy: 0.9947 - val_loss: 0.5177 - val_accuracy: 0.8784\n","\n","Epoch 00133: val_accuracy did not improve from 0.94595\n","Epoch 134/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.5165 - val_accuracy: 0.8986\n","\n","Epoch 00134: val_accuracy did not improve from 0.94595\n","Epoch 135/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.5129 - val_accuracy: 0.9054\n","\n","Epoch 00135: val_accuracy did not improve from 0.94595\n","Epoch 136/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 0.6569 - val_accuracy: 0.8919\n","\n","Epoch 00136: val_accuracy did not improve from 0.94595\n","Epoch 137/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0429 - accuracy: 0.9847 - val_loss: 0.3362 - val_accuracy: 0.8986\n","\n","Epoch 00137: val_accuracy did not improve from 0.94595\n","Epoch 138/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0334 - accuracy: 0.9926 - val_loss: 0.3803 - val_accuracy: 0.9122\n","\n","Epoch 00138: val_accuracy did not improve from 0.94595\n","Epoch 139/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.3694 - val_accuracy: 0.9054\n","\n","Epoch 00139: val_accuracy did not improve from 0.94595\n","Epoch 140/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.3505 - val_accuracy: 0.9054\n","\n","Epoch 00140: val_accuracy did not improve from 0.94595\n","Epoch 141/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.3921 - val_accuracy: 0.9054\n","\n","Epoch 00141: val_accuracy did not improve from 0.94595\n","Epoch 142/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3692 - val_accuracy: 0.9054\n","\n","Epoch 00142: val_accuracy did not improve from 0.94595\n","Epoch 143/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.7425 - val_accuracy: 0.8919\n","\n","Epoch 00143: val_accuracy did not improve from 0.94595\n","Epoch 144/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.6061 - val_accuracy: 0.8514\n","\n","Epoch 00144: val_accuracy did not improve from 0.94595\n","Epoch 145/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.4305 - val_accuracy: 0.8851\n","\n","Epoch 00145: val_accuracy did not improve from 0.94595\n","Epoch 146/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.3444 - val_accuracy: 0.9122\n","\n","Epoch 00146: val_accuracy did not improve from 0.94595\n","Epoch 147/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.4691 - val_accuracy: 0.8784\n","\n","Epoch 00147: val_accuracy did not improve from 0.94595\n","Epoch 148/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.6539 - val_accuracy: 0.8784\n","\n","Epoch 00148: val_accuracy did not improve from 0.94595\n","Epoch 149/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.3139 - val_accuracy: 0.9257\n","\n","Epoch 00149: val_accuracy did not improve from 0.94595\n","Epoch 150/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.3874 - val_accuracy: 0.8986\n","\n","Epoch 00150: val_accuracy did not improve from 0.94595\n","Epoch 151/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0218 - accuracy: 0.9911 - val_loss: 0.3732 - val_accuracy: 0.8986\n","\n","Epoch 00151: val_accuracy did not improve from 0.94595\n","Epoch 152/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.4410 - val_accuracy: 0.8986\n","\n","Epoch 00152: val_accuracy did not improve from 0.94595\n","Epoch 153/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.4356 - val_accuracy: 0.9122\n","\n","Epoch 00153: val_accuracy did not improve from 0.94595\n","Epoch 154/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5853 - val_accuracy: 0.8784\n","\n","Epoch 00154: val_accuracy did not improve from 0.94595\n","Epoch 155/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.6149 - val_accuracy: 0.8986\n","\n","Epoch 00155: val_accuracy did not improve from 0.94595\n","Epoch 156/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0305 - accuracy: 0.9932 - val_loss: 0.7461 - val_accuracy: 0.8851\n","\n","Epoch 00156: val_accuracy did not improve from 0.94595\n","Epoch 157/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0399 - accuracy: 0.9868 - val_loss: 0.6434 - val_accuracy: 0.8716\n","\n","Epoch 00157: val_accuracy did not improve from 0.94595\n","Epoch 158/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.4074 - val_accuracy: 0.8986\n","\n","Epoch 00158: val_accuracy did not improve from 0.94595\n","Epoch 159/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0408 - accuracy: 0.9889 - val_loss: 0.1955 - val_accuracy: 0.9257\n","\n","Epoch 00159: val_accuracy did not improve from 0.94595\n","Epoch 160/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1220 - val_accuracy: 0.9527\n","\n","Epoch 00160: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n","Epoch 161/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.8094 - val_accuracy: 0.8108\n","\n","Epoch 00161: val_accuracy did not improve from 0.95270\n","Epoch 162/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.5027 - val_accuracy: 0.8716\n","\n","Epoch 00162: val_accuracy did not improve from 0.95270\n","Epoch 163/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.7567 - val_accuracy: 0.8514\n","\n","Epoch 00163: val_accuracy did not improve from 0.95270\n","Epoch 164/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5098 - val_accuracy: 0.8919\n","\n","Epoch 00164: val_accuracy did not improve from 0.95270\n","Epoch 165/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8986\n","\n","Epoch 00165: val_accuracy did not improve from 0.95270\n","Epoch 166/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4252 - val_accuracy: 0.9122\n","\n","Epoch 00166: val_accuracy did not improve from 0.95270\n","Epoch 167/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.9684 - val_accuracy: 0.8446\n","\n","Epoch 00167: val_accuracy did not improve from 0.95270\n","Epoch 168/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0334 - accuracy: 0.9911 - val_loss: 0.4891 - val_accuracy: 0.8649\n","\n","Epoch 00168: val_accuracy did not improve from 0.95270\n","Epoch 169/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.6133 - val_accuracy: 0.8919\n","\n","Epoch 00169: val_accuracy did not improve from 0.95270\n","Epoch 170/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4271 - val_accuracy: 0.9189\n","\n","Epoch 00170: val_accuracy did not improve from 0.95270\n","Epoch 171/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.4463 - val_accuracy: 0.8919\n","\n","Epoch 00171: val_accuracy did not improve from 0.95270\n","Epoch 172/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.8189 - val_accuracy: 0.8649\n","\n","Epoch 00172: val_accuracy did not improve from 0.95270\n","Epoch 173/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4023 - val_accuracy: 0.9054\n","\n","Epoch 00173: val_accuracy did not improve from 0.95270\n","Epoch 174/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.4970 - val_accuracy: 0.9257\n","\n","Epoch 00174: val_accuracy did not improve from 0.95270\n","Epoch 175/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.5063 - val_accuracy: 0.8919\n","\n","Epoch 00175: val_accuracy did not improve from 0.95270\n","Epoch 176/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.4160 - val_accuracy: 0.9054\n","\n","Epoch 00176: val_accuracy did not improve from 0.95270\n","Epoch 177/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.2705 - val_accuracy: 0.9122\n","\n","Epoch 00177: val_accuracy did not improve from 0.95270\n","Epoch 178/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4906 - val_accuracy: 0.9054\n","\n","Epoch 00178: val_accuracy did not improve from 0.95270\n","Epoch 179/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4954 - val_accuracy: 0.8851\n","\n","Epoch 00179: val_accuracy did not improve from 0.95270\n","Epoch 180/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.5041 - val_accuracy: 0.9257\n","\n","Epoch 00180: val_accuracy did not improve from 0.95270\n","Epoch 181/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.5268 - val_accuracy: 0.8581\n","\n","Epoch 00181: val_accuracy did not improve from 0.95270\n","Epoch 182/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.6370 - val_accuracy: 0.8851\n","\n","Epoch 00182: val_accuracy did not improve from 0.95270\n","Epoch 183/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5893 - val_accuracy: 0.9054\n","\n","Epoch 00183: val_accuracy did not improve from 0.95270\n","Epoch 184/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.6675 - val_accuracy: 0.8919\n","\n","Epoch 00184: val_accuracy did not improve from 0.95270\n","Epoch 185/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0138 - accuracy: 0.9937 - val_loss: 0.3635 - val_accuracy: 0.8986\n","\n","Epoch 00185: val_accuracy did not improve from 0.95270\n","Epoch 186/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3644 - val_accuracy: 0.9459\n","\n","Epoch 00186: val_accuracy did not improve from 0.95270\n","Epoch 187/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3930 - val_accuracy: 0.9122\n","\n","Epoch 00187: val_accuracy did not improve from 0.95270\n","Epoch 188/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.4008 - val_accuracy: 0.9189\n","\n","Epoch 00188: val_accuracy did not improve from 0.95270\n","Epoch 189/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.3357 - val_accuracy: 0.8986\n","\n","Epoch 00189: val_accuracy did not improve from 0.95270\n","Epoch 190/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.4978 - val_accuracy: 0.9324\n","\n","Epoch 00190: val_accuracy did not improve from 0.95270\n","Epoch 191/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.4579 - val_accuracy: 0.9054\n","\n","Epoch 00191: val_accuracy did not improve from 0.95270\n","Epoch 192/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5781 - val_accuracy: 0.9054\n","\n","Epoch 00192: val_accuracy did not improve from 0.95270\n","Epoch 193/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.6208 - val_accuracy: 0.8851\n","\n","Epoch 00193: val_accuracy did not improve from 0.95270\n","Epoch 194/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0453 - accuracy: 0.9895 - val_loss: 0.3870 - val_accuracy: 0.9257\n","\n","Epoch 00194: val_accuracy did not improve from 0.95270\n","Epoch 195/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.4623 - val_accuracy: 0.9122\n","\n","Epoch 00195: val_accuracy did not improve from 0.95270\n","Epoch 196/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.4544 - val_accuracy: 0.9122\n","\n","Epoch 00196: val_accuracy did not improve from 0.95270\n","Epoch 197/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.3507 - val_accuracy: 0.9189\n","\n","Epoch 00197: val_accuracy did not improve from 0.95270\n","Epoch 198/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9189\n","\n","Epoch 00198: val_accuracy did not improve from 0.95270\n","Epoch 199/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5255 - val_accuracy: 0.9122\n","\n","Epoch 00199: val_accuracy did not improve from 0.95270\n","Epoch 200/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.4526 - val_accuracy: 0.8986\n","\n","Epoch 00200: val_accuracy did not improve from 0.95270\n","Epoch 201/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4415 - val_accuracy: 0.9122\n","\n","Epoch 00201: val_accuracy did not improve from 0.95270\n","Epoch 202/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.3855 - val_accuracy: 0.9122\n","\n","Epoch 00202: val_accuracy did not improve from 0.95270\n","Epoch 203/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.3393 - val_accuracy: 0.9189\n","\n","Epoch 00203: val_accuracy did not improve from 0.95270\n","Epoch 204/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.8851\n","\n","Epoch 00204: val_accuracy did not improve from 0.95270\n","Epoch 205/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4843 - val_accuracy: 0.8851\n","\n","Epoch 00205: val_accuracy did not improve from 0.95270\n","Epoch 206/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.7177 - val_accuracy: 0.8716\n","\n","Epoch 00206: val_accuracy did not improve from 0.95270\n","Epoch 207/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.5639 - val_accuracy: 0.8784\n","\n","Epoch 00207: val_accuracy did not improve from 0.95270\n","Epoch 208/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.3963 - val_accuracy: 0.9054\n","\n","Epoch 00208: val_accuracy did not improve from 0.95270\n","Epoch 209/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 0.5623 - val_accuracy: 0.8986\n","\n","Epoch 00209: val_accuracy did not improve from 0.95270\n","Epoch 210/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.4668 - val_accuracy: 0.9122\n","\n","Epoch 00210: val_accuracy did not improve from 0.95270\n","Epoch 211/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4160 - val_accuracy: 0.8986\n","\n","Epoch 00211: val_accuracy did not improve from 0.95270\n","Epoch 212/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.2453 - val_accuracy: 0.9122\n","\n","Epoch 00212: val_accuracy did not improve from 0.95270\n","Epoch 213/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.5409 - val_accuracy: 0.9054\n","\n","Epoch 00213: val_accuracy did not improve from 0.95270\n","Epoch 214/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.2725 - val_accuracy: 0.9122\n","\n","Epoch 00214: val_accuracy did not improve from 0.95270\n","Epoch 215/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.5481 - val_accuracy: 0.8986\n","\n","Epoch 00215: val_accuracy did not improve from 0.95270\n","Epoch 216/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.6048 - val_accuracy: 0.8851\n","\n","Epoch 00216: val_accuracy did not improve from 0.95270\n","Epoch 217/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.4121 - val_accuracy: 0.8986\n","\n","Epoch 00217: val_accuracy did not improve from 0.95270\n","Epoch 218/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.3064 - val_accuracy: 0.9257\n","\n","Epoch 00218: val_accuracy did not improve from 0.95270\n","Epoch 219/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6763 - val_accuracy: 0.8784\n","\n","Epoch 00219: val_accuracy did not improve from 0.95270\n","Epoch 220/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.3309 - val_accuracy: 0.9189\n","\n","Epoch 00220: val_accuracy did not improve from 0.95270\n","Epoch 221/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.8987 - val_accuracy: 0.8851\n","\n","Epoch 00221: val_accuracy did not improve from 0.95270\n","Epoch 222/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.3630 - val_accuracy: 0.9257\n","\n","Epoch 00222: val_accuracy did not improve from 0.95270\n","Epoch 223/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.4213 - val_accuracy: 0.8986\n","\n","Epoch 00223: val_accuracy did not improve from 0.95270\n","Epoch 224/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 1.0013 - val_accuracy: 0.8581\n","\n","Epoch 00224: val_accuracy did not improve from 0.95270\n","Epoch 225/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0275 - accuracy: 0.9932 - val_loss: 0.2209 - val_accuracy: 0.9257\n","\n","Epoch 00225: val_accuracy did not improve from 0.95270\n","Epoch 226/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.3348 - val_accuracy: 0.9257\n","\n","Epoch 00226: val_accuracy did not improve from 0.95270\n","Epoch 227/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.4595 - val_accuracy: 0.9054\n","\n","Epoch 00227: val_accuracy did not improve from 0.95270\n","Epoch 228/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5099 - val_accuracy: 0.8986\n","\n","Epoch 00228: val_accuracy did not improve from 0.95270\n","Epoch 229/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4931 - val_accuracy: 0.9054\n","\n","Epoch 00229: val_accuracy did not improve from 0.95270\n","Epoch 230/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5043 - val_accuracy: 0.8986\n","\n","Epoch 00230: val_accuracy did not improve from 0.95270\n","Epoch 231/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5608 - val_accuracy: 0.8851\n","\n","Epoch 00231: val_accuracy did not improve from 0.95270\n","Epoch 232/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.7183 - val_accuracy: 0.8851\n","\n","Epoch 00232: val_accuracy did not improve from 0.95270\n","Epoch 233/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.7725 - val_accuracy: 0.8446\n","\n","Epoch 00233: val_accuracy did not improve from 0.95270\n","Epoch 234/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.3678 - val_accuracy: 0.9054\n","\n","Epoch 00234: val_accuracy did not improve from 0.95270\n","Epoch 235/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9054\n","\n","Epoch 00235: val_accuracy did not improve from 0.95270\n","Epoch 236/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.6033 - val_accuracy: 0.8784\n","\n","Epoch 00236: val_accuracy did not improve from 0.95270\n","Epoch 237/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.4751 - val_accuracy: 0.9189\n","\n","Epoch 00237: val_accuracy did not improve from 0.95270\n","Epoch 238/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4568 - val_accuracy: 0.9054\n","\n","Epoch 00238: val_accuracy did not improve from 0.95270\n","Epoch 239/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4912 - val_accuracy: 0.9189\n","\n","Epoch 00239: val_accuracy did not improve from 0.95270\n","Epoch 240/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9189\n","\n","Epoch 00240: val_accuracy did not improve from 0.95270\n","Epoch 241/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5795 - val_accuracy: 0.9122\n","\n","Epoch 00241: val_accuracy did not improve from 0.95270\n","Epoch 242/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.5603 - val_accuracy: 0.9054\n","\n","Epoch 00242: val_accuracy did not improve from 0.95270\n","Epoch 243/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9324\n","\n","Epoch 00243: val_accuracy did not improve from 0.95270\n","Epoch 244/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.3286 - val_accuracy: 0.9122\n","\n","Epoch 00244: val_accuracy did not improve from 0.95270\n","Epoch 245/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.5905 - val_accuracy: 0.8649\n","\n","Epoch 00245: val_accuracy did not improve from 0.95270\n","Epoch 246/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.3863 - val_accuracy: 0.8919\n","\n","Epoch 00246: val_accuracy did not improve from 0.95270\n","Epoch 247/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.4779 - val_accuracy: 0.9189\n","\n","Epoch 00247: val_accuracy did not improve from 0.95270\n","Epoch 248/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.6626 - val_accuracy: 0.8851\n","\n","Epoch 00248: val_accuracy did not improve from 0.95270\n","Epoch 249/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0095 - accuracy: 0.9942 - val_loss: 0.6762 - val_accuracy: 0.8784\n","\n","Epoch 00249: val_accuracy did not improve from 0.95270\n","Epoch 250/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0216 - accuracy: 0.9911 - val_loss: 0.4980 - val_accuracy: 0.9189\n","\n","Epoch 00250: val_accuracy did not improve from 0.95270\n","Epoch 251/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.4991 - val_accuracy: 0.9122\n","\n","Epoch 00251: val_accuracy did not improve from 0.95270\n","Epoch 252/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4121 - val_accuracy: 0.9189\n","\n","Epoch 00252: val_accuracy did not improve from 0.95270\n","Epoch 253/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4599 - val_accuracy: 0.9257\n","\n","Epoch 00253: val_accuracy did not improve from 0.95270\n","Epoch 254/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5645 - val_accuracy: 0.9122\n","\n","Epoch 00254: val_accuracy did not improve from 0.95270\n","Epoch 255/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3851 - val_accuracy: 0.9122\n","\n","Epoch 00255: val_accuracy did not improve from 0.95270\n","Epoch 256/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5578 - val_accuracy: 0.9189\n","\n","Epoch 00256: val_accuracy did not improve from 0.95270\n","Epoch 257/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0551 - accuracy: 0.9884 - val_loss: 0.7510 - val_accuracy: 0.8378\n","\n","Epoch 00257: val_accuracy did not improve from 0.95270\n","Epoch 258/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.4285 - val_accuracy: 0.9189\n","\n","Epoch 00258: val_accuracy did not improve from 0.95270\n","Epoch 259/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4115 - val_accuracy: 0.8919\n","\n","Epoch 00259: val_accuracy did not improve from 0.95270\n","Epoch 260/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.6156 - val_accuracy: 0.8851\n","\n","Epoch 00260: val_accuracy did not improve from 0.95270\n","Epoch 261/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.4908 - val_accuracy: 0.9054\n","\n","Epoch 00261: val_accuracy did not improve from 0.95270\n","Epoch 262/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4647 - val_accuracy: 0.9324\n","\n","Epoch 00262: val_accuracy did not improve from 0.95270\n","Epoch 263/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.5707 - val_accuracy: 0.9189\n","\n","Epoch 00263: val_accuracy did not improve from 0.95270\n","Epoch 264/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.6857 - val_accuracy: 0.8581\n","\n","Epoch 00264: val_accuracy did not improve from 0.95270\n","Epoch 265/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.6448 - val_accuracy: 0.9054\n","\n","Epoch 00265: val_accuracy did not improve from 0.95270\n","Epoch 266/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.5289 - val_accuracy: 0.8919\n","\n","Epoch 00266: val_accuracy did not improve from 0.95270\n","Epoch 267/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.4149 - val_accuracy: 0.9189\n","\n","Epoch 00267: val_accuracy did not improve from 0.95270\n","Epoch 268/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0071 - accuracy: 0.9958 - val_loss: 0.6775 - val_accuracy: 0.8649\n","\n","Epoch 00268: val_accuracy did not improve from 0.95270\n","Epoch 269/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.4491 - val_accuracy: 0.8986\n","\n","Epoch 00269: val_accuracy did not improve from 0.95270\n","Epoch 270/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.7250 - val_accuracy: 0.9054\n","\n","Epoch 00270: val_accuracy did not improve from 0.95270\n","Epoch 271/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4807 - val_accuracy: 0.8919\n","\n","Epoch 00271: val_accuracy did not improve from 0.95270\n","Epoch 272/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.6298 - val_accuracy: 0.8919\n","\n","Epoch 00272: val_accuracy did not improve from 0.95270\n","Epoch 273/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4789 - val_accuracy: 0.8986\n","\n","Epoch 00273: val_accuracy did not improve from 0.95270\n","Epoch 274/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8851\n","\n","Epoch 00274: val_accuracy did not improve from 0.95270\n","Epoch 275/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.8919\n","\n","Epoch 00275: val_accuracy did not improve from 0.95270\n","Epoch 276/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.6796e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9189\n","\n","Epoch 00276: val_accuracy did not improve from 0.95270\n","Epoch 277/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.7981e-04 - accuracy: 0.9995 - val_loss: 0.4270 - val_accuracy: 0.9189\n","\n","Epoch 00277: val_accuracy did not improve from 0.95270\n","Epoch 278/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.5123 - val_accuracy: 0.8986\n","\n","Epoch 00278: val_accuracy did not improve from 0.95270\n","Epoch 279/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 0.7666 - val_accuracy: 0.8919\n","\n","Epoch 00279: val_accuracy did not improve from 0.95270\n","Epoch 280/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5926 - val_accuracy: 0.8919\n","\n","Epoch 00280: val_accuracy did not improve from 0.95270\n","Epoch 281/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.4481 - val_accuracy: 0.9189\n","\n","Epoch 00281: val_accuracy did not improve from 0.95270\n","Epoch 282/500\n","238/238 [==============================] - 28s 118ms/step - loss: 9.7178e-04 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.9122\n","\n","Epoch 00282: val_accuracy did not improve from 0.95270\n","Epoch 283/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.6045e-04 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.8851\n","\n","Epoch 00283: val_accuracy did not improve from 0.95270\n","Epoch 284/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.5789e-04 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.8919\n","\n","Epoch 00284: val_accuracy did not improve from 0.95270\n","Epoch 285/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.5238e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.8919\n","\n","Epoch 00285: val_accuracy did not improve from 0.95270\n","Epoch 286/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0597 - accuracy: 0.9858 - val_loss: 0.9585 - val_accuracy: 0.8108\n","\n","Epoch 00286: val_accuracy did not improve from 0.95270\n","Epoch 287/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.3113 - val_accuracy: 0.9189\n","\n","Epoch 00287: val_accuracy did not improve from 0.95270\n","Epoch 288/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.3009 - val_accuracy: 0.8986\n","\n","Epoch 00288: val_accuracy did not improve from 0.95270\n","Epoch 289/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.7243 - val_accuracy: 0.8716\n","\n","Epoch 00289: val_accuracy did not improve from 0.95270\n","Epoch 290/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3728 - val_accuracy: 0.9122\n","\n","Epoch 00290: val_accuracy did not improve from 0.95270\n","Epoch 291/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9122\n","\n","Epoch 00291: val_accuracy did not improve from 0.95270\n","Epoch 292/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.4249 - val_accuracy: 0.8986\n","\n","Epoch 00292: val_accuracy did not improve from 0.95270\n","Epoch 293/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.5941 - val_accuracy: 0.8986\n","\n","Epoch 00293: val_accuracy did not improve from 0.95270\n","Epoch 294/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.0963e-04 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9054\n","\n","Epoch 00294: val_accuracy did not improve from 0.95270\n","Epoch 295/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.4878e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.8919\n","\n","Epoch 00295: val_accuracy did not improve from 0.95270\n","Epoch 296/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2399 - val_accuracy: 0.9392\n","\n","Epoch 00296: val_accuracy did not improve from 0.95270\n","Epoch 297/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5174 - val_accuracy: 0.8716\n","\n","Epoch 00297: val_accuracy did not improve from 0.95270\n","Epoch 298/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4118 - val_accuracy: 0.9054\n","\n","Epoch 00298: val_accuracy did not improve from 0.95270\n","Epoch 299/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.3495e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9122\n","\n","Epoch 00299: val_accuracy did not improve from 0.95270\n","Epoch 300/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 1.8121 - val_accuracy: 0.8041\n","\n","Epoch 00300: val_accuracy did not improve from 0.95270\n","Epoch 301/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.5849 - val_accuracy: 0.8581\n","\n","Epoch 00301: val_accuracy did not improve from 0.95270\n","Epoch 302/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5541 - val_accuracy: 0.8581\n","\n","Epoch 00302: val_accuracy did not improve from 0.95270\n","Epoch 303/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4901 - val_accuracy: 0.9122\n","\n","Epoch 00303: val_accuracy did not improve from 0.95270\n","Epoch 304/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.6206 - val_accuracy: 0.8986\n","\n","Epoch 00304: val_accuracy did not improve from 0.95270\n","Epoch 305/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.6028 - val_accuracy: 0.8919\n","\n","Epoch 00305: val_accuracy did not improve from 0.95270\n","Epoch 306/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.3774 - val_accuracy: 0.9054\n","\n","Epoch 00306: val_accuracy did not improve from 0.95270\n","Epoch 307/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.3710 - val_accuracy: 0.9054\n","\n","Epoch 00307: val_accuracy did not improve from 0.95270\n","Epoch 308/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.3778 - val_accuracy: 0.9392\n","\n","Epoch 00308: val_accuracy did not improve from 0.95270\n","Epoch 309/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9189\n","\n","Epoch 00309: val_accuracy did not improve from 0.95270\n","Epoch 310/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.9169e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9324\n","\n","Epoch 00310: val_accuracy did not improve from 0.95270\n","Epoch 311/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4571 - val_accuracy: 0.9189\n","\n","Epoch 00311: val_accuracy did not improve from 0.95270\n","Epoch 312/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.8151e-04 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9122\n","\n","Epoch 00312: val_accuracy did not improve from 0.95270\n","Epoch 313/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.8580e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9054\n","\n","Epoch 00313: val_accuracy did not improve from 0.95270\n","Epoch 314/500\n","238/238 [==============================] - 28s 118ms/step - loss: 9.5862e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9257\n","\n","Epoch 00314: val_accuracy did not improve from 0.95270\n","Epoch 315/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.7898e-04 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8919\n","\n","Epoch 00315: val_accuracy did not improve from 0.95270\n","Epoch 316/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0490 - accuracy: 0.9863 - val_loss: 0.4482 - val_accuracy: 0.8919\n","\n","Epoch 00316: val_accuracy did not improve from 0.95270\n","Epoch 317/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.6922 - val_accuracy: 0.8919\n","\n","Epoch 00317: val_accuracy did not improve from 0.95270\n","Epoch 318/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.6327 - val_accuracy: 0.8784\n","\n","Epoch 00318: val_accuracy did not improve from 0.95270\n","Epoch 319/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4160 - val_accuracy: 0.9189\n","\n","Epoch 00319: val_accuracy did not improve from 0.95270\n","Epoch 320/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4185 - val_accuracy: 0.9122\n","\n","Epoch 00320: val_accuracy did not improve from 0.95270\n","Epoch 321/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4723 - val_accuracy: 0.8986\n","\n","Epoch 00321: val_accuracy did not improve from 0.95270\n","Epoch 322/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.4028 - val_accuracy: 0.8784\n","\n","Epoch 00322: val_accuracy did not improve from 0.95270\n","Epoch 323/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.8257 - val_accuracy: 0.8784\n","\n","Epoch 00323: val_accuracy did not improve from 0.95270\n","Epoch 324/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 0.4999 - val_accuracy: 0.9189\n","\n","Epoch 00324: val_accuracy did not improve from 0.95270\n","Epoch 325/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.3561e-04 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.9122\n","\n","Epoch 00325: val_accuracy did not improve from 0.95270\n","Epoch 326/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.9864e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8919\n","\n","Epoch 00326: val_accuracy did not improve from 0.95270\n","Epoch 327/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5116 - val_accuracy: 0.8986\n","\n","Epoch 00327: val_accuracy did not improve from 0.95270\n","Epoch 328/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.5199e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9122\n","\n","Epoch 00328: val_accuracy did not improve from 0.95270\n","Epoch 329/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.7125 - val_accuracy: 0.8784\n","\n","Epoch 00329: val_accuracy did not improve from 0.95270\n","Epoch 330/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.9053 - val_accuracy: 0.8716\n","\n","Epoch 00330: val_accuracy did not improve from 0.95270\n","Epoch 331/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.6009 - val_accuracy: 0.8716\n","\n","Epoch 00331: val_accuracy did not improve from 0.95270\n","Epoch 332/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.2779 - val_accuracy: 0.9324\n","\n","Epoch 00332: val_accuracy did not improve from 0.95270\n","Epoch 333/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.5351 - val_accuracy: 0.8986\n","\n","Epoch 00333: val_accuracy did not improve from 0.95270\n","Epoch 334/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.5346 - val_accuracy: 0.8851\n","\n","Epoch 00334: val_accuracy did not improve from 0.95270\n","Epoch 335/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.8259 - val_accuracy: 0.8514\n","\n","Epoch 00335: val_accuracy did not improve from 0.95270\n","Epoch 336/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8784\n","\n","Epoch 00336: val_accuracy did not improve from 0.95270\n","Epoch 337/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.8951e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8986\n","\n","Epoch 00337: val_accuracy did not improve from 0.95270\n","Epoch 338/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.3964e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9054\n","\n","Epoch 00338: val_accuracy did not improve from 0.95270\n","Epoch 339/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3828 - val_accuracy: 0.9054\n","\n","Epoch 00339: val_accuracy did not improve from 0.95270\n","Epoch 340/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.3715 - val_accuracy: 0.8986\n","\n","Epoch 00340: val_accuracy did not improve from 0.95270\n","Epoch 341/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.6784 - val_accuracy: 0.8851\n","\n","Epoch 00341: val_accuracy did not improve from 0.95270\n","Epoch 342/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 0.7210 - val_accuracy: 0.8851\n","\n","Epoch 00342: val_accuracy did not improve from 0.95270\n","Epoch 343/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.8739 - val_accuracy: 0.8446\n","\n","Epoch 00343: val_accuracy did not improve from 0.95270\n","Epoch 344/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.7726 - val_accuracy: 0.8986\n","\n","Epoch 00344: val_accuracy did not improve from 0.95270\n","Epoch 345/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.4727 - val_accuracy: 0.9054\n","\n","Epoch 00345: val_accuracy did not improve from 0.95270\n","Epoch 346/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.5910 - val_accuracy: 0.8986\n","\n","Epoch 00346: val_accuracy did not improve from 0.95270\n","Epoch 347/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0045 - accuracy: 0.9968 - val_loss: 0.5322 - val_accuracy: 0.8986\n","\n","Epoch 00347: val_accuracy did not improve from 0.95270\n","Epoch 348/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.7801e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9054\n","\n","Epoch 00348: val_accuracy did not improve from 0.95270\n","Epoch 349/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4910 - val_accuracy: 0.9189\n","\n","Epoch 00349: val_accuracy did not improve from 0.95270\n","Epoch 350/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.7508 - val_accuracy: 0.8784\n","\n","Epoch 00350: val_accuracy did not improve from 0.95270\n","Epoch 351/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.8120 - val_accuracy: 0.8716\n","\n","Epoch 00351: val_accuracy did not improve from 0.95270\n","Epoch 352/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0106 - accuracy: 0.9937 - val_loss: 0.7619 - val_accuracy: 0.8716\n","\n","Epoch 00352: val_accuracy did not improve from 0.95270\n","Epoch 353/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5676 - val_accuracy: 0.9122\n","\n","Epoch 00353: val_accuracy did not improve from 0.95270\n","Epoch 354/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.4106 - val_accuracy: 0.9324\n","\n","Epoch 00354: val_accuracy did not improve from 0.95270\n","Epoch 355/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5280 - val_accuracy: 0.9189\n","\n","Epoch 00355: val_accuracy did not improve from 0.95270\n","Epoch 356/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5077 - val_accuracy: 0.9122\n","\n","Epoch 00356: val_accuracy did not improve from 0.95270\n","Epoch 357/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.4932e-04 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8919\n","\n","Epoch 00357: val_accuracy did not improve from 0.95270\n","Epoch 358/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.3769e-04 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8919\n","\n","Epoch 00358: val_accuracy did not improve from 0.95270\n","Epoch 359/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6751 - val_accuracy: 0.8784\n","\n","Epoch 00359: val_accuracy did not improve from 0.95270\n","Epoch 360/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0280 - accuracy: 0.9942 - val_loss: 0.8983 - val_accuracy: 0.8514\n","\n","Epoch 00360: val_accuracy did not improve from 0.95270\n","Epoch 361/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.4563 - val_accuracy: 0.9054\n","\n","Epoch 00361: val_accuracy did not improve from 0.95270\n","Epoch 362/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.7215 - val_accuracy: 0.8784\n","\n","Epoch 00362: val_accuracy did not improve from 0.95270\n","Epoch 363/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4698 - val_accuracy: 0.9122\n","\n","Epoch 00363: val_accuracy did not improve from 0.95270\n","Epoch 364/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.6911 - val_accuracy: 0.8919\n","\n","Epoch 00364: val_accuracy did not improve from 0.95270\n","Epoch 365/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.4853 - val_accuracy: 0.9054\n","\n","Epoch 00365: val_accuracy did not improve from 0.95270\n","Epoch 366/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6616 - val_accuracy: 0.8919\n","\n","Epoch 00366: val_accuracy did not improve from 0.95270\n","Epoch 367/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.8851\n","\n","Epoch 00367: val_accuracy did not improve from 0.95270\n","Epoch 368/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.9295e-04 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.8851\n","\n","Epoch 00368: val_accuracy did not improve from 0.95270\n","Epoch 369/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.8908 - val_accuracy: 0.8716\n","\n","Epoch 00369: val_accuracy did not improve from 0.95270\n","Epoch 370/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.5593 - val_accuracy: 0.9189\n","\n","Epoch 00370: val_accuracy did not improve from 0.95270\n","Epoch 371/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.4336 - val_accuracy: 0.9054\n","\n","Epoch 00371: val_accuracy did not improve from 0.95270\n","Epoch 372/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.6686 - val_accuracy: 0.8784\n","\n","Epoch 00372: val_accuracy did not improve from 0.95270\n","Epoch 373/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.2995e-04 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9054\n","\n","Epoch 00373: val_accuracy did not improve from 0.95270\n","Epoch 374/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.4701e-04 - accuracy: 1.0000 - val_loss: 0.5663 - val_accuracy: 0.8986\n","\n","Epoch 00374: val_accuracy did not improve from 0.95270\n","Epoch 375/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.4415e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8986\n","\n","Epoch 00375: val_accuracy did not improve from 0.95270\n","Epoch 376/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.6493 - val_accuracy: 0.8851\n","\n","Epoch 00376: val_accuracy did not improve from 0.95270\n","Epoch 377/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5070 - val_accuracy: 0.9122\n","\n","Epoch 00377: val_accuracy did not improve from 0.95270\n","Epoch 378/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.4842 - val_accuracy: 0.8919\n","\n","Epoch 00378: val_accuracy did not improve from 0.95270\n","Epoch 379/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0299 - accuracy: 0.9937 - val_loss: 0.7297 - val_accuracy: 0.8716\n","\n","Epoch 00379: val_accuracy did not improve from 0.95270\n","Epoch 380/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.9912 - val_accuracy: 0.8446\n","\n","Epoch 00380: val_accuracy did not improve from 0.95270\n","Epoch 381/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.7102 - val_accuracy: 0.9189\n","\n","Epoch 00381: val_accuracy did not improve from 0.95270\n","Epoch 382/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5582 - val_accuracy: 0.9054\n","\n","Epoch 00382: val_accuracy did not improve from 0.95270\n","Epoch 383/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6944 - val_accuracy: 0.9054\n","\n","Epoch 00383: val_accuracy did not improve from 0.95270\n","Epoch 384/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 0.4834 - val_accuracy: 0.9122\n","\n","Epoch 00384: val_accuracy did not improve from 0.95270\n","Epoch 385/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4941 - val_accuracy: 0.8851\n","\n","Epoch 00385: val_accuracy did not improve from 0.95270\n","Epoch 386/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.6708e-04 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.8851\n","\n","Epoch 00386: val_accuracy did not improve from 0.95270\n","Epoch 387/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.1344e-04 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.8851\n","\n","Epoch 00387: val_accuracy did not improve from 0.95270\n","Epoch 388/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.9336e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8919\n","\n","Epoch 00388: val_accuracy did not improve from 0.95270\n","Epoch 389/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.0682 - val_accuracy: 0.8446\n","\n","Epoch 00389: val_accuracy did not improve from 0.95270\n","Epoch 390/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.8592 - val_accuracy: 0.8581\n","\n","Epoch 00390: val_accuracy did not improve from 0.95270\n","Epoch 391/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.6730 - val_accuracy: 0.8851\n","\n","Epoch 00391: val_accuracy did not improve from 0.95270\n","Epoch 392/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.4205 - val_accuracy: 0.9054\n","\n","Epoch 00392: val_accuracy did not improve from 0.95270\n","Epoch 393/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5367 - val_accuracy: 0.9054\n","\n","Epoch 00393: val_accuracy did not improve from 0.95270\n","Epoch 394/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.9122\n","\n","Epoch 00394: val_accuracy did not improve from 0.95270\n","Epoch 395/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.5690e-04 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.9054\n","\n","Epoch 00395: val_accuracy did not improve from 0.95270\n","Epoch 396/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6308 - val_accuracy: 0.8919\n","\n","Epoch 00396: val_accuracy did not improve from 0.95270\n","Epoch 397/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.5376 - val_accuracy: 0.8919\n","\n","Epoch 00397: val_accuracy did not improve from 0.95270\n","Epoch 398/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.7494 - val_accuracy: 0.8919\n","\n","Epoch 00398: val_accuracy did not improve from 0.95270\n","Epoch 399/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5859 - val_accuracy: 0.8986\n","\n","Epoch 00399: val_accuracy did not improve from 0.95270\n","Epoch 400/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.7872 - val_accuracy: 0.8851\n","\n","Epoch 00400: val_accuracy did not improve from 0.95270\n","Epoch 401/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.7851 - val_accuracy: 0.8851\n","\n","Epoch 00401: val_accuracy did not improve from 0.95270\n","Epoch 402/500\n","238/238 [==============================] - 28s 118ms/step - loss: 9.1056e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8919\n","\n","Epoch 00402: val_accuracy did not improve from 0.95270\n","Epoch 403/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.5957 - val_accuracy: 0.9122\n","\n","Epoch 00403: val_accuracy did not improve from 0.95270\n","Epoch 404/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 0.5842 - val_accuracy: 0.8986\n","\n","Epoch 00404: val_accuracy did not improve from 0.95270\n","Epoch 405/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9054\n","\n","Epoch 00405: val_accuracy did not improve from 0.95270\n","Epoch 406/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.1091e-04 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8784\n","\n","Epoch 00406: val_accuracy did not improve from 0.95270\n","Epoch 407/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.9822 - val_accuracy: 0.8851\n","\n","Epoch 00407: val_accuracy did not improve from 0.95270\n","Epoch 408/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.6651 - val_accuracy: 0.8784\n","\n","Epoch 00408: val_accuracy did not improve from 0.95270\n","Epoch 409/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.5942 - val_accuracy: 0.9189\n","\n","Epoch 00409: val_accuracy did not improve from 0.95270\n","Epoch 410/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.5417 - val_accuracy: 0.9122\n","\n","Epoch 00410: val_accuracy did not improve from 0.95270\n","Epoch 411/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.5699 - val_accuracy: 0.9054\n","\n","Epoch 00411: val_accuracy did not improve from 0.95270\n","Epoch 412/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.3800 - val_accuracy: 0.9189\n","\n","Epoch 00412: val_accuracy did not improve from 0.95270\n","Epoch 413/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4589 - val_accuracy: 0.8851\n","\n","Epoch 00413: val_accuracy did not improve from 0.95270\n","Epoch 414/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9122\n","\n","Epoch 00414: val_accuracy did not improve from 0.95270\n","Epoch 415/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9257\n","\n","Epoch 00415: val_accuracy did not improve from 0.95270\n","Epoch 416/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.6118e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9189\n","\n","Epoch 00416: val_accuracy did not improve from 0.95270\n","Epoch 417/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.7084e-04 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9054\n","\n","Epoch 00417: val_accuracy did not improve from 0.95270\n","Epoch 418/500\n","238/238 [==============================] - 28s 118ms/step - loss: 2.3569e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9257\n","\n","Epoch 00418: val_accuracy did not improve from 0.95270\n","Epoch 419/500\n","238/238 [==============================] - 28s 118ms/step - loss: 2.1751e-04 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9189\n","\n","Epoch 00419: val_accuracy did not improve from 0.95270\n","Epoch 420/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9189\n","\n","Epoch 00420: val_accuracy did not improve from 0.95270\n","Epoch 421/500\n","238/238 [==============================] - 28s 118ms/step - loss: 9.3691e-05 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9324\n","\n","Epoch 00421: val_accuracy did not improve from 0.95270\n","Epoch 422/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.7363e-05 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.9122\n","\n","Epoch 00422: val_accuracy did not improve from 0.95270\n","Epoch 423/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.2716e-05 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8986\n","\n","Epoch 00423: val_accuracy did not improve from 0.95270\n","Epoch 424/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.0440e-04 - accuracy: 1.0000 - val_loss: 0.5391 - val_accuracy: 0.9122\n","\n","Epoch 00424: val_accuracy did not improve from 0.95270\n","Epoch 425/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.9094 - val_accuracy: 0.8716\n","\n","Epoch 00425: val_accuracy did not improve from 0.95270\n","Epoch 426/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0538 - accuracy: 0.9900 - val_loss: 0.3838 - val_accuracy: 0.8986\n","\n","Epoch 00426: val_accuracy did not improve from 0.95270\n","Epoch 427/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5282 - val_accuracy: 0.8784\n","\n","Epoch 00427: val_accuracy did not improve from 0.95270\n","Epoch 428/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5096 - val_accuracy: 0.9054\n","\n","Epoch 00428: val_accuracy did not improve from 0.95270\n","Epoch 429/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.6030 - val_accuracy: 0.8986\n","\n","Epoch 00429: val_accuracy did not improve from 0.95270\n","Epoch 430/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.3187 - val_accuracy: 0.9257\n","\n","Epoch 00430: val_accuracy did not improve from 0.95270\n","Epoch 431/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.4100 - val_accuracy: 0.9189\n","\n","Epoch 00431: val_accuracy did not improve from 0.95270\n","Epoch 432/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5656 - val_accuracy: 0.8986\n","\n","Epoch 00432: val_accuracy did not improve from 0.95270\n","Epoch 433/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3745 - val_accuracy: 0.9054\n","\n","Epoch 00433: val_accuracy did not improve from 0.95270\n","Epoch 434/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3604 - val_accuracy: 0.9257\n","\n","Epoch 00434: val_accuracy did not improve from 0.95270\n","Epoch 435/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.4248 - val_accuracy: 0.8716\n","\n","Epoch 00435: val_accuracy did not improve from 0.95270\n","Epoch 436/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0341 - accuracy: 0.9926 - val_loss: 1.1888 - val_accuracy: 0.8108\n","\n","Epoch 00436: val_accuracy did not improve from 0.95270\n","Epoch 437/500\n","238/238 [==============================] - 28s 119ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.7388 - val_accuracy: 0.8649\n","\n","Epoch 00437: val_accuracy did not improve from 0.95270\n","Epoch 438/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8851\n","\n","Epoch 00438: val_accuracy did not improve from 0.95270\n","Epoch 439/500\n","238/238 [==============================] - 28s 118ms/step - loss: 2.9046e-04 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9189\n","\n","Epoch 00439: val_accuracy did not improve from 0.95270\n","Epoch 440/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5828 - val_accuracy: 0.8919\n","\n","Epoch 00440: val_accuracy did not improve from 0.95270\n","Epoch 441/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.6228 - val_accuracy: 0.8919\n","\n","Epoch 00441: val_accuracy did not improve from 0.95270\n","Epoch 442/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5324 - val_accuracy: 0.8919\n","\n","Epoch 00442: val_accuracy did not improve from 0.95270\n","Epoch 443/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.4944e-04 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9122\n","\n","Epoch 00443: val_accuracy did not improve from 0.95270\n","Epoch 444/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.4581e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9122\n","\n","Epoch 00444: val_accuracy did not improve from 0.95270\n","Epoch 445/500\n","238/238 [==============================] - 28s 118ms/step - loss: 7.2004e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9054\n","\n","Epoch 00445: val_accuracy did not improve from 0.95270\n","Epoch 446/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.4016e-04 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9054\n","\n","Epoch 00446: val_accuracy did not improve from 0.95270\n","Epoch 447/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.6862 - val_accuracy: 0.8649\n","\n","Epoch 00447: val_accuracy did not improve from 0.95270\n","Epoch 448/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.7189 - val_accuracy: 0.8986\n","\n","Epoch 00448: val_accuracy did not improve from 0.95270\n","Epoch 449/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.6989 - val_accuracy: 0.9054\n","\n","Epoch 00449: val_accuracy did not improve from 0.95270\n","Epoch 450/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0302 - accuracy: 0.9937 - val_loss: 0.5687 - val_accuracy: 0.8919\n","\n","Epoch 00450: val_accuracy did not improve from 0.95270\n","Epoch 451/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.3717 - val_accuracy: 0.9392\n","\n","Epoch 00451: val_accuracy did not improve from 0.95270\n","Epoch 452/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4088 - val_accuracy: 0.9054\n","\n","Epoch 00452: val_accuracy did not improve from 0.95270\n","Epoch 453/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.8440e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9054\n","\n","Epoch 00453: val_accuracy did not improve from 0.95270\n","Epoch 454/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.6246e-04 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8851\n","\n","Epoch 00454: val_accuracy did not improve from 0.95270\n","Epoch 455/500\n","238/238 [==============================] - 28s 118ms/step - loss: 2.4104e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9054\n","\n","Epoch 00455: val_accuracy did not improve from 0.95270\n","Epoch 456/500\n","238/238 [==============================] - 28s 118ms/step - loss: 2.0650e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9054\n","\n","Epoch 00456: val_accuracy did not improve from 0.95270\n","Epoch 457/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0178 - accuracy: 0.9905 - val_loss: 0.9064 - val_accuracy: 0.8649\n","\n","Epoch 00457: val_accuracy did not improve from 0.95270\n","Epoch 458/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.4674 - val_accuracy: 0.8716\n","\n","Epoch 00458: val_accuracy did not improve from 0.95270\n","Epoch 459/500\n","238/238 [==============================] - 28s 118ms/step - loss: 8.7685e-04 - accuracy: 0.9995 - val_loss: 0.4884 - val_accuracy: 0.8986\n","\n","Epoch 00459: val_accuracy did not improve from 0.95270\n","Epoch 460/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6283 - val_accuracy: 0.9122\n","\n","Epoch 00460: val_accuracy did not improve from 0.95270\n","Epoch 461/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.2505e-04 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8919\n","\n","Epoch 00461: val_accuracy did not improve from 0.95270\n","Epoch 462/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.6056 - val_accuracy: 0.8784\n","\n","Epoch 00462: val_accuracy did not improve from 0.95270\n","Epoch 463/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.7448 - val_accuracy: 0.8919\n","\n","Epoch 00463: val_accuracy did not improve from 0.95270\n","Epoch 464/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.5553 - val_accuracy: 0.8919\n","\n","Epoch 00464: val_accuracy did not improve from 0.95270\n","Epoch 465/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.4714 - val_accuracy: 0.9054\n","\n","Epoch 00465: val_accuracy did not improve from 0.95270\n","Epoch 466/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5735 - val_accuracy: 0.9189\n","\n","Epoch 00466: val_accuracy did not improve from 0.95270\n","Epoch 467/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.6294e-04 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.9122\n","\n","Epoch 00467: val_accuracy did not improve from 0.95270\n","Epoch 468/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.6884 - val_accuracy: 0.8919\n","\n","Epoch 00468: val_accuracy did not improve from 0.95270\n","Epoch 469/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.4700 - val_accuracy: 0.9122\n","\n","Epoch 00469: val_accuracy did not improve from 0.95270\n","Epoch 470/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.5314 - val_accuracy: 0.9189\n","\n","Epoch 00470: val_accuracy did not improve from 0.95270\n","Epoch 471/500\n","238/238 [==============================] - 28s 118ms/step - loss: 3.4185e-04 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.9189\n","\n","Epoch 00471: val_accuracy did not improve from 0.95270\n","Epoch 472/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.7082e-04 - accuracy: 1.0000 - val_loss: 0.5810 - val_accuracy: 0.9257\n","\n","Epoch 00472: val_accuracy did not improve from 0.95270\n","Epoch 473/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.8694e-04 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9392\n","\n","Epoch 00473: val_accuracy did not improve from 0.95270\n","Epoch 474/500\n","238/238 [==============================] - 28s 118ms/step - loss: 4.5010e-04 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9122\n","\n","Epoch 00474: val_accuracy did not improve from 0.95270\n","Epoch 475/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9324\n","\n","Epoch 00475: val_accuracy did not improve from 0.95270\n","Epoch 476/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.3926e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9257\n","\n","Epoch 00476: val_accuracy did not improve from 0.95270\n","Epoch 477/500\n","238/238 [==============================] - 28s 118ms/step - loss: 1.2584e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9189\n","\n","Epoch 00477: val_accuracy did not improve from 0.95270\n","Epoch 478/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4988 - val_accuracy: 0.9054\n","\n","Epoch 00478: val_accuracy did not improve from 0.95270\n","Epoch 479/500\n","238/238 [==============================] - 28s 118ms/step - loss: 5.1333e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9189\n","\n","Epoch 00479: val_accuracy did not improve from 0.95270\n","Epoch 480/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.9123 - val_accuracy: 0.8919\n","\n","Epoch 00480: val_accuracy did not improve from 0.95270\n","Epoch 481/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0331 - accuracy: 0.9932 - val_loss: 0.6216 - val_accuracy: 0.9257\n","\n","Epoch 00481: val_accuracy did not improve from 0.95270\n","Epoch 482/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6073 - val_accuracy: 0.9054\n","\n","Epoch 00482: val_accuracy did not improve from 0.95270\n","Epoch 483/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6083 - val_accuracy: 0.9122\n","\n","Epoch 00483: val_accuracy did not improve from 0.95270\n","Epoch 484/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.3738 - val_accuracy: 0.9324\n","\n","Epoch 00484: val_accuracy did not improve from 0.95270\n","Epoch 485/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.7540 - val_accuracy: 0.8851\n","\n","Epoch 00485: val_accuracy did not improve from 0.95270\n","Epoch 486/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5693 - val_accuracy: 0.9054\n","\n","Epoch 00486: val_accuracy did not improve from 0.95270\n","Epoch 487/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.0286 - val_accuracy: 0.8243\n","\n","Epoch 00487: val_accuracy did not improve from 0.95270\n","Epoch 488/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.5807 - val_accuracy: 0.8851\n","\n","Epoch 00488: val_accuracy did not improve from 0.95270\n","Epoch 489/500\n","238/238 [==============================] - 28s 118ms/step - loss: 9.1434e-04 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9257\n","\n","Epoch 00489: val_accuracy did not improve from 0.95270\n","Epoch 490/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 0.9989 - val_loss: 0.4864 - val_accuracy: 0.9122\n","\n","Epoch 00490: val_accuracy did not improve from 0.95270\n","Epoch 491/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.4111 - val_accuracy: 0.9189\n","\n","Epoch 00491: val_accuracy did not improve from 0.95270\n","Epoch 492/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4256 - val_accuracy: 0.9122\n","\n","Epoch 00492: val_accuracy did not improve from 0.95270\n","Epoch 493/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.8470 - val_accuracy: 0.8851\n","\n","Epoch 00493: val_accuracy did not improve from 0.95270\n","Epoch 494/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5287 - val_accuracy: 0.9189\n","\n","Epoch 00494: val_accuracy did not improve from 0.95270\n","Epoch 495/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.4372 - val_accuracy: 0.9189\n","\n","Epoch 00495: val_accuracy did not improve from 0.95270\n","Epoch 496/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.3681 - val_accuracy: 0.9257\n","\n","Epoch 00496: val_accuracy did not improve from 0.95270\n","Epoch 497/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0164 - accuracy: 0.9989 - val_loss: 0.8623 - val_accuracy: 0.8514\n","\n","Epoch 00497: val_accuracy did not improve from 0.95270\n","Epoch 498/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8784\n","\n","Epoch 00498: val_accuracy did not improve from 0.95270\n","Epoch 499/500\n","238/238 [==============================] - 28s 118ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9324\n","\n","Epoch 00499: val_accuracy did not improve from 0.95270\n","Epoch 500/500\n","238/238 [==============================] - 28s 118ms/step - loss: 6.1176e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9459\n","\n","Epoch 00500: val_accuracy did not improve from 0.95270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fcd3e1d7d10>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"kHmpkzRJyCrf","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1633041526956,"user_tz":-540,"elapsed":18,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"c4b2f6ee-ad49-49bb-9ae3-9300e84470a7"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n","plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n","\n","plt.legend()\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"qcElIu93yIQU","executionInfo":{"status":"ok","timestamp":1633041540251,"user_tz":-540,"elapsed":13305,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4N2pAZyiR-","executionInfo":{"status":"ok","timestamp":1633041541071,"user_tz":-540,"elapsed":832,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["!mkdir images_test/none\n","!mv images_test/*.png images_test/none"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxH98QOgyu1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633041541467,"user_tz":-540,"elapsed":400,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"12fbfa9b-5c18-4d61-f3fc-222aba598357"},"source":["datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20480 images belonging to 1 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"nFEcoCR-3DNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633041585260,"user_tz":-540,"elapsed":43795,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"3e1d935b-6dec-45a3-f21d-080abf4ee73c"},"source":["Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"]}]},{"cell_type":"code","metadata":{"id":"qYhGZuzr1AjD","executionInfo":{"status":"ok","timestamp":1633041585265,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWALVGA1shFz","executionInfo":{"status":"ok","timestamp":1633041585267,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["import numpy as np\n","mylist = []\n","\n","for i in range(len(submission)):\n","    name =  test_generator.filenames\n","    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n","    mylist.append(id)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xjLSWZJvuVK","executionInfo":{"status":"ok","timestamp":1633041586521,"user_tz":-540,"elapsed":1272,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["for i in range(len(submission)):\n","    submission[\"id\"][i] = mylist[i]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNg9gk9z3Noq","executionInfo":{"status":"ok","timestamp":1633041586522,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission[\"model_predict\"] = Target_predict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Smd-xg6deOK","executionInfo":{"status":"ok","timestamp":1633041597031,"user_tz":-540,"elapsed":10513,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["from collections import Counter\n","\n","for i in range(len(submission)) :\n","    predicts = submission.loc[i, ['model_predict']]\n","    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg9m6Zgk4foS","executionInfo":{"status":"ok","timestamp":1633041597034,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}}},"source":["submission = submission[['id', 'digit']]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"flAHWrtH4flu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1633041597433,"user_tz":-540,"elapsed":404,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"f805ac26-aed4-48f6-9db9-d345ec7c462d"},"source":["from google.colab import files\n","\n","submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n","files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_4058f32d-ba9d-46a4-a98e-20ce1bade6b1\", \"Xception_1.csv\", 155898)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lmZ06MWjdN2l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633041600745,"user_tz":-540,"elapsed":3317,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"2f42f364-8eb7-48f8-8416-6f329f7c5db6"},"source":["!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"oVdKDp3mdOZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633041601981,"user_tz":-540,"elapsed":1241,"user":{"displayName":"이상민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTtK8dO4H2M2Xk5k_NkLzdZIUtyrNANJ0VxafBbA=s64","userId":"17307703622932801245"}},"outputId":"e99fa430-a3f9-49f8-dab4-96e0203cdd78"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","    # 파일경로\n","    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n","    # d9249@kyonggi.ac.kr\n","    # 'c2ecc8b05a9867f71ebb86f632ae73326696cb7f6e21be07ab43a7b400ef1f11',\n","    # dodo9249@gmail.com\n","    # 'abc9927563b1882b2480ac943a313a002631fb00c5a0daea43b12720ed34114e',\n","    # d9249.acc001@gmail.com\n","    # 'b27d6929e0eedade68e6a882d4006ec463f061c75a81aa27561c2c606dde8ad7',\n","    # meanideal96@gamil.com\n","    # '895306aa742a46bd095afaf319bd0b9519e1e6e74f4bf98a32c2e4c15aee5026',\n","    # dodo402298@gmail.com\n","    '384b4c250944611e49156214ca31fd554bbc64d22ec31a2726302c22f1a05271',\n","    # d9249.acc002@gmail.com\n","    # 'b28b29dd8d3ed4701f3b4e5b4d95549078e543dbd4a12abd92a3dd9a09d85616',\n","    # 대회 ID\n","    '235626',\n","    # d9249@kyonggi.ac.kr 팀이릉\n","    # 'iDeal9',\n","    # dodo9249@gmail.com 팀이름\n","    # 'iDeal96',\n","    # d9249.acc001@gmail.com\n","    # 'iDeal01',\n","    # meanideal96@gamil.com\n","    # 'iDeal02',\n","    # dodo402298@gmail.com\n","    'mean01',\n","    # d9249.acc002@gmail.com\n","    # 'mean02',\n","    # memo\n","    'd9249_kyonggi_ac_kr' )"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"]}]}]}