{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSize_299_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNwuuIEJWurcNIhX8fv9Ag+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ImageSize_299_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f932a7-0d6f-41fe-d3ce-76bdb86dbe7b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 10 15:40:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed16b142-9c03-47d9-dc9c-12641293ce0d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(299, 299, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e73a5e-87b2-4158-dcee-29a891155be0"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051e3ab9-fe2c-4fee-d8c0-c5f27800037d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(299,299), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(299,299), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f4601a-3db1-42de-d2c6-03bfb7344213"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 74s 803ms/step - loss: 1.9435 - accuracy: 0.3112 - val_loss: 6.3600 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 32s 617ms/step - loss: 1.3261 - accuracy: 0.5225 - val_loss: 19.7698 - val_accuracy: 0.1182\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10099 to 0.11823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 33s 626ms/step - loss: 1.0798 - accuracy: 0.6370 - val_loss: 10.7313 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11823\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 33s 628ms/step - loss: 0.9154 - accuracy: 0.6973 - val_loss: 4.8804 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11823\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 33s 636ms/step - loss: 0.8048 - accuracy: 0.7266 - val_loss: 7.2194 - val_accuracy: 0.1872\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.11823 to 0.18719, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 33s 633ms/step - loss: 0.7076 - accuracy: 0.7607 - val_loss: 12.4472 - val_accuracy: 0.0862\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.18719\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.6919 - accuracy: 0.7783 - val_loss: 1.9244 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.18719 to 0.42857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 33s 636ms/step - loss: 0.5670 - accuracy: 0.8118 - val_loss: 6.6165 - val_accuracy: 0.1626\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.42857\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.5951 - accuracy: 0.8069 - val_loss: 3.2305 - val_accuracy: 0.3424\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.42857\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.5306 - accuracy: 0.8216 - val_loss: 5.8171 - val_accuracy: 0.1601\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.42857\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.4509 - accuracy: 0.8441 - val_loss: 1.9356 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.42857 to 0.56404, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 34s 641ms/step - loss: 0.4328 - accuracy: 0.8520 - val_loss: 1.6044 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.56404 to 0.61823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.4179 - accuracy: 0.8508 - val_loss: 1.0430 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.61823 to 0.73153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.3920 - accuracy: 0.8727 - val_loss: 1.2932 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.73153\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.3702 - accuracy: 0.8758 - val_loss: 2.5467 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.73153\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.3266 - accuracy: 0.8855 - val_loss: 2.1135 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.73153\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.3221 - accuracy: 0.8952 - val_loss: 0.6075 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.73153 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.2819 - accuracy: 0.8983 - val_loss: 1.8765 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.81281\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.3208 - accuracy: 0.8892 - val_loss: 0.6686 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.81281 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 34s 641ms/step - loss: 0.2458 - accuracy: 0.9099 - val_loss: 0.5693 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.81527 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 34s 641ms/step - loss: 0.2090 - accuracy: 0.9312 - val_loss: 0.4755 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.84729 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.2010 - accuracy: 0.9312 - val_loss: 0.5617 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84975\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.2481 - accuracy: 0.9172 - val_loss: 0.6524 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.84975 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.2654 - accuracy: 0.9111 - val_loss: 0.9612 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85468\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.2407 - accuracy: 0.9184 - val_loss: 1.8604 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.85468\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.1949 - accuracy: 0.9348 - val_loss: 0.4675 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.85468 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.2207 - accuracy: 0.9202 - val_loss: 0.9269 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.85714\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.1689 - accuracy: 0.9458 - val_loss: 0.6565 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.85714\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.2067 - accuracy: 0.9312 - val_loss: 0.6989 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.85714\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.2355 - accuracy: 0.9220 - val_loss: 0.6802 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85714\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1477 - accuracy: 0.9525 - val_loss: 0.5717 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85714\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 33s 642ms/step - loss: 0.1064 - accuracy: 0.9653 - val_loss: 0.4221 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.85714 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.1568 - accuracy: 0.9482 - val_loss: 0.6176 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89409\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1224 - accuracy: 0.9580 - val_loss: 0.5610 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89409\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0969 - accuracy: 0.9665 - val_loss: 0.6971 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89409\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1251 - accuracy: 0.9580 - val_loss: 0.6949 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89409\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1410 - accuracy: 0.9555 - val_loss: 0.8802 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89409\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1015 - accuracy: 0.9659 - val_loss: 0.7411 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89409\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1061 - accuracy: 0.9622 - val_loss: 0.5719 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89409\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.1084 - accuracy: 0.9635 - val_loss: 0.6854 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89409\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.1366 - accuracy: 0.9592 - val_loss: 3.4523 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89409\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.2051 - accuracy: 0.9263 - val_loss: 0.8523 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89409\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.1362 - accuracy: 0.9543 - val_loss: 0.9294 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89409\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.1217 - accuracy: 0.9592 - val_loss: 0.5036 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89409\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.1008 - accuracy: 0.9677 - val_loss: 1.1116 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89409\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0977 - accuracy: 0.9671 - val_loss: 0.6494 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89409\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 34s 654ms/step - loss: 0.1064 - accuracy: 0.9635 - val_loss: 0.8862 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89409\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1282 - accuracy: 0.9537 - val_loss: 0.6518 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89409\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.1329 - accuracy: 0.9568 - val_loss: 1.0107 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89409\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1017 - accuracy: 0.9659 - val_loss: 0.5852 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89409\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0564 - accuracy: 0.9823 - val_loss: 0.4944 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89409\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 0.6910 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89409\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0764 - accuracy: 0.9683 - val_loss: 0.4635 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89409\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0812 - accuracy: 0.9720 - val_loss: 0.7358 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89409\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 0.4990 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89409\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.5652 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89409\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.6504 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89409\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 1.0984 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89409\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0921 - accuracy: 0.9732 - val_loss: 0.6379 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89409\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.1447 - accuracy: 0.9470 - val_loss: 1.7714 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89409\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0946 - accuracy: 0.9695 - val_loss: 1.1524 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89409\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0759 - accuracy: 0.9708 - val_loss: 1.2895 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89409\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0821 - accuracy: 0.9708 - val_loss: 0.9633 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89409\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0569 - accuracy: 0.9781 - val_loss: 0.4329 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89409\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0369 - accuracy: 0.9915 - val_loss: 0.4439 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89409\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 0.8932 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89409\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.4722 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89409\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.6096 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89409\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.4874 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89409\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.5685 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89409\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0620 - accuracy: 0.9781 - val_loss: 0.8045 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89409\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0741 - accuracy: 0.9726 - val_loss: 0.6552 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89409\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1013 - accuracy: 0.9689 - val_loss: 0.6754 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89409\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0826 - accuracy: 0.9726 - val_loss: 0.4430 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.89409 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.1903 - accuracy: 0.9428 - val_loss: 1.1691 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90148\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0812 - accuracy: 0.9689 - val_loss: 0.5706 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90148\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0459 - accuracy: 0.9817 - val_loss: 0.7044 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90148\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.5029 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90148\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.4700 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.90148 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 1.0386 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90394\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.7351 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90394\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.5318 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90394\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.7281 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90394\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0632 - accuracy: 0.9799 - val_loss: 1.3972 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90394\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 0.4325 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90394\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.6641 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90394\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.4382 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90394\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0523 - accuracy: 0.9848 - val_loss: 0.6048 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90394\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.6948 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90394\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.5950 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90394\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.6375 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90394\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0480 - accuracy: 0.9829 - val_loss: 1.0171 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90394\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0550 - accuracy: 0.9817 - val_loss: 1.2279 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90394\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 34s 655ms/step - loss: 0.1075 - accuracy: 0.9665 - val_loss: 0.7752 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90394\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0745 - accuracy: 0.9732 - val_loss: 1.2348 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90394\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.5648 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90394\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.4867 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90394\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0832 - accuracy: 0.9738 - val_loss: 0.5874 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90394\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0519 - accuracy: 0.9866 - val_loss: 1.2833 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90394\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 0.5852 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90394\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.4886 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90394\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.7237 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90394\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.3881 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.90394 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 1.1684 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0690 - accuracy: 0.9738 - val_loss: 1.7277 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0478 - accuracy: 0.9866 - val_loss: 0.4689 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.5189 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.5776 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.4374 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.5088 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.4743 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 0.5685 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0230 - accuracy: 0.9945 - val_loss: 0.5197 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91379\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.5823 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91379\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0566 - accuracy: 0.9842 - val_loss: 1.1684 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91379\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.1296 - accuracy: 0.9586 - val_loss: 3.4724 - val_accuracy: 0.5099\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91379\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.1125 - accuracy: 0.9635 - val_loss: 1.0827 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91379\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 0.5836 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91379\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.7702 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91379\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.4737 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91379\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.6204 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91379\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.4825 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91379\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.4020 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91379\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 1.4692 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91379\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.8876 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91379\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 34s 641ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.5715 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91379\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.4206 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91379\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4685 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91379\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4481 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91379\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.4373 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91379\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1202 - accuracy: 0.9629 - val_loss: 2.2577 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91379\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0965 - accuracy: 0.9671 - val_loss: 1.3234 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91379\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.8226 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91379\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4300 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91379\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4547 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91379\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.4174 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91379\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91379\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5331 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91379\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.4852 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91379\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0442 - accuracy: 0.9872 - val_loss: 0.9820 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91379\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.6947 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91379\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.5505 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91379\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.6273 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91379\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 1.1163 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91379\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.6263 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91379\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 1.0668 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91379\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0308 - accuracy: 0.9866 - val_loss: 0.7260 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91379\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.4676 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91379\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4312 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91379\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.6299 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91379\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.3952 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91379\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.5365 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91379\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.5534 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91379\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.5026 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91379\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.5820 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91379\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.5468 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91379\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5695 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91379\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0335 - accuracy: 0.9866 - val_loss: 0.7461 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91379\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0154 - accuracy: 0.9927 - val_loss: 0.7445 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91379\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.5522 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91379\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0495 - accuracy: 0.9829 - val_loss: 0.9282 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91379\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.9324 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91379\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.5764 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91379\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.6579 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91379\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.7112 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91379\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.6887 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91379\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.5050 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91379\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.6060 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91379\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4206 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00169: val_accuracy improved from 0.91379 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5140 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92365\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4544 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92365\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.5098 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92365\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5658 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92365\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92365\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4359 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92365\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00176: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 5.9450e-04 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92857\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 7.0686e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92857\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92857\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.4512 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92857\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0708 - accuracy: 0.9787 - val_loss: 0.7064 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92857\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.1749 - accuracy: 0.9555 - val_loss: 2.2779 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92857\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.1068 - accuracy: 0.9653 - val_loss: 1.2166 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92857\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0489 - accuracy: 0.9829 - val_loss: 0.8270 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92857\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 0.6352 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92857\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.5042 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92857\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5106 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92857\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4923 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92857\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0244 - accuracy: 0.9963 - val_loss: 0.8972 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92857\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0529 - accuracy: 0.9829 - val_loss: 0.9215 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92857\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.7878 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92857\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.6805 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92857\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.9444 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92857\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.5386 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92857\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5117 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92857\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.4302 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92857\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4697 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92857\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92857\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5053 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92857\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4273 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92857\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92857\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 34s 651ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5543 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92857\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5025 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92857\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 34s 652ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4384 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92857\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92857\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 34s 651ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4317 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92857\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 34s 650ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92857\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5692 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92857\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5879 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92857\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.8558 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.7567 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.9680 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.7178 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5153 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.6719 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.9804 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.1701 - accuracy: 0.9562 - val_loss: 2.4235 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.6296 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.5222 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.4624 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4722 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 33s 639ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4651 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4372 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.7310 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.6912 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 34s 655ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.6011 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.8598 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6077 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.4804 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.9953 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0682 - accuracy: 0.9762 - val_loss: 0.8020 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.7751 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.7036 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6235 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 8.7664e-04 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4641 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5151 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.4560 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4990 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.6202 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.5808 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 1.2849 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 0.9866 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.7907 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.6872 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.6403 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6104 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4745 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.5269 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5565 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.6412 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6261 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.6067 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5222 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.6513 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.5846 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.5764 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.8740 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 1.0466 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0797 - accuracy: 0.9762 - val_loss: 0.9464 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.7493 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.9837 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.5836 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4329 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3897 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.4032 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4953 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4354 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 9.8410e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 5.9763e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5075 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 8.4315e-04 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5296 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 34s 649ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4936 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00280: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 9.8015e-04 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93103\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4865 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93103\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4745 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93103\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.3433 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93103\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.7502 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93103\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 1.0500 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93103\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.8140 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93103\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.6558 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93103\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.8142 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93103\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.8093 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93103\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 1.1286 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93103\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 1.0310 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93103\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0643 - accuracy: 0.9775 - val_loss: 1.5427 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93103\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.9978 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93103\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 34s 654ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.6022 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93103\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.4934 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93103\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5341 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93103\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6823 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93103\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6270 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93103\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4418 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93103\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.5588 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93103\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5104 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93103\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6737 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93103\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.4957 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93103\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93103\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 7.9660e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93103\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.5430 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93103\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5501 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93103\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5038 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93103\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93103\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5466 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93103\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6266 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93103\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.8121 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93103\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 1.1065 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93103\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0462 - accuracy: 0.9866 - val_loss: 2.1223 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93103\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 1.1114 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93103\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 0.9639 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93103\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0131 - accuracy: 0.9945 - val_loss: 0.7199 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93103\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 1.0737 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93103\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.8798 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93103\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.6874 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93103\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.5578 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93103\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.4918 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93103\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.5226 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93103\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.6691 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93103\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 34s 652ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4376 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93103\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93103\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4426 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93103\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.6092 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93103\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5582 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93103\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.5611 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93103\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4892 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93103\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4317 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93103\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.5995 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93103\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5028 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93103\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.6213 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93103\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.5323 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93103\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5413 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93103\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 1.4601 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93103\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.6583 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93103\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.8563 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93103\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 33s 639ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.6344 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93103\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 33s 642ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.9005 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93103\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.5548 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93103\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 33s 638ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.7056 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93103\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 33s 638ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.5744 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93103\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4701 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93103\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.5031 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93103\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5748 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93103\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 33s 648ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5007 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93103\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5753 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93103\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5102 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93103\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5940 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93103\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.4870 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93103\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5483 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93103\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5239 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93103\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 8.4388e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93103\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 1.0590 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93103\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.8943 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93103\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.7799 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93103\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.8615 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93103\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.7780 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93103\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 34s 653ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5708 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93103\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93103\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4336 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93103\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93103\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 7.6324e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93103\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 6.3750e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93103\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 5.2976e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93103\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 5.5639e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93103\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 9.1249e-04 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93103\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 4.3234e-04 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93103\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.6084 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93103\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5676 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93103\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4919 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93103\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 6.7466e-04 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93103\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5173 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93103\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93103\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 6.7121e-04 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93103\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5311 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93103\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 6.5535e-04 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93103\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 8.7690e-04 - accuracy: 0.9994 - val_loss: 0.5447 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93103\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.8606 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93103\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.5603 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93103\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.7759 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93103\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 1.1978 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93103\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 33s 639ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.8922 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93103\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 1.1371 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93103\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 1.2835 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93103\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0563 - accuracy: 0.9823 - val_loss: 1.1440 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93103\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 0.6787 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93103\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0228 - accuracy: 0.9903 - val_loss: 0.6959 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93103\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.6203 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93103\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.7097 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93103\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 34s 652ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93103\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.8233 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93103\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 34s 648ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5494 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93103\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 8.5335e-04 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93103\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 5.7198e-04 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93103\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 2.4760e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93103\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 3.0072e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93103\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 4.8129e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93103\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 3.4422e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93103\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 2.1905e-04 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93103\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 4.5846e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93103\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 2.1636e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93103\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 4.5034e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93103\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 1.2809e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93103\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 1.7978e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93103\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 2.2785e-04 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93103\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 2.1491e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93103\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 1.1316e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93103\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 4.3289e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93103\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 4.8662e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93103\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 7.0818e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93103\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.4275 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93103\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4680 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93103\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 2.5095 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93103\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.9733 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93103\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 0.8356 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93103\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.8168 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93103\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 33s 640ms/step - loss: 0.0229 - accuracy: 0.9909 - val_loss: 1.0272 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93103\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 0.6129 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93103\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.6407 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93103\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.5304 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93103\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5606 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93103\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0387 - accuracy: 0.9921 - val_loss: 0.6250 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93103\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.5953 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93103\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.4299 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93103\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4156 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93103\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5190 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93103\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 0.6737 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93103\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.6116 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93103\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4371 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93103\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4619 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93103\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5948 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93103\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4091 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93103\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5510 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93103\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93103\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 9.1916e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93103\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 3.7822e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93103\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 8.4525e-04 - accuracy: 0.9994 - val_loss: 0.4425 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93103\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4304 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93103\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 4.1940e-04 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93103\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 2.5537e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93103\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 4.0350e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93103\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 5.0703e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93103\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 2.0407e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93103\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 3.3024e-04 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93103\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5515 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93103\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93103\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.5079 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93103\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.6015 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93103\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.7649 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93103\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0593 - accuracy: 0.9860 - val_loss: 1.8461 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93103\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 1.5310 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93103\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.6771 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93103\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.5972 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93103\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4414 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93103\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.5466 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93103\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 0.5311 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93103\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4858 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93103\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5032 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93103\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5595 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93103\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 33s 641ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4128 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93103\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 4.1311e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93103\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 3.8785e-04 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93103\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 34s 653ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3742 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93103\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4592 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93103\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 33s 642ms/step - loss: 7.8098e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00470: val_accuracy improved from 0.93103 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 6.5637e-04 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93842\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 4.3544e-04 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93842\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 2.5077e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93842\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.5920 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93842\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.5546 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93842\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5504 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93842\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5118 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93842\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.5796 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93842\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93842\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5106 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93842\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93842\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.5411 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93842\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5249 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93842\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 34s 642ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5571 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93842\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 5.4677e-04 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93842\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 34s 646ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.6244 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93842\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6553 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93842\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5417 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93842\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 34s 643ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5001 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93842\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0354 - accuracy: 0.9915 - val_loss: 2.0893 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93842\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 1.0697 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93842\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 34s 647ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 1.2571 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93842\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0469 - accuracy: 0.9866 - val_loss: 0.8320 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93842\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0576 - accuracy: 0.9836 - val_loss: 0.8344 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93842\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.6109 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93842\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.5733 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93842\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93842\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.5805 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 34s 645ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.6069 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 34s 644ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5119 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d5dee6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5151d68b-f17c-46e4-fcb7-14a47e87407b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_299_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1004fff-a604-46c0-d81f-21d2c755c608"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(299,299), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed813b84-461f-4b36-cbd1-b398eea04afb"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9cb5b0f7-9ec0-497b-9dd8-d5bf363c0222"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "34ed8c3f-232b-4c05-cae1-ba8ec047e6bf"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_299_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_299_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_49102c2f-333e-4575-b93e-70711809314e\", \"ImageSize_299_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}