{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSize_32_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuax29VF8eQr07Hibe8hne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ImageSize_32_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996b7d08-5d90-4fb4-b07c-04620adba1cf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 20:49:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b442c0e7-9ae9-4062-e6de-7892a3a2df4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(32, 32, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717eb5fe-284c-40c1-c87a-9f05ced49edc"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vb-b5ho4ftu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c61876-ab57-4f7d-9918-bb3c145c19f4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(32,32), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(32,32), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09425ae1-8e3a-4aae-ff83-12920c574406"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 36s 151ms/step - loss: 2.3657 - accuracy: 0.2022 - val_loss: 2.3671 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 2.1552 - accuracy: 0.2747 - val_loss: 3.1886 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09852\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 1.9495 - accuracy: 0.3301 - val_loss: 3.5741 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09852\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 1.8081 - accuracy: 0.4111 - val_loss: 3.9826 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.09852\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 1.6145 - accuracy: 0.4458 - val_loss: 3.8578 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.09852\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 1.6377 - accuracy: 0.4574 - val_loss: 3.0856 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.09852 to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 1.5537 - accuracy: 0.4909 - val_loss: 4.0404 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.10099\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 1.5125 - accuracy: 0.4890 - val_loss: 6.7767 - val_accuracy: 0.0887\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.10099\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 1.2966 - accuracy: 0.5743 - val_loss: 2.0483 - val_accuracy: 0.3399\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.10099 to 0.33990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 1.3026 - accuracy: 0.5743 - val_loss: 2.7457 - val_accuracy: 0.2906\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.33990\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 1.1784 - accuracy: 0.6133 - val_loss: 2.1260 - val_accuracy: 0.4113\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.33990 to 0.41133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 1.0953 - accuracy: 0.6401 - val_loss: 2.7326 - val_accuracy: 0.3719\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.41133\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 1.0171 - accuracy: 0.6717 - val_loss: 2.1401 - val_accuracy: 0.3990\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.41133\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.9981 - accuracy: 0.6790 - val_loss: 3.9916 - val_accuracy: 0.3818\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.41133\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.9627 - accuracy: 0.6693 - val_loss: 1.7366 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.41133 to 0.53941, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.9134 - accuracy: 0.6894 - val_loss: 2.5649 - val_accuracy: 0.4557\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53941\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.8948 - accuracy: 0.6949 - val_loss: 1.4822 - val_accuracy: 0.5271\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.53941\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.8548 - accuracy: 0.7138 - val_loss: 2.0607 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53941\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.8104 - accuracy: 0.7223 - val_loss: 2.6240 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53941\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.7142 - accuracy: 0.7667 - val_loss: 1.5719 - val_accuracy: 0.5616\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53941 to 0.56158, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.6752 - accuracy: 0.7637 - val_loss: 1.5630 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.56158 to 0.60099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.6998 - accuracy: 0.7533 - val_loss: 3.3244 - val_accuracy: 0.4384\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.60099\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.6446 - accuracy: 0.7820 - val_loss: 1.7072 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.60099\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.6391 - accuracy: 0.7917 - val_loss: 1.9691 - val_accuracy: 0.5296\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.60099\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5224 - accuracy: 0.8161 - val_loss: 1.2886 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.60099 to 0.63300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5730 - accuracy: 0.7972 - val_loss: 1.7552 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.63300\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.5320 - accuracy: 0.8161 - val_loss: 1.8558 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.63300\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.6801 - accuracy: 0.7698 - val_loss: 2.6609 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.63300\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.5543 - accuracy: 0.8136 - val_loss: 1.8324 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.63300\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.5194 - accuracy: 0.8167 - val_loss: 1.7958 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.63300\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.5195 - accuracy: 0.8228 - val_loss: 2.5734 - val_accuracy: 0.4360\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.63300\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.5127 - accuracy: 0.8246 - val_loss: 1.5705 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.63300\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5926 - accuracy: 0.7996 - val_loss: 1.6603 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.63300\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4574 - accuracy: 0.8350 - val_loss: 1.3710 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.63300\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4356 - accuracy: 0.8410 - val_loss: 1.1890 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.63300 to 0.65271, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3847 - accuracy: 0.8630 - val_loss: 1.1626 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.65271 to 0.66010, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.3402 - accuracy: 0.8886 - val_loss: 1.2344 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.66010\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3669 - accuracy: 0.8618 - val_loss: 1.3732 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.66010\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.3784 - accuracy: 0.8636 - val_loss: 1.6950 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.66010\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3729 - accuracy: 0.8745 - val_loss: 1.8006 - val_accuracy: 0.5788\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.66010\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.4735 - accuracy: 0.8410 - val_loss: 1.6936 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.66010\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3597 - accuracy: 0.8691 - val_loss: 1.7229 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.66010\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2730 - accuracy: 0.9086 - val_loss: 1.8585 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.66010\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2777 - accuracy: 0.9026 - val_loss: 1.5157 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.66010\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3735 - accuracy: 0.8788 - val_loss: 1.3960 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.66010\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3090 - accuracy: 0.8892 - val_loss: 1.6158 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.66010\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2769 - accuracy: 0.9111 - val_loss: 1.7625 - val_accuracy: 0.5616\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.66010\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4061 - accuracy: 0.8599 - val_loss: 1.9056 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.66010\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2862 - accuracy: 0.8989 - val_loss: 1.3980 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.66010\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2477 - accuracy: 0.9111 - val_loss: 2.0384 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.66010\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3129 - accuracy: 0.8886 - val_loss: 2.0524 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.66010\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2793 - accuracy: 0.8989 - val_loss: 1.4174 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.66010 to 0.66502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2231 - accuracy: 0.9263 - val_loss: 1.3980 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.66502\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.2476 - accuracy: 0.9086 - val_loss: 1.5853 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.66502\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3222 - accuracy: 0.8928 - val_loss: 1.4386 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.66502\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2355 - accuracy: 0.9202 - val_loss: 1.3445 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.66502\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2981 - accuracy: 0.9019 - val_loss: 1.4641 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.66502\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2189 - accuracy: 0.9281 - val_loss: 1.3654 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00058: val_accuracy improved from 0.66502 to 0.67734, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2112 - accuracy: 0.9330 - val_loss: 1.3980 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.67734\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.2930 - accuracy: 0.8989 - val_loss: 2.5310 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.67734\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.2592 - accuracy: 0.9099 - val_loss: 1.4219 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.67734 to 0.69458, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1887 - accuracy: 0.9379 - val_loss: 1.5125 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.69458\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.2213 - accuracy: 0.9245 - val_loss: 1.5939 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.69458\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1716 - accuracy: 0.9440 - val_loss: 1.9997 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.69458\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1718 - accuracy: 0.9379 - val_loss: 1.4735 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.69458\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2962 - accuracy: 0.9038 - val_loss: 2.1973 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.69458\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2334 - accuracy: 0.9245 - val_loss: 1.6179 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.69458\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1796 - accuracy: 0.9464 - val_loss: 1.4623 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.69458\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1330 - accuracy: 0.9568 - val_loss: 1.8419 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.69458\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1223 - accuracy: 0.9580 - val_loss: 1.3817 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.69458\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1471 - accuracy: 0.9543 - val_loss: 1.6103 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.69458\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1743 - accuracy: 0.9373 - val_loss: 2.2195 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.69458\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1946 - accuracy: 0.9330 - val_loss: 2.8066 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.69458\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1794 - accuracy: 0.9348 - val_loss: 1.6454 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.69458\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1686 - accuracy: 0.9324 - val_loss: 2.0492 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.69458\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1396 - accuracy: 0.9501 - val_loss: 1.9263 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.69458\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1381 - accuracy: 0.9519 - val_loss: 1.3919 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.69458\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2244 - accuracy: 0.9336 - val_loss: 2.7193 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.69458\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2093 - accuracy: 0.9391 - val_loss: 2.4249 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.69458\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1631 - accuracy: 0.9421 - val_loss: 1.5897 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.69458 to 0.70936, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1701 - accuracy: 0.9415 - val_loss: 2.1067 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.70936\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2411 - accuracy: 0.9227 - val_loss: 2.3812 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.70936\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.1763 - accuracy: 0.9403 - val_loss: 1.8270 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.70936\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1192 - accuracy: 0.9592 - val_loss: 1.9566 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.70936\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1228 - accuracy: 0.9574 - val_loss: 1.5917 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.70936\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1413 - accuracy: 0.9501 - val_loss: 1.4778 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.70936 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1297 - accuracy: 0.9586 - val_loss: 1.7914 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.71182\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1413 - accuracy: 0.9495 - val_loss: 1.9082 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.71182\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1515 - accuracy: 0.9452 - val_loss: 2.0868 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.71182\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1882 - accuracy: 0.9373 - val_loss: 2.3139 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.71182\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1798 - accuracy: 0.9385 - val_loss: 2.5440 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.71182\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1072 - accuracy: 0.9610 - val_loss: 2.4778 - val_accuracy: 0.5936\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.71182\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1547 - accuracy: 0.9501 - val_loss: 1.9613 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.71182\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1083 - accuracy: 0.9647 - val_loss: 1.6759 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.71182\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.1078 - accuracy: 0.9616 - val_loss: 1.8780 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.71182\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2078 - accuracy: 0.9275 - val_loss: 2.1287 - val_accuracy: 0.5936\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.71182\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1696 - accuracy: 0.9336 - val_loss: 1.9720 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.71182\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1972 - accuracy: 0.9397 - val_loss: 1.5606 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.71182\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1323 - accuracy: 0.9574 - val_loss: 1.4642 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.71182\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1078 - accuracy: 0.9616 - val_loss: 1.4133 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.71182\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0870 - accuracy: 0.9702 - val_loss: 1.6303 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.71182\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0999 - accuracy: 0.9683 - val_loss: 1.6511 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.71182\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0919 - accuracy: 0.9677 - val_loss: 1.4779 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.71182\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0852 - accuracy: 0.9677 - val_loss: 1.4412 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.71182\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1365 - accuracy: 0.9525 - val_loss: 1.7408 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.71182\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1317 - accuracy: 0.9574 - val_loss: 1.8233 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.71182\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1077 - accuracy: 0.9580 - val_loss: 1.8914 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.71182\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0948 - accuracy: 0.9665 - val_loss: 1.7086 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.71182\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1174 - accuracy: 0.9635 - val_loss: 1.7489 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.71182\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1476 - accuracy: 0.9525 - val_loss: 2.2578 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.71182\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0893 - accuracy: 0.9677 - val_loss: 1.7704 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.71182\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 1.7751 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.71182\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0814 - accuracy: 0.9738 - val_loss: 2.0332 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.71182\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0817 - accuracy: 0.9775 - val_loss: 2.0638 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.71182\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1111 - accuracy: 0.9586 - val_loss: 1.8793 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.71182\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1266 - accuracy: 0.9592 - val_loss: 2.0163 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.71182\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1398 - accuracy: 0.9513 - val_loss: 1.7613 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.71182\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1222 - accuracy: 0.9574 - val_loss: 1.8207 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.71182\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1494 - accuracy: 0.9525 - val_loss: 1.8474 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.71182\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1073 - accuracy: 0.9647 - val_loss: 1.7116 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.71182\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1150 - accuracy: 0.9635 - val_loss: 2.2571 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.71182\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2214 - accuracy: 0.9287 - val_loss: 2.0996 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.71182\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1581 - accuracy: 0.9604 - val_loss: 1.6365 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.71182\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1088 - accuracy: 0.9592 - val_loss: 1.9053 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.71182\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 1.5148 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.71182\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.0870 - accuracy: 0.9769 - val_loss: 1.8796 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.71182\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0839 - accuracy: 0.9659 - val_loss: 1.4355 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.71182\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0950 - accuracy: 0.9677 - val_loss: 1.7659 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.71182\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0798 - accuracy: 0.9677 - val_loss: 1.4937 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.71182\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0850 - accuracy: 0.9762 - val_loss: 1.8386 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.71182\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0851 - accuracy: 0.9671 - val_loss: 1.5475 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.71182\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0816 - accuracy: 0.9756 - val_loss: 1.6587 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.71182\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1253 - accuracy: 0.9665 - val_loss: 1.9770 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.71182\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1282 - accuracy: 0.9513 - val_loss: 2.2112 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.71182\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0849 - accuracy: 0.9714 - val_loss: 2.8207 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.71182\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.0817 - accuracy: 0.9762 - val_loss: 1.9725 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.71182\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0792 - accuracy: 0.9702 - val_loss: 1.6165 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.71182\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 2.0939 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.71182\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0592 - accuracy: 0.9817 - val_loss: 2.1680 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.71182\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0820 - accuracy: 0.9720 - val_loss: 1.5187 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.71182 to 0.71921, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1598 - accuracy: 0.9513 - val_loss: 2.1294 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.71921\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0901 - accuracy: 0.9689 - val_loss: 1.7411 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.71921\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0906 - accuracy: 0.9726 - val_loss: 1.9349 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.71921\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 1.9337 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.71921\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0570 - accuracy: 0.9775 - val_loss: 1.6226 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.71921\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1340 - accuracy: 0.9549 - val_loss: 2.3746 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.71921\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 1.7831 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.71921\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0970 - accuracy: 0.9689 - val_loss: 1.7393 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.71921\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1783 - accuracy: 0.9458 - val_loss: 2.1177 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.71921\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1056 - accuracy: 0.9665 - val_loss: 1.7132 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.71921\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0889 - accuracy: 0.9732 - val_loss: 1.5592 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.71921\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0912 - accuracy: 0.9702 - val_loss: 1.7081 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.71921\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0632 - accuracy: 0.9817 - val_loss: 1.8216 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.71921\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 1.6705 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.71921\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0713 - accuracy: 0.9750 - val_loss: 1.7104 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.71921\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0573 - accuracy: 0.9817 - val_loss: 1.4533 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.71921\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 1.8587 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.71921\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 1.6122 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.71921\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0538 - accuracy: 0.9817 - val_loss: 1.8997 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.71921\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 1.4858 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.71921\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 1.4101 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.71921\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 2.2060 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.71921\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0547 - accuracy: 0.9799 - val_loss: 1.7786 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.71921\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 1.7024 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.71921\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0578 - accuracy: 0.9836 - val_loss: 1.6560 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.71921\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 1.8207 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.71921\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 2.0011 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.71921\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 1.9424 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.71921\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 1.7148 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.71921\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0901 - accuracy: 0.9695 - val_loss: 2.2591 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.71921\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1177 - accuracy: 0.9562 - val_loss: 1.7350 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.71921\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1090 - accuracy: 0.9635 - val_loss: 1.7527 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.71921\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0861 - accuracy: 0.9738 - val_loss: 2.1751 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.71921\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1048 - accuracy: 0.9720 - val_loss: 1.9662 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.71921\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0681 - accuracy: 0.9720 - val_loss: 1.8951 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.71921\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 1.7168 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.71921\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 1.7194 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.71921\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0574 - accuracy: 0.9793 - val_loss: 1.5720 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.71921\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 1.6385 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.71921\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 1.7870 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.71921\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 1.9314 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.71921\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 1.8025 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.71921\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 1.6747 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.71921\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0613 - accuracy: 0.9762 - val_loss: 1.8824 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.71921\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1026 - accuracy: 0.9689 - val_loss: 2.5138 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.71921\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0751 - accuracy: 0.9738 - val_loss: 2.1915 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.71921\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 2.0308 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.71921\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 2.0492 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.71921\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 2.0116 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.71921\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 2.0154 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.71921\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0825 - accuracy: 0.9744 - val_loss: 1.5623 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.71921\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1586 - accuracy: 0.9549 - val_loss: 3.6213 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.71921\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 2.4184 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.71921\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 1.9287 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.71921\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 2.6267 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.71921\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 2.0208 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.71921\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0588 - accuracy: 0.9817 - val_loss: 1.5650 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.71921\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 1.8163 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.71921\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 1.7277 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.71921\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0774 - accuracy: 0.9762 - val_loss: 1.8714 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.71921\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0572 - accuracy: 0.9817 - val_loss: 1.8419 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.71921\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0651 - accuracy: 0.9793 - val_loss: 1.7185 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.71921\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0691 - accuracy: 0.9775 - val_loss: 1.8970 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.71921\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 1.7502 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.71921\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 1.7020 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.71921\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 1.7538 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.71921\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 1.6558 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.71921\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0359 - accuracy: 0.9872 - val_loss: 1.8476 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.71921\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 1.6650 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.71921\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0551 - accuracy: 0.9811 - val_loss: 2.0424 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.71921\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 2.1883 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.71921\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 2.1607 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.71921\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 2.0260 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.71921\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0681 - accuracy: 0.9823 - val_loss: 2.3839 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.71921\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0553 - accuracy: 0.9829 - val_loss: 2.6822 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.71921\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 2.4926 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.71921\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 1.7821 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.71921\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 1.8302 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.71921\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0517 - accuracy: 0.9860 - val_loss: 1.8544 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.71921\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0496 - accuracy: 0.9872 - val_loss: 1.8777 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.71921\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 1.9183 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.71921\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 1.8017 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.71921\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 1.6941 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.71921\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 2.0875 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.71921\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 1.5995 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.71921\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0339 - accuracy: 0.9854 - val_loss: 1.7858 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.71921\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0461 - accuracy: 0.9823 - val_loss: 2.2121 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.71921\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 2.2156 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.71921\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0642 - accuracy: 0.9756 - val_loss: 2.1464 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.71921\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2091 - accuracy: 0.9434 - val_loss: 2.1387 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.71921\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1200 - accuracy: 0.9580 - val_loss: 2.1692 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.71921\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0543 - accuracy: 0.9823 - val_loss: 1.7613 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.71921\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0396 - accuracy: 0.9829 - val_loss: 1.8184 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.71921\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0594 - accuracy: 0.9805 - val_loss: 1.8178 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.71921\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 1.4752 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.71921\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 1.6031 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.71921\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 1.7042 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.71921\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 2.2526 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.71921\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 1.7796 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.71921\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0415 - accuracy: 0.9866 - val_loss: 1.4185 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00240: val_accuracy improved from 0.71921 to 0.73645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0426 - accuracy: 0.9836 - val_loss: 1.7823 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.73645\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 1.5488 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.73645\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 1.8318 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.73645\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0465 - accuracy: 0.9903 - val_loss: 2.0897 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.73645\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0530 - accuracy: 0.9836 - val_loss: 1.7689 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.73645\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0521 - accuracy: 0.9799 - val_loss: 2.1093 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.73645\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 2.3553 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.73645\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0456 - accuracy: 0.9836 - val_loss: 1.8142 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.73645\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 1.8786 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.73645\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0590 - accuracy: 0.9829 - val_loss: 1.8094 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.73645\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0702 - accuracy: 0.9787 - val_loss: 2.2461 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.73645\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 2.3147 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.73645\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0519 - accuracy: 0.9854 - val_loss: 1.9160 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.73645\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0393 - accuracy: 0.9842 - val_loss: 1.9170 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.73645\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0491 - accuracy: 0.9848 - val_loss: 1.9438 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.73645\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 1.8383 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.73645\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.6297 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.73645\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 1.7486 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.73645\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 1.8538 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.73645\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 3.5700 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.73645\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0945 - accuracy: 0.9756 - val_loss: 2.2103 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.73645\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 2.4164 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.73645\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 2.1648 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.73645\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0656 - accuracy: 0.9787 - val_loss: 2.3087 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.73645\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 1.8366 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.73645\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0540 - accuracy: 0.9811 - val_loss: 2.0911 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.73645\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 1.8827 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.73645\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 2.3050 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.73645\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 1.8538 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.73645\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 1.7260 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.73645\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 1.7598 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.73645\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 1.8538 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.73645\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 2.0275 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.73645\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 1.7842 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.73645\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 1.8809 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.73645\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 1.9378 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.73645\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 1.7619 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.73645\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0297 - accuracy: 0.9878 - val_loss: 1.9322 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.73645\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 2.1951 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.73645\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0805 - accuracy: 0.9726 - val_loss: 2.2879 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.73645\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0732 - accuracy: 0.9744 - val_loss: 2.9101 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.73645\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0481 - accuracy: 0.9872 - val_loss: 2.5158 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.73645\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 2.2148 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.73645\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 2.2374 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.73645\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 2.2288 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.73645\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0199 - accuracy: 0.9921 - val_loss: 2.1702 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.73645\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 1.8464 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.73645\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0291 - accuracy: 0.9884 - val_loss: 2.1775 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.73645\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 1.9874 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.73645\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 1.6887 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.73645\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 2.0308 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.73645\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 2.2468 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.73645\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 1.9007 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.73645\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 1.8069 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.73645\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 2.0157 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.73645\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 2.3880 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.73645\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0586 - accuracy: 0.9817 - val_loss: 1.7791 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.73645\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 2.2187 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.73645\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 2.1073 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.73645\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0586 - accuracy: 0.9848 - val_loss: 1.7555 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.73645\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0413 - accuracy: 0.9842 - val_loss: 2.0559 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.73645\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1238 - accuracy: 0.9659 - val_loss: 2.3390 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.73645\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 2.2758 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.73645\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0605 - accuracy: 0.9836 - val_loss: 2.3783 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.73645\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 2.1471 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.73645\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 2.2006 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.73645\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 2.2198 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.73645\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 1.8064 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.73645\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0445 - accuracy: 0.9836 - val_loss: 1.8530 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.73645\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0228 - accuracy: 0.9945 - val_loss: 1.5624 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.73645\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 1.8491 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.73645\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 2.0131 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.73645\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0202 - accuracy: 0.9909 - val_loss: 1.8835 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.73645\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 1.9912 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.73645\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0520 - accuracy: 0.9860 - val_loss: 2.2613 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.73645\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 2.9575 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.73645\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 1.9696 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.73645\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 1.8537 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.73645\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 1.7201 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.73645\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 1.9218 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.73645\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 1.5191 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.73645\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.3980 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00322: val_accuracy improved from 0.73645 to 0.74877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 1.7299 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.74877\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 1.6149 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.74877\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 1.6892 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.74877\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 2.0407 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.74877\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 1.6982 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.74877\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0150 - accuracy: 0.9939 - val_loss: 1.7869 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.74877\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.8320 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.74877\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 1.9819 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.74877\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 1.7290 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.74877\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 1.8585 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.74877\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0377 - accuracy: 0.9854 - val_loss: 1.8346 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.74877\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 1.8392 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.74877\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 2.7191 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.74877\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 2.1739 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.74877\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 1.9600 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.74877\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0425 - accuracy: 0.9854 - val_loss: 2.1017 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.74877\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 2.0314 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.74877\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 1.9454 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.74877\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0667 - accuracy: 0.9829 - val_loss: 2.2100 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.74877\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 2.3033 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.74877\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0550 - accuracy: 0.9787 - val_loss: 2.1241 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.74877\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 1.9398 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.74877\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0430 - accuracy: 0.9854 - val_loss: 2.3924 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.74877\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0708 - accuracy: 0.9829 - val_loss: 2.1833 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.74877\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 1.7695 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.74877\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 1.8157 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.74877\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 1.5865 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.74877\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0178 - accuracy: 0.9909 - val_loss: 1.5799 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.74877\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 1.8465 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.74877\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0979 - accuracy: 0.9805 - val_loss: 2.3041 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.74877\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 2.2244 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.74877\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0255 - accuracy: 0.9903 - val_loss: 1.8373 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.74877\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 1.8103 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.74877\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 1.8059 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.74877\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 1.5750 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.74877\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 1.8533 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.74877\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0440 - accuracy: 0.9866 - val_loss: 1.8887 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.74877\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0332 - accuracy: 0.9866 - val_loss: 2.0036 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.74877\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 2.3051 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.74877\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 1.9858 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.74877\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 1.8493 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.74877\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 1.8428 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.74877\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 1.7738 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.74877\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 1.6837 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.74877\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 1.8011 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.74877\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 1.7723 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.74877\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.8960 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.74877\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 1.7245 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.74877\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 1.6965 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.74877\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 1.7571 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.74877\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 1.6406 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.74877\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 2.4833 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.74877\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0437 - accuracy: 0.9878 - val_loss: 2.3232 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.74877\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 2.4387 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.74877\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0606 - accuracy: 0.9817 - val_loss: 2.1915 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.74877\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0386 - accuracy: 0.9872 - val_loss: 2.3565 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.74877\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0531 - accuracy: 0.9854 - val_loss: 2.4373 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.74877\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0301 - accuracy: 0.9884 - val_loss: 2.1383 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.74877\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0495 - accuracy: 0.9860 - val_loss: 2.2484 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.74877\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0353 - accuracy: 0.9860 - val_loss: 2.0714 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.74877\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 2.1717 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.74877\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 2.0539 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.74877\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 2.0419 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.74877\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 2.1815 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.74877\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 2.1793 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.74877\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 2.3306 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.74877\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 2.2252 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.74877\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 2.2241 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.74877\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0198 - accuracy: 0.9921 - val_loss: 2.1467 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.74877\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0543 - accuracy: 0.9842 - val_loss: 2.6509 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.74877\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 2.1855 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.74877\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0185 - accuracy: 0.9915 - val_loss: 1.7990 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.74877\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 1.8173 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.74877\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0212 - accuracy: 0.9963 - val_loss: 1.9821 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.74877\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 2.0303 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.74877\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 2.0279 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.74877\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 1.8388 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.74877\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0347 - accuracy: 0.9921 - val_loss: 1.8749 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.74877\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 1.5986 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.74877\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 1.6218 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.74877\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 1.8851 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.74877\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 1.9210 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.74877\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 1.8632 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.74877\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 1.8163 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.74877\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 2.0459 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.74877\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0282 - accuracy: 0.9945 - val_loss: 2.0464 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.74877\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 2.0118 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.74877\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0332 - accuracy: 0.9866 - val_loss: 2.1155 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.74877\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0462 - accuracy: 0.9866 - val_loss: 2.0262 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.74877\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 1.9729 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.74877\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 2.0809 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.74877\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 2.4686 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.74877\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 2.1682 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.74877\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 2.1899 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.74877\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 1.9529 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.74877\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 1.7876 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.74877\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 1.9145 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.74877\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0112 - accuracy: 0.9945 - val_loss: 2.0614 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.74877\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 1.7971 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.74877\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0333 - accuracy: 0.9866 - val_loss: 2.2750 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.74877\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 2.0670 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.74877\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0220 - accuracy: 0.9909 - val_loss: 1.8746 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.74877\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 1.8675 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.74877\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 2.1373 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.74877\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 1.8535 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.74877\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0954 - accuracy: 0.9756 - val_loss: 3.1574 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.74877\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 2.3600 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.74877\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 2.3658 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.74877\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 1.8781 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.74877\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0315 - accuracy: 0.9951 - val_loss: 2.2767 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.74877\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 2.1455 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.74877\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 2.4018 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.74877\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 1.8480 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.74877\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 1.7554 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.74877\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 1.9137 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.74877\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 2.1042 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.74877\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.9931 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.74877\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 1.9860 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.74877\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 2.1129 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.74877\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 2.1936 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.74877\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 1.9257 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.74877\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0357 - accuracy: 0.9927 - val_loss: 2.5166 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.74877\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0547 - accuracy: 0.9866 - val_loss: 2.5725 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.74877\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 2.6184 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.74877\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 2.3348 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.74877\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 2.1707 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.74877\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 1.9952 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.74877\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 2.0397 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.74877\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 2.0066 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.74877\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 1.9598 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.74877\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 2.0843 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.74877\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 1.9939 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.74877\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.8833 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.74877\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0097 - accuracy: 0.9951 - val_loss: 1.6639 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.74877\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 1.7819 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.74877\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 2.6022 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.74877\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 1.9195 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.74877\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 1.7480 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.74877\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 2.4950 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.74877\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 2.1625 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.74877\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 2.0671 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.74877\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0244 - accuracy: 0.9951 - val_loss: 2.0896 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.74877\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 2.2488 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.74877\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 2.3299 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.74877\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 2.1562 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.74877\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0489 - accuracy: 0.9890 - val_loss: 2.9236 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.74877\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 2.3834 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.74877\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0304 - accuracy: 0.9921 - val_loss: 2.1161 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.74877\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 1.8479 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.74877\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 1.8456 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.74877\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 1.9028 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.74877\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 1.6905 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.74877\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 1.8417 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.74877\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 1.7566 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.74877\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 1.5930 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00477: val_accuracy improved from 0.74877 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 1.8051 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.76601\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 1.9782 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.76601\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 1.7796 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.76601\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0453 - accuracy: 0.9903 - val_loss: 2.2797 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.76601\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 1.9487 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.76601\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 1.7740 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.76601\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 2.3832 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.76601\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 2.4066 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.76601\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 2.3489 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.76601\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.8775 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.76601\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 2.1022 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.76601\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 2.2714 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.76601\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 2.3311 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.76601\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 2.4427 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.76601\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 2.1418 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.76601\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 2.1894 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.76601\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 1.8526 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.76601\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 1.8057 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.76601\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 1.9147 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.76601\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.7183 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.76601\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0128 - accuracy: 0.9945 - val_loss: 1.8900 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.76601\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 1.8515 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.76601\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.7056 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.76601\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f309a61d690>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "19f07802-1f6f-4cc2-f906-84340c94f8bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_1_DN121.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(32,32), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a66916-c51f-4028-a3ee-518ca8d5385b"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6be9b20c-e97d-4cd0-b96a-f619351a8ef5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_32_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_32_1_DenseNet121_model.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_05799785-0f75-4d4c-b5ad-0dcf29e7401a\", \"ImageSize_32_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_05799785-0f75-4d4c-b5ad-0dcf29e7401a\", \"ImageSize_32_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}