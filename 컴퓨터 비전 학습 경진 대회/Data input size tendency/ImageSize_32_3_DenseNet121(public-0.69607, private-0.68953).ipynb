{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSize_32_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3+vLpP7GAnkDtjn+aQeEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ImageSize_32_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283e0125-2387-4da3-f4d7-e3e174e36484"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 21:51:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038e28aa-acae-4c54-85e9-313ddbe44d84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(32, 32, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d1f8ad-3e40-413c-b7ec-b7c12d7cf156"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vb-b5ho4ftu"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790c780d-06e9-45d6-f86a-bde5699205e4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(32,32), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(32,32), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3023fa7b-984e-457f-9f42-2dd95fd83f5a"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 35s 154ms/step - loss: 2.4008 - accuracy: 0.1772 - val_loss: 2.3888 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 2.0675 - accuracy: 0.2698 - val_loss: 3.0518 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09852\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 1.9035 - accuracy: 0.3691 - val_loss: 2.4363 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09852\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 1.8046 - accuracy: 0.3928 - val_loss: 6.6602 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.09852\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 1.6419 - accuracy: 0.4452 - val_loss: 5.2936 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.09852\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 1.6174 - accuracy: 0.4927 - val_loss: 5.3033 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.09852\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 1.4502 - accuracy: 0.5256 - val_loss: 3.8368 - val_accuracy: 0.0837\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.09852\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 1.3086 - accuracy: 0.5609 - val_loss: 4.4490 - val_accuracy: 0.1182\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.09852 to 0.11823, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 1.2295 - accuracy: 0.5981 - val_loss: 4.4098 - val_accuracy: 0.1700\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.11823 to 0.16995, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 1.2224 - accuracy: 0.5907 - val_loss: 4.4102 - val_accuracy: 0.2463\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.16995 to 0.24631, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 1.1094 - accuracy: 0.6218 - val_loss: 3.4872 - val_accuracy: 0.3424\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.24631 to 0.34236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 1.1118 - accuracy: 0.6212 - val_loss: 2.3014 - val_accuracy: 0.4384\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.34236 to 0.43842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 1.1071 - accuracy: 0.6248 - val_loss: 2.5187 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.43842\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.9734 - accuracy: 0.6602 - val_loss: 1.7276 - val_accuracy: 0.4729\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.43842 to 0.47291, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.9457 - accuracy: 0.6900 - val_loss: 2.3602 - val_accuracy: 0.4261\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.47291\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.8957 - accuracy: 0.7138 - val_loss: 4.4394 - val_accuracy: 0.2512\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.47291\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.9888 - accuracy: 0.6638 - val_loss: 1.9743 - val_accuracy: 0.4433\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.47291\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.7789 - accuracy: 0.7418 - val_loss: 1.5613 - val_accuracy: 0.5099\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.47291 to 0.50985, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.8096 - accuracy: 0.7302 - val_loss: 1.3719 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.50985 to 0.59113, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.7017 - accuracy: 0.7546 - val_loss: 1.6402 - val_accuracy: 0.5419\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.59113\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.7068 - accuracy: 0.7558 - val_loss: 1.5380 - val_accuracy: 0.5493\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.59113\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.6521 - accuracy: 0.7765 - val_loss: 1.6603 - val_accuracy: 0.5517\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.59113\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.6793 - accuracy: 0.7667 - val_loss: 1.9743 - val_accuracy: 0.4852\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.59113\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.6111 - accuracy: 0.7893 - val_loss: 1.6108 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.59113\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5632 - accuracy: 0.8045 - val_loss: 1.5843 - val_accuracy: 0.5271\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.59113\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.5817 - accuracy: 0.8069 - val_loss: 1.6275 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59113\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5554 - accuracy: 0.7990 - val_loss: 1.3893 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.59113 to 0.62315, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5837 - accuracy: 0.7978 - val_loss: 2.0331 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.62315\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.5385 - accuracy: 0.8185 - val_loss: 1.8717 - val_accuracy: 0.5419\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.62315\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.5050 - accuracy: 0.8228 - val_loss: 1.2326 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.62315\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4986 - accuracy: 0.8246 - val_loss: 1.4643 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.62315\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.5254 - accuracy: 0.8130 - val_loss: 1.6057 - val_accuracy: 0.5419\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.62315\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4642 - accuracy: 0.8368 - val_loss: 1.4745 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.62315\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4311 - accuracy: 0.8502 - val_loss: 1.3872 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.62315\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.4216 - accuracy: 0.8514 - val_loss: 1.6267 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.62315\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.3519 - accuracy: 0.8819 - val_loss: 1.5024 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.62315\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4018 - accuracy: 0.8624 - val_loss: 1.5863 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.62315\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.4240 - accuracy: 0.8544 - val_loss: 1.8652 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.62315\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.3103 - accuracy: 0.8910 - val_loss: 1.6025 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.62315\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3696 - accuracy: 0.8867 - val_loss: 1.4792 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.62315 to 0.65271, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.3553 - accuracy: 0.8758 - val_loss: 2.0909 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.65271\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.3373 - accuracy: 0.8764 - val_loss: 1.6910 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.65271\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.3183 - accuracy: 0.8886 - val_loss: 1.6935 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.65271\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3391 - accuracy: 0.8788 - val_loss: 2.0827 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.65271\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.3132 - accuracy: 0.8922 - val_loss: 2.6361 - val_accuracy: 0.4557\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.65271\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3417 - accuracy: 0.8837 - val_loss: 1.9175 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.65271\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3237 - accuracy: 0.8892 - val_loss: 1.8478 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.65271\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3035 - accuracy: 0.8922 - val_loss: 1.7239 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.65271\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2483 - accuracy: 0.9239 - val_loss: 1.5113 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.65271\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2415 - accuracy: 0.9214 - val_loss: 1.5328 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.65271\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.3241 - accuracy: 0.8886 - val_loss: 1.8502 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.65271\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3112 - accuracy: 0.8977 - val_loss: 1.9909 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.65271\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2242 - accuracy: 0.9214 - val_loss: 2.1699 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.65271\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2814 - accuracy: 0.9056 - val_loss: 1.7559 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.65271\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2483 - accuracy: 0.9227 - val_loss: 1.6527 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.65271\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2221 - accuracy: 0.9227 - val_loss: 1.7432 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.65271\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2925 - accuracy: 0.9038 - val_loss: 1.6038 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.65271\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2617 - accuracy: 0.9038 - val_loss: 1.9659 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.65271\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2427 - accuracy: 0.9263 - val_loss: 1.6857 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.65271\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2318 - accuracy: 0.9202 - val_loss: 1.7776 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.65271\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1962 - accuracy: 0.9306 - val_loss: 2.1511 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.65271\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1708 - accuracy: 0.9354 - val_loss: 1.7237 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.65271\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 4s 73ms/step - loss: 0.1940 - accuracy: 0.9306 - val_loss: 1.6176 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.65271\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2243 - accuracy: 0.9202 - val_loss: 1.5362 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.65271\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1940 - accuracy: 0.9342 - val_loss: 1.6471 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.65271\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3541 - accuracy: 0.8959 - val_loss: 3.6666 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.65271\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.2929 - accuracy: 0.8971 - val_loss: 2.1357 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.65271\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.3238 - accuracy: 0.8971 - val_loss: 1.7138 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.65271\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.2011 - accuracy: 0.9367 - val_loss: 1.6298 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.65271\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1470 - accuracy: 0.9525 - val_loss: 1.5992 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.65271\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1235 - accuracy: 0.9568 - val_loss: 2.0164 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.65271\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1378 - accuracy: 0.9525 - val_loss: 1.5661 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.65271\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2114 - accuracy: 0.9342 - val_loss: 1.9281 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.65271 to 0.65764, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2698 - accuracy: 0.9074 - val_loss: 2.1701 - val_accuracy: 0.5296\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.65764\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.2699 - accuracy: 0.9050 - val_loss: 2.1687 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.65764\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1970 - accuracy: 0.9446 - val_loss: 1.5535 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.65764\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1360 - accuracy: 0.9562 - val_loss: 1.4489 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.65764\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1289 - accuracy: 0.9537 - val_loss: 1.6333 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.65764\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1512 - accuracy: 0.9452 - val_loss: 1.7627 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.65764\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.1331 - accuracy: 0.9568 - val_loss: 1.6779 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00080: val_accuracy improved from 0.65764 to 0.66995, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1155 - accuracy: 0.9562 - val_loss: 1.4325 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.66995 to 0.70443, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0892 - accuracy: 0.9695 - val_loss: 1.4303 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.70443\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0941 - accuracy: 0.9671 - val_loss: 1.4564 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.70443 to 0.71675, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1059 - accuracy: 0.9641 - val_loss: 1.7757 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.71675\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.1439 - accuracy: 0.9513 - val_loss: 1.8255 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.71675\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1419 - accuracy: 0.9519 - val_loss: 2.0560 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.71675\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1853 - accuracy: 0.9464 - val_loss: 2.0483 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.71675\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1965 - accuracy: 0.9379 - val_loss: 2.4128 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.71675\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1459 - accuracy: 0.9574 - val_loss: 1.6992 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.71675\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1193 - accuracy: 0.9598 - val_loss: 1.6826 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.71675\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1349 - accuracy: 0.9580 - val_loss: 2.1825 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.71675\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1336 - accuracy: 0.9543 - val_loss: 1.8485 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.71675\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1015 - accuracy: 0.9659 - val_loss: 2.0348 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.71675\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 1.7181 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.71675\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0906 - accuracy: 0.9714 - val_loss: 2.0320 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.71675\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1231 - accuracy: 0.9574 - val_loss: 2.1921 - val_accuracy: 0.5788\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.71675\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1413 - accuracy: 0.9488 - val_loss: 2.6744 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.71675\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2028 - accuracy: 0.9348 - val_loss: 1.7143 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.71675\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1826 - accuracy: 0.9415 - val_loss: 1.8978 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.71675\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1944 - accuracy: 0.9348 - val_loss: 2.3297 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.71675\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1335 - accuracy: 0.9531 - val_loss: 1.6784 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.71675\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1008 - accuracy: 0.9653 - val_loss: 1.5130 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.71675\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 4s 74ms/step - loss: 0.0937 - accuracy: 0.9702 - val_loss: 1.7669 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.71675\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1300 - accuracy: 0.9501 - val_loss: 2.1201 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.71675\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1088 - accuracy: 0.9647 - val_loss: 1.5194 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.71675\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1217 - accuracy: 0.9592 - val_loss: 1.8013 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.71675\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1401 - accuracy: 0.9513 - val_loss: 1.8057 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.71675\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1028 - accuracy: 0.9683 - val_loss: 1.5780 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.71675\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1252 - accuracy: 0.9610 - val_loss: 1.5388 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.71675\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0890 - accuracy: 0.9689 - val_loss: 1.7028 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.71675\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1728 - accuracy: 0.9470 - val_loss: 5.3338 - val_accuracy: 0.4163\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.71675\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2264 - accuracy: 0.9379 - val_loss: 2.1938 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.71675\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1486 - accuracy: 0.9525 - val_loss: 1.4297 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.71675\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1130 - accuracy: 0.9635 - val_loss: 1.6808 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.71675\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 1.3519 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.71675\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0945 - accuracy: 0.9702 - val_loss: 1.4411 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.71675\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1274 - accuracy: 0.9641 - val_loss: 1.8542 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.71675\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1085 - accuracy: 0.9604 - val_loss: 2.0305 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.71675\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1036 - accuracy: 0.9629 - val_loss: 2.0189 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.71675\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1426 - accuracy: 0.9598 - val_loss: 1.9677 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.71675\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1904 - accuracy: 0.9434 - val_loss: 2.4853 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.71675\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1081 - accuracy: 0.9659 - val_loss: 1.6773 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.71675\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0806 - accuracy: 0.9732 - val_loss: 1.7412 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.71675\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 1.5686 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.71675\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 1.4720 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.71675\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 1.4448 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.71675\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0435 - accuracy: 0.9842 - val_loss: 1.7747 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.71675\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.2767 - accuracy: 0.9160 - val_loss: 2.4414 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.71675\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.2314 - accuracy: 0.9263 - val_loss: 1.9791 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.71675\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1395 - accuracy: 0.9555 - val_loss: 2.0460 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.71675\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.1146 - accuracy: 0.9568 - val_loss: 1.7369 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.71675\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1203 - accuracy: 0.9562 - val_loss: 1.6405 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.71675\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 1.9128 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.71675\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 1.6302 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.71675\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 1.4832 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.71675\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 1.8634 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.71675\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1036 - accuracy: 0.9708 - val_loss: 1.8865 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.71675\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 1.4610 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.71675\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 1.5066 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.71675\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 1.7607 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.71675\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 1.5578 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.71675\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0909 - accuracy: 0.9653 - val_loss: 1.9187 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.71675\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0929 - accuracy: 0.9714 - val_loss: 2.8765 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.71675\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 2.1222 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.71675\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0923 - accuracy: 0.9708 - val_loss: 1.7128 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.71675\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 1.9976 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.71675\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 1.7066 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.71675\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0583 - accuracy: 0.9769 - val_loss: 1.7953 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.71675\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 2.3401 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.71675\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 4s 75ms/step - loss: 0.1118 - accuracy: 0.9635 - val_loss: 2.3149 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.71675\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1107 - accuracy: 0.9592 - val_loss: 2.0455 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.71675\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1333 - accuracy: 0.9604 - val_loss: 2.2452 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.71675\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1031 - accuracy: 0.9671 - val_loss: 1.9767 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.71675\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0751 - accuracy: 0.9805 - val_loss: 1.8938 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.71675\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0606 - accuracy: 0.9829 - val_loss: 1.6499 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.71675\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 1.4884 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.71675\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0774 - accuracy: 0.9793 - val_loss: 1.5592 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.71675\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 2.0216 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.71675\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 1.7794 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.71675\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0942 - accuracy: 0.9683 - val_loss: 1.9456 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.71675\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0570 - accuracy: 0.9769 - val_loss: 1.7789 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.71675\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 1.7604 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.71675\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0774 - accuracy: 0.9775 - val_loss: 2.2276 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.71675\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0767 - accuracy: 0.9744 - val_loss: 2.0849 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.71675\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0584 - accuracy: 0.9781 - val_loss: 1.8353 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.71675\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0492 - accuracy: 0.9829 - val_loss: 2.0357 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.71675\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0650 - accuracy: 0.9799 - val_loss: 1.9213 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.71675\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0785 - accuracy: 0.9714 - val_loss: 2.2915 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.71675\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1594 - accuracy: 0.9555 - val_loss: 2.3939 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.71675\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.2253 - accuracy: 0.9312 - val_loss: 2.3856 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.71675\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.1132 - accuracy: 0.9629 - val_loss: 1.9672 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.71675\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0926 - accuracy: 0.9726 - val_loss: 1.6375 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.71675\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0417 - accuracy: 0.9836 - val_loss: 1.7887 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.71675\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 1.6256 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.71675\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 1.6414 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.71675\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0347 - accuracy: 0.9909 - val_loss: 1.5539 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.71675\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 1.6819 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.71675\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 1.9775 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.71675\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 1.6911 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.71675\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 1.9472 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.71675\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 1.6381 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.71675\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 1.9778 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.71675\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0604 - accuracy: 0.9787 - val_loss: 2.2091 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.71675\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0729 - accuracy: 0.9738 - val_loss: 2.4811 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.71675\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 1.8132 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.71675\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0390 - accuracy: 0.9860 - val_loss: 1.7823 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.71675\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 1.8644 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.71675\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0515 - accuracy: 0.9829 - val_loss: 1.9640 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.71675\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0500 - accuracy: 0.9805 - val_loss: 1.8449 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.71675\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 2.1096 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.71675\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.1047 - accuracy: 0.9708 - val_loss: 1.9894 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.71675\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0963 - accuracy: 0.9708 - val_loss: 1.8557 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.71675\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.1305 - accuracy: 0.9543 - val_loss: 1.9922 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.71675\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 1.9084 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.71675\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0519 - accuracy: 0.9769 - val_loss: 1.8049 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.71675\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 1.9711 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.71675\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0718 - accuracy: 0.9756 - val_loss: 2.1436 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.71675\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0591 - accuracy: 0.9787 - val_loss: 1.9641 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.71675\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 1.7562 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.71675\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 1.6160 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.71675\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 1.7907 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.71675\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0667 - accuracy: 0.9829 - val_loss: 1.7240 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.71675\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 1.8696 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.71675\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 2.1821 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.71675\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 2.0799 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.71675\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 1.9838 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.71675\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 1.8374 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.71675\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0467 - accuracy: 0.9823 - val_loss: 1.6246 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.71675\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0683 - accuracy: 0.9775 - val_loss: 2.1305 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.71675\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0703 - accuracy: 0.9756 - val_loss: 1.8626 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.71675\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 1.8421 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.71675\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0497 - accuracy: 0.9793 - val_loss: 1.5386 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00212: val_accuracy improved from 0.71675 to 0.71921, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 1.7100 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.71921\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 1.6529 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.71921\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0267 - accuracy: 0.9872 - val_loss: 1.7840 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.71921\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 1.6817 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.71921\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 1.6707 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.71921\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0754 - accuracy: 0.9775 - val_loss: 2.2120 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.71921\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 4s 76ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 1.8049 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.71921\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0509 - accuracy: 0.9866 - val_loss: 1.8724 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.71921\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 2.1165 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.71921\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0767 - accuracy: 0.9756 - val_loss: 2.2382 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.71921\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1047 - accuracy: 0.9702 - val_loss: 2.2135 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.71921\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0602 - accuracy: 0.9775 - val_loss: 2.3054 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.71921\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0512 - accuracy: 0.9872 - val_loss: 1.9231 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00225: val_accuracy improved from 0.71921 to 0.72660, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0666 - accuracy: 0.9787 - val_loss: 2.0745 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.72660\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0478 - accuracy: 0.9860 - val_loss: 2.9722 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.72660\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 1.9919 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.72660\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 2.1921 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.72660\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 1.9117 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.72660\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0419 - accuracy: 0.9823 - val_loss: 1.9843 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.72660\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 2.0591 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.72660\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 2.2902 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.72660\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 1.7228 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.72660\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0383 - accuracy: 0.9903 - val_loss: 2.1447 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.72660\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0377 - accuracy: 0.9896 - val_loss: 2.1220 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.72660\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0563 - accuracy: 0.9781 - val_loss: 2.8692 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.72660\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.1214 - accuracy: 0.9665 - val_loss: 2.9493 - val_accuracy: 0.5517\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.72660\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0951 - accuracy: 0.9677 - val_loss: 2.0914 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.72660\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 1.9874 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.72660\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0437 - accuracy: 0.9836 - val_loss: 1.7905 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.72660\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 1.9577 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.72660\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0381 - accuracy: 0.9860 - val_loss: 1.7703 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.72660\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 1.8244 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.72660\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 1.7276 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.72660\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 1.6867 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.72660\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 2.1300 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.72660\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 2.0795 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.72660\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0532 - accuracy: 0.9823 - val_loss: 2.0995 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.72660\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 1.7923 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.72660\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 1.8706 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.72660\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0188 - accuracy: 0.9915 - val_loss: 1.6527 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.72660\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 1.8866 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.72660\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 1.9036 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.72660\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 1.9263 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.72660\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 2.0645 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.72660\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 2.6594 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.72660\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0937 - accuracy: 0.9769 - val_loss: 2.1751 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.72660\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0603 - accuracy: 0.9854 - val_loss: 1.9239 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.72660\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.1066 - accuracy: 0.9708 - val_loss: 1.8758 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.72660\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0525 - accuracy: 0.9823 - val_loss: 2.1194 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.72660\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 1.7557 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.72660\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 1.9191 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.72660\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 1.8742 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.72660\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 1.8477 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.72660\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0664 - accuracy: 0.9756 - val_loss: 2.3122 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.72660\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0629 - accuracy: 0.9836 - val_loss: 2.4904 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.72660\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0663 - accuracy: 0.9787 - val_loss: 2.2392 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.72660\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 1.7668 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.72660\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0267 - accuracy: 0.9890 - val_loss: 1.9534 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.72660\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 1.6092 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.72660\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 1.6298 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.72660\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 1.8933 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.72660\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 1.7101 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.72660\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 1.7719 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.72660\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 1.8448 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.72660\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 1.8692 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.72660\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 2.0252 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.72660\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 1.8645 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.72660\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 1.8788 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.72660\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 4s 78ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.7664 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.72660\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.7779 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.72660\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0365 - accuracy: 0.9866 - val_loss: 2.2002 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.72660\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0524 - accuracy: 0.9860 - val_loss: 2.1538 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.72660\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 4s 77ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 2.1480 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.72660\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 2.4200 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.72660\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 2.2101 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.72660\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 1.8771 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.72660\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 2.1687 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.72660\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 1.9782 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.72660\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 1.9065 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.72660\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 2.0727 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.72660\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 2.5906 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.72660\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 2.0807 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.72660\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 2.2369 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.72660\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0493 - accuracy: 0.9860 - val_loss: 2.0271 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.72660\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0794 - accuracy: 0.9732 - val_loss: 2.1974 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.72660\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 2.1760 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.72660\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 1.8428 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.72660\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 2.1773 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.72660\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0674 - accuracy: 0.9793 - val_loss: 1.9549 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.72660\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0318 - accuracy: 0.9860 - val_loss: 1.9198 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.72660\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0334 - accuracy: 0.9860 - val_loss: 1.8981 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.72660\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0428 - accuracy: 0.9903 - val_loss: 2.0777 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.72660\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 2.0919 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.72660\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 2.0709 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.72660\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 1.9621 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.72660\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.7533 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.72660\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 1.7260 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.72660\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0335 - accuracy: 0.9909 - val_loss: 1.5722 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.72660\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 1.7901 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.72660\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 1.7157 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.72660\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 2.5541 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.72660\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 2.0560 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.72660\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 1.8662 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.72660\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 2.1209 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.72660\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 2.0494 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.72660\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 2.2155 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.72660\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 2.3650 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.72660\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0864 - accuracy: 0.9781 - val_loss: 2.9463 - val_accuracy: 0.5542\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.72660\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.1001 - accuracy: 0.9689 - val_loss: 2.7996 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.72660\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.1208 - accuracy: 0.9653 - val_loss: 2.9961 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.72660\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 2.3267 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.72660\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0368 - accuracy: 0.9848 - val_loss: 2.1697 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.72660\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0265 - accuracy: 0.9890 - val_loss: 2.0056 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.72660\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 2.0197 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.72660\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0797 - accuracy: 0.9750 - val_loss: 1.9855 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.72660\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 1.7376 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.72660\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 1.7678 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.72660\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 2.3032 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.72660\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 2.0646 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.72660\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 1.5415 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.72660\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 1.7528 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.72660\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.7083 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.72660\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 1.8004 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.72660\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 2.0138 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.72660\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 1.9775 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.72660\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 1.6656 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.72660\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 2.1073 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.72660\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 1.9097 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.72660\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.8375 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.72660\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 1.7913 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.72660\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 2.0193 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.72660\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 2.1909 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.72660\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 2.2483 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.72660\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 1.9496 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.72660\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0747 - accuracy: 0.9811 - val_loss: 3.2065 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.72660\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0539 - accuracy: 0.9805 - val_loss: 2.4511 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.72660\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0373 - accuracy: 0.9866 - val_loss: 2.1514 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.72660\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 4s 79ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 2.2433 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.72660\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0435 - accuracy: 0.9872 - val_loss: 2.3287 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.72660\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 2.2776 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.72660\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 2.0536 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.72660\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0466 - accuracy: 0.9829 - val_loss: 2.3138 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.72660\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0368 - accuracy: 0.9860 - val_loss: 2.1392 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.72660\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 2.1691 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.72660\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 1.9061 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.72660\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 1.8084 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.72660\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0157 - accuracy: 0.9933 - val_loss: 1.7773 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00359: val_accuracy improved from 0.72660 to 0.72906, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 2.0559 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.72906\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 1.8941 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.72906\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 1.8368 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.72906\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0282 - accuracy: 0.9951 - val_loss: 2.0034 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.72906\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 2.0607 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.72906\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0145 - accuracy: 0.9933 - val_loss: 1.9873 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.72906\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 1.8532 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.72906\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.9469 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.72906\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 2.4204 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.72906\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0416 - accuracy: 0.9896 - val_loss: 2.1524 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.72906\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 2.1840 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.72906\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0327 - accuracy: 0.9854 - val_loss: 2.5036 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.72906\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 2.6700 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.72906\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 1.9973 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.72906\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 2.0842 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.72906\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 1.7560 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.72906\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0216 - accuracy: 0.9909 - val_loss: 2.1977 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.72906\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0377 - accuracy: 0.9890 - val_loss: 2.1935 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.72906\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 2.5326 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.72906\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 2.1232 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.72906\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0458 - accuracy: 0.9884 - val_loss: 2.3348 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.72906\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 2.2425 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.72906\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 2.0699 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.72906\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 2.1202 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.72906\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 1.9160 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.72906\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0453 - accuracy: 0.9890 - val_loss: 2.2701 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.72906\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0525 - accuracy: 0.9842 - val_loss: 2.2272 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.72906\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0369 - accuracy: 0.9903 - val_loss: 2.2100 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.72906\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0159 - accuracy: 0.9933 - val_loss: 1.8932 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.72906\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 1.8324 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.72906\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.8662 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.72906\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 2.0182 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.72906\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 1.7134 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.72906\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 2.2501 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.72906\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 2.2419 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.72906\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 2.0334 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.72906\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.8429 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.72906\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 2.8008 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.72906\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0766 - accuracy: 0.9811 - val_loss: 2.9913 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.72906\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 2.4855 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.72906\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 2.2499 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.72906\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 2.2495 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.72906\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0327 - accuracy: 0.9909 - val_loss: 2.0488 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.72906\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 2.1114 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.72906\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 1.9699 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.72906\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 2.0852 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.72906\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 1.9469 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.72906\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 2.4375 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.72906\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 2.0748 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.72906\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 1.7766 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.72906\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 4s 81ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 1.9965 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.72906\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 4s 80ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 1.9260 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.72906\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 2.1506 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.72906\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0397 - accuracy: 0.9909 - val_loss: 3.3732 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.72906\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 2.2160 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.72906\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 1.9982 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.72906\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 2.5251 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.72906\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 2.1484 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.72906\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 1.8808 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.72906\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 2.0023 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.72906\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 1.8623 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.72906\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 1.8706 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.72906\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 2.4338 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.72906\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 2.5475 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.72906\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0502 - accuracy: 0.9848 - val_loss: 2.5605 - val_accuracy: 0.6478\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.72906\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 2.4045 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.72906\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0587 - accuracy: 0.9823 - val_loss: 2.3531 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.72906\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 2.4006 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.72906\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 2.0687 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.72906\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 2.0902 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.72906\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 1.9758 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.72906\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0547 - accuracy: 0.9872 - val_loss: 1.9925 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.72906\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 2.1449 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.72906\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0290 - accuracy: 0.9896 - val_loss: 1.7262 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.72906\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0125 - accuracy: 0.9945 - val_loss: 1.9545 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.72906\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 2.1161 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.72906\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 1.9193 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.72906\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 4s 82ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.9853 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.72906\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 2.0178 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.72906\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 2.1585 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.72906\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 1.8276 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.72906\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 1.8785 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.72906\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 2.3640 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.72906\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.8594 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.72906\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0178 - accuracy: 0.9909 - val_loss: 1.8530 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.72906\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 2.0025 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.72906\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 1.9654 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.72906\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0095 - accuracy: 0.9957 - val_loss: 2.0139 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.72906\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 1.9049 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.72906\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0419 - accuracy: 0.9909 - val_loss: 2.3274 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.72906\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 2.1051 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.72906\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 2.2416 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.72906\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 2.3126 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.72906\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 2.3561 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.72906\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 2.5107 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.72906\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 2.1984 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.72906\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 2.4620 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.72906\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0437 - accuracy: 0.9829 - val_loss: 2.2939 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.72906\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 1.8615 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.72906\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 2.1379 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.72906\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0158 - accuracy: 0.9933 - val_loss: 1.9755 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.72906\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 2.0413 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.72906\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 2.2221 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.72906\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 5s 88ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 2.0597 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.72906\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 1.8410 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.72906\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 1.9544 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.72906\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 1.8137 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.72906\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 1.9554 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.72906\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 2.1314 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.72906\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 2.1380 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.72906\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0343 - accuracy: 0.9933 - val_loss: 2.1463 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.72906\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0162 - accuracy: 0.9927 - val_loss: 2.1508 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.72906\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 2.0762 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.72906\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 2.4853 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.72906\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 2.0594 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.72906\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 2.3335 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.72906\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 2.5169 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.72906\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 4s 83ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 2.1180 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.72906\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0268 - accuracy: 0.9951 - val_loss: 2.0731 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.72906\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 2.2679 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.72906\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 2.2688 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.72906\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 2.6187 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.72906\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 2.2746 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.72906\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 1.8920 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.72906\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 2.0541 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.72906\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 1.9172 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.72906\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 2.1154 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.72906\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 5s 87ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 2.0234 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.72906\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.9765 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.72906\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 2.2188 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.72906\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 3.4089 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.72906\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 4s 84ms/step - loss: 0.0308 - accuracy: 0.9872 - val_loss: 2.6871 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.72906\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 2.3455 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.72906\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0344 - accuracy: 0.9860 - val_loss: 2.0729 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.72906\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 1.9506 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.72906\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 4s 87ms/step - loss: 0.0309 - accuracy: 0.9884 - val_loss: 1.9988 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.72906\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 4s 86ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 1.9516 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.72906\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 5s 89ms/step - loss: 0.0198 - accuracy: 0.9921 - val_loss: 2.0944 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.72906\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 2.5523 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.72906\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 5s 91ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 2.2874 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.72906\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 4s 85ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 1.9395 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.72906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f9c03ef10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "529934b5-7362-4921-c6af-a2d9d9bf0e7a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/IS_32_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398a0e66-0657-4ad2-98c0-93c1b470037e"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(32,32), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08eff86-063f-49c3-de44-52e02963f732"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4660366a-c5ec-4c0b-9bb4-1b755f8db9a5"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      3"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d915dbaf-3771-4e98-dbfb-4e4262ca0cbe"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_32_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/ImageSize_32_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_65306abd-d49c-4e96-9b69-13435bea3c9b\", \"ImageSize_32_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}