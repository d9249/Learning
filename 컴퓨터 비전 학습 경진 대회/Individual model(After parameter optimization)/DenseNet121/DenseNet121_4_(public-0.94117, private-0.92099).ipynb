{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet121_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86896906-946a-479b-bcf1-f64c3c0e4289"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 27 20:06:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0dae83-5879-4c50-caed-adf06c479223"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet121_4'\n",
        "Target_model = 'DenseNet121_model'\n",
        "Target_predict = 'DenseNet121_predict'\n",
        "Target_acc = 'DenseNet121_acc'\n",
        "Target_val = 'DenseNet121_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75577cc8-dbe6-4584-df21-e36dbda6fffa"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d82012a-c578-40ad-bc0e-eee02b4b53a3"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 40s 73ms/step - loss: 1.9441 - accuracy: 0.3705 - val_loss: 4.7272 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 1.1481 - accuracy: 0.6289 - val_loss: 4.9097 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09459 to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.8694 - accuracy: 0.7058 - val_loss: 1.4345 - val_accuracy: 0.5878\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.58784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.7834 - accuracy: 0.7521 - val_loss: 0.8812 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.58784 to 0.69595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.6490 - accuracy: 0.7837 - val_loss: 1.2149 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.69595\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 0.7750 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.69595 to 0.75000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.5329 - accuracy: 0.8295 - val_loss: 1.2813 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.75000 to 0.75676, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.5464 - accuracy: 0.8263 - val_loss: 0.9290 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.75676 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.4889 - accuracy: 0.8379 - val_loss: 0.5813 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.81081 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.4200 - accuracy: 0.8642 - val_loss: 0.4665 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.81757 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.4327 - accuracy: 0.8626 - val_loss: 0.5704 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.82432 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3653 - accuracy: 0.8763 - val_loss: 0.5091 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83108\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3765 - accuracy: 0.8753 - val_loss: 0.5305 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.83108 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3773 - accuracy: 0.8732 - val_loss: 0.9285 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83784\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3469 - accuracy: 0.8874 - val_loss: 0.8685 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.83784\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3367 - accuracy: 0.8968 - val_loss: 0.6558 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.83784\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3159 - accuracy: 0.8974 - val_loss: 0.6354 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.83784\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2880 - accuracy: 0.8989 - val_loss: 0.7647 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.83784\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2623 - accuracy: 0.9153 - val_loss: 0.9582 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.83784\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3098 - accuracy: 0.9026 - val_loss: 0.5950 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83784\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3243 - accuracy: 0.8911 - val_loss: 0.4941 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.83784 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.2614 - accuracy: 0.9121 - val_loss: 0.3950 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.84459 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.2077 - accuracy: 0.9274 - val_loss: 0.4048 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88514\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2586 - accuracy: 0.9184 - val_loss: 0.5816 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88514\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.2156 - accuracy: 0.9242 - val_loss: 0.5575 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88514\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2188 - accuracy: 0.9258 - val_loss: 2.5171 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88514\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2306 - accuracy: 0.9221 - val_loss: 0.5293 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88514\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2628 - accuracy: 0.9195 - val_loss: 0.7581 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88514\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1510 - accuracy: 0.9547 - val_loss: 0.7894 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88514\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1757 - accuracy: 0.9442 - val_loss: 0.4796 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88514\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.2405 - accuracy: 0.9179 - val_loss: 0.6154 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88514\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2144 - accuracy: 0.9284 - val_loss: 0.4075 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88514\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1655 - accuracy: 0.9458 - val_loss: 0.5143 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88514\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1383 - accuracy: 0.9589 - val_loss: 0.4081 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88514\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1714 - accuracy: 0.9442 - val_loss: 0.5098 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88514\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1476 - accuracy: 0.9505 - val_loss: 0.5351 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88514\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1323 - accuracy: 0.9579 - val_loss: 0.5154 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.88514 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.1406 - accuracy: 0.9553 - val_loss: 0.4332 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89865\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1874 - accuracy: 0.9405 - val_loss: 0.6496 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89865\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1260 - accuracy: 0.9600 - val_loss: 0.3384 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89865\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1629 - accuracy: 0.9474 - val_loss: 0.5195 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89865\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1175 - accuracy: 0.9574 - val_loss: 0.3923 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89865\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1327 - accuracy: 0.9521 - val_loss: 0.4206 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89865\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1269 - accuracy: 0.9532 - val_loss: 0.3106 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.89865 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0993 - accuracy: 0.9689 - val_loss: 0.3865 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91892\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1629 - accuracy: 0.9474 - val_loss: 0.4161 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91892\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1065 - accuracy: 0.9658 - val_loss: 0.3929 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91892\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1111 - accuracy: 0.9663 - val_loss: 0.4411 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91892\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1186 - accuracy: 0.9642 - val_loss: 0.4112 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91892\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0858 - accuracy: 0.9695 - val_loss: 0.5885 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91892\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 0.3484 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91892\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.1009 - accuracy: 0.9653 - val_loss: 0.2860 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91892\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1160 - accuracy: 0.9621 - val_loss: 0.8734 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91892\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1056 - accuracy: 0.9668 - val_loss: 0.4261 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 0.3679 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0483 - accuracy: 0.9868 - val_loss: 0.3583 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1016 - accuracy: 0.9663 - val_loss: 0.4828 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1005 - accuracy: 0.9705 - val_loss: 0.6793 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0890 - accuracy: 0.9684 - val_loss: 0.4170 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.3974 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.4798 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0761 - accuracy: 0.9747 - val_loss: 0.7462 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1161 - accuracy: 0.9658 - val_loss: 0.3528 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0453 - accuracy: 0.9879 - val_loss: 0.4642 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0623 - accuracy: 0.9789 - val_loss: 0.5208 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0937 - accuracy: 0.9732 - val_loss: 0.4969 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91892\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0754 - accuracy: 0.9732 - val_loss: 0.4219 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91892\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.4258 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91892\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1273 - accuracy: 0.9621 - val_loss: 0.2922 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00069: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0413 - accuracy: 0.9921 - val_loss: 0.3184 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.2872 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.5446 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0778 - accuracy: 0.9774 - val_loss: 0.4339 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.4233 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 0.4493 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.3728 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0786 - accuracy: 0.9763 - val_loss: 0.4050 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.4363 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.3578 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0398 - accuracy: 0.9847 - val_loss: 0.5054 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.9450 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 0.5457 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.3282 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.7877 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.5864 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.4665 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.3442 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.5144 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.8231 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.4437 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.7473 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1006 - accuracy: 0.9700 - val_loss: 0.5425 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.4107 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.3468 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.3446 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.7692 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0227 - accuracy: 0.9895 - val_loss: 0.3968 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.4244 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.8371 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0691 - accuracy: 0.9768 - val_loss: 0.5116 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.4613 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.5968 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.3211 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0422 - accuracy: 0.9858 - val_loss: 0.5863 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.6123 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.3325 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.5664 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.7756 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92568\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.4754 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92568\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.4137 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92568\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.6810 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92568\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0461 - accuracy: 0.9826 - val_loss: 0.4062 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92568\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0425 - accuracy: 0.9837 - val_loss: 0.4971 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92568\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.4341 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92568\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.4639 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92568\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.5144 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92568\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.4273 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92568\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.8479 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92568\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0674 - accuracy: 0.9832 - val_loss: 0.6436 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92568\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0350 - accuracy: 0.9874 - val_loss: 0.5210 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92568\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.4332 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92568\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.4942 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92568\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0200 - accuracy: 0.9968 - val_loss: 0.4365 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92568\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.5654 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92568\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.7056 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92568\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.6913 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92568\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.5502 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92568\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.4670 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92568\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0221 - accuracy: 0.9916 - val_loss: 0.6234 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92568\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.4379 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92568\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5663 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92568\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.3516 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92568\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.5347 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92568\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.4252 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92568\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0859 - accuracy: 0.9753 - val_loss: 0.7741 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.92568\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.2983 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.92568\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.4759 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.92568\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.4815 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.92568\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.4752 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.92568\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0543 - accuracy: 0.9842 - val_loss: 0.4621 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.92568\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.3686 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92568\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.4140 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92568\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.3512 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00143: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.2687 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4307 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5887 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.5803 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 1.0509 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0662 - accuracy: 0.9784 - val_loss: 0.6003 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.5346 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.5478 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.4071 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.5000 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93243\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.3425 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93243\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.6347 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93243\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.5777 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93243\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0153 - accuracy: 0.9932 - val_loss: 0.5029 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93243\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0317 - accuracy: 0.9911 - val_loss: 0.4174 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93243\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.5834 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93243\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0308 - accuracy: 0.9874 - val_loss: 0.7653 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93243\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.4250 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93243\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.8012 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93243\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.6103 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93243\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.7351 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93243\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6567 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93243\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.5690 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93243\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.4998 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93243\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.7434 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93243\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6254 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93243\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.4556 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93243\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0231 - accuracy: 0.9963 - val_loss: 0.5625 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93243\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.8314 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93243\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.5155 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93243\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.6477 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93243\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.7114 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93243\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.6262 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93243\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.6168 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93243\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.5392 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93243\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93243\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.4976 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93243\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.4244 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93243\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.5356 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93243\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0691 - accuracy: 0.9816 - val_loss: 0.3339 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93243\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0235 - accuracy: 0.9905 - val_loss: 0.4244 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93243\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.3324 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93243\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.4626 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93243\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 0.4581 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93243\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.5886 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93243\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0377 - accuracy: 0.9895 - val_loss: 0.4388 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93243\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3453 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93243\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0138 - accuracy: 0.9937 - val_loss: 0.4753 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93243\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0175 - accuracy: 0.9921 - val_loss: 0.3821 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93243\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.3795 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93243\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.7155 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93243\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0385 - accuracy: 0.9842 - val_loss: 0.4390 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93243\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.6008 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93243\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.5066 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93243\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.5862 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93243\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.5142 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93243\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93243\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.6267 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93243\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.7438 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93243\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.5073 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93243\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4274 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93243\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.6356 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93243\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4637 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93243\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5775 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93243\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6400 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93243\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.6914 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93243\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0507 - accuracy: 0.9874 - val_loss: 0.8546 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93243\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0314 - accuracy: 0.9879 - val_loss: 0.5994 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93243\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.7220 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93243\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.7642 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93243\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5677 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93243\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.6210 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93243\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.7196 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93243\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0324 - accuracy: 0.9942 - val_loss: 0.7947 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93243\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5552 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93243\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6105 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93243\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.4866 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93243\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.4221 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93243\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.4524 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93243\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.2741 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93243\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.5883 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93243\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.6420 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93243\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.7368 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93243\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.4896 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93243\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.5563 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93243\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 1.0967 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93243\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.5469 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93243\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6612 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93243\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.4877 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93243\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5969 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93243\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 9.2110e-04 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93243\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5648 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93243\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5872 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93243\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.6538 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93243\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.7742 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93243\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.6281 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93243\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93243\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.5132 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93243\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.5042 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93243\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.3782 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93243\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.2794 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93243\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5714 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93243\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.6284 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93243\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.6380 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93243\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.6533 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93243\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.5173 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93243\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.5699 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93243\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 0.5289 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93243\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.4865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93243\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4072 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93243\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93243\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.4887 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93243\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.8167e-04 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93243\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93243\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0456 - accuracy: 0.9884 - val_loss: 0.8851 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93243\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.5019 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93243\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.5398 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93243\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5023 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93243\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5112 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93243\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5591 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93243\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.5002 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93243\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5195 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93243\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.6356 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93243\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0343 - accuracy: 0.9921 - val_loss: 0.5501 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93243\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4973 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93243\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.4783 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93243\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.3397 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93243\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.6086 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93243\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.5407 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93243\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.4762 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93243\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93243\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.5699 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93243\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6197 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93243\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.7735 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93243\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.6185 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93243\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.4927 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93243\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.6488 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93243\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0046 - accuracy: 0.9974 - val_loss: 0.5567 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93243\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4989 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93243\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.5271 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93243\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.8315 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93243\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.6484 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93243\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.4885 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93243\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4457 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93243\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.4143 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93243\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.3926 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93243\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.7994 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93243\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0226 - accuracy: 0.9958 - val_loss: 0.6177 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93243\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4633 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93243\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.5655 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93243\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.5546 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93243\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.5038 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93243\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.5890 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93243\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.5275 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93243\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.5824 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93243\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93243\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5557 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93243\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.5305 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93243\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4589 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93243\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5158 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93243\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4237 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93243\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.6553 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93243\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.6803 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93243\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.6213 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93243\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.6679 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93243\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.9201 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93243\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.7153 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93243\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.6704 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93243\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.6461 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93243\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6967 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93243\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0077 - accuracy: 0.9958 - val_loss: 0.5966 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93243\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.6085 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93243\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 8.3326e-04 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93243\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 8.1001e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93243\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.9253 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93243\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0389 - accuracy: 0.9911 - val_loss: 0.7311 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93243\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.6323 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93243\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0057 - accuracy: 0.9968 - val_loss: 0.7196 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93243\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6961 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93243\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 6.9408e-04 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93243\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.5858 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93243\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.5968 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93243\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0429 - accuracy: 0.9926 - val_loss: 0.7957 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93243\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.3110 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93243\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.6881 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93243\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.4063 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93243\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.6196 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93243\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5657 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93243\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.7868 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93243\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.6309 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93243\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3506 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00335: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_4.h5\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.5648 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5936 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5103 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.5414 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.4040 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.7390 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.4636 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5034 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.6941 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.7485 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.7706 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 7.3919e-04 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0154 - accuracy: 0.9979 - val_loss: 0.8072 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.3920 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.8635 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.5087 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4375 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.4490 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.4331 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.5734 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.6743 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4434 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.3489 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5000 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 18s 76ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.3551 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 8.8353e-04 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 6.8032e-04 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 7.8974e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4860 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0413 - accuracy: 0.9900 - val_loss: 0.7364 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.7336 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4336 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.5887 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.7125 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.5094 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4876 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5844 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.5878 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.6247 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.6345 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5529 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6870 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.7228 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.5629 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 1.0693 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.6726 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.6569 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.6209 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6354 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.6517 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.6894 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.6709 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 3.0368e-04 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 8.9005e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.6371 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.8578 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.8646 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0244 - accuracy: 0.9963 - val_loss: 0.7867 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.4909 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.6607 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4769 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.5648 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5364 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.6205 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 0.6683 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.6264 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4894 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.6796 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.7382 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.7170 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.7452 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.7007 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.9613 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6266 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.5232 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4902 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6854 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0311 - accuracy: 0.9942 - val_loss: 0.7379 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.4850 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5507 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 6.7534e-04 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 6.9473e-04 - accuracy: 0.9995 - val_loss: 0.6559 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 3.1823e-04 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 3.0324e-04 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6978 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.7029 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.8380 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.8010 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6431 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 8.9813e-04 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 4.9660e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 18s 73ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.5751 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.6760 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.9195 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.4393 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5640 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.4867 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.6100 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4830 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 7.5312e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.3666 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5204 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.5535 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.6556 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.7274 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.5426 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5257 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4368 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.6201 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.6734 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.6734 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.7058 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.6081 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.5257 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 18s 73ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4038 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5913 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 18s 73ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.7420 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.6764 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.6709 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.6163 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 3.5607e-04 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 2.8277e-04 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 6.5850e-05 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 2.0284e-04 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 5.8283e-05 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 2.0441e-04 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.4972 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 1.0385 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6986 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.5331 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.5026 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.6314 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.5449 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4272 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.4305 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 8.2888e-04 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5655 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5493 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.5912 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5657 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.5157 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 18s 73ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6559 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.4410 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.9658 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.5591 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6110 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 17s 73ms/step - loss: 8.6709e-04 - accuracy: 0.9995 - val_loss: 0.7770 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.7044 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.5529 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4864 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 18s 73ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.5372 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5799 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.5624 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.6725 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.5990 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94595\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.6149 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94595\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 2.9735e-04 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94595\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.6543 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94595\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.5569 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94595\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.7387 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94595\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 18s 75ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6599 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94595\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 18s 74ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.8067 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70c651a990>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ab733eb0-54b6-490f-e411-e68820b7490d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3xUVdrHvye9kEoSCIQSkI7UgCCiuIKgoq4F17aWdcX6brOsrru2ffVV17bIrqLrqqu71rV3QbBgoShFeofQkpCQ3mbmvH+cuTN3SpJJSIgzPN/PZz4z994z955zy+8+5znPOUdprREEQRDCn6jOzoAgCILQPoigC4IgRAgi6IIgCBGCCLogCEKEIIIuCIIQIcR01oGzsrJ03759O+vwgiAIYcny5ctLtNbZwbZ1mqD37duXZcuWddbhBUEQwhKl1I6mtonLRRAEIUIQQRcEQYgQRNAFQRAiBBF0QRCECEEEXRAEIUJoUdCVUv9UShUppX5oYrtSSs1RSm1WSq1SSo1p/2wKgiAILRGKhf4sMKOZ7acAA9yf2cDjh54tQRAEobW0GIeutf5cKdW3mSRnAv/SZhzeb5RS6UqpXK313nbKoxAidY1OXFqTFNf27gXr91VwoKqBif26EhWlPOsr6hopq26ga5d4usSb/dc7nEQrRXFVPd1SEnzS2zlY08C7q/Zyzpg8EuOifbY1Ol3UNjpJTYj1WV9UUccXm0o4a3RPoqIUP+wuZ+3eCsb3zaRvVjIAWmuUMsd0uTRKgVIKh9PFgeoGuqUm+Jyb15YX4nRpTh/Zg8zkOMqqG+iSEENsdKBds7+ijhW7DrKrtIaqegfj+mYysV9Xymoa2H2wliG5qcRGR1Fe00hVg4MdB6oZ3D2V15bv4rijshnaIxUAh9PFjtIaeqYnEh2lWFV4kIHdUkiMjebzTcX0zkziqJwUXC7Na8sLGd07nX7ZXfh8UzFdk+MY3iMNgKgoRXW9g5Kqejbtr2LD/kp+Nq4XWV3iWbq9lDW7yzl1RC45KQme61VUUUd+Vhf+u7yQftnJbD9QQ35WMvlZyWQmxwGwcH0RCbHRTOzfla+2lFBcWc/MET2Idl/LRqeLLzeX8P2OMnqkJ/Kzcb1QSrF+XwVbi6upqG0EIDM5jimDcoiLifKUe/mOMmKio6hrdLKqsJwe6Qkcd1QWXbvEU+9wsmBdEQBjemdQWt3Agep6JvXPorSmgS7xMWwuqqKwrIa0xDiS4qL5dtsBnC6IjVacOzYPp0vz/c6DrN5dzilHd2dw91SWbCslOgq2FFdzsKaBM0b2JCclHodLs2hDEfGx0QzJTSE1IZbaBieFZbX0SE8gJjqKt1fuobiiznMP9EhP5JyxecRGR+FymWHGv99VxoZ9VQzJTaFLfAwrC8uJi4mioE8Ge8vr2FVaw6lH57JxfyX7yutIT4qlss7BtpJqTh/Zg33ldVTWN3JMflfPOW5PVCjjobsF/V2t9fAg294F7tNaf+leXgD8Xmsd0GtIKTUbY8XTu3fvsTt2NBkff0RS0+AgKS4GrTVLtpUyqnc68THRAemKKuqIj4kmLckrgv/+dge3vfEDBX0yeO2aY1ldWM6DH2/gysn9GN07negoRXxMFDUNTpLcolrvcPHeqr188MM+Hjh3BEWVdcx64msq6xwAzD6+H384dQjbS6qZ8uAiAAZ268JLsyeyt7yWM+cuxuG+0S86pjdnjOzBa8sLqW10ckx+JpMHZHPFc0vZUlwNwKSjuvLweaN47qvtvLhkJ8N7ppGZHMdbK/bw/Z+mkZEcx4pdB/ndyyuod7jYfbCWvIxE9lfU0eg0x0mKi+bDXx9PUWUdv//vKo7p15Vj8jO5/4P1HmH6aM0+SqoaOO6oLK6Z0p995XW8uWI3X2wqASA3LYFXr57I1Ic/Iz4mmuMHZqOAATldSIyLJjUxlkc+2cjecu/D3T01gZzUeFYVlgOQkxLPMf268s7KPZ40SXHR1DQ4SYyN5rJJfflqcwk7S2soq2mkS3wMPdIT2Li/ithoRa/MJLYWVxMXHUXvrknsLK2hweECICUhxnMNThnenVWF5QzqnsL2kmq2llR7jpcSH0N8bBQlVQ0AxMdEERsdRVW9gygFLg1ZXeI82y2UgsHdU9ldVkOF+zhXTs7n6S+34dKQmhDDtKHd2V9Rx+ItJdglYnjPVKKU8pwHO/lZySTHR7Nxf5WnLMEY3jMVlwvW7q0AICZKee6j/KxktpVUoxS0ZqqGmChF36xkNhdVBWyzzoWduOgoGpzB82g/dlaXODKS4tgUZL+txV7OW08ZzFUn9G/TfpRSy7XWBUG3HU5Bt1NQUKAjuafo5qIqHpm/kf87+2gf6/NfX28nPyuZ447KwunSxLitw4/X7GP288v51y/GU9vo5KrnlzN1SDf2ltfym6kDcWnNB6v3ctKQbtzwykpy0xN47epjaXS6qK53MO2Rzz3H+ObWkzh97pcUV9b75KlrchwHqs3DrZRZth72388YzL++3k5lnYOqeocnzce/OZ5/fLGNl5ft8uynR1oCe2xiB+bGr2lwUtPgDDgX6UmxTB/anTdX7CYpLpqKOgdOvyesS3wMaYmxFFXWERMVRZ3D6XmoUuJjOHN0D6YP685Vzy8nq0s8O0trgp53peCY/Ey+2VoasP7m6YPpmZHIr1783rP+lOHdWbHrIC6t2V/he77+eNoQRvVK59P1Rfx90RbAvLh6ZiTy2vJCthZ7xfXkod1YvbucyQOyeGflXmobnQzs1oWReekUVdbz2cZiAE4bkUvP9EQWri/i2P5deeHbnThdmryMRHJS4vlu50EAHvnZSBZtKOatFd4XRkpCDFX1Dq45oT+9MpO49fXVAPzPT45i2tBunDF3sSftpKO6kpkcz2cbisjqEs/s4/sxJDeVr7Yc4MM1+3A4XYzpnUFGUiwfrtnHxv1VDM1NJTk+mqXby+iWGk+0UhysbeSO04fy09E9ufyZpXy15QBgXl63nDKYKQNziIlWLNtRxgtf7+CHPeUkxkYzeUAWkweY3unJ8dEM6p7Ke6v28ODHGz15PHNUD84Y2YMl20pJS4ple0k1rywr9Jzn2gYnOakJPPHZFkb1SuepSwqIj43i1WWFLNpQ5HlBL/nDSTwyfxP7ymtZuMGc51lj85gyKIfb3lzN0T3TyElJYEhuCsN7pvHdzjIKy2r5bkcZ04Z2Y+2eCpZuL+Wfl41jbJ8MlFJorRl/7wLPMxQbrRjYLYXTRuRy4qAcPl1fRHFlPRP6dSU1IYanv9zG4NwUnvtqB1X1DmYf348TBmZTWeegttFBt9QEXv9uNwO7dSE7JZ4J/bqSm5YY9B5uiY4W9HnAIq31i+7lDcCUllwu4S7oz3+zg+E9UhndOwMAp0tz1fPLufTYPkwekM2zi7dx5ztruXJyPku3lzFzRC4XT+jDiDs/Ji8jkSsm53PbGz/w3Z+mUV7byBlzv6SyzsFFx/Tms43FFJbVBj1udJTyEcMoBcN6pLGpqJI7Th/Gra+vpntqAgeq6/nDqUO46521nrRx0VGccnR3H5H43bSB/G3hZuodLrrEx/DyVRN4bXkhx+RncvUL35EcF011g5PJA7J4/opj+HrLAf7nxe88L4JLJ/bhQLVxqQA8f8V4RvVK54S/LKKqzsGzl49jYv+uKKX4aM0+rnp+OQDzfj6Wkqp6bnvjB04f2QOny8X7q/cBxno5f3xv5n66iae+2Mblk/pyx+nDALj5tZWeh/60EblccVw+jQ4Xo3tnUF3vID0pFqUUn28s5qstB4iJUqQmxvCzgt6kJcXicLo4/oGF7CmvY2huKu//erLnXOwqrWFveR3nzfuaYT1See9XZtu6vRWc8tcvmDqkG/+41PsczV+7ny82FdO1SzzXTulPdJRCKcXS7aV8sHofvz9lEPEx0TQ4XLyzcg8nD+tGip9racO+Sr7ddoCfT+iDUooN+ypJTYwhNy2RTfsrueCpb7jj9GHMGN6dGPf+wbiYLnt2KRP6ZXLtlKMA+G5nGVuKqhifn0mfroFuqaYoqqhjS3E1E/plUu9wsa+8jr5ZybhcmuoGhyfPizeXcNE/vuWJi8cyY3j3ZvfZFCt3HaS63kG3tAT6Z3fx2eZyaT5Zt5+e6YkM75nmk7/0pDiPO8di8eYSMpLiPO4tgOU7yrjlv6v4z5UTyE6JD6n8WmtqGpwkx/u6Kn/z0ve8uWIPH/5mMoO6pbS4H4ADVfWUVjcwoFtKi2nbSkcL+mnA9cCpwDHAHK31+Jb2Gc6CvuNANSf8ZRFdk+P49MYpfLp+P70ykjj3ia8B2H7fafzlo/X8beEWn+reH04dzL3vrw/pGKN7p/P9zoP8rKCXxzq2quIFfTJYtqPMJ/2lE/tw3YlHMf7eBQDcPGMQ1045ijkLNvHFpmJ6ZSbx8HmjfPIPsOjGKdz25mq+3VrKM5eP81hVAP3/8D5Ol2bGsO48/LORHt+81pq/fLSB4T3TOPXoXJbvKOWcx03Z1/95Bgmx0ZRWNxAdpUhL9ApYRV0jI+782JMuPiaKNXsqGJqbSlSU4vTHvmT17nK+vvUn5KYlsrmoivOf/JqXZk/gqBzzgGwuquS+D9Yzq6AX04e1TVQO1jRQWWfE319gAb7deoD+OV3I6hLvKe9LS3cxdUg3slPi23TMtuJy6SbbJjqDkqp6z3mJdCrrGllVWM6ko7I6Oys+HJKgK6VeBKYAWcB+4A4gFkBr/YQyr625mEiYGuDyltwtEJ6C/tryQkb1SuedlXv464JN5KYlMGtsHnM+3eyT7oZpA3nok42kJMS4rRxfN0RKfAyVbreGxTH5mfTLTubFJbuIjlKsuWs6FXWNbN5fxYX/+JZuqfHMvXAMs574mssn9WVbSTWLNhRz0/RBbCmq4o8zh5KZHMdnG4tZsu0Av5s2qNlGl763vAfAlntPZVtJNWU1DYzrm+mTZuBtH9DgdLHghhMCrCk7WmvmryuiS3wME/t3bfYcXvyPb+ndNYl7zzo6YFtRZR0b9lX6vFQEQfClOUEPJcrlgha2a+C6NuYtbNhVWsONr66kd2YSfbomAVDT4GTJ9tKAtA99YvyEOSnxXDYpn78vNIK/t7yOSyf2oXtaIvd/uJ5rpvTn03VFbNhfyX+unMDHa/bx4pJdOF2ahNhozwfgxpMHUdAngztPH8qJg3PITomnss7hE8kBcMLAbE4YGLogRkcpjsoJLtbP/mIcy7eXNSvmYCJLpg3tFtLxXvjlMU1uy0lJ8ERpCILQekJyuXQE4WChL1xfxKaiSmaN7cUzi7cx59PNRCnTgGdFB4Dx5b7n9iGfP64XLy01LpKclHiW3DbVk66yrpGUhFi01nyztZTRvdNpcLqorHPQMz2RgzUNjLr7E3LTEvj61pM6tGw7DlTjcOkWxVoQhB8Xh2ShH8lc/uxSAB+/t0tDRZ2DqUNymO+Oo/3FpL4eQb/vnBH8cnI+Ux/+nIM1jT77s/y1SimPayIhNtoTBZOeFMfcC0czNDeVjsZqNBMEIXI44gW9qt7Bf5cXcl5BL3aV1bBubwWFZbWcV9DLJ93xA7O5+vh+XPHcMjKSYplzwWhWF5YzPj8TpRQLb5zCgSoT4mSJ5dShOa3Oz8wRPQ69UIIgHJEckS6Xoso6Xl6yi2um9Ofud9fyr693kJeR2GSoIJjIFTARElpDhrunXVPsPlhL1+Q4jw9cEAShPRCXix+Pzt/Ef77dyYBuXdjm7nnXnJjbSU9qXsgteqa3rdOAIAhCWzkih89Ndnd9X7Gr3Kd7d480b4RFXEwUT/58LMBh8WkLQoew5g1Y9Upn50I4TByRFro1Lsiy7aVsLTZjNIzqlc6AnC68uryQ8X0zmffzsWQkx/GPSwoY0Sutud0Jwo+XVy8z3yPO69RsHHYc9VBXDl1a344VzhyRgl7qHs/E6m35l3NHcNqIXLaVVPPWyj08OGukx0c+NcT4akEQfkS89gtY/y7ccdAM5HOEcES6XMpqfEefG94zjaS4GIb1SGPj/55Cb3fHoSOOz/8CL5wLVUUdd4yv/w5vXQevXwVvXQ9OR8v/EdoHlwve/S0U+Q0/seVT+OwvnZOnjmL9u+a7MbS2sQ5h03xYeO9hPeQRYaFrrZn76WamD+9OVb0jYBTC/KwOiMku2w7JORDXwS+H6hJAQXLzXe5D4tP/Nd87v4GhZ7Tuv/WVUFcBaT2bT/fRrb7Lx/0WurZtGNGgOOph59fQfQQkZbacvj2oKgYV1T7XoKNwOaF8Fyz7J2yeD79Z7d32/Fnm+4Sbgv+39iDUV4CzsX2v1eGgrrx9n8H6KqgthfTeLaf99znm+/ibIfrwSO0RIeiFZbU89MlGT5d8gITYKOoaXcRGq/YPLXQ64K8jYdCpcMGL7btvf/7ifsDuDByfulXYw1cr97X+/0+dBCUbms9HsBBZR33gukPh++fhvRtg6Jlw3r/ad99N8eBRgII7Dx6e47WFunJvbai2lfl8bCzUmKFquXnb4XtRtgf1FUBu++3v3+cag6ElV479Xq8ohIy+7ZeHZjgiXC7WQPp2urvHQGmy63ttGbx4IVTYRgF+8zr410+hoQY+/hOsfy/4f8vdY4dveP9Qsg2f3AFr3zq0fTSFo8E0mBWtg2XPwMd/9G6r3BOYfstCI5RNUbKh6W2V++Gli6Bid+C2xhp44xp47nRzzg8V63qVF4aWvqoY/vOz0NM3ySH05yjfbc5PXeB9GsDBnfDyxaZGZKdyH7x4Afz7PLOvZc/4bq8tg0b3+O31FbDy5cB915TCc2fAvONh3buwfbFxjVliDlBjxkOnocYcp3Rr6OXsDEI5p61hpxlVlM8egG+amW3zoG3ynscnGdfPezfA+kPUhBaIaAv9laW7uPvdtVx6bB8ApgzK5u8XjeGlJbsY0yeDW/67iv87O3DUP8Cc+A3vQVwynPOUqW6ueMFsK9sGX80xn2AWadk28x0VODRrq1j8qPkO1fqu3A/OBkjv1XSaunLz8O/4yoS07VsNB3xHiwxqoT//U/N9ygOwfw1kD4KYIMOoupwQ5Vfj+eJB49MMJtirX4WV/zG/v/83HHt903lvjgNbwOWAvSvdZdgfPF3hMsgdCdGxJu32xbDxQ1DRcMF/vOksgU/La/64dmvX5TT77GmbJ33nt1C5F3pPgJTuvmn3rYYeo2DB3eb8rDweUntA3ngjohn5ge6CRffDunfgqGkw9lLv+reuh82feJfXvwtjbNu3fwlZA7zLb8yGvAJzHiyWPg3bPoOYBHOMLjmw6iXf41eXmPNctsMco3IfnPqAsUit82pRUwp1ByGzX/PnUGtzXfIK2taA6aiHorXQY7RpH0i1WeT15d5j7F4OPcd6j+F0wP4fzDXwz8/u7yBvrHddYx1sWeBdXuT2jeefAN2G2sqxFGKT4IfXvGkbquCNq4xx9sPrMHhb68sYIhFtod/97lqq6h28+f0e+nRN4tnLx5MUF8MvjstnVK90PvzN8Z4JKgJIcMeel7jdNDW2URVLW7gg1vbYdupcFGpv3ocGwqMBQ9b78sK58Lfx8O5vzLK/mANUBLHQLfavgXmTTQ0lGA1Bpupyuhuhd3hn1CHdvGT59gnvug0fNH3clnhsjCmXJWpV+0wjoJ1dS+EfJ8H8O83LZd7xXp/+3hW+aeeOh0eGtXzuy2z3wg+vw1MnGqEG81L553R49VLfGhDAlw/DkydA4XJwuBvuPnvAWN+v/BwePxZevzLweJbA+1vo278MTNtom9XpnV8F/uexMfCozaD5+jHodYwR5so9XmvcTuVe+PsEbzjk7mXw1E/Mef3kDt+0c8fBnNGB+/Bnx1fw9NS210YXz4Enpxgj7O/HmFqFhWWhr3/X5HGlzQW64E5zDUo2+e7vh//CP35ivi1WvAAvXRh47HnHe2uFa9+Ep6fBE5Pgy0egz3HedFbZcoa0rYwhEtGCnpJgKiC7D9bSt7WDUTW4q6fWxbZXO0u8vvigD7wlksG2FW+EZ2e6GzODULQO/j7RiI7F8meMELtcxpJ5dqapwr388+D5KC+EeSfA34+FrZ/57r9wSfDjWqT1DnQ/fP6g9/e+VeZ7z3fB/z//LvjiYd91wSJZuviFg/adDA02wdk8H/49y7iGWqKhOnCdy+F7zQCWP2u+V/wnUNwqdptzuvo1eOfXXvfEnFFmnZ1dS+E/55u8vWh7yAuXurcvMe65hwYCGqLjfV13YO4DgOL1xvoDb353fWu+178LXz1mfleXwL/ONI3tANXuSCRHg7k3HEGiOfzPS0ttI3XlUHCFqUls+xxW/DswTZF7Bqxgx1vxb5PfD//gW54WX4rbzffSf5jayrfzmk5bssn9/NheNtb/X3KP9L3RZhh8/hf49B7v+d/mnaqRrYvMtyX6jbWmgXjNG2b5tV/A2reNO3DNm8Hz42qEuQUm30v+4bstdyTcaHtZxHUxRs2c0YH3VDsRsYJeXe/w6QXaO7OFlu7ag6aaZWE98I3VJurjh9e92+xvdH9hdjq8F7+hEvauMh8r3UsXwvYvzIXd5RbXwmXGYtzmXl+01rzhLd79rbE86w7C2/9j/v/N32Hd29409of3m8eNxVm0Bl673Dd/scFebLZq7pDToXSLyXPlfljxInz6Z+/2fT+Y7/gmes8uexoW3OW7rjHI/J/2Dh9jLjENbVYDaelWeOEc2PQxLJlnagUlm8z12bc6cF/WA+2PvaaxZ4W3ylxb6nvdurmt1LId8N8rjPAnuDuTVRWbsD4wZa/Ya67Bxg/MNbG3N1h52/6F1z0HkD/ZV9y2fgbx7inK6g76iuN4m3UJsOg+cy8uus8I0CYz4xPLnzXXfM/3vq4WO/b7A7xtGEfPCp4eIP94SLG5LHqOhcEzbWX8Ifj/+hxnyvLxH+Gbv8F+79SHAS+WmlJzPUq3Gl/+AffztP0L+OIh+OBms1y0zvRybbTNX/vSRSad9fKE4DUJi6K18PkDXmOhYo+5Bls+NS8wAGe9OY8bPzLrrZBHMLWlbZ+bY/abYqKy/GmoMvne4VdLysz3vc8HnWq+S7dCUsdEREWkD/37nWWcN880XljTtrUo6C9fbC7an0qMH9Buwf1zum9aezW7fBd0sU0osW+VeciPPg9Wv2IaQgqXQM4wuGax9+Z981pzI8xeZKqC6X1MQ0p0M2PFNFQZXy8EVk/rbY0/TrtV6+eTTMqEcr8HbOQFxo8dFQuTfm1C25Y9DTGJ8K1fw4/lmohpYSKK6hJIdk/dVRXEn22PlDjhFmPhNNaah82qzkOgqwLg9lJfP72/C0xFg3aaWkSPUWafT55gtiWkmQfZargGOOlP8J/zfBv46srh2F+ZB9zy/T8xyXznuWdYtK7ByffAx7d5/feWhQeQ2R/SehnBAPjuX8b9YYW91Zb5Cl53vzadhipY9bK5N+3UlRsjw9lMDeb9G823dS9aNa8Z95k2ECtM1U5CmvEBW6T2hLOegHvdo4AGe6ECTL/He44BHp/o/V1TAvG24IN/nWmek97Hws6vzLrYJN8Xv8tpah4VhTBtr7kvtfY2vttfgsEaZqfdDZ/c7l22LPSy7cYwsEI1wTzrz5wSvFx2+kyCE2427QvBXJVg7g2rFpyRb76zB5s2OEvcx/0S+p/Y8vHaQERa6O+s3EujU/P8FeO55ZTBAPRqSdAta9nTih/EF2xht+7WvgX/nGE6zDw02DTyART8wtyw1sUtWuP7IrD2v/iv5ttqFW/uAX30aHODg7Em7dTZGk7tLfs1JfDIcCh2PwgJQYYxOGY23LITbt4KKd3g6HONZWS3Pn/i9plbrfx1tsZAp++474BXwMA3umWyW2TibA94YjrEJoCjzjRc7V0JU/5g/LnBsB6m4g3w+HGBbqTMftBtuKnZPDbW93rljTPfr1xivi98BXq6B67zt3QTM8xnw/umM5RF0TrzvcodKdLvBEB53TQWv1sH131rXmw1pabq/s6vzDbLlfTtPFNmC39BV9Emjb1WaL1QakpM7a4lrL4BlgslLrnpGlZsom/DZEO1Sf/HYiNQFU1EA3UbZlxLwag+YF5kDw0xrgbLbWeJOZiwPmWTo//L8x5r+XPmhf/vc73ba8tMdNCcMb4uUIuuR/ku71/j/t/BwPQHtjRRJr9r0cPd2G2/RrmjzLMOxhj7xYdG+MF73q9eDNct8ZavS9vmwg2FiBT0RRuKmDIom8kDsjl5aHcuG+Ti+INv+jZsgukRaQm5ZXFaD7+/j9WOvYq3+FEjckueNA1GlnWWkAY5g33/tzuI33mn218aFWJlybIW6/xiie0+OX/fcfkuE5pXfSCw+jvhOhMdkJDmbQjOP95YS8UbISnLiPkQv45G1cUmbHPLp8FD/iw3SH2l78vHcjXYH97YJHP+G+uMHzUuBSZeZ44djN3fmQbURffB/tXmZQow0u3PdtSZ6jEY8V9wp/e//oKZmGlqC126GdHx2ZZhXjYA39tcKA1+90bWQG80jL1cqT1MbS8pC9C+/tta971YX+FbK/PvuJM3zgiQts1Lm5lv7peKPYFulWCk+nX2iknwfaHaUQom/cZ7/qznICau+Yif6NhAEbWoKTENjJV7fGsvdlJyTY3QwrLWJ1xnXIBfPGTaVSxqD5oXeekWY4BkDfTu56Q7YOAMOOMxb/y39dKsL/fWki2sF0xmfzj9r971GX180/VwN/DOfMREGVnlTnZb3vEppuZ47j9h+r3GMgfTqSg6xnsuE5p4mbYDESfo5TWNbC2pZny+qdJnp8RzZ8obJM3/vQnLsvPUSaZVGrwheJYY1jdjodeWBvqiLeu70l21S0j1EyTlfXnYsaxg1yF2gf/C1nAZLGSvbJup6tZX+Irzsf8TmNby7x3cYR6I42/0dZGMvdyIzEsXmqqrv0sKvA1we1diYrRV0wKtlBGZercbYeT5poreVM/LT/4EL54Pa9ztGq5G49Y47SGzPOFaXz+wXYz7/8R3X5ZF2mOMuQa5thC2xHRISA+eh7HutonckebeyXRXry3r7IzHvGmTg5TbXhM7+ynvb+uFZ9HDFiWS6L4GKd2Nhb3kqaZrkqfa7odUv0lTlPJ1gfiTkPz/g94AACAASURBVArnuJ+VAlsbjH/nGMv9N8Fde2mqw1F1sbfGZq+5ASS73ZWZ/UwtzR//F3CX7ua4tWVeV9vMR0yNDMy5mfw7I6xjLoGz3Q2VTlsHtj0rzH7i3bVVy4100asw9jJT0xj9c9/abM+x3vsxMQPO/Jv5PX6291xaRllKd2OQ+IdgDj3TfPfrGHcLRJigf7+zjHveN40xR/e0XQzLoi71q1qV7zTfd3f1Wr5vXA13pnljo+1cYbMQUlqoNsWn+j3I2rhjQmkMyTzE7tVNNRLuX23OhT3vwR4iK9+NNd4wOXsVPTnbN30wH3nlXnj/ZnjWTAzCTZvh5iaqtuAN8XTWw7grzG//c3XaQ5Az1AhEsDzHJZmY/YnXBr8+v/zUV7DBWz4rdvzEP3i3JWYEd1EBnHQ7/GEP/NLd0GrFWmcPgtvLjJh48tbEpN1JWXDLLhj20+Db7zjo26fAstJzR7qtPHfsd7CXTrdh3t/+Fjo0baF78pxlzuUoWxSP9dKyaiFxySbNDHdMdlNunK2LjEswe0hg5zLLzzzqAq9Fa7kwwDfM7w974TerzEvvqzmm8T02ySxbBpm/28d+H1iuqi0LTEy+dT/udzf0prnP9R/3w5lzQbvDXi99x3udPfvtZso+4jzbS7iFGPr+J5r/ZA9sPt0hEFGNoje8upKtxcalMLyH7UG0xLqp+HG7dVy5N3ga8LWeUnsEviA8KPPAWIIUn2os49pSEzFgb0UPRo9Rzew7CNmDTfibhb9LwB97y3tskLYFuwBZD36MzS3QUmeb3FG+IW9pvYJbqXYsl1dUjPch9u+YlZhhBKBoLQH4W//+VikYC8vfArbKP/YyY2FaVWkILlDnu+OY/a3RCdca8R91EUT52Ul9joXp/2ciiDZ/Ap8/ZPzDcUne6veVnwbWCpXyzYPVTtJjjHd938lwcBcBRMfDmX838fjdRwRut5+HUO5J8L7ccoYZ4yDOr5bqf24tVr9qrOoJV5uQUDvnPm1cUT3HwqznTCcvhy2qxXqJgPfla3c3Wq4ZS9D9O7vZ79WjTvK2t0y51bcT1OiLvfe4ZVmfdIfpENZ3cvMdnqxnRHW+fdz5OWgnahucbC+ppl92Mr+fMdh3ijiPoB9iN2X7DZDSzPgQ8anmoU50d1rKHgQjzjcXfFAIremtHfdhyi3w8ybiZINhb8QMFlVjt4ztD21yDhxzje9DZjHmEkjNMwMR+d/8dit3oNs9M+xsI0yWgFoWelMNa2AsUX+xDJZPCG6hJ2WZvCUHeaF1yTHRB1FRxt0QFWvK6T9a34CTYfCpgfvOHmQiK7IHBW6LjjW1hvRexvq0RNzuM+451t24imkLsO4Bu7/1pDvMiy+jL56hBlJyvUKSZbP8MvNh9EUw+QZTphT3C85q2LOL78lBol2CYbkKpro7EPmfc7t7xuK43wLKRFLZ3UcW6b2NmIKJFhvzc9+8JaQZ94jVmG4nId34+8FrEPhHXykFp/zFlN9yhwH0neSb7oTfB+4/Nde86FvqvRqsXaiTiBgL/dQ5X+DScMuMwZw8zO9htrpnVxcZK6g5/2Fz2Bsug7lOMvKNr9p6CC2xyBlqGlvOnGsaJe0RE8HICCKYzRGTaKpzv10LjwxtOt2sZ90hgbYbNNjNGhPvrVXYH9qb3I1J/o2gv/ret3v3NndnplnPmV6S2bbG4Zwh3qEMZi+0HdP9INpfmv6TEyRmBEYI9Bht/LL+vuRgL1yrLDdtMm41CF5DOfpc8wHfmkX3o9tn1DzLug7m7gI46/HAtGB8w5N/Z35bjdupud5reNY832EH7NywznfZ7nJpyiXkT9f+5tppbe45f0HvPcG0B7x+pRHbW9yN4SfeZp6dpjrT+ePvDrqxiXGCrP2D1zCJCWKgHDPbfPx7hNoJ5pYKFbHQ25eaBodnbtCCvn5VYafDCJMlKmVNuF2CcYVfGJtdbOyWU6q7Wmf5La2HsPcE85DNuM88dNGxwS1i/6p9MAu4OaxqZnOzs1zyFgz9Kfz0CRPT2xLWCytYR6QUP3eGv8ie/ZRxTQw9E856Emb69RwNhkfQbeen4BfGbWBZq3HJxjo8a57XurV84v5RSbGJ3gYxgAteCv7yakmgJ98AP33clOOSECJKQiGYhd5k2iZ8+A1uV0NKLp4XdEt+cTt2o6a1Q1QoZWpAwe4N6zraxS061vwnqSst+pmhadeNxTVfw+V+w0R47p8Wangmc4Hb/Mcfag0eC73tu2gvIkLQ97l7hD583kgyk/0E0+53BF8/enNv1NSeJj7ZEtuRF/j6dO0ibAlw9iCTxnpglTIRG/YBluyCZd2EWX6NJBn5MOP+pt06/i8F60Vjf+H4j9fcb4rJz6gLQhsf2uqa72+FganCWw1MELi/jD7GLaEUjPxZ06JkJzaIoEdFG7fBtLvN+rQ88/CMPN/rZx043QhjsCq5ZWVDaK6uYMTEm4bBkT9rv2FjrXsn2OBm/jQp6G4L3e5yac243/Gp5r+n/9Wc56SupoNUqAyYBn0mBq63ajzBnq2oKN/7acqtgWmg5Rp0t6GmXcKOx//dzDOdmGEihc6c61037Gxv9Elbaa7Mh5mIcLnsqzAPtzUkrg+W/7znGBO5YrfQo2J9w5nsvdW6DTc34K27AvcFvha6JbzxKcb10Fwki90SSO1pGj97jDaDHNn3N+Fq87kzyAOd3tu3p5rVGm/nZy+YuPvnm4igaAnL2g8m6AC//CR43tqKZa0GqzIPPTPIQ+f2IWcPgj82MUbJj3XqMUukQ7GMm4ocyRlsur+ndDc1w6p9LffetRMVDTfYGtJvbmX70qlNzHBklakpcUvLMw34Z80zL+ZgxLVgoQcjlLJHx8Dv/Wros54JnrY1xNlcq51MRAj6fregd0trRtDT+5i3s9UwunWRr5iDscLzJ5uqa6/xBGC30O1CZwm4ijZD7QYdL8WNXWSsSBn7y+HyD4I3/J39lBkuwIq5tgu6yxmYPiU3NMu4KSwLvbmq6K9WeDvIHCqxIVSZg9Fc4/SPFasHYbDr5k9TnVAueMmE28Ummo4su5e1HEl0OLCuY1P3zdlPms50g09reh9taeNq7X3TnqT2gIv+G1wzDjMRIej7yo0wd09NMBEcdteD5XJJSDMPf5U7hvlffhZfzjAj6L3GNX0g+37t/k/LD+tymLjgUBn3S9NQM+oi0405LS+wKmnRZ5JpUNy3yiu2vSeaDj726IFznzFDsyZlBbfcLQquCD5KoYV1jOYasjLzgVb6+5vCOp/Rsc2nszhjrhlvpq1DFB/7K99JCA4nVqN3VQgzQ8XEm3tz4rW+65OzvL05E9PhqKntmcO205L7IXdky89Ia9oCLEJxX3UkA34c5z8iBH33wRpSEmJILlsHTxwHF74KA082G61BqxLcoYRNzSxz7VfB19uxW+h2IbF6zOkQLC47WQO9LfhnNzNkKJhqnT3EDkyo2y8+9E03/GzzMRluen8tNVRaPfQOt9XX3OBkdsb83Hzaysl/bjlNR2G1ufgPqdsUodybPxYsYT0Uf7Il6P6dwJojVEMgwgl7Qd9fUceCdUVM6V4PT0w2K/euNBe4rtwb/RCfYm6y3cvNkLBtwe4KiU0yE+021pqBrCBwQoWWaI1VEZvk9dVZYWbBBsXy59pv2zZJ7qAZ8PM3oO/xrf9vW7C6wocq6KFy/fJDi2DoCCwL3X/MnUjiUNovoqJMz8yWZjryPWDbjxdBhL2gz3zsS4or67ki42081ndCmrcx0Gq5twS9aj+8efWhHzg2wRtJMvYy09PO6iARKq1pxIqOc4t6ird24ApB0P0HCGsN/uOedCQ9RplawfQQO7mESlYTA0Z1JonppkOVfXiASCE1z0SUTb3z0PaTV9C69NYL5MfaEH6YCHtBL66sJ4k6jj7wgbcLs73rsDVUZlyXpquBWUF697WEvUNKei8zTGpraY2gW3G8Kd29I/L5hzuGM3HJcHWQadQilYs7ZsaaTicmzrfDmHBYCWtBd7o0UQr+OmQj0VurYOL1bkG3Ra9s+8yIeVQ0Qatl/X9iogRaS2vEuMl9tLIh5yd/Mm0CXfubTk89W2nFCIIQ0YS1oJdWN+DSmrFFr5sBiHpPMA2U9tH4yrZ7Q9uCWeg5Q71jrrSGYF3GW0trXwpdsr2zI/0IQqQE4UeDNW9pqBOqRyghNUUrpWYopTYopTYrpW4Jsr23UmqhUup7pdQqpVSQ0Yvan+LKevqrPWRWbYSxl3rH1fYfPra5wXNCaVgMRlvD5eyEMi6I+pE16AnCjxGrAbWpsWyOEFpUFKVUNPA3YBpQCCxVSr2ttbaPYfpH4BWt9eNKqaHA+0DfDsivD0WVdXTFHZZojSEeEx9E0K2u+EEEPZSGxWC0h8slFG7a7OtCEgQhkN7HmDFe7OOnH4GE4nIZD2zWWm8FUEq9BJwJ2AVdA1aXtjRgD4eBosp6kpW7AdQzPkZC4JyBzVnobZ0pqKlhXNub9ho/RBAinW6d3/W+swlFlXoC9hH0C93r7NwJXKyUKsRY50HmNQOl1Gyl1DKl1LLi4iCzzrSS7SXVpEZZgm5NxBAPaDNcpyXyHkEP0ijqPMSp3wRBEH4ktJeZeQHwrNY6DzgVeF6pQHNYa/2k1rpAa12QnR3iGMzNsHF/Jfkp7t6Znpl13K6QtF5eIfd3ucQmm2FZoe0uF0EQhB8ZobhcdgO2iQ3Jc6+zcwUwA0Br/bVSKgHIAoraI5NNsXF/Facma6jFa6FbgwNl9vP60v1dLum9bXNYdoKgX/hK4CQRgiAIh0goFvpSYIBSKl8pFQecD/iP9L8TOAlAKTUESAAO3afSDPUOJztLa+iR6HaZ+FvoGX28oYX+gq6ivI0n/aZ0ZDaDM3C6dyJkQRCEdqJFC11r7VBKXQ98BEQD/9Rar1FK3Q0s01q/DdwAPKWU+i2mgfQyrTs2IPRAlRn7Iz2m3rhQrPE6rDC/Lt28Vri/D90S9Ju2ND92uSAIQhgRUscirfX7mMZO+7rbbb/XApP8/9eRlFSZUL4uqs53/ORG95CwSV297pcEPx+6JextGUnw/P+ENo61IAjCYSZse4pagp6sa3zHT653TxacnNW8y6WtNDcwvyAIQifS+ZPgtZESt8slQdf6WujW7O9JWTaXi7+FHrbFFgRBaJKwVTbLQo9z1vjOQWi30GP8fegi6IIgRC5hq2wllQ2kxWmiSzdDSjfvBstCT85uvlFUEAQhwghbZSuraeDUhNVmZMURttnDrYbOxIwggu7XKCoIghBBhG2jaEVtI4NiSqEB39lNfvGRmWYuKlp86IIgHFGEr6DXNZIS7Q4ftI982LW/d0afnCHQ9SjxoQuCcEQQtoJeWecgJcbdS7SpmX+Gn2M+HsSHLghC5BK2ylZZ5yA5ygFRsaHP6i4+dEEQIpiwFfSK2kaSox2tnGhZXC6CIEQuYalsLpemqsFBYpSjdRMti6ALghDBhKWyVdY70BoSVaNY6IIgCG7CUtkq68wY5gmq0TsAVyhIxyJBECKYsFS2yjoT3RKPWOiCIAgWYalslqDH6gbxoQuCILgJS2WrbXSicJmBucRCFwRBAMJU0OsanTwb+wBdipa10kJXvt+CIAgRRNgK+gnRq8yCWOiCIAhAGAt6mxBBFwQhgglLZatrdHkXrPHPQ0EEXRCECCYslc3HQq8XQRcEQYAwFfTaRicO7c56qyx06VgkCELkEpbKVtfoopIksyAWuiAIAhC2gu6kVrmjW5z1of9RBF0QhAgmLJWtrtFJHW5Bv/i/of9RxkMXBCGCCcsZi+oancQpBww/D3qMbsU/xYcuCELkEpbKVtvoJB4HRMe17o/ichEEIYIJS2Wra3QRiwNi2ijoiMtFEITII0wF3UksjRDdinFcQCxzQRAimrBUOK+gx7bujyLogiBEMGGpcHWNLmJ0K+cTBYluEQQhoglLQXc4GonC1fZGUUEQhAgkLBUu2tXg/iGCLgiCYBGWChflMpNEt97lEpbFFQRBCImQFE4pNUMptUEptVkpdUsTac5TSq1VSq1RSv2nfbPpS7S2LPTWNoqKD10QhMilxZ6iSqlo4G/ANKAQWKqUeltrvdaWZgBwKzBJa12mlMrpqAyDzUJva9iiCLsgCBFIKBb6eGCz1nqr1roBeAk40y/NlcDftNZlAFrrovbNpi8x2hJ08aELgiBYhKJwPYFdtuVC9zo7A4GBSqnFSqlvlFIz2iuDwfAIept7igqCIEQe7TU4VwwwAJgC5AGfK6WO1loftCdSSs0GZgP07t27zQc7ZJeLIAhCBBKKwu0GetmW89zr7BQCb2utG7XW24CNGIH3QWv9pNa6QGtdkJ2d3dY8E9tWl4sgCEIEE4qgLwUGKKXylVJxwPnA235p3sRY5yilsjAumK3tmE8fojyC3soKhjSGCoIQwbQo6FprB3A98BGwDnhFa71GKXW3UuoMd7KPgANKqbXAQuAmrfWBjso02mW+xYUiCILgISQTV2v9PvC+37rbbb818Dv3p8PR2v1DBF0QBMFDeCqiZaG3dlxzz5tAEAQh8ghLQXd5XC5t9YmLL10QhMgj7ARda00UbktbXC6CIAgewk4RnS6NwuNE79S8CIIg/JgIP0HX2ivjYqELgiB4CDtFdLlAcag+dEEQhMgj/ATdx0IXQRcEQbAIO0F3am2mnwPEhy4IguAl7ATd5RIfuiAIQjDCThGdLpuFLi4XQRAED2En6C6NWOiCIAhBCDtFNI2iEocuCILgT9gJuk/HIrHQBUEQPISdIhofuiXoYqELgiBYhJ2ga41Y6IIgCEEIO0V02gfnEh+6IAiCh/ATdJcGsdAFQRACCDtFdGnxoQuCIAQj7ATdd/hcQRAEwSLsBN3VHhNciGUvCEIEEn6C7gKlxOUiCILgT9gJulNLxyJBEIRghJ0iyhR0giAIwQk7QdeHMgVdfKr5TsxszywJgiD8KIjp7Ay0lkMaPvfoWdBQBaMvbv+MCYIgdDLhJ+iHYqFHRcG4K9o7S4IgCD8Kws7l4nIhU9AJgiAEIfwEXds6FUmUiyAIgoewU0SfSaIlDl0QBMFD2Am6TBItCIIQnLBTRJ8oF0EQBMFD2Am6TBItCIIQnLBTRDNJtPjQBUEQ/Ak7QXfafegStigIguAh7ATd5RPlEnbZFwRB6DBCUkSl1Ayl1Aal1Gal1C3NpDtHKaWVUgXtl0VfXD49RcVCFwRBsGhR0JVS0cDfgFOAocAFSqmhQdKlAL8Gvm3vTNpxujj0CS4EQRAikFAUcTywWWu9VWvdALwEnBkk3Z+B+4G6dsxfAC4ZPlcQBCEooQh6T2CXbbnQvc6DUmoM0Etr/V5zO1JKzVZKLVNKLSsuLm51ZsH0FEUsdEEQhAAOWRGVUlHAw8ANLaXVWj+ptS7QWhdkZ2e36XimY5FMQScIguBPKIK+G+hlW85zr7NIAYYDi5RS24EJwNsd1TCqZQo6QRCEoISiiEuBAUqpfKVUHHA+8La1UWtdrrXO0lr31Vr3Bb4BztBaL+uIDPtY6OJDFwRB8NCioGutHcD1wEfAOuAVrfUapdTdSqkzOjqD/jg1KCUuF0EQBH9CmrFIa/0+8L7futubSDvl0LPVND5RLiLogiAIHsLOCe1y+9C1+M8FQRB8CLs5RScdlYVrexZsF+tcEATBTtgJ+vCeadAzFXaIhS4IgmAnPFVRu8R/LgiC4Ed4CjpaYtAFQRD8CE9V1C4kBl0QBMGXMBV0LS4XQRAEP8JY0MMz64IgCB1FmKqiRlwugiAIvoSnoGuXWOiCIAh+hKcqai0GuiAIgh/hKegStigIghBAeKqihC0KgiAEEKaCLha6IAiCP+GpitL1XxAEIYDwFHTxoQuCIAQQnqooPnRBEIQAwlTQxUIXBEHwJzxVUcZyEQRBCCA8BV186IIgCAGEpyqKD10QBCGAMBV06fovCILgT5gKugzOJQiC4E+YqqIMnysIguBPeAq6WOiCIAgBhKcqStiiIAhCAGEq6GKhC4Ig+BOmqig+dEEQBH/CU9Cl678gCEIA4amKMnyuIAhCAOEp6CAWuiAIgh8xnZ2BNiFd/4UjjMbGRgoLC6mrq+vsrAiHiYSEBPLy8oiNjQ35P2Eq6BK2KBxZFBYWkpKSQt++fVFy70c8WmsOHDhAYWEh+fn5If8vPP0W4kMXjjDq6uro2rWriPkRglKKrl27trpGFp6CLsPnCkcgIuZHFm253iGpolJqhlJqg1Jqs1LqliDbf6eUWquUWqWUWqCU6tPqnLQG8aELgiAE0KKgK6Wigb8BpwBDgQuUUkP9kn0PFGitRwCvAQ+0d0Z9kDh0QRCEAEJRxfHAZq31Vq11A/AScKY9gdZ6oda6xr34DZDXvtn0Q3zognBYiY6OZtSoUQwbNoyRI0fy0EMP4XK5Dsuxn332WaKioli1apVn3fDhw9m+fXuz/3v00UepqanxLN9222306tWLLl26+KR7+OGHGTp0KCNGjOCkk05ix44dnm0zZswgPT2dmTNntk9hOphQolx6Artsy4XAMc2kvwL4INgGpdRsYDZA7969Q8xiMKTrv3Dkctc7a1i7p6Jd9zm0Ryp3nD6sye2JiYmsWLECgKKiIi688EIqKiq466672jUfTZGXl8c999zDyy+/HPJ/Hn30US6++GKSkpIAOP3007n++usZMGCAT7rRo0ezbNkykpKSePzxx7n55ps9x7npppuoqalh3rx57VeYDqRd/RZKqYuBAuAvwbZrrZ/UWhdorQuys7PbfiAZnEsQOo2cnByefPJJ5s6di9Yap9PJTTfdxLhx4xgxYoRH/BYtWsSUKVM499xzGTx4MBdddBFaawBuueUWj1V84403AlBcXMw555zDuHHjGDduHIsXL/Ycc+bMmaxZs4YNGzYE5Ofjjz9m4sSJjBkzhlmzZlFVVcWcOXPYs2cPJ554IieeeCIAEyZMIDc3N+D/J554okf0J0yYQGFhoWfbSSedREpKSkjn5e6772bcuHEMHz6c2bNne8q6efNmpk6dysiRIxkzZgxbtmwB4P777+foo49m5MiR3HJLQNNk29BaN/sBJgIf2ZZvBW4Nkm4qsA7IaWmfWmvGjh2r28wzp2n99PS2/18Qwoy1a9d26vGTk5MD1qWlpel9+/bpefPm6T//+c9aa63r6ur02LFj9datW/XChQt1amqq3rVrl3Y6nXrChAn6iy++0CUlJXrgwIHa5XJprbUuKyvTWmt9wQUX6C+++EJrrfWOHTv04MGDtdZaP/PMM/q6667Tzz33nL7kkku01loPGzZMb9u2TRcXF+vJkyfrqqoqrbXW9913n77rrru01lr36dNHFxcXh1QWi+uuu85TFouFCxfq0047rcVzdODAAc/viy++WL/99ttaa63Hjx+vX3/9da211rW1tbq6ulq///77euLEibq6ujrgv3aCXXdgmW5CV0NxuSwFBiil8oHdwPnAhfYESqnRwDxghta6qH1eNc0gjaKC8KPh448/ZtWqVbz22msAlJeXs2nTJuLi4hg/fjx5eaZJbdSoUWzfvp0JEyaQkJDAFVdcwcyZMz3+6fnz57N27VrPfisqKqiqqvIsX3jhhdxzzz1s27bNs+6bb75h7dq1TJo0CYCGhgYmTpzYpnK88MILLFu2jM8++6xN/1+4cCEPPPAANTU1lJaWMmzYMKZMmcLu3bs566yzANP7E0xZL7/8ck/NIDMzs03H9KdFQddaO5RS1wMfAdHAP7XWa5RSd2PeFG9jXCxdgFfdsZM7tdZntEsOg+cK8aELQuexdetWoqOjycnJQWvNY489xvTp033SLFq0iPj4eM9ydHQ0DoeDmJgYlixZwoIFC3jttdeYO3cun376KS6Xi2+++cYjev7ExMRwww03cP/993vWaa2ZNm0aL7744iGVZ/78+dxzzz189tlnPnkOlbq6Oq699lqWLVtGr169uPPOOztlmIaQzFyt9fta64Fa6/5a63vc6253izla66la625a61HuTweKORLlIgidSHFxMVdffTXXX389SimmT5/O448/TmNjIwAbN26kurq6yf9XVVVRXl7OqaeeyiOPPMLKlSsBOPnkk3nsscc86axGWDuXXXYZ8+fPp7i4GDA+78WLF7N582YAqqur2bhxIwApKSlUVla2WJ7vv/+eq666irfffpucnJwQz4IvlnhnZWVRVVXlqa2kpKSQl5fHm2++CUB9fT01NTVMmzaNZ555xhOFU1pa2qbj+hOefgsZy0UQDiu1tbWesMWpU6dy8sknc8cddwDwy1/+kqFDhzJmzBiGDx/OVVddhcPhaHJflZWVzJw5kxEjRnDcccfx8MMPAzBnzhyWLVvGiBEjGDp0KE888UTAf+Pi4vjVr35FUZHx7GZnZ/Pss89ywQUXMGLECCZOnMj69esBmD17NjNmzPA0it58883k5eVRU1NDXl4ed955J2AiWaqqqpg1axajRo3ijDO89ujkyZOZNWsWCxYsIC8vj48++ihomdLT07nyyisZPnw406dPZ9y4cZ5tzz//PHPmzGHEiBEce+yx7Nu3jxkzZnDGGWdQUFDAqFGjePDBB0O9FM2itLsl9nBTUFCgly1b1rY/P30yxCbCJW+1b6YE4UfKunXrGDJkSGdnQzjMBLvuSqnlWuuCYOnD1EKXrv+CIAj+hPHwueH5LhIEIbw566yzfCJtwMSU+zcKdwZhKujSKCoIQufwxhtvdHYWmiRMzVyx0AVBEPwJT1UUH7ogCEIAYSroYqELgiD4E56qKHHogiAIAYSnoIsPXRAOKzIeevuPhz5lyhTa3BenCcI3ykUQjlQ+uAX2rW7ffXY/Gk65r8nNMh76ETge+mFDXC6C0GnIeOiBfPjhh8yaNcuzvGjRIo9Vf80111BQUMCwYcM8wyV0FOFroYvLRThSacaSTGDCVQAABm5JREFUPlz069cPp9NJUVERb731FmlpaSxdupT6+nomTZrEySefDJiBr9asWUOPHj2YNGkSixcvZsiQIbzxxhusX78epRQHDx4E4Ne//jW//e1vOe6449i5cyfTp09n3bp1AERFRXHzzTdz77338txzz3nyUVJSwv/+7/8yf/58kpOTuf/++3n44Ye5/fbbefjhh1m4cCFZWVkhl+vpp5/mlFNOafX5mDp1KrNnz6a6uprk5GRefvllzj//fADuueceMjMzcTqdnHTSSaxatYoRI0a0+hihEJ6CLsPnCsKPBhkP3QztO2PGDN555x3OPfdc3nvvPR544AEAXnnlFZ588kkcDgd79+5l7dq1Iug+iIUuCJ2KjIceyPnnn8/cuXPJzMykoKCAlJQUtm3bxoMPPsjSpUvJyMjgsssu69Bx0sNPFR31UF0CsUmdnRNBOCKR8dCDc8IJJ/Ddd9/x1FNPedwtFRUVJCcnk5aWxv79+/nggw/avP9QCD9BX/s21B2E4Wd3dk4E4YhBxkNvfjx0MDWQmTNn8sEHH3jcSCNHjmT06NEMHjyYCy+80OMa6ijCbzz0DR/A9y/Aec9DVPi9jwShLch46EcmrR0PPfx86INOMR9BEATBh/ATdEEQhE5ExkMXBOGQ0VqjpENdp3O4xkNviztcnNCCEAYkJCRw4MCBNj3kQvihtebAgQNNhnA2hVjoghAG5OXlUVhY6AnXEyKfhIQET6esUBFBF4QwIDY2lvz8/M7OhvAjR1wugiAIEYIIuiAIQoQggi4IghAhdFpPUaVUMbCjxYTByQJK2jE74YCU+chAynxkcChl7qO1zg62odME/VBQSi1rqutrpCJlPjKQMh8ZdFSZxeUiCIIQIYigC4IgRAjhKuhPdnYGOgEp85GBlPnIoEPKHJY+dEEQBCGQcLXQBUEQBD9E0AVBECKEsBN0pdQMpdQGpdRmpdQtnZ2f9kIp9U+lVJFS6gfbukyl1CdKqU3u7wz3eqWUmuM+B6uUUmM6L+dtRynVSym1UCm1Vim1Rin1a/f6iC23UipBKbVEKbXSXea73OvzlVLfusv2slIqzr0+3r282b29b2fmv60opaKVUt8rpd51L0d0eQGUUtuVUquVUiuUUsvc6zr03g4rQVdKRQN/A04BhgIXKKWGdm6u2o1ngRl+624BFmitBwAL3Mtgyj/A/ZkNPH6Y8tjeOIAbtNZDgQnAde7rGcnlrgd+orUeCYwCZiilJgD3A49orY8CyoAr3OmvAMrc6x9xpwtHfg2ssy1HenktTtRaj7LFnHfsva21DpsPMBH4yLZ8K3BrZ+erHcvXF/jBtrwByHX/zgU2uH/PAy4Ili6cP8BbwLQjpdxAEvAdcAym12CMe73nPgc+Aia6f8e406nOznsry5nnFq+fAO8CKpLLayv3diDLb12H3tthZaEDPYFdtuVC97pIpZvWeq/79z6gm/t3xJ0Hd9V6NPAtEV5ut/thBVAEfAJsAQ5qrR3uJPZyecrs3l4OdD28OT5kHgVuBlzu5a5EdnktNPCxUmq5Umq2e12H3tsyHnqYoLXWSqmIjDFVSnUB/gv8RmtdYZ9mLRLLrbV2AqOUUunAG8DgTs5Sh6GUmgkUaa2XK6WmdHZ+DjPHaa13K6VygE+UUuvtGzvi3g43C3030Mu2nOdeF6nsV0rlAri/i9zrI+Y8KKViMWL+b6316+7VEV9uAK31QWAhxuWQrpSyDCx7uTxldm9PAw4c5qweCpOAM5RS24GXMG6XvxK55fWgtd7t/i7CvLjH08H3drgJ+lJggLuFPA44H3i7k/PUkbwNXOr+fSnGx2ytv8TdMj4BKLdV48IGZUzxp4F1WuuHbZsittxKqWy3ZY5SKhHTZrAOI+znupP5l9k6F+cCn2q3kzUc0FrfqrXO01r3xTyvn2qtLyJCy2uhlEpWSqVYv4GTgR/o6Hu7sxsO2tDQcCqwEeN3vK2z89OO5XoR2As0YvxnV2B8hwuATcB8INOdVmGifbYAq4GCzs5/G8t8HMbPuApY4f6cGsnlBkYA37vL/ANwu3t9P2AJsBl4FYh3r09wL292b+/X2WU4hLJPAd49EsrrLt9K92eNpVUdfW9L139BEIQIIdxcLoIgCEITiKALgiBECCLogiAIEYIIuiAIQoQggi4IghAhiKALgiBECCLogiAIEcL/A9/MGQmqb88tAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb94d1fc-35ca-45cb-f681-4e6c6b77c5b9"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1684da09-35f1-44dd-a45b-0b1a3844abcd"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbe9b47-a978-483e-da1c-00287d8edc78"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}