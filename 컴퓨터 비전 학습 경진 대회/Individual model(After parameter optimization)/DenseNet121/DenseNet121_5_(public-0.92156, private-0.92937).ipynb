{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet121_5_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet121_5_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd06ac2-51b2-47ff-95bf-826a5fbfab30"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 27 20:33:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c94f83-204d-4cfe-ac20-386554ca11c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet121_5'\n",
        "Target_model = 'DenseNet121_model'\n",
        "Target_predict = 'DenseNet121_predict'\n",
        "Target_acc = 'DenseNet121_acc'\n",
        "Target_val = 'DenseNet121_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ce0448-0d76-475d-fa11-93ebcf558651"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbdf2f7-a2b3-40d8-9f5e-d12abbc793c1"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 40s 71ms/step - loss: 1.9819 - accuracy: 0.3426 - val_loss: 12.8156 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 1.1700 - accuracy: 0.6237 - val_loss: 4.6936 - val_accuracy: 0.0541\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.9312 - accuracy: 0.7026 - val_loss: 1.2351 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.67568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.8009 - accuracy: 0.7489 - val_loss: 0.6128 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.67568 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.6700 - accuracy: 0.7889 - val_loss: 0.5857 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.83108\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.5980 - accuracy: 0.8105 - val_loss: 1.1269 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.83108\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.5728 - accuracy: 0.8153 - val_loss: 0.6688 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.83108\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.5526 - accuracy: 0.8232 - val_loss: 0.8190 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.83108\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.4827 - accuracy: 0.8395 - val_loss: 0.8915 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.83108\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.4674 - accuracy: 0.8553 - val_loss: 0.9516 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.83108\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.4633 - accuracy: 0.8489 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83108\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.4587 - accuracy: 0.8484 - val_loss: 0.4846 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.83108 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.4242 - accuracy: 0.8679 - val_loss: 0.6932 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84459\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.3848 - accuracy: 0.8784 - val_loss: 0.2941 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.84459 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.3112 - accuracy: 0.9005 - val_loss: 0.5251 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89865\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3321 - accuracy: 0.8942 - val_loss: 0.8922 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89865\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3576 - accuracy: 0.8916 - val_loss: 0.4122 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89865\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.3349 - accuracy: 0.8953 - val_loss: 0.7247 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89865\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.3068 - accuracy: 0.9037 - val_loss: 0.8009 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89865\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2915 - accuracy: 0.9021 - val_loss: 0.3580 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89865\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2810 - accuracy: 0.9042 - val_loss: 0.4071 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.2923 - accuracy: 0.8995 - val_loss: 1.2433 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.90541\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2383 - accuracy: 0.9189 - val_loss: 0.4633 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.90541\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2814 - accuracy: 0.9142 - val_loss: 0.6152 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.90541\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2449 - accuracy: 0.9142 - val_loss: 0.4184 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.90541\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1833 - accuracy: 0.9405 - val_loss: 0.4384 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.90541\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.2505 - accuracy: 0.9184 - val_loss: 0.6737 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.90541\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2085 - accuracy: 0.9305 - val_loss: 0.6733 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.90541\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2389 - accuracy: 0.9168 - val_loss: 0.4222 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.90541\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2545 - accuracy: 0.9195 - val_loss: 0.4331 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90541\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1932 - accuracy: 0.9421 - val_loss: 0.4439 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.90541\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1617 - accuracy: 0.9453 - val_loss: 0.5294 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.90541\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1778 - accuracy: 0.9389 - val_loss: 0.3843 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.90541\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1661 - accuracy: 0.9411 - val_loss: 0.3688 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1556 - accuracy: 0.9463 - val_loss: 0.6280 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91216\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1408 - accuracy: 0.9547 - val_loss: 0.3714 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91216\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1396 - accuracy: 0.9521 - val_loss: 0.4371 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91216\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1606 - accuracy: 0.9447 - val_loss: 0.3819 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91216\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1458 - accuracy: 0.9537 - val_loss: 0.4247 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91216\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1409 - accuracy: 0.9589 - val_loss: 0.3746 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91216\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1051 - accuracy: 0.9668 - val_loss: 0.6591 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91216\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1362 - accuracy: 0.9553 - val_loss: 0.6461 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1837 - accuracy: 0.9342 - val_loss: 0.7385 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1253 - accuracy: 0.9616 - val_loss: 0.4901 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91216\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1007 - accuracy: 0.9695 - val_loss: 0.4549 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91216\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1190 - accuracy: 0.9632 - val_loss: 0.5071 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91216\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0840 - accuracy: 0.9747 - val_loss: 0.7204 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91216\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1303 - accuracy: 0.9563 - val_loss: 0.4358 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91216\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1027 - accuracy: 0.9647 - val_loss: 0.4869 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91216\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0902 - accuracy: 0.9705 - val_loss: 0.4895 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91216\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1181 - accuracy: 0.9579 - val_loss: 0.5021 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91216\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0835 - accuracy: 0.9716 - val_loss: 0.2239 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.1028 - accuracy: 0.9674 - val_loss: 0.4096 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.92568\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.7701 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.92568\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1206 - accuracy: 0.9589 - val_loss: 0.7280 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92568\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0751 - accuracy: 0.9711 - val_loss: 0.4761 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92568\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0780 - accuracy: 0.9711 - val_loss: 0.6053 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92568\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1144 - accuracy: 0.9668 - val_loss: 0.4492 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.92568\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0782 - accuracy: 0.9742 - val_loss: 0.4718 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92568\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0672 - accuracy: 0.9821 - val_loss: 0.5323 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92568\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.3657 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92568\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0831 - accuracy: 0.9753 - val_loss: 0.4718 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92568\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1400 - accuracy: 0.9516 - val_loss: 0.5759 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.92568\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0900 - accuracy: 0.9753 - val_loss: 0.5930 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.92568\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.5210 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.92568\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.5927 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.92568\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1146 - accuracy: 0.9684 - val_loss: 0.5583 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0744 - accuracy: 0.9795 - val_loss: 0.6077 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.4661 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0429 - accuracy: 0.9884 - val_loss: 0.4950 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.8071 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.1051 - accuracy: 0.9653 - val_loss: 1.1586 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1164 - accuracy: 0.9658 - val_loss: 0.4963 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.3425 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.4043 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.5212 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.7210 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1154 - accuracy: 0.9674 - val_loss: 0.4395 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 0.4501 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0228 - accuracy: 0.9900 - val_loss: 0.3530 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 1.0895 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.5246 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.6271 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.6777 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0166 - accuracy: 0.9926 - val_loss: 0.4437 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.4707 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0882 - accuracy: 0.9705 - val_loss: 0.7783 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.5521 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0685 - accuracy: 0.9821 - val_loss: 0.3738 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.6931 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.6058 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0508 - accuracy: 0.9821 - val_loss: 0.4442 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.5424 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 0.6039 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.6905 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.4980 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.7151 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93243\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0841 - accuracy: 0.9747 - val_loss: 0.7540 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0427 - accuracy: 0.9858 - val_loss: 0.4986 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.4731 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.5461 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0391 - accuracy: 0.9905 - val_loss: 0.6609 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0380 - accuracy: 0.9868 - val_loss: 0.5556 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.6165 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93243\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0382 - accuracy: 0.9858 - val_loss: 0.6226 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93243\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.5798 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93243\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0481 - accuracy: 0.9858 - val_loss: 0.6226 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93243\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0834 - accuracy: 0.9763 - val_loss: 0.6986 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93243\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0551 - accuracy: 0.9847 - val_loss: 0.6990 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.3852 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.3742 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.5444 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.5593 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.4934 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.3929 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.4042 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0220 - accuracy: 0.9905 - val_loss: 0.5713 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 0.7529 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.6074 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.4454 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0538 - accuracy: 0.9821 - val_loss: 0.6208 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.7653 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.8544 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.3125 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.4725 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.4393 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.6260 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93243\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0280 - accuracy: 0.9895 - val_loss: 0.7513 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93243\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.3923 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93243\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.5198 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93243\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0296 - accuracy: 0.9926 - val_loss: 0.6704 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93243\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.6312 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93243\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.6962 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93243\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.6111 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93243\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.4762 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93243\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.6504 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93243\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.4341 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93243\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.4632 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93243\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.6332 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93243\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0252 - accuracy: 0.9953 - val_loss: 0.7239 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93243\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.5443 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93243\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.6456 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 0.7646 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0524 - accuracy: 0.9858 - val_loss: 0.6208 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.4653 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.6176 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0128 - accuracy: 0.9937 - val_loss: 0.6505 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.5332 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5382 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.6130 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.4409 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00151: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.5290 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.4677 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3273 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.4287 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.6880 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.6067 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.4370 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0232 - accuracy: 0.9911 - val_loss: 0.3743 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.5195 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5117 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.6296 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.6092 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.5762 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0130 - accuracy: 0.9942 - val_loss: 0.5410 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0531 - accuracy: 0.9853 - val_loss: 0.5678 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0282 - accuracy: 0.9926 - val_loss: 0.4548 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.5641 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.5336 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.4609 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.4679 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.5315 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.7266 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.4306 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5580 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5909 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.6947 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.5950 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.6150 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 0.7600 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0307 - accuracy: 0.9937 - val_loss: 0.8024 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.5246 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.3500 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.4832 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.4012 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.6334 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.3863 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.6610 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0667 - accuracy: 0.9816 - val_loss: 0.6053 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.5025 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.5022 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.4587 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.6144 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.6680 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.6074 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.7322 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.6683 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.5322 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5679 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.6004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.8462 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.5516 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0415 - accuracy: 0.9895 - val_loss: 0.6308 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.5692 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.5470 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.6424 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.7185 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.5566 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.6068 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.6945 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.6633 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0644 - accuracy: 0.9837 - val_loss: 0.4874 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.5678 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.4220 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.5371 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0257 - accuracy: 0.9932 - val_loss: 0.5505 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.4970 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4573 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.4124 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.3996 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3243 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00223: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet121_5.h5\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95270\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95270\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.8406 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95270\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.5242 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95270\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.6695 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95270\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.3506 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95270\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95270\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6520 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95270\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.6688 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95270\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.5594 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95270\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.6101 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95270\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.6113 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95270\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 0.7649 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95270\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.6472 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95270\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.5282 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95270\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.9624 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95270\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.8121 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95270\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.8262 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95270\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.8191 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95270\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5658 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95270\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.6335 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95270\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.5584 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95270\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0461 - accuracy: 0.9884 - val_loss: 0.5776 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95270\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.8025 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95270\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.7120 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95270\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.6754 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95270\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.7130 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95270\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.5024 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95270\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.6856 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95270\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.5747 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95270\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5265 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95270\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.5835 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95270\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.4217 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95270\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.7295 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95270\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.9151 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95270\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.8560 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95270\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.8347 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95270\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.5617 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95270\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.4025 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95270\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.6534 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95270\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.4012 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95270\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.5798 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95270\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.6179 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95270\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.5375 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95270\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.6334 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95270\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6258 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95270\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.6431 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95270\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.8024 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95270\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6425 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95270\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.5514 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95270\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4908 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95270\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 5.6772e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95270\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.8615 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95270\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0284 - accuracy: 0.9884 - val_loss: 0.5142 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95270\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.6220 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95270\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 0.6757 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95270\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 0.7743 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95270\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.7083 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95270\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.9793 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95270\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.7360 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95270\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0384 - accuracy: 0.9916 - val_loss: 0.6019 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95270\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.8615 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95270\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.6872 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95270\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.6330 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95270\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.7768 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95270\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.6742 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95270\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0049 - accuracy: 0.9968 - val_loss: 0.7054 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95270\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.6640 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95270\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5442 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95270\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0161 - accuracy: 0.9932 - val_loss: 0.7175 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95270\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0146 - accuracy: 0.9932 - val_loss: 0.6293 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95270\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.4936 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5268 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.5532 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.4503 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5126 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.5291 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4323 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.7734 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.6044 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 5.3998e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5788 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 1.0845 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6256 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.4885 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.6147 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.7240 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.7056 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.6172 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 1.8936e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 7.7767e-04 - accuracy: 0.9995 - val_loss: 0.7340 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.7629 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0564 - accuracy: 0.9858 - val_loss: 0.4754 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.5145 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.6075 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0057 - accuracy: 0.9968 - val_loss: 0.5344 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.7584 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.6359 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.7936 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.6964 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4881 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 4.7954e-04 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5920 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 4.0411e-04 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.9643e-04 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6445 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.7709 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.9945 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.6611 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.4713 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.6590 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.7086 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.6131 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5878 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.6832 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.6194 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.4331 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5976 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.6622 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.8806 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6207 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 0.6095 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.6944 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.5478 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0227 - accuracy: 0.9958 - val_loss: 0.7254 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.6112 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6272 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 5.3373e-04 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.8463e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.7138 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.6762 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.6385 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.7424 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.6826 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.8104 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.8337 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.6448 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.9252 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.7441 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0380 - accuracy: 0.9911 - val_loss: 0.5172 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5185 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5777 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 7.5353e-04 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5957 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5584 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.6322 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.4003 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.4420 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5124 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5691 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.3920 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.8909 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.7876 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.7123 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 0.9029 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.6726 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.7034 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.7227 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.6487 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.8945 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.8915 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.5699 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.5325 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.4654 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.5625 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0067 - accuracy: 0.9968 - val_loss: 0.6072 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.5506 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.5520 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5853 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 9.3391e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 5.2839e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.5522e-04 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5394 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.5114 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.7204 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.8577 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 6.2353e-04 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.8675 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.6375 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.7745 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.8018 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 8.4807e-04 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6559 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.7663 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.7174 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.8405 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.8045 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.8395 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.8344 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0060 - accuracy: 0.9968 - val_loss: 0.7490 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.9921 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 3.4976e-04 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 2.5227e-04 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.9693e-04 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 3.9512e-04 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.2507e-04 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 1.1835e-04 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.3646e-04 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 2.7521e-04 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.8729e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 1.0469 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0346 - accuracy: 0.9926 - val_loss: 0.6025 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.8989 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.7723 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6284 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 8.6010e-04 - accuracy: 0.9995 - val_loss: 0.7335 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 4.1420e-04 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.5924 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 4.3014e-04 - accuracy: 1.0000 - val_loss: 0.7320 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0225 - accuracy: 0.9958 - val_loss: 0.7712 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.9149 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.7299 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.6727 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.6945 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.6660 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.7322 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.6783 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 5.1715e-04 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.7199 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5517 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.7519 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.6902 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0274 - accuracy: 0.9942 - val_loss: 0.5152 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.4650 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.7507 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.8032 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.6748 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.7355 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0234 - accuracy: 0.9958 - val_loss: 0.5847 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4842 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5722 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6420 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.5955 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6204 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.7019 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.7986 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.4020 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.8912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.8616 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.7184 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6643 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.6922e-04 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.8163 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5679 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.8575 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.7977 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 7.4087e-04 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.6913 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 4.8448e-04 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.5169 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.8552 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.7659 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.6010 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5105 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.4685 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5045 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5820 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.5813 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.6017 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.5227 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.9016 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6312 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.6834 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5415 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.5947e-04 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 2.2658e-04 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.8512 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.8009 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 5.0300e-04 - accuracy: 1.0000 - val_loss: 0.7467 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.8369 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.8553 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d0d77fbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ce76bb41-c0d2-4f3e-af3d-86ff88bd77dc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c711c0-bc62-44fa-9b8c-4e176bc6a8b1"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4848a7-0ffd-4e9f-c72f-be7ac566958a"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9273801f-1f28-40ea-f85b-f249b973fe8f"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a980b9dc-ec8a-4891-80f5-9e5424bc3dff\", \"DenseNet121_5.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1c6665-52da-431a-a97f-7409659a79e5"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2733c1-65e6-4c2d-d47d-1a6616f2d1e9"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}