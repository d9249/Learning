{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet201_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/DenseNet201_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9a8dfd-47ef-4aee-fc44-63739232c0db"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 30 10:22:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bf4c02-f202-4253-baba-dfe3b48ebd86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'DenseNet201_4'\n",
        "Target_model = 'DenseNet201_model'\n",
        "Target_predict = 'DenseNet201_predict'\n",
        "Target_acc = 'DenseNet201_acc'\n",
        "Target_val = 'DenseNet201_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.DenseNet201(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207ab54d-8663-4260-fa43-0512aa4fc1f9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6529710-9f0d-4007-8f43-38689f58b3b7"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 67s 143ms/step - loss: 1.8775 - accuracy: 0.3421 - val_loss: 11.0105 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.2644 - accuracy: 0.5726 - val_loss: 2.4774 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09459 to 0.25000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.9798 - accuracy: 0.6726 - val_loss: 2.0145 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25000 to 0.49324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.8737 - accuracy: 0.7174 - val_loss: 2.0171 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.49324\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.7682 - accuracy: 0.7500 - val_loss: 0.6417 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.49324 to 0.75000, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.6934 - accuracy: 0.7737 - val_loss: 0.5925 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.75000 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.6222 - accuracy: 0.7963 - val_loss: 0.7578 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.82432\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.5765 - accuracy: 0.8132 - val_loss: 0.9278 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.82432\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.5386 - accuracy: 0.8121 - val_loss: 0.4824 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.82432 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.5174 - accuracy: 0.8263 - val_loss: 0.7098 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.83784\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.4949 - accuracy: 0.8347 - val_loss: 0.5032 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83784\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.4835 - accuracy: 0.8374 - val_loss: 0.5698 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83784\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.4089 - accuracy: 0.8532 - val_loss: 0.4614 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.83784 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.3860 - accuracy: 0.8768 - val_loss: 0.4175 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.87162\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.4083 - accuracy: 0.8705 - val_loss: 0.7070 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.87162\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3603 - accuracy: 0.8705 - val_loss: 0.3908 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.87162\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.3752 - accuracy: 0.8737 - val_loss: 0.4507 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87162\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2828 - accuracy: 0.9100 - val_loss: 0.5527 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87162\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3682 - accuracy: 0.8821 - val_loss: 0.3991 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3030 - accuracy: 0.8989 - val_loss: 0.5759 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.3345 - accuracy: 0.8932 - val_loss: 0.4721 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87162\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2674 - accuracy: 0.9111 - val_loss: 0.5234 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2841 - accuracy: 0.9074 - val_loss: 0.7142 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2691 - accuracy: 0.9147 - val_loss: 0.4273 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2675 - accuracy: 0.9158 - val_loss: 0.5167 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2402 - accuracy: 0.9158 - val_loss: 0.6358 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2510 - accuracy: 0.9163 - val_loss: 0.3309 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.87162 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2303 - accuracy: 0.9216 - val_loss: 0.4404 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89865\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2011 - accuracy: 0.9374 - val_loss: 0.4504 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89865\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2348 - accuracy: 0.9274 - val_loss: 0.5120 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89865\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1998 - accuracy: 0.9347 - val_loss: 0.4504 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89865\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2021 - accuracy: 0.9253 - val_loss: 0.3355 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89865\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1879 - accuracy: 0.9374 - val_loss: 0.3567 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1945 - accuracy: 0.9332 - val_loss: 0.4786 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.90541\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1693 - accuracy: 0.9416 - val_loss: 0.3426 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.90541\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1329 - accuracy: 0.9521 - val_loss: 0.3372 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.90541\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1641 - accuracy: 0.9421 - val_loss: 1.5802 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.90541\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1455 - accuracy: 0.9479 - val_loss: 0.2727 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.90541\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1334 - accuracy: 0.9611 - val_loss: 0.3507 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1539 - accuracy: 0.9511 - val_loss: 0.4880 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91216\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1792 - accuracy: 0.9416 - val_loss: 0.4225 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91216\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1415 - accuracy: 0.9547 - val_loss: 0.4886 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1365 - accuracy: 0.9574 - val_loss: 0.3491 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1178 - accuracy: 0.9579 - val_loss: 0.4594 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91216\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1270 - accuracy: 0.9558 - val_loss: 0.3504 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91216\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1077 - accuracy: 0.9600 - val_loss: 0.4413 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91216\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1066 - accuracy: 0.9642 - val_loss: 0.4921 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91216\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1478 - accuracy: 0.9526 - val_loss: 0.3153 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91216\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1341 - accuracy: 0.9553 - val_loss: 0.3934 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91216\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.0963 - accuracy: 0.9695 - val_loss: 0.4036 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91216\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1074 - accuracy: 0.9616 - val_loss: 0.5727 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91216\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1099 - accuracy: 0.9626 - val_loss: 0.3959 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91216\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1258 - accuracy: 0.9616 - val_loss: 0.4481 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91216\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0820 - accuracy: 0.9753 - val_loss: 0.2977 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 0.5271 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.92568\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0788 - accuracy: 0.9753 - val_loss: 0.3560 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.92568\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 0.3890 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.92568\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0860 - accuracy: 0.9684 - val_loss: 0.3299 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.92568\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0864 - accuracy: 0.9784 - val_loss: 0.5070 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.92568\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0777 - accuracy: 0.9747 - val_loss: 0.4532 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.92568\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0974 - accuracy: 0.9668 - val_loss: 0.5523 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.92568\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0933 - accuracy: 0.9653 - val_loss: 0.4874 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.92568\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.3667 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0966 - accuracy: 0.9732 - val_loss: 0.5541 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93919\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.4446 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93919\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.5324 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93919\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.4292 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93919\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1203 - accuracy: 0.9611 - val_loss: 0.2440 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93919\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0832 - accuracy: 0.9705 - val_loss: 0.4226 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93919\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.5201 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93919\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.3733 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93919\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0680 - accuracy: 0.9747 - val_loss: 0.4632 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93919\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0967 - accuracy: 0.9684 - val_loss: 0.4138 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93919\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0928 - accuracy: 0.9663 - val_loss: 0.5242 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93919\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.3884 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93919\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.4693 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93919\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0837 - accuracy: 0.9758 - val_loss: 0.3642 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93919\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 0.3833 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93919\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.4741 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93919\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.5413 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93919\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0789 - accuracy: 0.9774 - val_loss: 0.4305 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93919\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0396 - accuracy: 0.9863 - val_loss: 0.3632 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93919\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0302 - accuracy: 0.9863 - val_loss: 0.3797 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93919\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0805 - accuracy: 0.9716 - val_loss: 0.4364 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93919\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.4025 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93919\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0421 - accuracy: 0.9837 - val_loss: 0.5830 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93919\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.4681 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93919\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 0.7131 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93919\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0418 - accuracy: 0.9858 - val_loss: 0.7355 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93919\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.4132 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93919\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0801 - accuracy: 0.9753 - val_loss: 0.4947 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93919\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0654 - accuracy: 0.9789 - val_loss: 0.4718 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93919\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.5033 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93919\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0657 - accuracy: 0.9795 - val_loss: 0.2873 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93919\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 0.5293 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93919\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0261 - accuracy: 0.9895 - val_loss: 0.5008 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93919\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.5785 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93919\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.4262 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93919\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0646 - accuracy: 0.9795 - val_loss: 0.5565 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93919\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.2535 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93919\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.4635 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93919\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0320 - accuracy: 0.9879 - val_loss: 0.4132 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93919\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0405 - accuracy: 0.9853 - val_loss: 0.7423 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93919\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0678 - accuracy: 0.9763 - val_loss: 0.7937 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93919\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 0.4770 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93919\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0244 - accuracy: 0.9900 - val_loss: 0.3031 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93919\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.3336 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93919\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4719 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93919\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0439 - accuracy: 0.9863 - val_loss: 0.2938 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93919\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.6866 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93919\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.3261 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93919\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0952 - accuracy: 0.9711 - val_loss: 0.4677 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93919\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.4551 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93919\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.4820 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93919\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.3386 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93919\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.2437 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93919\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.4046 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93919\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.6278 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93919\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0434 - accuracy: 0.9884 - val_loss: 0.3438 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93919\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 0.3940 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93919\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.2936 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93919\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.4664 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93919\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.4897 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93919\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.4008 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93919\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0317 - accuracy: 0.9911 - val_loss: 0.5110 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93919\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0509 - accuracy: 0.9795 - val_loss: 0.5915 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93919\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0414 - accuracy: 0.9868 - val_loss: 0.4779 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93919\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.4316 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.4536 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.4519 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0312 - accuracy: 0.9879 - val_loss: 0.5522 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.4008 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0364 - accuracy: 0.9863 - val_loss: 0.5681 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.6506 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.4124 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.3610 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.4211 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.6469 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.6414 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0574 - accuracy: 0.9842 - val_loss: 0.3946 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.3546 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.4333 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.5459 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.6187 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.2833 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.4991 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 1.6288 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0621 - accuracy: 0.9784 - val_loss: 0.3910 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0175 - accuracy: 0.9921 - val_loss: 0.3398 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.3654 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.3819 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0041 - accuracy: 0.9974 - val_loss: 0.3102 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.5111 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.4840 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.5503 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.4111 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.3846 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0211 - accuracy: 0.9916 - val_loss: 0.3317 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.3052 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.3093 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.3291 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.3411 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.5292 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.4251 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 0.5207 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0207 - accuracy: 0.9911 - val_loss: 0.5069 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5541 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0409 - accuracy: 0.9847 - val_loss: 0.7221 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.5404 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4196 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.6863 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.4915 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.3813 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.4579 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.4255 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.3557 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 0.3411 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.5030 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.6463 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5511 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.4051 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5046 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.4364 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.7053 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0271 - accuracy: 0.9884 - val_loss: 0.5411 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5460 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5921 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.5546 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 1.1923 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.4386 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0268 - accuracy: 0.9942 - val_loss: 0.6849 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.4312 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.5529 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.5639 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4300 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3311 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5227 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.5190 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0378 - accuracy: 0.9900 - val_loss: 0.4677 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.4390 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.4510 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.5999 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.4851 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.4957 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.4782 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.4362 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.5053 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0581 - accuracy: 0.9847 - val_loss: 0.5175 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.3763 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.5557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.3202 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.4184 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0064 - accuracy: 0.9968 - val_loss: 0.5046 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4717 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.5704 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5797 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4679 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.8212 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6064 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5386 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4782 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.3517 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.5885 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.3357 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.3896 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.7445 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.3506 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.4287 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.5168 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.6266 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4774 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.3288 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.2871 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4162 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3421 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.4412 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.7503 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.6675 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.6863 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.5297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.4521 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.4118 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.3956 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.5157 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.5050 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.3900 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.5290 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.4713 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.5501 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.6676 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.5044 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.7352 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.4748 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.5402 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.5470 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.6637 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.7242 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.7228 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.6185 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.5706 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.5763 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.5804 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.6144 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.8945 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.5827 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.7107 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.6790 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5021 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.6363 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4869 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4642 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 5.4853e-04 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.6275 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0429 - accuracy: 0.9874 - val_loss: 0.5414 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.5118 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.4635 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4324 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.4967 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.5865 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.5045 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0280 - accuracy: 0.9947 - val_loss: 0.3777 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.3683 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.3000 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00288: val_accuracy improved from 0.93919 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/DenseNet201_4.h5\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4407 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95270\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95270\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95270\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.8003 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95270\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0589 - accuracy: 0.9874 - val_loss: 0.6495 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95270\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.5873 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95270\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.6572 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.5450 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.5096 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.5218 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.6404 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.3799 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4565 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6900 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.7932 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0292 - accuracy: 0.9937 - val_loss: 0.5472 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.7807 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0175 - accuracy: 0.9921 - val_loss: 0.5939 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4052 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6381 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 9.7393e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.5653 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0172 - accuracy: 0.9916 - val_loss: 0.4924 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.5905 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.6055 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.5827 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0158 - accuracy: 0.9974 - val_loss: 0.9222 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.5892 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.5969 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5284 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4110 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 5.3837e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.5021 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4542 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4772 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 0.5101 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0207 - accuracy: 0.9905 - val_loss: 0.6852 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.6490 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5701 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.7136 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.4561 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0108 - accuracy: 0.9953 - val_loss: 0.5563 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.5077 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5376 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.5107 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5554 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.4513 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.5369 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 0.5395 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5637 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5337 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3931 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.3912 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.3089 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.3699 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.3753 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5324 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4849 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.4454 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.4061 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.5605 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5328 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.6185 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.8021 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4613 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.3414 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.3660 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.5474 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.6027 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4768 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4058 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.6181 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.4981 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0111 - accuracy: 0.9942 - val_loss: 0.6634 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.4902 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0059 - accuracy: 0.9968 - val_loss: 0.5288 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4881 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.6509 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.6202 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.6556 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.4633 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.7659 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 1.0450 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.7165 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 6.6054e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 8.1052e-04 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.4491 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0382 - accuracy: 0.9911 - val_loss: 0.8584 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.6024 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0256 - accuracy: 0.9947 - val_loss: 0.7003 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5005 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4612 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5516 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6131 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.4723 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.4659 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5377 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.8090 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.7419 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.8670 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4072 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.4459 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 33s 139ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.5920 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.5470 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5620 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.7271 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.7839 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.2815 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4640 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.5639 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.6483 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.3512 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5453 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5037 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.4240 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5369 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.3877 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6688 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4544 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6146 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.4514 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 9.4109e-04 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0019 - accuracy: 0.9979 - val_loss: 0.5138 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.5568 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.3604 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.5256 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5825 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.3760 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6078 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5288 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5357 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4932 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 8.0234e-04 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 4.4421e-04 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.3755 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0119 - accuracy: 0.9942 - val_loss: 0.3599 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4757 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4696 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4725 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 3.6679e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.6073 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 8.5474e-04 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 2.3511e-04 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 7.9544e-04 - accuracy: 0.9995 - val_loss: 0.4061 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 2.9775e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 3.8629e-04 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 3.4144e-04 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.7412 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0462 - accuracy: 0.9816 - val_loss: 1.0990 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4458 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.3763 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4779 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5190 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 7.3553e-04 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 6.1794e-04 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5598 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 1.0619 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.5141 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.6870 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.5237 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.7825 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 33s 139ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.8080 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.4196 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5650 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.3993 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5417 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.6294 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.5917 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.5153 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4657 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.5817 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.5352 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5166 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 8.9630e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6903 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4975 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4938 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.5212 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0051 - accuracy: 0.9968 - val_loss: 0.4589 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.6158 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4791 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0111 - accuracy: 0.9947 - val_loss: 0.6526 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.5616 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.6204 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4615 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 3.8726e-04 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 33s 138ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6235 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.6823 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4964 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.6468 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.6141 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 6.3973e-04 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 6.1011e-04 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 2.0006e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 2.1270e-04 - accuracy: 1.0000 - val_loss: 0.6113 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55ffa97b90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "53b7a499-ae47-488f-c53f-bb61e649d525"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d922980-0ef9-4035-c275-7db17eeb9305"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705f8d51-043b-4511-8446-490892e525fd"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6bd6d59c-f1c3-4921-9347-1d98aebf1790"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c0f99891-bdee-4904-bfca-28f59fec3ba2\", \"DenseNet201_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}