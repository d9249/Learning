{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB1_5_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB1_5_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac3f490-bd32-46dc-b8ea-d6d6bb7941d8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 28 18:43:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5351b710-ff1c-4d5c-c95b-48c04e7addb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '1'\n",
        "model_save = 'EfficientNetB' + nunbering + '_5'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB1(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3bc460-9b7a-4bc0-c672-a82aca9c5991"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069bcd9f-62be-4519-d1cd-ca1205a43b3f"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 61s 136ms/step - loss: 3.4016 - accuracy: 0.1095 - val_loss: 2.6763 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 2.2815 - accuracy: 0.1995 - val_loss: 4.6767 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09459 to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 1.9349 - accuracy: 0.3411 - val_loss: 3.2344 - val_accuracy: 0.1149\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.11486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.5374 - accuracy: 0.4816 - val_loss: 2.0388 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.11486 to 0.45946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 1.2179 - accuracy: 0.6063 - val_loss: 1.6078 - val_accuracy: 0.5135\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.45946 to 0.51351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 1.0462 - accuracy: 0.6632 - val_loss: 1.0904 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.51351 to 0.66216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.8500 - accuracy: 0.7332 - val_loss: 1.2437 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.66216\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.7938 - accuracy: 0.7495 - val_loss: 4.7624 - val_accuracy: 0.1622\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.66216\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.7123 - accuracy: 0.7621 - val_loss: 0.6856 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.66216 to 0.77703, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.6024 - accuracy: 0.8168 - val_loss: 0.4270 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.77703 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.5923 - accuracy: 0.8079 - val_loss: 0.3767 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.85135 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.5644 - accuracy: 0.8253 - val_loss: 0.8618 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.86486\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.4867 - accuracy: 0.8442 - val_loss: 0.5827 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.86486\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.5024 - accuracy: 0.8405 - val_loss: 0.7562 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.86486\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.4666 - accuracy: 0.8505 - val_loss: 0.7245 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.86486\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.4075 - accuracy: 0.8653 - val_loss: 0.8242 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.86486\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.4183 - accuracy: 0.8689 - val_loss: 0.5517 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.86486\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.4245 - accuracy: 0.8611 - val_loss: 0.8166 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.86486\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3817 - accuracy: 0.8753 - val_loss: 0.4370 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.86486 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3684 - accuracy: 0.8842 - val_loss: 0.5629 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89189\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3283 - accuracy: 0.8989 - val_loss: 0.5752 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.89189\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3235 - accuracy: 0.8989 - val_loss: 0.3297 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89189\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.3737 - accuracy: 0.8816 - val_loss: 0.4490 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89189\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3085 - accuracy: 0.9005 - val_loss: 0.5232 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89189\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.3031 - accuracy: 0.8995 - val_loss: 0.5789 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89189\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.3040 - accuracy: 0.9000 - val_loss: 0.4717 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89189\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2633 - accuracy: 0.9116 - val_loss: 0.8637 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89189\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2779 - accuracy: 0.9158 - val_loss: 0.9421 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89189\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2863 - accuracy: 0.9105 - val_loss: 0.7838 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89189\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2481 - accuracy: 0.9211 - val_loss: 6.8567 - val_accuracy: 0.1216\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.89189\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2434 - accuracy: 0.9268 - val_loss: 0.7328 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89189\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2197 - accuracy: 0.9295 - val_loss: 0.8532 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89189\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2312 - accuracy: 0.9247 - val_loss: 8.6626 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89189\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2703 - accuracy: 0.9100 - val_loss: 0.4335 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89189\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2024 - accuracy: 0.9374 - val_loss: 0.9328 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89189\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.2172 - accuracy: 0.9274 - val_loss: 0.9391 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89189\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1918 - accuracy: 0.9416 - val_loss: 0.5008 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89189\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1881 - accuracy: 0.9384 - val_loss: 0.3069 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.89189 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1652 - accuracy: 0.9479 - val_loss: 0.4697 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91892\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1674 - accuracy: 0.9437 - val_loss: 0.5920 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91892\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1856 - accuracy: 0.9421 - val_loss: 0.3557 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91892\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1758 - accuracy: 0.9489 - val_loss: 4.1435 - val_accuracy: 0.3041\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91892\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1763 - accuracy: 0.9463 - val_loss: 0.6938 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91892\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1460 - accuracy: 0.9568 - val_loss: 0.6093 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91892\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1561 - accuracy: 0.9516 - val_loss: 2.4442 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91892\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1963 - accuracy: 0.9358 - val_loss: 0.6479 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91892\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1587 - accuracy: 0.9453 - val_loss: 0.5182 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91892\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1694 - accuracy: 0.9468 - val_loss: 1.4862 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91892\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1659 - accuracy: 0.9468 - val_loss: 0.6011 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91892\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1445 - accuracy: 0.9500 - val_loss: 6.1251 - val_accuracy: 0.1824\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91892\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1328 - accuracy: 0.9558 - val_loss: 0.6269 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91892\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1181 - accuracy: 0.9653 - val_loss: 1.7295 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91892\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1177 - accuracy: 0.9626 - val_loss: 2.5410 - val_accuracy: 0.5541\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91892\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1290 - accuracy: 0.9595 - val_loss: 0.7720 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1256 - accuracy: 0.9568 - val_loss: 0.5341 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1336 - accuracy: 0.9574 - val_loss: 0.3899 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1076 - accuracy: 0.9621 - val_loss: 0.5109 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1127 - accuracy: 0.9684 - val_loss: 0.6947 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1060 - accuracy: 0.9668 - val_loss: 0.4398 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1026 - accuracy: 0.9689 - val_loss: 0.4675 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0942 - accuracy: 0.9721 - val_loss: 1.3547 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1330 - accuracy: 0.9574 - val_loss: 0.7061 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1151 - accuracy: 0.9595 - val_loss: 0.3375 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0956 - accuracy: 0.9726 - val_loss: 3.5520 - val_accuracy: 0.4189\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1096 - accuracy: 0.9637 - val_loss: 0.3362 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0828 - accuracy: 0.9742 - val_loss: 0.2292 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00066: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0878 - accuracy: 0.9732 - val_loss: 0.2616 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.92568\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1094 - accuracy: 0.9626 - val_loss: 1.9226 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.92568\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1034 - accuracy: 0.9705 - val_loss: 0.7659 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.92568\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0948 - accuracy: 0.9705 - val_loss: 0.5595 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.92568\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0906 - accuracy: 0.9732 - val_loss: 0.7857 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.92568\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0730 - accuracy: 0.9758 - val_loss: 0.4427 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.92568\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1014 - accuracy: 0.9726 - val_loss: 0.4001 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.92568\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0778 - accuracy: 0.9737 - val_loss: 0.5384 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0964 - accuracy: 0.9726 - val_loss: 0.4512 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0970 - accuracy: 0.9674 - val_loss: 3.2899 - val_accuracy: 0.4122\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0970 - accuracy: 0.9679 - val_loss: 1.9492 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0867 - accuracy: 0.9737 - val_loss: 0.6096 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0655 - accuracy: 0.9795 - val_loss: 0.5839 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0770 - accuracy: 0.9747 - val_loss: 0.3890 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0686 - accuracy: 0.9800 - val_loss: 0.5794 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0795 - accuracy: 0.9753 - val_loss: 0.5713 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1066 - accuracy: 0.9689 - val_loss: 1.2817 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.5679 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.9272 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 0.6426 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.1013 - accuracy: 0.9663 - val_loss: 0.9617 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 0.6608 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0657 - accuracy: 0.9774 - val_loss: 0.5896 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.4662 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.4776 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0599 - accuracy: 0.9805 - val_loss: 0.5997 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0721 - accuracy: 0.9779 - val_loss: 0.4551 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0943 - accuracy: 0.9742 - val_loss: 2.0697 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.1037 - accuracy: 0.9674 - val_loss: 0.6624 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0540 - accuracy: 0.9784 - val_loss: 2.2671 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.5198 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0692 - accuracy: 0.9821 - val_loss: 0.4351 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0553 - accuracy: 0.9826 - val_loss: 0.6016 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.7375 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 0.4715 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.6584 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0933 - accuracy: 0.9674 - val_loss: 0.6125 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0636 - accuracy: 0.9784 - val_loss: 0.5486 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0480 - accuracy: 0.9863 - val_loss: 0.5249 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.3201 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0691 - accuracy: 0.9774 - val_loss: 0.4584 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0564 - accuracy: 0.9842 - val_loss: 0.5726 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92568\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0326 - accuracy: 0.9916 - val_loss: 0.8839 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92568\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0589 - accuracy: 0.9805 - val_loss: 0.8440 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92568\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0744 - accuracy: 0.9795 - val_loss: 0.4423 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92568\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0729 - accuracy: 0.9758 - val_loss: 0.4413 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92568\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.8557 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92568\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0627 - accuracy: 0.9826 - val_loss: 0.5346 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92568\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0360 - accuracy: 0.9895 - val_loss: 0.5209 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92568\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.3687 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92568\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0912 - accuracy: 0.9747 - val_loss: 0.5140 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92568\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 0.6542 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92568\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0621 - accuracy: 0.9821 - val_loss: 0.6323 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92568\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0506 - accuracy: 0.9858 - val_loss: 0.8521 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92568\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.4555 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92568\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.7037 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92568\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.3309 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92568\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.5941 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92568\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.6071 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92568\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.5696 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92568\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.6731 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92568\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.4885 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92568\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.4298 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92568\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0380 - accuracy: 0.9900 - val_loss: 0.7379 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92568\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.6672 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92568\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 0.5870 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.92568\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.6946 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.92568\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.5211 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.92568\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 0.3688 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00135: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0530 - accuracy: 0.9847 - val_loss: 0.6983 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 4.1133 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 7.7280 - val_accuracy: 0.1351\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0609 - accuracy: 0.9837 - val_loss: 0.4135 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.6699 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.6366 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.7380 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 0.4704 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.7289 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0503 - accuracy: 0.9853 - val_loss: 0.6618 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0464 - accuracy: 0.9863 - val_loss: 0.5615 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.5421 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.4733 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 0.5918 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 1.4944 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.5379 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.5851 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.6470 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.9013 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.6728 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.6109 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.5354 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.7181 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0462 - accuracy: 0.9874 - val_loss: 0.5038 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.5378 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.6643 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.8110 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.6442 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.6353 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 0.6409 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.3942 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0501 - accuracy: 0.9879 - val_loss: 0.5961 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.6240 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.6810 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.8277 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.4905 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0246 - accuracy: 0.9905 - val_loss: 0.4800 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.8062 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0301 - accuracy: 0.9889 - val_loss: 0.7597 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.5563 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0301 - accuracy: 0.9932 - val_loss: 0.6350 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0354 - accuracy: 0.9868 - val_loss: 0.8138 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0537 - accuracy: 0.9858 - val_loss: 0.4432 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.6714 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.7984 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.6530 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.7706 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.7818 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0378 - accuracy: 0.9853 - val_loss: 0.5304 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0524 - accuracy: 0.9821 - val_loss: 0.5311 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0634 - accuracy: 0.9763 - val_loss: 0.5425 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.5063 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0229 - accuracy: 0.9905 - val_loss: 0.3920 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.5852 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4515 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4912 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0277 - accuracy: 0.9874 - val_loss: 0.9648 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.5397 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0219 - accuracy: 0.9905 - val_loss: 0.3883 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.3669 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.4672 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0343 - accuracy: 0.9868 - val_loss: 0.6714 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 2.9352 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.5175 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5536 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4867 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.5419 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.7722 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0520 - accuracy: 0.9863 - val_loss: 0.6530 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0578 - accuracy: 0.9826 - val_loss: 0.7470 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.4743 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.5403 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.6682 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.5719 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.6504 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0204 - accuracy: 0.9911 - val_loss: 0.5578 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0483 - accuracy: 0.9805 - val_loss: 0.6288 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.4371 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0421 - accuracy: 0.9889 - val_loss: 0.7188 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.8439 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.7017 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.6398 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.9198 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.5849 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.4863 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.9231 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.6809 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.8236 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.4707 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0319 - accuracy: 0.9853 - val_loss: 0.5298 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.6038 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.5257 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.5520 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 3.1163 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.8320 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0340 - accuracy: 0.9895 - val_loss: 0.3811 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.4351 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.3862 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.4959 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0160 - accuracy: 0.9932 - val_loss: 0.6050 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.5246 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.8726 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 1.0338 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 2.6317 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.6410 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.6605 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.5389 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.6984 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.5693 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.6246 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.5082 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0361 - accuracy: 0.9926 - val_loss: 0.7315 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.6746 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.7727 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0331 - accuracy: 0.9916 - val_loss: 0.6393 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 0.5975 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.6444 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.7359 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.8033 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.6048 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 1.0788 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.5633 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.7964 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 0.4140 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.8181 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.6387 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.7797 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.5352 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.6679 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6376 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.8097 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.5783 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.6841 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 0.5318 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4281 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.5200 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93919\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.6954 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93919\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.5405 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93919\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5433 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93919\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.7716 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93919\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0591 - accuracy: 0.9853 - val_loss: 0.6204 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93919\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5608 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93919\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.6877 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93919\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.5778 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93919\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.9767 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93919\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.7226 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0171 - accuracy: 0.9921 - val_loss: 0.7209 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.7403 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.4619 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0198 - accuracy: 0.9911 - val_loss: 0.4846 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.5799 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.5498 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.6132 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.7069 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.6933 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93919\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.9298 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93919\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0464 - accuracy: 0.9884 - val_loss: 0.5926 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93919\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.4876 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93919\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.6637 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93919\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.7699 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93919\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.7499 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93919\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.5349 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93919\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0382 - accuracy: 0.9921 - val_loss: 0.6340 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93919\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.5803 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93919\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.5515 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93919\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.3816 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93919\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.6125 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93919\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4240 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93919\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.6702 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93919\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.5565 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93919\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.6419 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93919\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.6489 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93919\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.6819 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93919\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.5223 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93919\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.8689 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93919\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.5633 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93919\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.5166 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93919\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.5790 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93919\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.8165 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93919\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5528 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93919\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0301 - accuracy: 0.9889 - val_loss: 0.8173 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93919\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0391 - accuracy: 0.9921 - val_loss: 0.7977 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93919\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0303 - accuracy: 0.9932 - val_loss: 0.7105 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93919\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.7381 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93919\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.5482 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93919\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4399 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93919\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.4844 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93919\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4809 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93919\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.4742 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93919\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.4926 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93919\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.4424 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93919\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.5078 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93919\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.6971 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93919\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.5557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93919\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.6020 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93919\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.4359 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93919\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0599 - accuracy: 0.9884 - val_loss: 0.4028 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93919\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.3367 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93919\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4808 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93919\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.5071 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93919\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.4888 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93919\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.3266 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93919\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.3187 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93919\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.2581 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00339: val_accuracy improved from 0.93919 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB1_5.h5\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.9671 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95946\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.4865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95946\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.6369 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95946\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.5376 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95946\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.5310 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95946\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.9375 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95946\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.6685 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95946\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.4277 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95946\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.4349 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95946\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4443 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95946\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 0.5669 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95946\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7381 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95946\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.4318 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95946\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.6670 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95946\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.6236 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95946\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.4411 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95946\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0202 - accuracy: 0.9911 - val_loss: 0.5307 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95946\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5138 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95946\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.7115 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95946\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0108 - accuracy: 0.9942 - val_loss: 0.6420 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95946\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.7244 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95946\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.6687 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95946\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.4572 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95946\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.6349 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95946\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 0.7845 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95946\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0339 - accuracy: 0.9921 - val_loss: 0.7450 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95946\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.6813 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95946\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.6832 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95946\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.6194 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95946\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.6851 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95946\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.6743 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95946\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.4294 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95946\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.7945 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95946\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.7330 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95946\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.7478 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95946\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.8212 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95946\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.6849 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95946\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.6128 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95946\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.6719 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95946\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4727 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95946\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.8271 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95946\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.9035 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95946\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.7637 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95946\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.6640 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95946\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5227 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95946\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.5655 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95946\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.5369 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95946\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.5252 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95946\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.4377 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95946\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.8434 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95946\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.8293 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95946\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.6425 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95946\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0100 - accuracy: 0.9947 - val_loss: 0.4167 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95946\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5559 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95946\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.6939 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95946\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5507 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95946\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.5361 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95946\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.8826 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95946\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.7626 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95946\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.5562 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95946\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.5641 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95946\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.6522 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95946\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.6116 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95946\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.5911 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95946\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0280 - accuracy: 0.9932 - val_loss: 0.6641 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95946\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0104 - accuracy: 0.9984 - val_loss: 0.5115 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95946\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.6951 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95946\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.6802 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95946\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6979 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95946\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.7274 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95946\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.8712 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95946\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.7021 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95946\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.7249 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95946\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 3.2786 - val_accuracy: 0.5203\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95946\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.6551 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95946\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.5595 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95946\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.7098 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95946\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.7816 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95946\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.7800 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95946\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.5682 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95946\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.7082 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95946\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.8067 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95946\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.5650 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95946\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.5238 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95946\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0148 - accuracy: 0.9932 - val_loss: 0.4886 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95946\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0120 - accuracy: 0.9942 - val_loss: 0.7796 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95946\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.7527 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95946\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 0.5717 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95946\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.5219 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95946\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.6272 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95946\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95946\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4481 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95946\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.8406 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95946\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.8202 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95946\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.7619 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95946\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0190 - accuracy: 0.9916 - val_loss: 0.8125 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95946\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.7955 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95946\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.4928 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95946\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.5854 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95946\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5976 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95946\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.6146 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95946\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.7834 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95946\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.4965 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95946\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.7831 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95946\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 1.3505 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95946\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.6202 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95946\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.7725 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95946\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5866 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95946\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.5540 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95946\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.6532 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95946\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.6193 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95946\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5872 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95946\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.8059 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95946\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.7665 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95946\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.6233 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95946\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.5561 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95946\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5603 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95946\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.7010 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95946\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.7608 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95946\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.7313 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95946\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7675 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95946\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.8538 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95946\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.7489 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95946\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0318 - accuracy: 0.9916 - val_loss: 0.7345 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95946\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.8457 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95946\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.7520 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95946\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.7970 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95946\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0306 - accuracy: 0.9932 - val_loss: 0.6232 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95946\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.7470 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95946\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.8123 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95946\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.7693 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95946\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.8142 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95946\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.6087 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95946\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.5275 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95946\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6323 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95946\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.5340 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95946\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.5280 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95946\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.6899 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95946\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.4551 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95946\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.5579 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.7264 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.7449 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.7008 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.5821 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 33s 136ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6845 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 33s 137ms/step - loss: 0.0139 - accuracy: 0.9942 - val_loss: 0.6505 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.4496 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.5976 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5586 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.7632 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.7972 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.4864 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5901 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.4196 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.5902 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5178 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.5717 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.9116 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.8731 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.7277 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.6551 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f845f7cea90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "822e063e-af70-49ee-d0df-b3263570a592"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9fcc69-974f-4c13-96d0-ea72b667e0e4"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5946bdb7-4351-417e-ec8d-191260ea565c"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ed9b2db2-cd47-4a27-b43d-769107c82d7a"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_aee83a61-e557-4a10-8102-bbef53278edb\", \"EfficientNetB1_5.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12268d0c-bb8b-4162-e2ba-abf5d0809bfe"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e969f8a1-5177-488d-c57e-88ff008c68c1"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
          ]
        }
      ]
    }
  ]
}