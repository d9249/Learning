{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB3_3_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB3_3_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458c874a-066e-4c3c-87a0-e2dfdceafadf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 16:06:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a72e4d0-9621-4685-d894-8f7bdb393e21"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '3'\n",
        "model_save = 'EfficientNetB' + nunbering + '_3'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b2d993-2d0f-4e36-b8b1-d04c41ceb16e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deabeec5-aa7d-4b4d-dd59-2205a4e6835b"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 62s 143ms/step - loss: 3.4946 - accuracy: 0.1489 - val_loss: 3.3984 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 2.1696 - accuracy: 0.2526 - val_loss: 2.9965 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 1.8920 - accuracy: 0.3463 - val_loss: 2.5765 - val_accuracy: 0.0811\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10135\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 1.5075 - accuracy: 0.4795 - val_loss: 1.1498 - val_accuracy: 0.5878\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10135 to 0.58784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 1.2194 - accuracy: 0.5921 - val_loss: 0.7546 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.58784 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 1.0172 - accuracy: 0.6663 - val_loss: 0.8746 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73649\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.9216 - accuracy: 0.6979 - val_loss: 1.1128 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73649\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.7696 - accuracy: 0.7616 - val_loss: 0.8283 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.73649\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.6939 - accuracy: 0.7779 - val_loss: 0.9770 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.73649 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.6434 - accuracy: 0.7847 - val_loss: 1.3347 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.74324\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.5865 - accuracy: 0.8074 - val_loss: 2.3068 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.74324\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.5891 - accuracy: 0.8126 - val_loss: 0.5213 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.74324 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.5239 - accuracy: 0.8311 - val_loss: 0.8362 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.81757\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4931 - accuracy: 0.8426 - val_loss: 0.7576 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.81757\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.5012 - accuracy: 0.8437 - val_loss: 0.5726 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.81757\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4732 - accuracy: 0.8511 - val_loss: 0.3961 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.81757 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.4520 - accuracy: 0.8674 - val_loss: 0.7333 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87162\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4247 - accuracy: 0.8642 - val_loss: 0.4611 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87162\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4335 - accuracy: 0.8626 - val_loss: 0.5389 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4372 - accuracy: 0.8637 - val_loss: 0.8300 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.4108 - accuracy: 0.8726 - val_loss: 0.5746 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87162\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3717 - accuracy: 0.8816 - val_loss: 0.4677 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3981 - accuracy: 0.8758 - val_loss: 0.6842 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3299 - accuracy: 0.8953 - val_loss: 0.5801 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3500 - accuracy: 0.8984 - val_loss: 0.5332 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3552 - accuracy: 0.8837 - val_loss: 0.4615 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3072 - accuracy: 0.9116 - val_loss: 0.5098 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.3089 - accuracy: 0.9032 - val_loss: 1.2053 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87162\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2898 - accuracy: 0.9074 - val_loss: 0.5141 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.87162 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.2712 - accuracy: 0.9211 - val_loss: 0.4797 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87838\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2873 - accuracy: 0.9111 - val_loss: 3.2696 - val_accuracy: 0.3446\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87838\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2491 - accuracy: 0.9232 - val_loss: 0.5568 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87838\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2499 - accuracy: 0.9232 - val_loss: 2.5827 - val_accuracy: 0.4527\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87838\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2543 - accuracy: 0.9195 - val_loss: 0.6490 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87838\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2243 - accuracy: 0.9300 - val_loss: 0.3920 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.87838 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2359 - accuracy: 0.9247 - val_loss: 0.2046 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.91216 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2450 - accuracy: 0.9137 - val_loss: 0.9273 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.95270\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2106 - accuracy: 0.9326 - val_loss: 0.3502 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.95270\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.2570 - accuracy: 0.9237 - val_loss: 0.4301 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.95270\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1999 - accuracy: 0.9337 - val_loss: 0.7042 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.95270\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1888 - accuracy: 0.9426 - val_loss: 0.5246 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.95270\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1869 - accuracy: 0.9363 - val_loss: 0.3722 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.95270\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1921 - accuracy: 0.9411 - val_loss: 0.4408 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.95270\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1851 - accuracy: 0.9395 - val_loss: 0.4706 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.95270\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1658 - accuracy: 0.9447 - val_loss: 0.4143 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.95270\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1740 - accuracy: 0.9411 - val_loss: 0.5660 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.95270\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1743 - accuracy: 0.9432 - val_loss: 0.7243 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.95270\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1485 - accuracy: 0.9500 - val_loss: 0.5475 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.95270\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1586 - accuracy: 0.9500 - val_loss: 0.6450 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.95270\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1601 - accuracy: 0.9463 - val_loss: 0.4233 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.95270\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1693 - accuracy: 0.9442 - val_loss: 0.5223 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.95270\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1583 - accuracy: 0.9511 - val_loss: 0.4185 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.95270\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1685 - accuracy: 0.9463 - val_loss: 0.4253 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.95270\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1195 - accuracy: 0.9611 - val_loss: 0.7034 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.95270\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1667 - accuracy: 0.9479 - val_loss: 0.3428 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.95270\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1088 - accuracy: 0.9689 - val_loss: 0.8072 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.95270\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1513 - accuracy: 0.9542 - val_loss: 0.4585 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.95270\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1355 - accuracy: 0.9553 - val_loss: 0.3138 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.95270\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0976 - accuracy: 0.9679 - val_loss: 0.5219 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.95270\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1274 - accuracy: 0.9584 - val_loss: 0.4016 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.95270\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0826 - accuracy: 0.9732 - val_loss: 0.5848 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.95270\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1335 - accuracy: 0.9605 - val_loss: 0.5224 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.95270\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1205 - accuracy: 0.9658 - val_loss: 0.3298 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.95270\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0937 - accuracy: 0.9705 - val_loss: 0.3990 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.95270\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1094 - accuracy: 0.9668 - val_loss: 0.4008 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.95270\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1094 - accuracy: 0.9626 - val_loss: 0.2702 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.95270\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1226 - accuracy: 0.9589 - val_loss: 0.5527 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.95270\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1014 - accuracy: 0.9679 - val_loss: 0.4088 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.95270\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1164 - accuracy: 0.9689 - val_loss: 0.3615 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.95270\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1077 - accuracy: 0.9642 - val_loss: 0.6438 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.95270\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0723 - accuracy: 0.9747 - val_loss: 0.3498 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.95270\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1065 - accuracy: 0.9642 - val_loss: 0.4407 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.95270\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0900 - accuracy: 0.9721 - val_loss: 1.2140 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.95270\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0989 - accuracy: 0.9653 - val_loss: 0.4463 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.95270\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.1068 - accuracy: 0.9647 - val_loss: 0.4366 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.95270\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0788 - accuracy: 0.9721 - val_loss: 0.8981 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.95270\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1262 - accuracy: 0.9589 - val_loss: 0.5886 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.95270\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0966 - accuracy: 0.9721 - val_loss: 0.2965 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.95270\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.1073 - accuracy: 0.9668 - val_loss: 0.3976 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.95270\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0545 - accuracy: 0.9842 - val_loss: 0.6187 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.95270\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0656 - accuracy: 0.9784 - val_loss: 0.5200 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.95270\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0744 - accuracy: 0.9763 - val_loss: 0.2752 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.95270\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.4043 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.95270\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0825 - accuracy: 0.9737 - val_loss: 0.4456 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.95270\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 0.4192 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.95270\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.1145 - accuracy: 0.9705 - val_loss: 0.3514 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.95270\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.2845 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.95270\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.3259 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.95270\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0932 - accuracy: 0.9716 - val_loss: 0.5524 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.95270\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0761 - accuracy: 0.9763 - val_loss: 0.3110 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.95270\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0983 - accuracy: 0.9695 - val_loss: 0.4229 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.95270\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0784 - accuracy: 0.9758 - val_loss: 0.4578 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.95270\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.5015 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.95270\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0741 - accuracy: 0.9763 - val_loss: 0.4517 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.95270\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0575 - accuracy: 0.9811 - val_loss: 0.3911 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.95270\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.4783 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.95270\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0826 - accuracy: 0.9747 - val_loss: 0.2793 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.95270\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0528 - accuracy: 0.9768 - val_loss: 0.6409 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.95270\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0758 - accuracy: 0.9784 - val_loss: 0.5708 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.95270\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0726 - accuracy: 0.9795 - val_loss: 0.2801 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.95270\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.3803 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.95270\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.4017 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.95270\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 0.5266 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.95270\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0828 - accuracy: 0.9747 - val_loss: 0.3818 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.95270\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0612 - accuracy: 0.9768 - val_loss: 0.2423 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.95270\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.2818 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.95270\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0790 - accuracy: 0.9763 - val_loss: 0.4774 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.95270\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.4376 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.95270\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 0.2123 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.95270\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.4962 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.95270\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.3424 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.95270\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0451 - accuracy: 0.9837 - val_loss: 0.4935 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.95270\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 0.2906 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.95270\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0693 - accuracy: 0.9732 - val_loss: 0.4313 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.95270\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0452 - accuracy: 0.9868 - val_loss: 0.4935 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.95270\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.5896 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.95270\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.4172 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.95270\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0726 - accuracy: 0.9742 - val_loss: 0.4933 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.95270\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0573 - accuracy: 0.9800 - val_loss: 0.4409 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.95270\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.5884 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.95270\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 0.4019 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.95270\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0405 - accuracy: 0.9847 - val_loss: 0.2436 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.95270\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0387 - accuracy: 0.9889 - val_loss: 0.3514 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.95270\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.4461 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.95270\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.5917 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.95270\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0829 - accuracy: 0.9721 - val_loss: 0.4030 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.95270\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.2996 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.95270\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0424 - accuracy: 0.9847 - val_loss: 0.5299 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.95270\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.4209 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.95270\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.4295 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.95270\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 0.4587 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.95270\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.5146 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.95270\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.4419 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.95270\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.6058 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.95270\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.5668 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.95270\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0705 - accuracy: 0.9821 - val_loss: 0.4261 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.95270\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.5671 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.95270\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.5402 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.95270\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.5427 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.95270\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0816 - accuracy: 0.9747 - val_loss: 0.4994 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.95270\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.4223 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.95270\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0466 - accuracy: 0.9821 - val_loss: 0.4706 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.95270\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.5193 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.95270\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0336 - accuracy: 0.9926 - val_loss: 0.5212 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.95270\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.4596 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.95270\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0222 - accuracy: 0.9911 - val_loss: 0.6942 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.95270\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.4577 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.95270\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0651 - accuracy: 0.9816 - val_loss: 0.6434 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.95270\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0491 - accuracy: 0.9816 - val_loss: 0.5165 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.95270\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.5114 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.95270\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.3560 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.95270\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0268 - accuracy: 0.9884 - val_loss: 0.4382 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.95270\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.6762 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.95270\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.5146 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.95270\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0310 - accuracy: 0.9932 - val_loss: 0.5657 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.95270\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.4570 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.95270\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.6020 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.95270\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.5435 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95270\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0810 - accuracy: 0.9768 - val_loss: 0.4871 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.95270\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0541 - accuracy: 0.9811 - val_loss: 0.5609 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95270\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.5220 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95270\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.5000 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95270\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.4916 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.95270\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.7368 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.95270\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0628 - accuracy: 0.9795 - val_loss: 0.3833 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.95270\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.5815 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.95270\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0252 - accuracy: 0.9900 - val_loss: 0.3412 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.95270\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0751 - accuracy: 0.9805 - val_loss: 0.6854 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.95270\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.5346 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95270\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.3517 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95270\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.5450 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95270\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.4875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95270\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.6760 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.95270\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.5972 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95270\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.5232 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95270\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.7387 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95270\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.8283 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.95270\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.4257 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95270\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0557 - accuracy: 0.9837 - val_loss: 0.6310 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95270\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.6698 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95270\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.6269 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95270\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.6093 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95270\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.3955 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95270\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.6659 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95270\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.4400 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95270\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.4130 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95270\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.6821 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95270\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.4312 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95270\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0413 - accuracy: 0.9879 - val_loss: 0.4761 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95270\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.4613 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95270\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.5640 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95270\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.5229 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95270\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0525 - accuracy: 0.9874 - val_loss: 0.7152 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95270\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.6242 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95270\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.6177 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95270\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.5101 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95270\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.5078 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95270\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.4698 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95270\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0332 - accuracy: 0.9905 - val_loss: 0.6325 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95270\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0294 - accuracy: 0.9937 - val_loss: 0.4928 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95270\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.5763 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.95270\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.5768 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95270\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.3848 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95270\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.3333 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95270\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.3176 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00205: val_accuracy improved from 0.95270 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_3.h5\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.4747 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95946\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0448 - accuracy: 0.9879 - val_loss: 0.5051 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95946\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.5525 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95946\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0252 - accuracy: 0.9900 - val_loss: 0.4534 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95946\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.5517 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95946\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.4381 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95946\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.5385 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95946\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.3622 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95946\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.5143 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95946\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.5639 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95946\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.5413 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95946\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 0.4484 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.95946\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.5389 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95946\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0538 - accuracy: 0.9863 - val_loss: 0.5697 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95946\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.4890 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95946\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0372 - accuracy: 0.9858 - val_loss: 0.6226 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95946\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.6639 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95946\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0561 - accuracy: 0.9821 - val_loss: 0.6267 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95946\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0538 - accuracy: 0.9863 - val_loss: 0.4696 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95946\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.5845 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95946\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.5516 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95946\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.6990 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95946\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.6146 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95946\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0408 - accuracy: 0.9889 - val_loss: 0.7277 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95946\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.5477 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95946\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4515 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95946\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.4845 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95946\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 0.5643 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95946\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.6593 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95946\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.5554 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95946\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.6016 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95946\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.6038 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95946\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.5065 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95946\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3827 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95946\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.5399 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95946\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0382 - accuracy: 0.9916 - val_loss: 0.6868 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95946\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0378 - accuracy: 0.9911 - val_loss: 0.7896 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95946\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.4100 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95946\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 0.4536 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95946\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.6269 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95946\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.3886 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95946\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.5341 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95946\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.6038 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95946\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.7575 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95946\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0399 - accuracy: 0.9916 - val_loss: 0.8465 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95946\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.6675 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95946\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.3610 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95946\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.4613 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95946\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.4042 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95946\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.2994 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95946\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.4898 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95946\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.6201 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95946\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0230 - accuracy: 0.9905 - val_loss: 0.5872 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95946\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.4728 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95946\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.6295 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95946\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5361 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95946\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.6069 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95946\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5070 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95946\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.5387 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95946\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.5592 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95946\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0175 - accuracy: 0.9926 - val_loss: 0.5256 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95946\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 0.6376 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95946\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.7748 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95946\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.5462 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95946\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.4762 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95946\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.5315 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95946\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.4579 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95946\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4747 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95946\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0163 - accuracy: 0.9968 - val_loss: 0.7405 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95946\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0501 - accuracy: 0.9811 - val_loss: 0.7284 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95946\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.5390 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95946\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.5972 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95946\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.5118 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95946\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.4914 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95946\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0362 - accuracy: 0.9905 - val_loss: 0.3891 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95946\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.5386 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95946\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0209 - accuracy: 0.9958 - val_loss: 0.6008 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95946\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.8910 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95946\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.4483 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95946\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.4893 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95946\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.4197 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95946\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0498 - accuracy: 0.9921 - val_loss: 0.6801 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95946\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.3600 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95946\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.4890 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95946\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.6290 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95946\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4293 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95946\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.5256 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95946\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.6695 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95946\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.5463 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95946\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.3910 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95946\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.6007 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95946\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0261 - accuracy: 0.9932 - val_loss: 0.4760 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95946\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.4644 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95946\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.5743 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95946\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5157 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95946\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.6283 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95946\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.5732 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95946\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.7855 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95946\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 0.7483 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95946\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.6530 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95946\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.5403 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95946\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.5716 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95946\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.5626 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95946\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.4867 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95946\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 32s 136ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 1.2174 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95946\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.4815 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95946\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.7134 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95946\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.4689 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95946\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.5228 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95946\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.5867 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95946\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.5807 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95946\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.5934 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95946\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.5994 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95946\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.4937 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95946\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.4615 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95946\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.5501 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95946\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.5325 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95946\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.5245 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95946\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6333 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95946\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.6160 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95946\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.7250 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95946\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.3871 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95946\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.5098 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95946\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.6074 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95946\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 0.6014 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95946\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5078 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95946\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0138 - accuracy: 0.9932 - val_loss: 0.6273 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95946\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.4884 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95946\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.4900 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95946\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.5220 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95946\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.5301 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95946\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.6022 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95946\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3312 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95946\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.4986 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95946\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.6823 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95946\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6175 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95946\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.4301 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95946\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.7154 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95946\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6128 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95946\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4976 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95946\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.3947 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95946\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.4399 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95946\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.4315 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95946\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.3842 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95946\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.7287 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95946\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.5940 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95946\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.4604 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95946\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.6297 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95946\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.4607 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95946\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4768 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95946\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.4949 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95946\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.6952 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95946\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.7451 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95946\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.8196 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95946\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.5539 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95946\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.5005 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95946\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.4054 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95946\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.9591 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95946\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5216 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95946\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.7312 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95946\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.6994 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95946\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 0.5878 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95946\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.6752 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95946\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.4213 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95946\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5038 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95946\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6461 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95946\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.7995 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95946\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.8091 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95946\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0158 - accuracy: 0.9979 - val_loss: 0.5690 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95946\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.4465 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95946\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.7123 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95946\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.5686 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95946\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.7355 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95946\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6181 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95946\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.5317 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95946\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0190 - accuracy: 0.9911 - val_loss: 0.5403 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95946\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.6221 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95946\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4521 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95946\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.5412 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95946\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.6870 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95946\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0302 - accuracy: 0.9932 - val_loss: 0.6194 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95946\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.3215 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95946\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.4417 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95946\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5622 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95946\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.5842 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95946\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.8263 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95946\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.6824 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95946\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.6735 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95946\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.8227 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95946\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.7080 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95946\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.7069 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95946\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.4372 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95946\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4181 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95946\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 0.7591 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95946\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0205 - accuracy: 0.9916 - val_loss: 0.3913 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95946\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.4850 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95946\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.7717 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95946\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.5510 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95946\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.3764 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95946\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.6827 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95946\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 0.4993 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95946\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.7063 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95946\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4496 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95946\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0087 - accuracy: 0.9958 - val_loss: 0.5761 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95946\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.4506 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95946\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.6473 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95946\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.3917 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95946\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0104 - accuracy: 0.9947 - val_loss: 0.6099 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95946\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.6976 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95946\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.5087 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95946\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.6322 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95946\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.7331 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95946\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.7495 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95946\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0178 - accuracy: 0.9926 - val_loss: 0.6107 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95946\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.4119 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95946\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.6695 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95946\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.5733 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95946\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.7380 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95946\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.6017 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95946\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.6972 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95946\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.6045 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95946\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.6281 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95946\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.6026 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95946\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.6612 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95946\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.6122 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95946\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0145 - accuracy: 0.9937 - val_loss: 0.6033 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95946\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.5532 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95946\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.5675 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95946\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.4041 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95946\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.5598 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95946\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3557 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95946\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.5562 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95946\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.4811 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95946\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.5573 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95946\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.6644 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95946\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 0.5218 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95946\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.5506 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95946\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.6131 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95946\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.5827 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95946\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 1.0544 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95946\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.5115 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95946\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.4504 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95946\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.5393 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95946\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3172 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95946\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 0.6647 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95946\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.6434 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95946\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.7160 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95946\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0121 - accuracy: 0.9942 - val_loss: 0.7023 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95946\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.6542 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95946\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5440 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95946\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.5402 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95946\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.7298 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95946\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.3503 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95946\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.6955 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95946\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5328 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95946\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4909 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95946\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.6792 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95946\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.6665 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95946\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.5141 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95946\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.5492 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95946\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.8452 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95946\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.7297 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95946\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.7664 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95946\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0530 - accuracy: 0.9895 - val_loss: 0.5570 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95946\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.5217 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95946\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.7492 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95946\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.6328 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95946\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.4645 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95946\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.7748 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95946\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.6939 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95946\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.8103 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95946\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.8531 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95946\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.5852 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95946\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.5275 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.7426 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.5417 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.5806 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.6990 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.4727 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.5704 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.6013 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.7173 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5764 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.4940 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.4944 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0110 - accuracy: 0.9947 - val_loss: 0.6167 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.5921 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.5140 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.3042 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.5837 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0338 - accuracy: 0.9916 - val_loss: 0.7489 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.7703 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5396 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.5741 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4968 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcbf650d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "395259c9-7e55-4d03-c036-64159a222030"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6284b2f7-ee36-4bab-9dc1-81d19b9558b9"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7766a2b2-c9e9-4565-dc0d-aa01d539d2de"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dadf99ef-aa8a-42fd-fc6b-b7d852a35a22"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b8ae6f3d-ea69-4eea-aed3-99e8d72373d0\", \"EfficientNetB3_3.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}