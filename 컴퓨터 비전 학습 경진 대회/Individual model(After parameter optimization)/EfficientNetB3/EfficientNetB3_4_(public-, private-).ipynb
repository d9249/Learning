{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB3_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB3_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c6f18e-a03b-4a83-b3a4-73bb788f67c6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 16:06:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8f7758-c439-4d37-a910-155e85ab7413"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '3'\n",
        "model_save = 'EfficientNetB' + nunbering + '_4'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658dd813-87cf-43ad-db1d-202743a970af"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f316f6-f390-44a0-e963-4c3c3c05b719"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 67s 161ms/step - loss: 3.4413 - accuracy: 0.1395 - val_loss: 2.5266 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 2.1984 - accuracy: 0.2453 - val_loss: 2.9548 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 1.8476 - accuracy: 0.3689 - val_loss: 4.0465 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10135\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 1.4189 - accuracy: 0.5184 - val_loss: 0.9058 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10135 to 0.70270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 1.1110 - accuracy: 0.6405 - val_loss: 1.6468 - val_accuracy: 0.5135\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.70270\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 1.0075 - accuracy: 0.6853 - val_loss: 1.0335 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.70270\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.8364 - accuracy: 0.7305 - val_loss: 0.9417 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.70270\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.7404 - accuracy: 0.7637 - val_loss: 0.8742 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.70270 to 0.71622, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.6955 - accuracy: 0.7768 - val_loss: 2.1870 - val_accuracy: 0.4595\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71622\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.6401 - accuracy: 0.8089 - val_loss: 1.1418 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71622\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.5560 - accuracy: 0.8274 - val_loss: 1.2969 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71622\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.5617 - accuracy: 0.8247 - val_loss: 0.4830 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.71622 to 0.81757, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.5513 - accuracy: 0.8242 - val_loss: 1.2967 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.81757\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.4985 - accuracy: 0.8447 - val_loss: 2.3431 - val_accuracy: 0.3649\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.81757\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.4752 - accuracy: 0.8521 - val_loss: 0.5247 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.81757\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.4651 - accuracy: 0.8447 - val_loss: 0.4448 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.81757 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.4276 - accuracy: 0.8626 - val_loss: 0.6304 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.86486\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.4474 - accuracy: 0.8537 - val_loss: 2.8557 - val_accuracy: 0.3919\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.86486\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.3967 - accuracy: 0.8721 - val_loss: 0.4157 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.86486 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3811 - accuracy: 0.8811 - val_loss: 0.4755 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.3960 - accuracy: 0.8832 - val_loss: 0.5117 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.87162 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3702 - accuracy: 0.8842 - val_loss: 0.4814 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87838\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3285 - accuracy: 0.9000 - val_loss: 0.4659 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87838\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3195 - accuracy: 0.8947 - val_loss: 0.4813 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87838\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3145 - accuracy: 0.9021 - val_loss: 1.2513 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87838\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3198 - accuracy: 0.9032 - val_loss: 0.4440 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.87838 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.3318 - accuracy: 0.8937 - val_loss: 0.8745 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88514\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.2897 - accuracy: 0.9021 - val_loss: 0.7681 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88514\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.2923 - accuracy: 0.9100 - val_loss: 0.6692 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88514\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.2368 - accuracy: 0.9142 - val_loss: 0.5744 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88514\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.3289 - accuracy: 0.8947 - val_loss: 0.4868 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88514\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.2276 - accuracy: 0.9274 - val_loss: 0.8824 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88514\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.2311 - accuracy: 0.9237 - val_loss: 0.4484 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88514\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 36s 150ms/step - loss: 0.2537 - accuracy: 0.9232 - val_loss: 0.3902 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88514\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.2600 - accuracy: 0.9242 - val_loss: 0.8890 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88514\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.2226 - accuracy: 0.9347 - val_loss: 0.5087 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88514\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1916 - accuracy: 0.9379 - val_loss: 0.4170 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88514\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.2522 - accuracy: 0.9211 - val_loss: 2.6179 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88514\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.2089 - accuracy: 0.9247 - val_loss: 2.1518 - val_accuracy: 0.5473\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88514\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1507 - accuracy: 0.9521 - val_loss: 0.5671 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88514\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1837 - accuracy: 0.9411 - val_loss: 0.4123 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.88514 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.1891 - accuracy: 0.9400 - val_loss: 0.4766 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89865\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.2031 - accuracy: 0.9326 - val_loss: 0.8996 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89865\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1720 - accuracy: 0.9453 - val_loss: 0.3567 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89865\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1672 - accuracy: 0.9500 - val_loss: 0.5339 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89865\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1797 - accuracy: 0.9442 - val_loss: 1.1340 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89865\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1326 - accuracy: 0.9532 - val_loss: 0.6224 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89865\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1808 - accuracy: 0.9453 - val_loss: 0.5815 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89865\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1578 - accuracy: 0.9563 - val_loss: 0.5627 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89865\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1146 - accuracy: 0.9663 - val_loss: 0.3320 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89865\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1757 - accuracy: 0.9474 - val_loss: 0.7135 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89865\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1685 - accuracy: 0.9421 - val_loss: 1.2898 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89865\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1369 - accuracy: 0.9542 - val_loss: 0.9130 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89865\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.4680 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89865\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1361 - accuracy: 0.9568 - val_loss: 0.5740 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89865\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1395 - accuracy: 0.9563 - val_loss: 0.4990 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89865\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1346 - accuracy: 0.9553 - val_loss: 0.3741 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89865\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1297 - accuracy: 0.9616 - val_loss: 1.1160 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89865\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1085 - accuracy: 0.9747 - val_loss: 1.0335 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89865\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1264 - accuracy: 0.9595 - val_loss: 0.5403 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89865\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1115 - accuracy: 0.9653 - val_loss: 0.4751 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89865\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1384 - accuracy: 0.9595 - val_loss: 0.4345 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89865\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1190 - accuracy: 0.9637 - val_loss: 0.4827 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89865\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0964 - accuracy: 0.9732 - val_loss: 0.6707 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89865\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0840 - accuracy: 0.9753 - val_loss: 0.5212 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89865\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.1438 - accuracy: 0.9553 - val_loss: 0.5004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89865\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0793 - accuracy: 0.9726 - val_loss: 0.4549 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89865\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0790 - accuracy: 0.9705 - val_loss: 0.5349 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89865\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0914 - accuracy: 0.9732 - val_loss: 0.3773 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89865\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1026 - accuracy: 0.9679 - val_loss: 0.5123 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89865\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1015 - accuracy: 0.9684 - val_loss: 0.3795 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00071: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.1142 - accuracy: 0.9600 - val_loss: 0.7485 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90541\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1243 - accuracy: 0.9637 - val_loss: 0.3027 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.90541 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0774 - accuracy: 0.9784 - val_loss: 0.4724 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 0.4975 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.4098 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0666 - accuracy: 0.9811 - val_loss: 0.4386 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0747 - accuracy: 0.9789 - val_loss: 0.5781 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1101 - accuracy: 0.9621 - val_loss: 0.6482 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.1440 - accuracy: 0.9558 - val_loss: 0.3350 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0785 - accuracy: 0.9711 - val_loss: 0.8029 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0884 - accuracy: 0.9726 - val_loss: 0.4620 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.5004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0794 - accuracy: 0.9763 - val_loss: 1.2225 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0913 - accuracy: 0.9737 - val_loss: 0.5766 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.3083 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.92568 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB3_4.h5\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0562 - accuracy: 0.9768 - val_loss: 0.5028 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.94595\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.5519 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.94595\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 0.3956 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.94595\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0798 - accuracy: 0.9758 - val_loss: 1.5283 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.94595\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 2.3210 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.94595\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0888 - accuracy: 0.9716 - val_loss: 0.5341 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.94595\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.7677 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.94595\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0832 - accuracy: 0.9763 - val_loss: 0.8113 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.94595\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0611 - accuracy: 0.9800 - val_loss: 0.4200 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.94595\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0954 - accuracy: 0.9700 - val_loss: 0.5783 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.94595\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0520 - accuracy: 0.9805 - val_loss: 0.4372 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.94595\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.4923 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.94595\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0750 - accuracy: 0.9758 - val_loss: 0.5329 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.94595\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0819 - accuracy: 0.9789 - val_loss: 0.8041 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.94595\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 0.6030 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.94595\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0772 - accuracy: 0.9742 - val_loss: 0.8031 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.94595\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 0.5254 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.94595\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0818 - accuracy: 0.9726 - val_loss: 0.6331 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.94595\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0578 - accuracy: 0.9837 - val_loss: 0.8938 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.94595\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.2914 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.94595\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0418 - accuracy: 0.9847 - val_loss: 0.6362 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.94595\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0605 - accuracy: 0.9847 - val_loss: 0.5433 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.94595\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 2.0707 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.94595\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0638 - accuracy: 0.9768 - val_loss: 0.5949 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.94595\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 1.6838 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.94595\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0617 - accuracy: 0.9842 - val_loss: 0.4949 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.94595\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.5009 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.94595\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0690 - accuracy: 0.9753 - val_loss: 0.5537 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.94595\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0555 - accuracy: 0.9795 - val_loss: 0.5352 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.94595\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0567 - accuracy: 0.9774 - val_loss: 0.4607 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.94595\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0346 - accuracy: 0.9858 - val_loss: 0.5736 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.94595\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.6296 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.94595\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.6332 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.94595\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0636 - accuracy: 0.9779 - val_loss: 0.6245 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.94595\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0696 - accuracy: 0.9768 - val_loss: 0.7988 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.94595\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.5986 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.94595\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.7314 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.94595\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.6831 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.94595\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0675 - accuracy: 0.9811 - val_loss: 0.5323 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.94595\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 0.7431 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.94595\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 1.0734 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.94595\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0430 - accuracy: 0.9879 - val_loss: 0.5922 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.94595\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.7930 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.94595\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0510 - accuracy: 0.9874 - val_loss: 0.5246 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.94595\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0474 - accuracy: 0.9868 - val_loss: 0.8699 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.94595\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0344 - accuracy: 0.9879 - val_loss: 1.0425 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.94595\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0304 - accuracy: 0.9884 - val_loss: 1.5989 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.94595\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.4793 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.94595\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 4.9194 - val_accuracy: 0.3378\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.94595\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0675 - accuracy: 0.9784 - val_loss: 0.6721 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.94595\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.4686 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.94595\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 1.0852 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.94595\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.6236 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.94595\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.6452 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.94595\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0395 - accuracy: 0.9858 - val_loss: 0.4068 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.94595\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.5807 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.94595\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0320 - accuracy: 0.9879 - val_loss: 0.5265 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94595\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 0.5574 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.94595\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 0.5351 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.94595\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0725 - accuracy: 0.9795 - val_loss: 0.7219 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.94595\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.6425 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.94595\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.9984 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.94595\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 1.1088 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.94595\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0319 - accuracy: 0.9889 - val_loss: 1.6054 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.94595\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.7300 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.94595\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0516 - accuracy: 0.9853 - val_loss: 1.1377 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.94595\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0696 - accuracy: 0.9816 - val_loss: 1.1134 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.94595\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.5015 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.94595\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.3885 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.94595\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.5235 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.94595\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0424 - accuracy: 0.9858 - val_loss: 0.5144 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.94595\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.4267 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.94595\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.5920 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.8889 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.7259 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.7056 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.4934 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0477 - accuracy: 0.9863 - val_loss: 0.5176 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.4009 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 0.5651 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.8592 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0384 - accuracy: 0.9858 - val_loss: 0.9659 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5838 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.7477 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0619 - accuracy: 0.9800 - val_loss: 0.6691 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.6016 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 1.2238 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.5160 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.5356 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0417 - accuracy: 0.9900 - val_loss: 0.5831 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.5595 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.5500 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.5238 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.5667 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 0.6229 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.5187 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.5382 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0473 - accuracy: 0.9868 - val_loss: 1.3117 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.6296 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.4735 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.4298 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 2.2118 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.7179 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 0.6172 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.6132 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.6078 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.5051 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.6305 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.6873 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.6833 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0203 - accuracy: 0.9916 - val_loss: 0.6635 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0569 - accuracy: 0.9858 - val_loss: 0.9636 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0484 - accuracy: 0.9874 - val_loss: 0.6379 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0286 - accuracy: 0.9889 - val_loss: 0.4796 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.6612 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.4346 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.5779 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.5491 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 0.5653 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.6062 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 0.5217 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.4960 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.5225 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.5505 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 1.2752 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0381 - accuracy: 0.9889 - val_loss: 0.4285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.5290 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.3622 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.5096 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.8343 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.3940 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.4384 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.6684 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.8796 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.5690 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.5645 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0347 - accuracy: 0.9874 - val_loss: 0.5598 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0381 - accuracy: 0.9900 - val_loss: 2.0342 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.5166 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 1.0737 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.4828 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.4507 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0226 - accuracy: 0.9900 - val_loss: 0.5412 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.7731 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0309 - accuracy: 0.9858 - val_loss: 0.5302 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94595\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.6496 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94595\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.7992 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94595\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.6574 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94595\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.5787 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94595\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.4797 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94595\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.5930 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94595\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0133 - accuracy: 0.9942 - val_loss: 0.7122 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94595\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.5352 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94595\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.7401 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94595\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0465 - accuracy: 0.9874 - val_loss: 0.7593 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94595\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.7726 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94595\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4784 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94595\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.7087 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94595\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.7787 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94595\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0314 - accuracy: 0.9932 - val_loss: 0.7709 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94595\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0289 - accuracy: 0.9942 - val_loss: 0.7136 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94595\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.5276 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.4232 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0191 - accuracy: 0.9926 - val_loss: 0.4560 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.5537 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0249 - accuracy: 0.9868 - val_loss: 0.5956 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.4902 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.5100 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.9029 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.5453 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.4235 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.4025 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.4802 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.5007 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.5357 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.6749 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0354 - accuracy: 0.9868 - val_loss: 2.9656 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0317 - accuracy: 0.9863 - val_loss: 1.2935 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 1.6869 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.5335 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5050 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.5656 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.3615 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.5314 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.6703 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0244 - accuracy: 0.9905 - val_loss: 0.7974 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.5796 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.6712 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.7004 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.5607 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 1.0289 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 1.0322 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.7395 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.5862 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.4787 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.7665 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.6627 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0404 - accuracy: 0.9905 - val_loss: 0.6676 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 0.9386 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 1.0805 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.6884 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.6491 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.5395 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0301 - accuracy: 0.9916 - val_loss: 0.5963 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.6292 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.9163 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.6393 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0157 - accuracy: 0.9926 - val_loss: 0.6735 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.5474 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.5859 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.6002 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.4959 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.6407 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.4745 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.8669 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5880 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5653 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.5966 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.8822 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.7408 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 2.9615 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.6378 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.8346 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.7227 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.7539 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 1.8454 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.6359 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.6526 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.4569 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.6966 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.6933 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.5767 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.5995 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 0.4819 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.7713 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 36s 152ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 1.6260 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.7626 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.6298 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.5059 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.7897 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.7633 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.6579 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.7067 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.8181 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.4819 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.5671 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.9026 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.5285 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.7822 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.7614 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.8236 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.7281 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 1.0317 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.8453 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0320 - accuracy: 0.9926 - val_loss: 0.5797 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.5613 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.4553 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.7164 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.6636 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5589 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.6720 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 1.0705 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 1.2388 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0308 - accuracy: 0.9874 - val_loss: 0.8213 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0253 - accuracy: 0.9953 - val_loss: 0.5398 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.6208 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0380 - accuracy: 0.9889 - val_loss: 0.6899 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0173 - accuracy: 0.9926 - val_loss: 0.4687 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0105 - accuracy: 0.9947 - val_loss: 0.6004 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.8002 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.6696 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6324 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0147 - accuracy: 0.9926 - val_loss: 0.5743 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0269 - accuracy: 0.9895 - val_loss: 0.5230 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.5865 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.5265 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.4731 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.4874 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5112 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.4397 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.5752 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.5089 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.4471 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.8088 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.7705 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.4891 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.7794 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.6091 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.6665 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.6442 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.6424 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.6171 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.7088 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.7093 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.8364 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 1.0318 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 2.4145 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.6568 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.7662 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.7485 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.7900 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 0.8353 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.9400 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.8256 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.8126 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0174 - accuracy: 0.9921 - val_loss: 0.7173 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 1.2417 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.8642 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.9746 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0237 - accuracy: 0.9953 - val_loss: 0.7155 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0233 - accuracy: 0.9953 - val_loss: 0.8148 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.6843 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.7541 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7688 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.7204 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.8217 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.5785 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.6781 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 0.7581 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.7743 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.9268 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.7866 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.5804 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.7543 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.8175 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.7939 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.6268 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0270 - accuracy: 0.9942 - val_loss: 0.9753 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 0.7364 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 1.0157 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.5427 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.7367 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.8811 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 2.3421 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.6043 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.5414 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.7470 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 1.2631 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0160 - accuracy: 0.9926 - val_loss: 0.6648 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 36s 153ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.9072 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 37s 153ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.8683 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.8080 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.6370 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.8108 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.7741 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 1.0212 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.7285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4633 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4005 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.7740 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0277 - accuracy: 0.9942 - val_loss: 0.7846 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.7406 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.8253 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.6162 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5733 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6874 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.5856 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.5199 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5298 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.7071 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.7063 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.7852 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.7302 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.6045 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.7481 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6020 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.8525 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.5914 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 0.5721 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.6157 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.7015 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6302 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.8922 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0073 - accuracy: 0.9958 - val_loss: 0.6287 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.9089 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.8846 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.6211 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.7681 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 2.3887 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.6232 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.6823 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5587 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.8929 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.8492 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.8167 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.6045 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.5825 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0185 - accuracy: 0.9926 - val_loss: 0.7835 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.6345 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5614 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.6070 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.6042 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 2.9092 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.4273 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.6023 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.5782 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.9080 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.5766 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.6034 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6077 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.5852 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 1.2469 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.8241 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.7952 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.7285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.6097 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.5415 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94595\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 0.6718 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94595\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.7865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94595\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.7880 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94595\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.8819 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94595\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.7240 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94595\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.7514 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94595\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 37s 156ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.3733 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feeca4edd10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3df64844-898b-4195-dda7-dceb06e5322e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed052f6c-dbcc-4107-e5bf-80eac3ba7976"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e3da51-366b-4c6c-bcec-8e32ae10064d"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "44dbf1bb-0b55-4e51-c3dd-6820b75577be"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_522dfe25-1182-47c6-af46-f786f046e200\", \"EfficientNetB3_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}