{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB4_1_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB4_1_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb683f1-c62c-41ec-df9c-cc3ff2bf0d26"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 05:13:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b8ca04-e9c6-45d1-96d4-836f6360469b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '4'\n",
        "model_save = 'EfficientNetB' + nunbering + '_1'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32e9818-d86d-4ce2-eb81-1df9bad9c86e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54e44cf-3253-494a-8b39-3298df8f74fb"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 56s 122ms/step - loss: 3.2626 - accuracy: 0.1505 - val_loss: 2.8298 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 2.2372 - accuracy: 0.2216 - val_loss: 5.1424 - val_accuracy: 0.0946\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09459\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.8305 - accuracy: 0.3774 - val_loss: 3.0240 - val_accuracy: 0.1351\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.09459 to 0.13514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 1.4457 - accuracy: 0.5189 - val_loss: 1.8817 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.13514 to 0.47973, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.1320 - accuracy: 0.6268 - val_loss: 0.9366 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.47973 to 0.66892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 1.0050 - accuracy: 0.6821 - val_loss: 1.1555 - val_accuracy: 0.5743\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.66892\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.8445 - accuracy: 0.7300 - val_loss: 5.6707 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.66892\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.7162 - accuracy: 0.7689 - val_loss: 0.6460 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.66892 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.6998 - accuracy: 0.7732 - val_loss: 1.2162 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.74324\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.6121 - accuracy: 0.8005 - val_loss: 0.6794 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.74324 to 0.77703, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5810 - accuracy: 0.8268 - val_loss: 0.3874 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.77703 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5709 - accuracy: 0.8163 - val_loss: 0.7849 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84459\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.5342 - accuracy: 0.8337 - val_loss: 0.5471 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84459\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.5170 - accuracy: 0.8379 - val_loss: 0.4099 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.84459 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.5078 - accuracy: 0.8458 - val_loss: 0.6697 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.87838\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.4365 - accuracy: 0.8542 - val_loss: 0.5459 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.87838\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.4079 - accuracy: 0.8747 - val_loss: 0.4256 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87838\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.4206 - accuracy: 0.8711 - val_loss: 0.5677 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87838\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3698 - accuracy: 0.8763 - val_loss: 0.4973 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87838\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3978 - accuracy: 0.8658 - val_loss: 0.7296 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87838\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3872 - accuracy: 0.8737 - val_loss: 0.3471 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87838\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3624 - accuracy: 0.8905 - val_loss: 0.7634 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87838\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3649 - accuracy: 0.8800 - val_loss: 0.7392 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87838\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.3135 - accuracy: 0.8921 - val_loss: 3.6483 - val_accuracy: 0.3649\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87838\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3179 - accuracy: 0.9026 - val_loss: 0.6730 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87838\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3380 - accuracy: 0.8884 - val_loss: 0.7817 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87838\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2781 - accuracy: 0.9105 - val_loss: 1.7144 - val_accuracy: 0.4797\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87838\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2804 - accuracy: 0.9142 - val_loss: 1.1922 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87838\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2965 - accuracy: 0.9000 - val_loss: 0.5869 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87838\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2702 - accuracy: 0.9184 - val_loss: 0.8807 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87838\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2415 - accuracy: 0.9279 - val_loss: 0.3136 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.87838 to 0.88514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2452 - accuracy: 0.9195 - val_loss: 0.9810 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88514\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2345 - accuracy: 0.9274 - val_loss: 0.6149 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88514\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2014 - accuracy: 0.9311 - val_loss: 0.8156 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88514\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.3077 - accuracy: 0.9058 - val_loss: 0.5894 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88514\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2362 - accuracy: 0.9184 - val_loss: 0.5770 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88514\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.2218 - accuracy: 0.9326 - val_loss: 0.9321 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88514\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1810 - accuracy: 0.9395 - val_loss: 0.5527 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88514\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1787 - accuracy: 0.9458 - val_loss: 0.7591 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88514\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2432 - accuracy: 0.9321 - val_loss: 0.8417 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88514\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1483 - accuracy: 0.9563 - val_loss: 0.5210 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88514\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1541 - accuracy: 0.9521 - val_loss: 1.6572 - val_accuracy: 0.5946\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88514\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1730 - accuracy: 0.9495 - val_loss: 0.7704 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88514\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1804 - accuracy: 0.9368 - val_loss: 0.3497 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.88514 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.2114 - accuracy: 0.9274 - val_loss: 1.0753 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90541\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1646 - accuracy: 0.9453 - val_loss: 0.4382 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90541\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1234 - accuracy: 0.9605 - val_loss: 0.4494 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90541\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1510 - accuracy: 0.9474 - val_loss: 0.4387 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90541\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1607 - accuracy: 0.9511 - val_loss: 0.4362 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90541\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1184 - accuracy: 0.9642 - val_loss: 0.4272 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90541\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1799 - accuracy: 0.9437 - val_loss: 0.8739 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90541\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1487 - accuracy: 0.9542 - val_loss: 0.5447 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90541\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1185 - accuracy: 0.9653 - val_loss: 0.4250 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1118 - accuracy: 0.9626 - val_loss: 0.7048 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91216\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1643 - accuracy: 0.9479 - val_loss: 0.9352 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91216\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1010 - accuracy: 0.9689 - val_loss: 0.5145 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91216\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1283 - accuracy: 0.9600 - val_loss: 0.7337 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91216\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.1495 - accuracy: 0.9542 - val_loss: 0.4840 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1131 - accuracy: 0.9642 - val_loss: 0.5248 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1193 - accuracy: 0.9595 - val_loss: 0.4103 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1231 - accuracy: 0.9605 - val_loss: 0.5067 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1189 - accuracy: 0.9637 - val_loss: 0.6870 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91216\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1091 - accuracy: 0.9668 - val_loss: 0.7340 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91216\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1028 - accuracy: 0.9689 - val_loss: 0.3872 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 0.4334 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1156 - accuracy: 0.9642 - val_loss: 0.6110 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1303 - accuracy: 0.9595 - val_loss: 0.5844 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1019 - accuracy: 0.9695 - val_loss: 0.5418 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1236 - accuracy: 0.9626 - val_loss: 0.4339 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1112 - accuracy: 0.9653 - val_loss: 1.2915 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0790 - accuracy: 0.9768 - val_loss: 0.3939 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1104 - accuracy: 0.9574 - val_loss: 0.6108 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1157 - accuracy: 0.9605 - val_loss: 0.4421 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91216\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0791 - accuracy: 0.9758 - val_loss: 0.6696 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91216\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0988 - accuracy: 0.9721 - val_loss: 0.6413 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91216\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.6173 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91216\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.5244 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91216\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0940 - accuracy: 0.9721 - val_loss: 1.5353 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91216\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0997 - accuracy: 0.9695 - val_loss: 0.6656 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91216\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0891 - accuracy: 0.9726 - val_loss: 0.6624 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91216\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0936 - accuracy: 0.9684 - val_loss: 0.5934 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91216\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0914 - accuracy: 0.9742 - val_loss: 0.6916 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91216\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.4366 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00083: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 0.7392 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91892\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0699 - accuracy: 0.9795 - val_loss: 0.5746 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91892\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.1045 - accuracy: 0.9684 - val_loss: 0.6137 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0849 - accuracy: 0.9737 - val_loss: 0.5579 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0741 - accuracy: 0.9753 - val_loss: 0.5528 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0776 - accuracy: 0.9747 - val_loss: 1.2023 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 0.5424 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0624 - accuracy: 0.9779 - val_loss: 0.6748 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 1.2759 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0997 - accuracy: 0.9674 - val_loss: 0.4626 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.4853 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91892\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0593 - accuracy: 0.9837 - val_loss: 0.5731 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91892\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.4916 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91892\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0893 - accuracy: 0.9689 - val_loss: 0.9772 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91892\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0658 - accuracy: 0.9789 - val_loss: 0.6088 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91892\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0375 - accuracy: 0.9889 - val_loss: 0.3862 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91892\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0418 - accuracy: 0.9853 - val_loss: 0.5167 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91892\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0550 - accuracy: 0.9853 - val_loss: 0.7110 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91892\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0645 - accuracy: 0.9821 - val_loss: 0.6613 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91892\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0595 - accuracy: 0.9826 - val_loss: 1.0368 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91892\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0804 - accuracy: 0.9726 - val_loss: 0.5690 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91892\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0810 - accuracy: 0.9758 - val_loss: 0.2031 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91892\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.5065 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91892\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.4767 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91892\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0668 - accuracy: 0.9805 - val_loss: 3.0571 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91892\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.5498 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91892\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0775 - accuracy: 0.9742 - val_loss: 1.3238 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91892\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.7895 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91892\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.6484 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91892\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.9890 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91892\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0539 - accuracy: 0.9821 - val_loss: 1.5388 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91892\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0678 - accuracy: 0.9753 - val_loss: 0.5089 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91892\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.5132 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91892\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0422 - accuracy: 0.9889 - val_loss: 0.5104 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91892\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0471 - accuracy: 0.9868 - val_loss: 0.4568 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91892\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.4624 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91892\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0462 - accuracy: 0.9868 - val_loss: 0.6280 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91892\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0652 - accuracy: 0.9837 - val_loss: 0.4743 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91892\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0468 - accuracy: 0.9863 - val_loss: 0.4960 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91892\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0716 - accuracy: 0.9742 - val_loss: 0.6602 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91892\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 0.6160 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91892\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.6917 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91892\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0815 - accuracy: 0.9737 - val_loss: 1.4619 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91892\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0787 - accuracy: 0.9763 - val_loss: 0.3777 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91892\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0380 - accuracy: 0.9900 - val_loss: 0.8041 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91892\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0501 - accuracy: 0.9863 - val_loss: 1.8306 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91892\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.7507 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91892\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0333 - accuracy: 0.9858 - val_loss: 0.8343 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91892\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0452 - accuracy: 0.9905 - val_loss: 0.7233 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91892\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.5703 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91892\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0385 - accuracy: 0.9879 - val_loss: 0.7685 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91892\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.4881 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91892\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0646 - accuracy: 0.9795 - val_loss: 2.8645 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91892\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 0.6251 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91892\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 2.2073 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91892\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.5582 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91892\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.7740 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91892\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.6563 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91892\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0541 - accuracy: 0.9863 - val_loss: 0.2941 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91892\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0457 - accuracy: 0.9879 - val_loss: 0.4988 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91892\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0473 - accuracy: 0.9889 - val_loss: 0.4910 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91892\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.5936 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91892\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.6955 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91892\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0424 - accuracy: 0.9884 - val_loss: 0.6179 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91892\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.8282 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91892\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0496 - accuracy: 0.9847 - val_loss: 0.4418 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91892\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0548 - accuracy: 0.9821 - val_loss: 0.7835 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91892\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0389 - accuracy: 0.9858 - val_loss: 0.4958 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91892\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.5795 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00152: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.3407 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92568\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.5675 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92568\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.5845 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92568\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.5889 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92568\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0583 - accuracy: 0.9789 - val_loss: 1.2198 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92568\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0645 - accuracy: 0.9837 - val_loss: 0.6512 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92568\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.0740 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92568\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.5257 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92568\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.4151 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92568\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.4018 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92568\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0170 - accuracy: 0.9921 - val_loss: 0.4108 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92568\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.8562 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92568\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.6397 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92568\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.5634 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92568\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0616 - accuracy: 0.9816 - val_loss: 1.3656 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92568\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0422 - accuracy: 0.9889 - val_loss: 1.5798 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92568\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.8398 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92568\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0309 - accuracy: 0.9879 - val_loss: 0.6778 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92568\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.5782 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92568\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.6356 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92568\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.6986 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92568\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.5238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92568\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 1.0150 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92568\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 1.9793 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92568\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.7203 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92568\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.8706 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92568\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 2.1443 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92568\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0489 - accuracy: 0.9874 - val_loss: 1.4744 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92568\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 0.7131 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92568\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.6124 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92568\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.5949 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92568\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0263 - accuracy: 0.9895 - val_loss: 0.6102 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92568\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.5780 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92568\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.8067 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92568\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 1.2212 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92568\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.4356 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92568\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0311 - accuracy: 0.9926 - val_loss: 0.5509 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92568\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0447 - accuracy: 0.9874 - val_loss: 0.6918 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92568\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0585 - accuracy: 0.9826 - val_loss: 0.4714 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92568\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.6806 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92568\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0317 - accuracy: 0.9879 - val_loss: 0.4643 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92568\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.6061 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92568\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 1.2555 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92568\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 27s 112ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 2.0657 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92568\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.8269 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92568\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.3977 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92568\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.7049 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92568\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.5311 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92568\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.5998 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92568\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.5209 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92568\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.5611 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92568\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 0.6684 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92568\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.7693 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92568\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0538 - accuracy: 0.9842 - val_loss: 2.0366 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92568\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 0.7719 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92568\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0525 - accuracy: 0.9863 - val_loss: 4.1754 - val_accuracy: 0.3514\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92568\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.5644 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92568\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.7312 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92568\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.5037 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92568\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0269 - accuracy: 0.9932 - val_loss: 0.5054 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92568\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.5114 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92568\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.5973 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92568\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.6546 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92568\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.5116 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92568\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.4783 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92568\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.6935 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92568\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.5015 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92568\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.5941 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92568\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.7016 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92568\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.6265 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92568\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.7700 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92568\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 1.7369 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92568\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0632 - accuracy: 0.9779 - val_loss: 0.8517 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92568\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0261 - accuracy: 0.9900 - val_loss: 0.7520 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92568\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.6527 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92568\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0383 - accuracy: 0.9916 - val_loss: 5.3644 - val_accuracy: 0.2162\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92568\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.5457 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92568\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.8105 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92568\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.5107 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92568\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 0.6274 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92568\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.7059 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92568\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0366 - accuracy: 0.9916 - val_loss: 1.8358 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92568\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.6975 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92568\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.7965 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92568\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0288 - accuracy: 0.9926 - val_loss: 0.7215 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92568\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.6141 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92568\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 1.0810 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92568\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.7845 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92568\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.6944 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92568\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.9479 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92568\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 1.1133 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92568\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 1.3526 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92568\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 0.9611 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92568\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.6743 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92568\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.5765 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92568\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.7063 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92568\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.8691 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92568\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.6761 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92568\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.7812 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92568\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 2.2208 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92568\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 1.0623 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92568\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0453 - accuracy: 0.9847 - val_loss: 0.4759 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92568\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.7002 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92568\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.7906 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92568\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.7471 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92568\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0157 - accuracy: 0.9932 - val_loss: 0.5593 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92568\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.5599 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92568\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.7877 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92568\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 1.3463 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92568\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5963 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92568\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.7105 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92568\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.7485 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92568\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 1.3558 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92568\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.3883 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92568\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.9034 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92568\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.7702 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92568\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.5648 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92568\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 0.6107 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92568\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 1.2561 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92568\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.6916 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92568\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.5482 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92568\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 1.1564 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92568\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.4724 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92568\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.6147 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92568\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.8044 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92568\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.8443 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92568\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.7361 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92568\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0363 - accuracy: 0.9926 - val_loss: 0.4453 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00280: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_1.h5\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.7310 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93919\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 1.1403 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93919\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0335 - accuracy: 0.9916 - val_loss: 2.7124 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93919\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0380 - accuracy: 0.9916 - val_loss: 0.6176 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93919\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.7223 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93919\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.8650 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.6237 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.6782 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 1.0465 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.7443 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93919\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.7402 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93919\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.9378 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93919\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.6495 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93919\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 2.2506 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93919\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 1.9657 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93919\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.6554 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93919\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.5952 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93919\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.6240 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93919\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.8453 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93919\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.5570 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93919\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0361 - accuracy: 0.9884 - val_loss: 0.3653 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93919\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6634 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93919\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.6578 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93919\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.5404 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93919\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6463 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93919\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.8323 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93919\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.8421 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93919\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 2.3140 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93919\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 1.1634 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93919\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0258 - accuracy: 0.9889 - val_loss: 0.9990 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93919\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.8023 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93919\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.8456 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93919\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 2.1837 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93919\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0098 - accuracy: 0.9947 - val_loss: 1.4191 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93919\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 1.1976 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93919\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0351 - accuracy: 0.9937 - val_loss: 0.6957 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93919\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.6369 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93919\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0377 - accuracy: 0.9921 - val_loss: 0.8281 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93919\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0355 - accuracy: 0.9889 - val_loss: 1.1225 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93919\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.8106 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93919\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.8917 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93919\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 0.5794 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93919\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.6611 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93919\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.7081 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93919\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.6700 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93919\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.5707 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93919\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0368 - accuracy: 0.9911 - val_loss: 1.2024 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93919\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.8900 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93919\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.6810 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93919\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.6768 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93919\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.6655 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93919\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0086 - accuracy: 0.9958 - val_loss: 0.6520 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93919\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 2.5419 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93919\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 1.1710 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93919\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5910 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93919\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5849 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93919\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.7261 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93919\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0103 - accuracy: 0.9942 - val_loss: 1.9430 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93919\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.8004 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93919\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0298 - accuracy: 0.9937 - val_loss: 0.7457 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93919\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 2.1472 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93919\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5429 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93919\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.4681 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93919\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0133 - accuracy: 0.9937 - val_loss: 3.3676 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93919\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 1.2140 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93919\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 1.0237 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93919\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.7669 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93919\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0257 - accuracy: 0.9895 - val_loss: 1.2574 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93919\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.7423 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93919\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0047 - accuracy: 0.9968 - val_loss: 0.7842 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93919\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.7083 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93919\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.8429 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93919\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.7492 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93919\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.4800 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93919\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.9421 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93919\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0166 - accuracy: 0.9905 - val_loss: 1.5794 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93919\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.9426 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93919\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.6066 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93919\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.5400 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93919\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.7105 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93919\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.7676 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93919\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 1.0017 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93919\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.5975 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93919\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.6705 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93919\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.4760 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93919\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.7861 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93919\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.6342 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93919\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.5975 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93919\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0327 - accuracy: 0.9926 - val_loss: 0.6681 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93919\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.8301 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93919\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.5791 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93919\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 27s 113ms/step - loss: 0.0446 - accuracy: 0.9900 - val_loss: 0.6037 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93919\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.6582 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93919\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.6051 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93919\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.6494 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93919\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.5478 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93919\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.6546 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93919\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.6321 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93919\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 1.2864 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93919\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.5440 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93919\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 1.8676 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93919\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4996 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93919\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.7193 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93919\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.6784 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93919\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.7015 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93919\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.6595 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93919\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.8109 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93919\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 1.1660 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93919\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.8517 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93919\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.7606 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93919\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 1.1343 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93919\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.9084 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93919\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0265 - accuracy: 0.9942 - val_loss: 3.1673 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93919\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.6300 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93919\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 1.2642 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93919\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.7743 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93919\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.8364 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93919\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 2.4716 - val_accuracy: 0.6892\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93919\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 1.0224 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93919\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.7076 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93919\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 2.3540 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93919\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.6941 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93919\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.7124 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93919\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.7555 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93919\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.5540 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93919\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.8188 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93919\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.8260 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93919\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 1.1285 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93919\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.6695 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93919\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 0.5664 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93919\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.8839 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93919\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.9689 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93919\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.8669 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93919\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.9530 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93919\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 1.4402 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93919\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.7127 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93919\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.6650 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93919\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 1.4477 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93919\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.8781 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93919\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0138 - accuracy: 0.9932 - val_loss: 0.7671 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93919\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0248 - accuracy: 0.9947 - val_loss: 0.7396 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93919\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.9058 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93919\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.7109 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93919\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.6745 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93919\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 1.1631 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93919\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0356 - accuracy: 0.9921 - val_loss: 3.3027 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93919\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0122 - accuracy: 0.9947 - val_loss: 0.8128 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93919\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.8979 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93919\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.7182 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93919\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 0.6506 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93919\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.4408 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93919\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.6677 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93919\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.8511 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93919\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.9531 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93919\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6467 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93919\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 1.8338 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93919\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 0.8773 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93919\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.6606 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93919\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.8377 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93919\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.7444 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93919\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.7529 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93919\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.3955 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93919\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.6092 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93919\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4998 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93919\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.5993 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93919\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 28s 115ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 1.2384 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93919\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.7627 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93919\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0076 - accuracy: 0.9963 - val_loss: 0.7169 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93919\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.5800 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93919\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.6696 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93919\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.7049 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93919\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.9207 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93919\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 1.6237 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93919\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 2.7433 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93919\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.8103 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93919\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0273 - accuracy: 0.9921 - val_loss: 0.7356 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93919\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0136 - accuracy: 0.9937 - val_loss: 0.6947 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93919\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.6887 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93919\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0312 - accuracy: 0.9953 - val_loss: 0.7427 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93919\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.5071 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93919\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.6243 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93919\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7222 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93919\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.6611 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93919\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.8097 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93919\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0257 - accuracy: 0.9937 - val_loss: 0.7275 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93919\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.6098 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93919\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.6631 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93919\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 1.1022 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93919\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.5377 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93919\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.6488 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93919\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6601 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93919\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.9244 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93919\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.6935 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93919\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.8717 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93919\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.6932 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93919\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.6675 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93919\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.7509 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93919\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.5422 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93919\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.7251 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93919\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.6010 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93919\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 27s 114ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.7934 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93919\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0310 - accuracy: 0.9932 - val_loss: 4.9598 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93919\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.7141 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93919\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.5633 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93919\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0101 - accuracy: 0.9947 - val_loss: 1.0946 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93919\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.6897 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93919\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.7155 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93919\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0079 - accuracy: 0.9953 - val_loss: 0.6744 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93919\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.8556 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93919\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.7204 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93919\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0083 - accuracy: 0.9963 - val_loss: 1.0884 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93919\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.8710 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93919\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5049 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93919\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 28s 116ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 3.0841 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93919\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.7374 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93919\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0159 - accuracy: 0.9937 - val_loss: 0.8308 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93919\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.7654 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93919\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.5215 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93919\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0463 - accuracy: 0.9889 - val_loss: 1.2625 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93919\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 27s 115ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.8369 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09162f4e90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "21ec5d99-5caa-45c6-9e90-a0a33a41a3f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f2a1d0-bbf1-438d-ed94-213e2a3724a8"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6886fcc3-291f-493d-cf48-6c9713e706c6"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a391f7e7-c1ad-4d10-e099-f5b00d1568e7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_82f48104-3599-41f3-859b-bd717370b053\", \"EfficientNetB4_1.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}