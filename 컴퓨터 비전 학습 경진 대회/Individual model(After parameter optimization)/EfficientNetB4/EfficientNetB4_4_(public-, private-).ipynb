{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB4_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB4_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99742170-472c-4992-a907-8dfca236b8d6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 05:16:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f9643d-a028-4aeb-9a6b-036e7913e270"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '4'\n",
        "model_save = 'EfficientNetB' + nunbering + '_4'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943c1c72-26df-4aa8-e494-b9c505a37b69"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8db5380-ab4c-49ef-8472-e0f41483f7bb"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 59s 136ms/step - loss: 3.3294 - accuracy: 0.1495 - val_loss: 3.1451 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 2.2359 - accuracy: 0.2163 - val_loss: 2.9480 - val_accuracy: 0.1149\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.11486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 1.7831 - accuracy: 0.3816 - val_loss: 2.5937 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11486\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 1.4316 - accuracy: 0.5321 - val_loss: 1.0381 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.11486 to 0.63514, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 1.0995 - accuracy: 0.6526 - val_loss: 3.4066 - val_accuracy: 0.2230\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.63514\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.9436 - accuracy: 0.6958 - val_loss: 0.7297 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.63514 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.8307 - accuracy: 0.7274 - val_loss: 0.6278 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.74324 to 0.79730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.7249 - accuracy: 0.7647 - val_loss: 0.8378 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.79730\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.6642 - accuracy: 0.7889 - val_loss: 0.7011 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.79730\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.5621 - accuracy: 0.8116 - val_loss: 0.7240 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.79730\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.6252 - accuracy: 0.8089 - val_loss: 0.5204 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.79730 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.5204 - accuracy: 0.8453 - val_loss: 0.4570 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.84459 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.5147 - accuracy: 0.8295 - val_loss: 0.5540 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.87162\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.4633 - accuracy: 0.8511 - val_loss: 0.5091 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.87162\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.4537 - accuracy: 0.8516 - val_loss: 0.5837 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.87162\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.4588 - accuracy: 0.8584 - val_loss: 0.3374 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.87162\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3940 - accuracy: 0.8737 - val_loss: 0.5720 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.87162\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.4043 - accuracy: 0.8732 - val_loss: 0.9600 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.87162\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.3870 - accuracy: 0.8758 - val_loss: 0.8186 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.3653 - accuracy: 0.8874 - val_loss: 0.4638 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3659 - accuracy: 0.8795 - val_loss: 0.5579 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.87162\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3796 - accuracy: 0.8779 - val_loss: 0.4354 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.87162\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3093 - accuracy: 0.9037 - val_loss: 0.5890 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.87162\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2887 - accuracy: 0.9105 - val_loss: 0.4603 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.87162\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3117 - accuracy: 0.9000 - val_loss: 1.3493 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87162\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3208 - accuracy: 0.9011 - val_loss: 0.4495 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2721 - accuracy: 0.9116 - val_loss: 0.6325 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.3146 - accuracy: 0.8958 - val_loss: 0.4912 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87162\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2794 - accuracy: 0.9074 - val_loss: 0.5014 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87162\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.2392 - accuracy: 0.9289 - val_loss: 0.4966 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87162\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2618 - accuracy: 0.9137 - val_loss: 1.9056 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87162\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2265 - accuracy: 0.9253 - val_loss: 1.9597 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87162\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.2449 - accuracy: 0.9216 - val_loss: 1.6777 - val_accuracy: 0.5878\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87162\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2704 - accuracy: 0.9158 - val_loss: 0.6489 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87162\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2240 - accuracy: 0.9279 - val_loss: 0.5306 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87162\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2098 - accuracy: 0.9274 - val_loss: 0.5102 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87162\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1645 - accuracy: 0.9453 - val_loss: 1.1653 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87162\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.2332 - accuracy: 0.9300 - val_loss: 0.5703 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87162\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1589 - accuracy: 0.9521 - val_loss: 0.5199 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87162\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.2195 - accuracy: 0.9316 - val_loss: 0.8828 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87162\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1703 - accuracy: 0.9426 - val_loss: 0.3925 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.87162 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1675 - accuracy: 0.9447 - val_loss: 0.4439 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1876 - accuracy: 0.9447 - val_loss: 0.3845 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1321 - accuracy: 0.9553 - val_loss: 0.7344 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91216\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1691 - accuracy: 0.9432 - val_loss: 0.4654 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91216\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1949 - accuracy: 0.9400 - val_loss: 0.4056 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91216\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1419 - accuracy: 0.9532 - val_loss: 0.5130 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91216\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1404 - accuracy: 0.9621 - val_loss: 0.5358 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91216\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1868 - accuracy: 0.9421 - val_loss: 0.5384 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91216\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1378 - accuracy: 0.9584 - val_loss: 0.4829 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.1354 - accuracy: 0.9537 - val_loss: 0.4603 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91892\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1310 - accuracy: 0.9521 - val_loss: 0.5225 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91892\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1220 - accuracy: 0.9589 - val_loss: 0.5153 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91892\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1212 - accuracy: 0.9605 - val_loss: 0.3951 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1285 - accuracy: 0.9568 - val_loss: 0.8405 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.1109 - accuracy: 0.9663 - val_loss: 0.5138 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1299 - accuracy: 0.9584 - val_loss: 0.4600 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 30s 126ms/step - loss: 0.1179 - accuracy: 0.9611 - val_loss: 0.5037 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1243 - accuracy: 0.9600 - val_loss: 1.9398 - val_accuracy: 0.6419\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.1463 - accuracy: 0.9605 - val_loss: 0.5905 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0859 - accuracy: 0.9742 - val_loss: 0.4638 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.4188 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1051 - accuracy: 0.9647 - val_loss: 1.0695 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1010 - accuracy: 0.9642 - val_loss: 0.5430 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1255 - accuracy: 0.9658 - val_loss: 0.5365 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0724 - accuracy: 0.9768 - val_loss: 0.6286 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91892\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.1188 - accuracy: 0.9632 - val_loss: 0.6474 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91892\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0887 - accuracy: 0.9700 - val_loss: 0.4190 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91892\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1044 - accuracy: 0.9653 - val_loss: 0.7191 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91892\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1325 - accuracy: 0.9621 - val_loss: 0.5297 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91892\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0813 - accuracy: 0.9763 - val_loss: 0.5350 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91892\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0955 - accuracy: 0.9679 - val_loss: 0.6063 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91892\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0753 - accuracy: 0.9747 - val_loss: 0.4788 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91892\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0807 - accuracy: 0.9795 - val_loss: 0.7828 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0913 - accuracy: 0.9732 - val_loss: 0.4348 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.1048 - accuracy: 0.9679 - val_loss: 0.5802 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91892\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0950 - accuracy: 0.9695 - val_loss: 0.5516 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0987 - accuracy: 0.9679 - val_loss: 0.4848 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0681 - accuracy: 0.9768 - val_loss: 0.3898 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0846 - accuracy: 0.9747 - val_loss: 0.7784 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0894 - accuracy: 0.9716 - val_loss: 0.5136 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0814 - accuracy: 0.9726 - val_loss: 1.5775 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91892\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0840 - accuracy: 0.9700 - val_loss: 0.6819 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91892\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0818 - accuracy: 0.9721 - val_loss: 0.5527 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91892\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0539 - accuracy: 0.9811 - val_loss: 0.6659 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91892\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 1.5845 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0746 - accuracy: 0.9753 - val_loss: 0.4352 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.4072 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0698 - accuracy: 0.9758 - val_loss: 0.4201 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0806 - accuracy: 0.9721 - val_loss: 0.7045 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0714 - accuracy: 0.9795 - val_loss: 0.5776 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0765 - accuracy: 0.9726 - val_loss: 0.4193 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0840 - accuracy: 0.9774 - val_loss: 0.5367 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0915 - accuracy: 0.9668 - val_loss: 0.3688 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.91892 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.3442 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.4676 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.8470 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.92568\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.7450 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.92568\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.1256 - accuracy: 0.9616 - val_loss: 0.6000 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.92568\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0721 - accuracy: 0.9768 - val_loss: 0.4068 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.92568\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.5161 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.92568\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.4178 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.92568\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.6485 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.92568\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0430 - accuracy: 0.9837 - val_loss: 0.7983 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.92568\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.6720 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.92568\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.6477 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.92568\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0583 - accuracy: 0.9805 - val_loss: 0.7716 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.92568\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 1.1350 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.92568\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.8655 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.92568\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0551 - accuracy: 0.9853 - val_loss: 0.4959 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.92568\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.4241 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.92568\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0388 - accuracy: 0.9842 - val_loss: 0.8067 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.92568\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0647 - accuracy: 0.9832 - val_loss: 0.6002 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.92568\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 0.6572 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.92568\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.8102 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.92568\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0401 - accuracy: 0.9847 - val_loss: 0.4383 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.92568\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 0.5863 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.92568\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0732 - accuracy: 0.9737 - val_loss: 1.0535 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.92568\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0504 - accuracy: 0.9805 - val_loss: 0.6791 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.92568\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0690 - accuracy: 0.9800 - val_loss: 1.0076 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.92568\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.4620 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.92568\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.5544 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.92568\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.4491 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.92568\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.7202 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.92568\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.5417 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.92568\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.4746 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.92568\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0620 - accuracy: 0.9784 - val_loss: 0.4662 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.92568\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 0.4728 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.92568\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.4414 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.92568\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0324 - accuracy: 0.9863 - val_loss: 0.6102 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.92568\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 0.5418 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.92568\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.4458 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00132: val_accuracy improved from 0.92568 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0494 - accuracy: 0.9889 - val_loss: 0.5969 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0511 - accuracy: 0.9858 - val_loss: 0.6260 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.7505 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.3633 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.5707 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 0.5637 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.5068 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.3913 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 30s 127ms/step - loss: 0.0415 - accuracy: 0.9889 - val_loss: 0.4528 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0477 - accuracy: 0.9805 - val_loss: 0.4699 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.4640 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.5762 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.8686 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.5605 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0407 - accuracy: 0.9847 - val_loss: 0.4788 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 0.6822 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0300 - accuracy: 0.9879 - val_loss: 0.5431 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.4550 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.5815 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0547 - accuracy: 0.9826 - val_loss: 0.3784 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.4171 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.6341 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.4907 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0494 - accuracy: 0.9863 - val_loss: 0.6152 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.4934 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 0.3207 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00158: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB4_4.h5\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0475 - accuracy: 0.9858 - val_loss: 0.4940 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.94595\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 0.4795 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.94595\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.5066 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.94595\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0351 - accuracy: 0.9911 - val_loss: 1.1729 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.94595\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0666 - accuracy: 0.9784 - val_loss: 0.5719 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.94595\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.5495 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.94595\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.3683 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.94595\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.5215 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.5250 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.5384 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.6036 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0397 - accuracy: 0.9863 - val_loss: 0.5342 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.6254 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0426 - accuracy: 0.9889 - val_loss: 0.5951 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.5724 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.6187 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.5285 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0738 - accuracy: 0.9805 - val_loss: 1.3557 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.5661 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.5949 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 0.6328 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.5207 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.6637 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0501 - accuracy: 0.9879 - val_loss: 0.5014 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.5227 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.6644 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.7160 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.8528 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0566 - accuracy: 0.9853 - val_loss: 0.5189 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.4098 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.94595\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 30s 128ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.6603 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.94595\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.6149 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.94595\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0487 - accuracy: 0.9874 - val_loss: 0.6267 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.94595\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.4298 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.94595\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.5168 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.94595\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0578 - accuracy: 0.9837 - val_loss: 0.7904 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.94595\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.4693 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.94595\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.4641 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.94595\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.4675 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.94595\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.6215 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.94595\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.5388 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.94595\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 0.5429 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.94595\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.6341 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.94595\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.6556 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.94595\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.7416 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.94595\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0400 - accuracy: 0.9853 - val_loss: 0.7936 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.94595\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 0.6046 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.94595\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.4581 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.94595\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.6684 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.94595\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.6685 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.94595\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.6282 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.94595\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.6990 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.94595\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.6138 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.94595\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.7457 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.94595\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 0.6357 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.94595\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.6678 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.94595\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.5155 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.94595\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.5895 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.94595\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.5588 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.94595\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.6770 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.94595\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0474 - accuracy: 0.9889 - val_loss: 0.7167 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.94595\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.5781 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.94595\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.5716 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.94595\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.6497 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.94595\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.6074 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.94595\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.7339 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.94595\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 1.2220 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.94595\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0452 - accuracy: 0.9879 - val_loss: 0.6978 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.94595\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.6615 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.94595\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 31s 128ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.7040 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.94595\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.4989 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.94595\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.6025 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.94595\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.7953 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.94595\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 0.4435 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.94595\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.4974 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.94595\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.7595 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.94595\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.4538 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.94595\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.6127 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.94595\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0637 - accuracy: 0.9826 - val_loss: 0.5346 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.94595\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 0.5781 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.94595\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.5521 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.94595\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.5706 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.94595\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.7757 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.94595\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.7939 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.94595\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.6402 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.94595\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0306 - accuracy: 0.9874 - val_loss: 0.6192 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.94595\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.5368 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.94595\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5811 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.94595\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.6931 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.94595\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.5995 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.5207 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.7868 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0291 - accuracy: 0.9926 - val_loss: 0.7700 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0386 - accuracy: 0.9879 - val_loss: 0.8487 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0110 - accuracy: 0.9942 - val_loss: 0.5306 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.6184 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0262 - accuracy: 0.9937 - val_loss: 1.3264 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.5862 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.5977 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0408 - accuracy: 0.9832 - val_loss: 0.6931 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.5796 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.2086 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0113 - accuracy: 0.9947 - val_loss: 0.4437 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.5230 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0323 - accuracy: 0.9863 - val_loss: 0.6598 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.6354 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.6961 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.5612 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.5698 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.6100 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.7230 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.8060 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.6355 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.6285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.5935 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 1.1426 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.4085 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 1.9690 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.7880 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.5894 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.6634 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.5575 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.5352 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 1.8410 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.4457 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.6776 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.7429 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0278 - accuracy: 0.9916 - val_loss: 0.5130 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.2725 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.5840 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.4310 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.6051 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.6556 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.6164 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.7662 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.8059 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.6566 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 1.0276 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.7148 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.8248 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.8995 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.9181 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.5157 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.7345 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0062 - accuracy: 0.9968 - val_loss: 0.3841 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 1.2240 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.5719 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.5570 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 1.0822 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5834 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 2.2045 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.4486 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.5687 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.5557 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.6000 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.6300 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.6758 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.6609 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5569 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.5358 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.7928 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.8020 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.6457 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.4765 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4481 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 31s 129ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.5285 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.6003 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.9074 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.8096 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.8869 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.6861 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 1.2056 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.6308 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0136 - accuracy: 0.9937 - val_loss: 0.5753 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.7540 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 2.1523 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.5587 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.7455 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.8654 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.4510 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.6150 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.6327 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.6886 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.5987 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.5842 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 1.2239 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.9403 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 0.6723 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.7970 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5796 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0047 - accuracy: 0.9968 - val_loss: 0.6859 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.4916 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 1.1446 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.7677 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0260 - accuracy: 0.9963 - val_loss: 0.7249 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.7550 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.8704 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.8289 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.6049 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.7412 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.7414 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 0.9421 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.8921 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0162 - accuracy: 0.9932 - val_loss: 0.6905 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0127 - accuracy: 0.9942 - val_loss: 2.3351 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.6375 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.9986 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.6045 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.9131 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.7328 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.7801 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.6139 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.7907 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 1.1862 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.8623 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0137 - accuracy: 0.9942 - val_loss: 0.7829 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.7074 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.6517 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.5887 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.7338 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 0.6012 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 1.2221 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.6856 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.5079 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.6762 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.8866 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.6603 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0356 - accuracy: 0.9889 - val_loss: 0.6994 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.6715 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 0.8403 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 31s 130ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.6567 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.4984 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.5205 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4837 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.6186 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.6522 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.4836 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.6449 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.6374 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.8356 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.6774 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.7984 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.7226 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.9296 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.6969 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.7165 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.6185 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 1.3862 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.8435 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.6207 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5624 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.8104 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.5544 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.5633 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.8192 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.7828 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.8418 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.6855 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.7429 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.7392 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.8274 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0256 - accuracy: 0.9937 - val_loss: 0.8503 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 0.7781 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 0.9865 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.8969 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 1.2466 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.4040 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.7759 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.8110 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.5689 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.7548 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 1.4145 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.7515 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 1.0592 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.7216 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.7205 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.8221 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.6277 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.6223 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.5178 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.6387 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6154 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.8416 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.8255 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.8121 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.7767 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.7623 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 1.5674 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.9288 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.7886 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.9081 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.6485 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.6531 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.9239 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.6572 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.7544 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.8263 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.7440 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.6081 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.7466 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.7335 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.8130 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.8377 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5302 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.7586 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.5894 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.8535 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 0.8448 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 1.0041 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.6694 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.8957 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.9963 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 1.1199 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 1.1832 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.9646 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 31s 131ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.9521 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.9814 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 1.0744 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6715 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0125 - accuracy: 0.9947 - val_loss: 0.6093 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.7695 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.7958 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.7748 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.6405 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 0.9536 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.7697 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.9560 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.8703 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.7529 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.8294 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 1.0078 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 31s 132ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.7983 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 32s 132ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 0.6873 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94595\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 32s 135ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.7428 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94595\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.7653 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94595\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.6879 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94595\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.7675 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94595\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.5779 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94595\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 32s 134ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.8302 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94595\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 32s 133ms/step - loss: 0.0337 - accuracy: 0.9932 - val_loss: 1.4026 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20801f5850>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8cf495b9-30c2-44ef-85b4-ed4ef612c3e9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ec1bc-bdda-4ca9-83ad-be4381d44f33"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f314485-5130-4fea-c665-17c2fa675bbc"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0bef335d-71a8-4e9c-a5cf-a4ca0761a2df"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9120a435-6daa-4c55-84f1-8ea8bfb54535\", \"EfficientNetB4_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}