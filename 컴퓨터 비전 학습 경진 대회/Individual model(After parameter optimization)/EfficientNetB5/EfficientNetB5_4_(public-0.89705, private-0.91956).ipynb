{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB5_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/EfficientNetB5_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ba1301-bb68-43c3-924f-3ed802412409"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 13:21:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    34W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b46e2a-6a04-4016-f10a-638e836d2fc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32528f1f-731d-42a1-c487-1c8d5341fb8c"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘images_train’: File exists\n",
            "mkdir: cannot create directory ‘images_train/0’: File exists\n",
            "mkdir: cannot create directory ‘images_train/1’: File exists\n",
            "mkdir: cannot create directory ‘images_train/2’: File exists\n",
            "mkdir: cannot create directory ‘images_train/3’: File exists\n",
            "mkdir: cannot create directory ‘images_train/4’: File exists\n",
            "mkdir: cannot create directory ‘images_train/5’: File exists\n",
            "mkdir: cannot create directory ‘images_train/6’: File exists\n",
            "mkdir: cannot create directory ‘images_train/7’: File exists\n",
            "mkdir: cannot create directory ‘images_train/8’: File exists\n",
            "mkdir: cannot create directory ‘images_train/9’: File exists\n",
            "mkdir: cannot create directory ‘images_test’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "nunbering = '5'\n",
        "model_save = 'EfficientNetB' + nunbering + '_4'\n",
        "Target_model = 'EfficientNetB' + nunbering + '_model'\n",
        "Target_predict = 'EfficientNetB' + nunbering + '_predict'\n",
        "Target_acc = 'EfficientNetB' + nunbering + '_acc'\n",
        "Target_val = 'EfficientNetB' + nunbering + '_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.EfficientNetB5(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c2c5e7-31cf-4e2d-85e6-c2c38ff532dc"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b825efa1-b768-4842-c387-42cdfd033a93"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 79s 252ms/step - loss: 4.0559 - accuracy: 0.0947 - val_loss: 2.4252 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 2.6501 - accuracy: 0.1326 - val_loss: 2.4572 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 2.3904 - accuracy: 0.1779 - val_loss: 2.7455 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10135\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 2.2206 - accuracy: 0.2311 - val_loss: 2.7668 - val_accuracy: 0.2027\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10135 to 0.20270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 1.9788 - accuracy: 0.3042 - val_loss: 1.6680 - val_accuracy: 0.4189\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.20270 to 0.41892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 1.6518 - accuracy: 0.4316 - val_loss: 3.5266 - val_accuracy: 0.2432\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.41892\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 57s 237ms/step - loss: 1.3194 - accuracy: 0.5689 - val_loss: 1.0447 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.41892 to 0.64865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 1.1575 - accuracy: 0.6100 - val_loss: 1.1675 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.64865\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 1.0065 - accuracy: 0.6774 - val_loss: 0.9779 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.64865 to 0.70270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.8826 - accuracy: 0.7274 - val_loss: 0.9140 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.70270 to 0.70946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.7958 - accuracy: 0.7474 - val_loss: 0.9957 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.70946\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.7213 - accuracy: 0.7721 - val_loss: 2.5381 - val_accuracy: 0.4392\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.70946\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.6816 - accuracy: 0.7779 - val_loss: 1.7904 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.70946\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 56s 236ms/step - loss: 0.6630 - accuracy: 0.7911 - val_loss: 0.5814 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.70946 to 0.80405, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.6453 - accuracy: 0.7989 - val_loss: 4.5704 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.80405\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.6240 - accuracy: 0.8037 - val_loss: 0.4411 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.80405 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.5351 - accuracy: 0.8274 - val_loss: 0.7232 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85811\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.5217 - accuracy: 0.8453 - val_loss: 4.0817 - val_accuracy: 0.2162\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85811\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.5042 - accuracy: 0.8395 - val_loss: 0.6118 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85811\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.5298 - accuracy: 0.8311 - val_loss: 0.5636 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85811\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 56s 236ms/step - loss: 0.4736 - accuracy: 0.8479 - val_loss: 0.4939 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85811\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 56s 236ms/step - loss: 0.4531 - accuracy: 0.8511 - val_loss: 1.5313 - val_accuracy: 0.6014\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85811\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.4384 - accuracy: 0.8721 - val_loss: 5.1477 - val_accuracy: 0.1554\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.85811\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.4381 - accuracy: 0.8679 - val_loss: 0.4383 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.85811 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.4357 - accuracy: 0.8632 - val_loss: 0.5106 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.87838\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.4033 - accuracy: 0.8695 - val_loss: 0.6795 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87838\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.3809 - accuracy: 0.8811 - val_loss: 1.1371 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87838\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 56s 236ms/step - loss: 0.3533 - accuracy: 0.8974 - val_loss: 0.5594 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87838\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.3643 - accuracy: 0.8874 - val_loss: 0.4375 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87838\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.3594 - accuracy: 0.8900 - val_loss: 0.7599 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87838\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 56s 237ms/step - loss: 0.3679 - accuracy: 0.8768 - val_loss: 1.3911 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87838\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.3316 - accuracy: 0.8958 - val_loss: 0.5806 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87838\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.3336 - accuracy: 0.8868 - val_loss: 0.8258 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87838\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.3295 - accuracy: 0.9037 - val_loss: 1.6787 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87838\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.2404 - accuracy: 0.9226 - val_loss: 0.4631 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87838\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.3108 - accuracy: 0.9111 - val_loss: 1.3678 - val_accuracy: 0.6284\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87838\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2714 - accuracy: 0.9226 - val_loss: 0.3598 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87838\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2834 - accuracy: 0.9121 - val_loss: 0.4101 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.87838\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.2679 - accuracy: 0.9095 - val_loss: 0.6830 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.87838\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2674 - accuracy: 0.9189 - val_loss: 0.5610 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.87838\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2679 - accuracy: 0.9168 - val_loss: 0.3493 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.87838\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2266 - accuracy: 0.9289 - val_loss: 0.5550 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.87838\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2367 - accuracy: 0.9242 - val_loss: 1.6631 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.87838\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.2282 - accuracy: 0.9284 - val_loss: 0.6241 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.87838\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2252 - accuracy: 0.9274 - val_loss: 0.5324 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.87838\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2355 - accuracy: 0.9253 - val_loss: 0.6458 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.87838\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.2185 - accuracy: 0.9321 - val_loss: 0.5268 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.87838\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.1985 - accuracy: 0.9347 - val_loss: 0.4691 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.87838\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.2039 - accuracy: 0.9305 - val_loss: 0.5231 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.87838\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.1890 - accuracy: 0.9432 - val_loss: 0.4328 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.87838 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1733 - accuracy: 0.9468 - val_loss: 1.4420 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89189\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.1739 - accuracy: 0.9453 - val_loss: 0.3956 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89189\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.1730 - accuracy: 0.9479 - val_loss: 0.4019 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.89189 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1990 - accuracy: 0.9358 - val_loss: 0.4777 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90541\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1762 - accuracy: 0.9411 - val_loss: 0.4363 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90541\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1328 - accuracy: 0.9537 - val_loss: 0.3916 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90541\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1785 - accuracy: 0.9479 - val_loss: 0.6538 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90541\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1361 - accuracy: 0.9553 - val_loss: 0.4730 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90541\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.1560 - accuracy: 0.9442 - val_loss: 1.6197 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90541\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.2031 - accuracy: 0.9447 - val_loss: 0.4207 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90541\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1510 - accuracy: 0.9547 - val_loss: 0.9423 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90541\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1417 - accuracy: 0.9542 - val_loss: 0.6186 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90541\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1254 - accuracy: 0.9600 - val_loss: 2.1595 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90541\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1189 - accuracy: 0.9647 - val_loss: 0.4436 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90541\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1449 - accuracy: 0.9589 - val_loss: 0.4439 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90541\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1272 - accuracy: 0.9584 - val_loss: 0.5359 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90541\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.1232 - accuracy: 0.9611 - val_loss: 0.4665 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1162 - accuracy: 0.9632 - val_loss: 0.4354 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1212 - accuracy: 0.9595 - val_loss: 0.8741 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.1534 - accuracy: 0.9547 - val_loss: 0.4892 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1264 - accuracy: 0.9589 - val_loss: 0.6724 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1325 - accuracy: 0.9521 - val_loss: 0.5313 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1133 - accuracy: 0.9584 - val_loss: 0.3326 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0985 - accuracy: 0.9705 - val_loss: 0.3922 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.1279 - accuracy: 0.9568 - val_loss: 0.4297 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0853 - accuracy: 0.9747 - val_loss: 0.5041 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91892\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1187 - accuracy: 0.9653 - val_loss: 1.2032 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1132 - accuracy: 0.9616 - val_loss: 0.4043 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1086 - accuracy: 0.9642 - val_loss: 0.5656 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0774 - accuracy: 0.9721 - val_loss: 0.4619 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1304 - accuracy: 0.9668 - val_loss: 0.4533 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0808 - accuracy: 0.9737 - val_loss: 0.3192 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00082: val_accuracy improved from 0.91892 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0986 - accuracy: 0.9658 - val_loss: 0.6046 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93243\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0828 - accuracy: 0.9747 - val_loss: 0.6077 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93243\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 0.3199 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93243\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0657 - accuracy: 0.9763 - val_loss: 0.4623 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93243\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1115 - accuracy: 0.9663 - val_loss: 0.2679 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93243\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.5435 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93243\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0868 - accuracy: 0.9705 - val_loss: 0.8310 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93243\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0792 - accuracy: 0.9753 - val_loss: 1.0294 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93243\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0854 - accuracy: 0.9774 - val_loss: 0.6498 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93243\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0707 - accuracy: 0.9753 - val_loss: 0.5282 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0755 - accuracy: 0.9747 - val_loss: 0.6730 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.1232 - accuracy: 0.9642 - val_loss: 0.5366 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0783 - accuracy: 0.9721 - val_loss: 0.4757 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0752 - accuracy: 0.9732 - val_loss: 0.5105 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0989 - accuracy: 0.9695 - val_loss: 0.3719 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93243\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.7954 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.5673 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0617 - accuracy: 0.9795 - val_loss: 0.5426 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0974 - accuracy: 0.9711 - val_loss: 0.5866 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0918 - accuracy: 0.9711 - val_loss: 0.4465 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.4120 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0643 - accuracy: 0.9721 - val_loss: 0.4598 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93243\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0647 - accuracy: 0.9747 - val_loss: 0.5684 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93243\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.5888 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93243\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 4.1274 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93243\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0895 - accuracy: 0.9763 - val_loss: 0.4966 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93243\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0771 - accuracy: 0.9763 - val_loss: 0.5811 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.1087 - accuracy: 0.9674 - val_loss: 0.5905 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0491 - accuracy: 0.9821 - val_loss: 1.0380 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.8267 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0781 - accuracy: 0.9763 - val_loss: 0.4730 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.7671 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0741 - accuracy: 0.9805 - val_loss: 0.7017 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0371 - accuracy: 0.9863 - val_loss: 0.4643 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 1.0003 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0573 - accuracy: 0.9816 - val_loss: 0.6542 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0652 - accuracy: 0.9816 - val_loss: 0.7208 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.1025 - accuracy: 0.9711 - val_loss: 1.5164 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.5084 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.5403 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0583 - accuracy: 0.9832 - val_loss: 0.4932 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.4626 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.4049 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0650 - accuracy: 0.9763 - val_loss: 0.5467 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0666 - accuracy: 0.9763 - val_loss: 0.4433 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93243\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 6.6771 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93243\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 0.4733 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93243\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0563 - accuracy: 0.9858 - val_loss: 0.6104 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93243\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.6760 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93243\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.4755 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93243\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 0.4246 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93243\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0900 - accuracy: 0.9779 - val_loss: 0.3654 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93243\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.3092 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93243\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0535 - accuracy: 0.9842 - val_loss: 0.3733 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93243\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0428 - accuracy: 0.9863 - val_loss: 0.4138 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93243\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.3975 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93243\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0221 - accuracy: 0.9900 - val_loss: 1.5026 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93243\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0636 - accuracy: 0.9805 - val_loss: 0.6202 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93243\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.5564 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93243\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.8068 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.6188 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.6687 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.5610 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0422 - accuracy: 0.9858 - val_loss: 0.8725 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0736 - accuracy: 0.9763 - val_loss: 0.4392 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.7795 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0426 - accuracy: 0.9858 - val_loss: 0.4368 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.5712 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.5849 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0530 - accuracy: 0.9879 - val_loss: 0.3598 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.4882 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0776 - accuracy: 0.9737 - val_loss: 0.3566 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93243\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.3463 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93243\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.4767 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93243\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.7596 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93243\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0980 - accuracy: 0.9695 - val_loss: 0.6248 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93243\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.4295 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93243\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.4600 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93243\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.6017 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93243\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0648 - accuracy: 0.9805 - val_loss: 0.4492 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93243\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.5243 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93243\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0421 - accuracy: 0.9832 - val_loss: 0.6380 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93243\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.3170 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00165: val_accuracy improved from 0.93243 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.4315 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.94595\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0677 - accuracy: 0.9821 - val_loss: 0.6926 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.94595\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0659 - accuracy: 0.9816 - val_loss: 0.3504 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.94595\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.3466 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.94595\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.4956 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.94595\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0411 - accuracy: 0.9889 - val_loss: 0.5044 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.94595\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.3923 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.94595\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.4219 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.94595\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0416 - accuracy: 0.9889 - val_loss: 0.5574 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.94595\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0463 - accuracy: 0.9889 - val_loss: 0.3587 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.94595\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.7579 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.94595\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.5776 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.94595\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.4542 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.94595\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.7131 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.94595\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0253 - accuracy: 0.9905 - val_loss: 0.4570 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.94595\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0340 - accuracy: 0.9863 - val_loss: 0.4229 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.94595\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 57s 242ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.7756 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.94595\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.6585 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.94595\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0519 - accuracy: 0.9847 - val_loss: 0.3917 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.94595\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0332 - accuracy: 0.9911 - val_loss: 0.4628 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.94595\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0455 - accuracy: 0.9821 - val_loss: 0.4445 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.94595\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.4761 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.94595\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0240 - accuracy: 0.9905 - val_loss: 0.3239 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00188: val_accuracy improved from 0.94595 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/EfficientNetB5_4.h5\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 0.3636 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95946\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.5358 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95946\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0202 - accuracy: 0.9916 - val_loss: 0.4268 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95946\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0427 - accuracy: 0.9837 - val_loss: 0.9791 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95946\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.6078 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95946\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0409 - accuracy: 0.9853 - val_loss: 0.5447 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95946\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.4023 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95946\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.4000 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95946\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3207 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95946\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0374 - accuracy: 0.9889 - val_loss: 0.5564 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95946\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.5512 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95946\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0673 - accuracy: 0.9811 - val_loss: 0.4142 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95946\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.3935 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.95946\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0462 - accuracy: 0.9895 - val_loss: 0.9269 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95946\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0558 - accuracy: 0.9826 - val_loss: 0.4994 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95946\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.5128 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95946\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.3516 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.95946\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0222 - accuracy: 0.9911 - val_loss: 0.6137 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95946\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.4666 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95946\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.5683 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95946\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.5796 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95946\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.5801 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95946\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.4892 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95946\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0563 - accuracy: 0.9853 - val_loss: 0.7853 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95946\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0331 - accuracy: 0.9874 - val_loss: 0.5827 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95946\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.4655 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95946\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.9441 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95946\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.5558 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95946\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.7430 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.95946\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 0.5860 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95946\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0604 - accuracy: 0.9847 - val_loss: 0.9469 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95946\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 1.5307 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95946\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0338 - accuracy: 0.9921 - val_loss: 0.5372 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95946\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.6779 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95946\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.6541 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95946\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0451 - accuracy: 0.9874 - val_loss: 0.5497 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95946\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.5692 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95946\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 0.5487 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95946\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.4708 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95946\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.5322 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95946\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.5975 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95946\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.5964 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95946\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.5900 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95946\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.6978 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95946\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 0.7481 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95946\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.6907 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95946\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.5406 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95946\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.6859 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95946\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.5376 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95946\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.5348 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95946\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0332 - accuracy: 0.9916 - val_loss: 0.5137 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95946\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.3200 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95946\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.4673 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95946\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.6496 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95946\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 0.5116 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95946\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.8047 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95946\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.6395 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95946\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0366 - accuracy: 0.9926 - val_loss: 0.7737 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95946\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 0.8578 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95946\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0280 - accuracy: 0.9884 - val_loss: 0.8493 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95946\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.5652 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95946\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 0.5627 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95946\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.5161 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95946\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.7388 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95946\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.7823 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95946\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.5474 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95946\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0648 - accuracy: 0.9826 - val_loss: 0.7786 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95946\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.4141 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95946\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.5666 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95946\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.4717 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95946\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.4823 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95946\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 57s 238ms/step - loss: 0.0398 - accuracy: 0.9926 - val_loss: 0.4969 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95946\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.5406 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95946\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.4890 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95946\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.5809 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95946\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.4545 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95946\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.7568 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95946\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.5438 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95946\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0279 - accuracy: 0.9895 - val_loss: 0.5096 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95946\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0538 - accuracy: 0.9868 - val_loss: 0.3884 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95946\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.4583 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95946\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.4916 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95946\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.5836 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95946\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.3878 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95946\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.5264 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95946\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.5605 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95946\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.5505 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95946\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.6561 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95946\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.4457 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95946\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.5865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95946\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.6829 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95946\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.6207 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95946\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0397 - accuracy: 0.9858 - val_loss: 0.8814 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95946\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.4774 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95946\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.7091 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95946\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0311 - accuracy: 0.9911 - val_loss: 0.7315 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95946\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.5462 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95946\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0298 - accuracy: 0.9932 - val_loss: 0.8768 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95946\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.8317 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95946\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.6339 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95946\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 0.6295 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95946\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.5893 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95946\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.6120 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95946\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 57s 240ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.6727 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95946\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.6305 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95946\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.6062 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95946\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.3621 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95946\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0577 - accuracy: 0.9837 - val_loss: 0.5612 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95946\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.4238 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95946\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4046 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95946\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.4739 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95946\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.3705 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95946\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0229 - accuracy: 0.9942 - val_loss: 0.8357 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95946\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.4924 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95946\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.7939 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95946\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 0.6008 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95946\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.4775 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95946\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0183 - accuracy: 0.9968 - val_loss: 0.5504 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95946\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.6613 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95946\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.6148 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95946\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.4422 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95946\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0272 - accuracy: 0.9895 - val_loss: 2.7546 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95946\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 57s 239ms/step - loss: 0.0257 - accuracy: 0.9900 - val_loss: 2.9645 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95946\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0329 - accuracy: 0.9879 - val_loss: 0.6712 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95946\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.6222 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95946\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.6983 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95946\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.7532 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95946\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.4382 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95946\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0411 - accuracy: 0.9884 - val_loss: 0.6054 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95946\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.5227 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95946\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.6137 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95946\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.5603 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95946\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.5552 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95946\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.5816 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95946\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.6837 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95946\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0262 - accuracy: 0.9932 - val_loss: 0.5380 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95946\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 57s 241ms/step - loss: 0.0202 - accuracy: 0.9921 - val_loss: 1.3062 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95946\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.4175 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95946\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.4450 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95946\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.2964 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95946\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.5262 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95946\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0270 - accuracy: 0.9937 - val_loss: 0.7720 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95946\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4295 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95946\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.7359 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95946\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0193 - accuracy: 0.9932 - val_loss: 0.6033 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95946\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.3333 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95946\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 0.3093 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95946\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.9354 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95946\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 0.5506 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95946\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.7644 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95946\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.4068 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95946\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.3764 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95946\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0296 - accuracy: 0.9926 - val_loss: 0.4925 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95946\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.7726 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95946\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.6955 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95946\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.5765 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95946\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.6258 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95946\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.4923 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95946\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0404 - accuracy: 0.9905 - val_loss: 0.5363 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95946\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0321 - accuracy: 0.9932 - val_loss: 0.4237 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95946\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.4818 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95946\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4581 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95946\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.5318 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95946\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.6427 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95946\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0280 - accuracy: 0.9884 - val_loss: 0.8395 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95946\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.5386 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95946\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0396 - accuracy: 0.9911 - val_loss: 0.5249 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95946\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.6602 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95946\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.8488 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95946\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.3732 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95946\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.4710 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95946\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.5308 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95946\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.5085 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95946\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.4064 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95946\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.5146 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95946\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.9032 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95946\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.6628 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95946\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.8779 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95946\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.7493 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95946\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.7372 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95946\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.7878 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95946\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.5607 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95946\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.6992 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95946\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.5071 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95946\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.4142 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95946\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.4347 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95946\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.6614 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95946\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.9862 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95946\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.8029 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95946\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.5899 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95946\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.6673 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95946\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.6606 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95946\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.5659 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95946\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 1.0898 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95946\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.4300 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95946\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.5379 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95946\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.6049 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95946\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 1.0362 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95946\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0234 - accuracy: 0.9895 - val_loss: 0.5451 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95946\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 0.5667 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95946\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.6086 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95946\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.5391 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95946\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6339 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95946\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5986 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95946\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.4704 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95946\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6285 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95946\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0568 - accuracy: 0.9868 - val_loss: 1.0789 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95946\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.5006 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95946\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.9935 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95946\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0169 - accuracy: 0.9926 - val_loss: 0.9851 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95946\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.5707 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95946\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6550 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95946\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 1.1085 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95946\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.4501 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95946\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.5920 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95946\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0091 - accuracy: 0.9958 - val_loss: 0.6494 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95946\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.5188 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95946\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.6418 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95946\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.6836 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95946\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.6564 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95946\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.6156 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95946\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.5603 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95946\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 0.5850 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95946\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.5948 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95946\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.5539 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95946\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.5799 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95946\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.7535 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95946\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0421 - accuracy: 0.9911 - val_loss: 0.3481 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95946\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0247 - accuracy: 0.9947 - val_loss: 0.6955 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95946\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0082 - accuracy: 0.9958 - val_loss: 0.5585 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95946\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.5889 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95946\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.3787 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95946\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.5001 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95946\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.6313 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95946\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5182 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95946\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.4520 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95946\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.7472 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95946\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.8361 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95946\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0272 - accuracy: 0.9937 - val_loss: 0.5408 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95946\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.6595 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95946\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0063 - accuracy: 0.9968 - val_loss: 0.3678 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95946\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.7038 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95946\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 58s 246ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.3594 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95946\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.6270 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95946\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0286 - accuracy: 0.9932 - val_loss: 0.8195 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95946\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.7076 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95946\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.6192 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95946\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.6839 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95946\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.8847 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95946\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.5335 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95946\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.7194 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95946\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0501 - accuracy: 0.9905 - val_loss: 0.8718 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95946\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.7865 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95946\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.3869 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95946\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0158 - accuracy: 0.9926 - val_loss: 0.8312 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95946\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.7336 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95946\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.8679 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95946\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.7086 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95946\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.6969 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95946\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.5856 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95946\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.3617 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95946\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.6510 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95946\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 58s 246ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.6415 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95946\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.5046 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95946\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5195 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95946\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 59s 247ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.7090 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95946\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.5549 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95946\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.5938 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95946\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 0.4284 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95946\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.5476 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95946\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.5795 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95946\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5756 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95946\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 7.9792e-04 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95946\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.5917 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95946\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 8.9631e-04 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95946\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.6400 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95946\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.6617 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95946\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 59s 246ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.6236 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95946\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0648 - accuracy: 0.9868 - val_loss: 0.7359 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95946\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.5682 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95946\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.6536 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95946\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.7496 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95946\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.7119 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95946\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.7879 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95946\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.8286 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95946\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.5432 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95946\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.7213 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95946\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.7815 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95946\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.9342 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95946\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.7718 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95946\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.8431 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0311 - accuracy: 0.9926 - val_loss: 0.5457 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.5588 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 58s 246ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.8016 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0142 - accuracy: 0.9932 - val_loss: 0.5880 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.5871 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.5513 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 58s 246ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.5798 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.9185 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 58s 242ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 0.6575 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.6464 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.5643 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.6960 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0115 - accuracy: 0.9947 - val_loss: 0.6620 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.7063 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 0.7276 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.5360 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.5813 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 58s 243ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 0.6010 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 58s 244ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.5322 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.7677 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 58s 245ms/step - loss: 0.0093 - accuracy: 0.9958 - val_loss: 0.5893 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4eb5dc110>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7de52fdb-3c03-4151-8f6d-1984a751d86e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5wURfr/3zWzOcEuu8QlB4nLkhUTAiomTChm8VQ8w53pvDOHu/Ond9738PQ8D09PRT1FERUVRU8QFM8AknPOYVlg2bw7M/X7o6ZnemZ60rLLMjP1fr32tdPd1T1VPdWfeuqpp6qFlBKNRqPRxD625s6ARqPRaBoHLegajUYTJ2hB12g0mjhBC7pGo9HECVrQNRqNJk5Iaq4vzs/Pl126dGmur9doNJqYZPHixQeklAVWx5pN0Lt06cKiRYua6+s1Go0mJhFCbAt2TLtcNBqNJk7Qgq7RaDRxghZ0jUajiRO0oGs0Gk2coAVdo9Fo4oSwgi6E+LcQYr8QYmWQ40II8ZwQYqMQYrkQYnDjZ1Oj0Wg04YjEQn8NGBfi+DlAT/ffZODFo8+WRqPRaKIlbBy6lHKBEKJLiCQXAtOkWof3eyFESyFEOynlnkbKo0ajsWD34WpapCeTmdqw6SRVdQ7Sk+24JNTUO8lIsSOEAMDlkths6nOdw4XD5SIjJfB7zOlCsXr3ETYfqKBTXgZFhS0blF8zG/eX07lVJsn24DZpsLxJKT3l9GfX4WrmryuhvKaeguxUzitqR2qSPaLrBqO6zolTSjKS7VGd1xAaY2JRB2CHaXune1+AoAshJqOseDp16tQIX605WmodTlLstqAV/FhSU+9k9oo9DOqUS9f8TM/+NXuO0Ckvgx+3HqQgK5W+7XI8D8Z/V+9jy4FKrh/ZhcXbDrHvSA0XDeqAw+li2v+2Mbp3azq3yggoX53DxUdLdzGyRz4t0pPJMonimj1HePqztZzeq4DLh3UkKzWJHQereOP7bXy+ci/Du+Zx26judCvIQkrJppIK3vx+O6f3KmB3WTUDC1vSv0MLn3Il2238sKWU/h1acKiyjufnbmT17iP85uxe9G3XgufmbmDSyC6kJtnolJfBD1sO8odPVjO0cy6/OfsEstOSqal3snTHYTrlZVBSXsuFLyxkQIcWvHXzCHLSkimtqOXL1fsoyE6lfct0erXJpt7pIi1ZCdKOg1VU1DrISLFz3nPfUlHr4MFze7No6yG+WL2P9GQ770w+kT1l1fx2xnKevrSIc/q35ZY3FrFwYynFnVpyWs98erTOZliXXH7ccpDff7Ka4V3z+NOlRWwqqWDNnnI27C8nOzWJsup6bji5Ky9+vYk3vvfOhfntuBMozM1gt1s8J5/WjbLqej5cuovhXfMYP7A997y7jJO6teKrtfv43bjedGiZzkdLd5OabGPXoWre+mE7lw8t5A8X9Wfad9v4au0+7DbBOf3b8d2mA8xesZe2OWn83+UDKa+pp3+HFny3qZTvN5WycNMBLh5UyDcbSjhUWUdpZR2vXD+MAxW13DdjGfVO7zsinv3vBmbeNpL560o4UlPPjMU72V9ey18uG8jCjQdYuuMwo3u35owTWrOttJI3vt9G1/xMstOSaJuThtMl+dtXGzhUVU92WhInd8/H4XJx71kn0KddTuM+QICI5AUXbgv9Eyllf4tjnwBPSym/dW9/BfxOShlyGujQoUOlninaOCzceIAvVu3liQsDfp6QOF2Ss6bMp0NuBq9NGobNJpBS4nRJkuw21uw5wk9bD3L50I58va6ElxZs4rqTunDRoA6Asjw+XrabJ2ev4cFze/PztsOc2iufdi3SWbmrjIuKO7CvvIZWmSnMX1/CZyv3svtwNef0b8vEYZ2YvWIP//h6IxcN6sAD5/ThzneW8NHS3QztnMu/rhvKgg0l9G2Xw5lTFvjk+76zTyDJJnjqs7WefZNGduG177YC8PQlA5i3bj9zVilxS7HbuP2MHmzcX0HXgkxapifzwryNrN1b7jm/TU4qI7vn89gFfbnn3WXMXbs/5L3Lz0rhqUuK2H6wij98stoyzfUndSYvM5Up/13v2Tekcy51DhcrdpV59nXMS2fHwWrPthBgPJY2AW1y0rjltG48+9UGDlfVB3yPEJBit+Fwqd/On5y0JFplpbL9YJXl8WCkJtl4+Lw+PPLRKgB6tM5i4/4Ky7TdCzLZVFIZ9FqXDOrA9SO78P9mr+GHLQct06Ql26ipd0WcP4CUJBt1DhcF2alU1zmpqHVEdW6vNlms3HXEs69zqwz+cfVgOrRM54ctB7nljcU+53Romc6R6nrKax0k2QQF2ansKavxHLfbhOU97tMuh31HajhYWQfAc1cOYvzA9lGV1UAIsVhKOdTyWCMI+lTgaynl2+7tdcCocC4XLejhkVKybl85vdt6W/Kdh6p4f/Eu7hjdA7vbSu1y/6cA3H5Gd24b1cOyC15R6+CzFXtYsauMFbvK+Nd1Q5mzai8PfaDGut+8cQQjuuXxyIcr+W5TKcO75jFj8U4ACnPT6VaQxYL1JQBcd1JnquqcnuONwR8v6s/DH670PKCDOrVkyfbDPmmGdcmlrLqeQ1X1lJTXeva3b5HGbvdDlZWaREWtAyGgd9sc1uw5ghV2m+CBc3rzz/mbOVBRy6gTCvh6XUnIPN46qjun9yrgk+W7mb++xEeER/duzagTCigqbMkr327h42W7fc4d3bs1NgHz15dQ75Rce2JnzurXhmtf+RGAwZ1aUlHroLzGwb4jNbTNSePpS4uw2wTX/ftHj0g8fkFfHv9YNSBf3n0aNfUuPl2xh9KKWnIzU7iwuD2Hq+pZsv0QWw5UsamkglqHi22llbTKSqFX62y+Wruftjlp3Hf2CTzx8Soeu6AfFw/qQLcHZwNKuP88oYibXl/Ewco6UpJsLH/sLNKS7ewvr+GzFXv5cvU+rjupMyd1b8XJT8/lSI2DlCQbb944gso6B+/+tIPPVu4F4JoTO/HHiwYAMPPnndzz7jIA7hrbk/OL2vHF6n30aZfD6T0LeGHeRg65G62FGw/w6zE9+WnrQb7ZUMKfJwykRbqy/PcfqeWvX67HJgQPndeH03oV4HRJPlq6ix6tsxjQoQVl1fXc+c5S5q8vYViXXNq3TKd7QRaLth0ixW5j6rVDsNsED32wgrd+2E5uRjIL7x/t41qaPG0RX6zex9DOuUwYUsjFgzuwdk85f/liHXef2YvOeRm8unArhbnp2ITgwkHtmb1iD4M75VJeo3pDOw9Vc2rPfAA+WLKLg5V13HRqt5B1LRRNLejnAXcA5wIjgOeklMPDXVMLenhmLN7Jb95bxuu/GM7pvdRaPNf9+0cWrC/hnckn0r0gi5e/2czUBZs95/Rqk8WFxR34aOkuquqcTJlYzNDOuVz98g98t6k04Dvys1I5UKHE0WwZGvxqdA/+8fUmnC7pkzYYVwzrSPeCLISAP366BoBu+ZkM7NiS8hoH/12zL+i53Qoy+eC2k7n0xe98LMHBnVry6qThpCTZ+P0nq3j7xx1kpyXRvkU6N57alU0lFUydr+7BR7efzCvfbuHmU7vRITedmT/vpEfrLF5asJn2LdM5tWc+Ow9VM6hjS0b2yKei1kFqko1ku42FGw/w0oLNlFbW8voNwxn+/75SXeYrimmbk8aIbq08eXI4Xfztqw18v7mUx8f3o197r4vF5ZIcrq7nsVmrWL7zMG/dNILC3AwAKmsdrN17hEEdc7HZBPe8u5SZP+9i9q9PpW971XA7XdLTWAOs3XuE+etK6Nwqg3H927F0x2Gq65yc1N2bn3AcrqojIyWJlCQb89btp7BlOj3bZPv4g3/cchAppaecC9aXcPtbP3PpkEIeH98v6LXf+H4bc1bu5eHz+/gYH9N/2s43Gw7w1CUDyE5LBuBITT03v76Ih87rc9S+dKdLYhOEdBdKKZESH9+1vw+8rKqeP89Zy5l92zDqhNY+5+84WMVd05fyzIQiuhVkHVV+G4ujEnQhxNvAKCAf2Ac8BiQDSCn/KdTd/DsqEqYKuCGcuwW0oBscrKzjUFUd3Quy+GnrQVbtKuPKEZ1ITbLz+KxVHjfCC1cN5ryidox7dgFr95Zzeq8CWmWlMPPnXZ5rtcxIDuiSdyvIZGyfNry0YDOTRnbhQEUt328+yIGKWgYWtuDfk4Zx/8wVfLl6H7ec1o30FDv/+HoTdQ4Xz04s5qJBHfjV20v4eNluLipuz4dLleV51YhO/OeH7fRtl8Nvx53AgzNX0DonjQ9vP9nz3Re9sJCKWgf/ved0z75tpZX858ftTJ2/mbzMFJ68qD+7DlfzwZJdPDuxmJ5tslm5q4wJ//yO20f1YNnOMh49vy+dWilBXLjxAL96ewnTfjHc46c+UFHLyKfmcuXwjlG7nULxzYYS5qzayx8u7N+gMQbDqraHGAjbXFLB4m2HuGxoxwbnsylxuiQCmnwwTxM5R22hNwWJJuiPfrSSHQer3K6OfXy1dh/fbSxl7xHlKph8WjdeclvaOWlJ3HJ6d56Zs87nGunJdqrrnZbXf+yCvlwxrBObSio4//lvAbh7bC+P/7ZdizS+vm8UqUl21u8r58lP1/DsxGJyM1OoqHXgcLpomZECwNT5m3jqs7X8+OAYWuek8e5PO/jt+8uZOLQj0xep8e+VT5xNSXmtz+Clf/RAncOFRAZECQD8vP0QJ7TJDhqhUekevLMSUqsoheo6JylJtpDiqdHEA1rQmxEpJT0f+gyH21r73bje/OnztZZp8zJT+MXJXfjLF+stj4PyF0+/5SS+Xl/CIx8q//fSR8+kRXoyQghcLkm3B2fTNT+Tz+86lZ+2HKJFejId89I9gh1Jno9UO2iRobrJNfVOHvtoFbef0YPTnpkHwNanz4v4Hmg0msZDC/oxoNbh5J7py7hqRCfa5KSy+3ANp/UqYOuBSkb95eug5xVkp3oG+ObcdRq92mTR9QE1OPWr0T04pUc+Awpb8N3GUoZ0ziUrLYlku41ah5MTHv6cW0d153fjevtcc3tpFdlpSeRmRibg0TBv3X6OVNdzYXGHRr+2RqMJjxb0Y8BrC7d4og8Mbjm9GwfK63j/Z99okAfO6c2YPm3YuL+ccf3bsXznYboVZHliof/97RZqHE5uG9Uj5HfWOpwk22yx6d88shsWvw6j7lejsRqNJiK0oDcBy3Yc5vvNpSTbbaQl23nwgxWAim3tlp/J+n3l+Iejvnj1YPIyU3yiJRKW1y+ALQtg8nxoX9zcuYkfqg9DajbYAsctNPFBKEFvtlfQxSoul6TO6eLCFxYGHJt1x8n0bZeD3SZYtO0Ql/3zfwBMHNqRM/u2YUyf1sfFjMzjglp3WKIr8okgmjC4nPCnzjDoGrjwhebOjaYZ0MvnRkhlrYOr/vU93R6czVl+MxcBXr1hGEWFLUlyT6Mf1iWPLU+dy/NXDuKx8X0Z27dNfIp56Sb48lFwRTfDD+Gueo6a0OkShTWfKBfU0VDlnoG55E3vvpUzYfl7Db9m9WH45B6oLQ+fNlaor4ZP74XKwHkZsY4W9Aj5x9cbPRNzth+sAuDeM3uRYreRkWLnxK6BbhQhBBcMbG+5qFHcsOZjWPg3KNsRPq0ZQ9Br/GZyVh5QD1xTU1sB1YciT39kd/SNVqRUHoDpV8PHvw6c2RUNVQe8n8t2qmvNuAFm3uTdF46yXb55WPgsLHoFlv4nMG19DVSEnl17XLLiPfjpZZj/p6O/lpRw2FT3zZ8jud+NjBb0CCitqOXzlXsZ1iWXf1ztXe79jtE9WHj/aBY/fCbpKQnqs6xxT88v3xvdeYag1/oJ+jPd4c0JR5+vcLwwHP7UJbK0FSXw1z7w1RNNk5dnuns/H97e8OtUmsR1Sj9Y9G/v9vL31L7t3wc//8BGmNIX/vd37z6j0bNqaN6aAH8JPXB/XOJU66ngaATDYdNX8Gx/WPUhrP1Ufd40F3YuUvd7yVtH/x1RoAU9DBv2lTPsyf+yqaSSfu1bcGK3VuRnpfLCVYMRQi3OE7WYu1ww+7ew1/KdIc3PgY3w8V3KJ3toG3x4G2yaB3Me8k235hP4dor6XL478DqhsLLQjc/bvg1//uavlaunoRzZFfq4ow4+ul0JrCFqC59VD63Bus/gtfNha+B4CpWl8MEvw7sqXH4TxXb/HDp92U6YOVm5Qgz2rVb1qdLPWl5qEpOt36j/e1cEv3aFe1mGNR979xm9pZqywPTGNcP1XH78Fyx/Fw5tVXXJ4bd8xDd/hVUfqDLsWR76WguegfVfeLfXz/HWwUiptV5gLChrZ8PcJ62PHdnjzZdx3w5uhhL3pMAt89X/TXNV+Zo4CCWOfQEN5/OVe/jlmz/7LPoEMOqEAvIyU1j08Nij+4KKvfDjVFUB7l0TPF3ZLkjLUVELjUVdpfK1JmeAdIKzXl0/zbSU54xJ6sEfdhN88TBsnucVh5G/guy26vP0q73nHNigxM8QgPxeocMRjWO1JqE4tMV0vY2Q2wXsFlVUSph2ofp85u+tr1+yHvJ7hg+JrK+B5LTA/ZvnKV90ZSmc9hvv/neugsfdeV71gRK1lb0gs8D3+xb8GZa9De0Hw4jJwb/f3+1zcLN1OqNMq2bC8umQ1hJOvBXyuqp7Ublf1SszocTb+K6cDnBwCxSc4M27uZEtczd85aa19pz1sP1/3u3aI5DeMrC+lqxT9WC2+/4VDoOdP0HR5ZDXHZLTYf9q357Putlw90plSGS1VmmkhAProVVPmPtHle6X7kb0P5er/6fcHbqsZozeZG256n0JG2S6Xab716rfsfaIqhs57eCHfyphHjBB3afDOyAjD1IyvWNAZTsgzb2ej8sFdvccEGedyv8bF6vtvG5w4i8jz2uUaAsdtWbHi19v4tWFSlD+vXArgEfMJ43swpJHzvQskHXUON3rrYSL8JjSF/41pnG+0+A/E1W38Jlu8PwQ9R3/9nshlZE/mx2q/AaOdi+xvu68J+HZAcqV8cJwJXahMB4Es3gcNAn634fAJ3dZn2sWfmfgcrJs+BJeGAYr3w+dBwgUQU/+3FaksFlbp+AV4zWz1PeZXRVGtz4clQd8t4O5rkrWq+/4+im1/eNUeK5YNdBGL2D1R77nWOXBaHDrq+G5QTClP/xjBPw8TV0LvNerr4F97kbBLOgr31dhpwaG22xKX3jlLPV5xQxVD9Z+4k1XulH9n3ahqoMf3up7HQCE+k3/VgQzb1a7vp2irrXpK2+yf56s/gzqqgLLGgyjN3lkj3IZ/d8JartsJ7x4Enz3PLx4Cvy1txLn3UvV8Z9eUeL8bH/1HJnLbkvyjiNVHfDee2e96pkYfP471aNqIrSgA9e+8iN/+nwtT3y8milfrufHLQdJSbLx8R2n8Nmdp3L/Ob3JzUxpWJTKhi/hpTN8u+r17sonXaqCzPo1bPvO+vwD66z3R8PKmV73hNFNBm9l3L/KN73R0DjrA10Gu8K4BAwMX+227+DjO1U5dy2G929S7gyj22uIZc0ReO9632sseUM9UB/cqq636gOYejpMHeVNYwhU5QF452plUe90z29Y/i5Muwjeusz3oTK7jo4EWeXZeCDtyYF+/pm3qO/a4O76G66OTXO9aaTbDfHZfV5B8ByT8OHtqjyvuZdQuPAfUNBbDb4C7FwM701Swvjfx4MP4O5ZHpkvuNodAWMMnBoCXele933bQqhz/yZHdip30ppZ6vexp3rzBb4NL6jfzmhY969W9//9G935W2bKQwS9keQ07ziC4VpZ4Y7S2Rli3sqr51g37k4HvHeDqnsGRqNpfI+rHl4apXze0qWE+4h7QPPZ/qoXmdpCNaL/OkPtN54jwyCpr/EOglaWeOvMvpXw77PV5xNvU/9fPEk9k01Awgu6/8Sqv321AVDrcw8obEGfdjmeN75EzK7FXl/Z+s+VX9TslzQsIelSPsCfX/e2+AY7frS+trM+vJ/Rnxk3qEiUPctBRFAWQ9CP7PK1hsFr0TrCWKC7Fivxf/UcWPwabP0WFj6nHs4V73nFY91s9dAtn259nfLdsOw/6qGY/wzsWerrpjG6/j+/rqzB/z3vbYQ2zFGukw1fqHNB+azNlnR5EEE3Gl17SmAkzvJ3fC1Pgz3LlW+7rtLX3fHS6aphN3zNW7+BpW8qwTYEtt1AyG7nFZuXRyvBf/9GZaHWBfHFb/jCd7tdkElaB7eq/5vmKvHxb8jKdvmOBbx9hfr+lGzoe6FvL6V8D6RkKRcIKPGqMC2LbPZpr/vMOj/gDbM0U7HPW/dTs2HHT17Lfm+Ier9nqTedmfI9yk31r9HefYaQm8d99pvWVyozDUwbYy3n/Z/6b+6h7l7i7cHWV3ob8coD3jpzaKv33vQZ7z03KTV4WY6ChBd084sSDB4+rw+XDSls2AW3/6Aqz8Jn1bZhlZgtHEPMqg/C224hN/xvoB66V860vv4Ht8DUU60fhnBMPVX5zf2xJftuG8LzgYWvz7CIKyzWNS/o4/28a5HXmgF4/XzvANGSN72iW1kCi19VUQJtBsDYx32vWWJ60PavUr5XM/+5XM04zXa//eXwDmvxS3L7NP0HQ80WpBlj0NGe4rW2rrRodJJM/veqA2ogdc5DvhYhqIgQo/wrZgReJzPfLeh7rH9bc6My8Crv52//6ptu9CPW5TF6KHtXwDf/F9iQbfsWfvqX7751s5WPPiXD28CBOjevG1wy1Zs3cwOR39P7eZ9p4P+8v/oaFNVW5SyDD931ruoAvDLW21sK9luZz/XH3LuqPqRcM+V7oOMI33T5PaFFJ2jRETLyfY91Gqn859l+bxh6aZTqRZoRNiXy/r06gJam1262Hxx4vBFIeEHfWKLE9eZTu/L+rSdx6eBCJgwpDO5e+XaK19qzwqj4qz5U/w1B3zLfe16dxau60nO9n3/2qyRvXOztbhp+YcOKrq1QfsvVs1RDYnzf4tfhxZPhzUuD59UgI8/7ecmbXgul5jD0u8R7TNiVoG/8Cl628O3nhwlhM/K2/TtV4Ufcqh6ixa/BwU3Qrggy/OL59/m5gwotZjzvX6tEB1S31yqKoXyf6qV8eJvv/iVvqt7G21ephmHl+zDrV968Ln3THf4noIfFYHi3Ub7be1cE722snKFCMrct9G3AQZU7p51qcPzzCF6BuPYDGP88/HYLdD4lMJ35tzRjbuR2/OB1idz0FZz7F9+0bQd4P2e1geRM37kB5Xsgp71yQxh5MzcQ/m66kb9S+R12Y/D8RYJ/Y5zqdw8rD8C716txp6qDaqD+pVHe47uXeBu2/n7PRXI63PEj3P4D3PET3LlM5fn+HeqeC6H2h6NwmPp9zb1Ag0xTQ5HTLvy1GkBCRrmY33RivAfxxlO60bZFGkM6h6lw/31c/T/9vsBj9dXKtQCw3x29Yg4vm/dH6DHauhua7n57y57lgQOPm+ZCxX648h3vPqN7t+079YDu+EFtb/hSRRF8/Gu1vS+C0EiziH50u++x4qtVlxWU4NZXw5smkR94pRL6pW9CVtvw32WmTT/lo/7uObWd2xXS/e7/d8+r/yN+qQaehkwKFMy6cnC6z9v9s6+l1usc5XpZ96n6M+g/QYnxrDuUr3jdp0qMjcbMfE8OblbiYU+Ca2b6lr9Nf+VWMzjsfRlyAOYZnENvVBN2AM76o7oPAy5TIX7rLeqHYaEXDlP5yMiDvC6BIZ7+DYWZTicpF5XRUwDoMESJmZnWfb0uo9oj6nhdhXKF1Fep3maHId7IqDUf+w7AHtyiLFWjjuZ18wp5Rn5geCVAnwt83ZIGrXqqpQy++n1g77J1H9hhiqtf9rbXFbbkDRUZY87X7iXeiVCFQ2HsE+r4vCdVT8u4DymZ1g1PagRvLCro7X0WQdWzle4eWVIqXD3D2npvJBLOQne6JN0fnM3Tn6/lu40HeOTDlWSm2GmT0wg+rfdvgm/c1o7T7crxHwj61+jAbhp4oyqmnhrotwYlMB/e6t02Hhb/noQRLpUZJiInz/ROw1BhkWktlCslu72y1Er8BmnPn6JCuSCyBaFyTMvudhjs+915XQMfpMoSyGwN5/wJzn4y0OUCyiL0DOTWQYkpFHToL+D0+wPPueQlJXDgnYDTwuRm84/uMcSrxxho2dm731Wv8te2CLq638yUE4G7rpcpsmjkr9T/1n3gyrfV57ZFkO++r6ktVCMlbMp3bZBiITBmFxBAoeltkKf9Bjqe6N3Oaqvqj/E9VtcdeIW39/PKmSpCpapU3atUQ9Bn+TZqh7b49jiTM7yfM/3cGQY9xqrGCuDaD5WIg7LqT7nLa/Aku1+o0m6gqi/gddOZxzV+nubr2hJ2NSbww4tqu1UPdd0Bl6ntYlMIbiiKrlD/7anqGv749zAnvOK73fPMwN5BI5Jwgm5M2586fzNXvaxaUptNhI9g+fFfvuF9r48PnCRgNVBWczhwn5nkDPVw1xxRg4PBqDmsBtOMbubfh8H0a7zCbmB3+8Od9aqSdj0t8Fo9z/a19g0xfP+mwLRpOfDLb+Gu5cqCMUb/PflP9z68Kd63F/GrINEw5oc7/wRf8cizsNABLjetcWKzqLLfTvH2jCZ9CneaBs/SW8Lpv1UCYNBhiGp88rqp+7nNPRgYseVk+t2T0uCe1TD5a+99sHIL+dP9DOv9XU6B32yAG7+AWxfC8MnqN649oho/cz21ulfmwbaH98NFL3q32w/25v2sJ+EutxVuT4LfmXoWLne0yNn/D4bc4PubGbQrDozfP+Nh9f/wDhUn78mTKZ3RCATkO81bf3Lae2+x4Y83rtfzTPjNRvjFF6pHB4HGS8vOaoDUvE7Qibd6ex3j/+7tyeR1VfdpoF9QQjAuehEeOQD3b4Pubrej2eee3tL6vGNEwgn6ur2BA2Yu/3VurZj9G9/JFFvmh+5eg4qoqD6s3AXByGqtWvXaI8EjGUD5AwGK3BZFXYXqovr7Kx21yi1Sc9jd1bWwiNJy1ISPMY+ph9yIWDHCw8yk5qgH3p7s7ZL6R8oMvAJGPwyn3uvdF8xXmpQGN82FS15W1zV3Y7PaBlo4YC1c/hi9nrzukGuyoNNzlQheMxNGPQhnPARXuNclsdmg66netPtWKiv41KZLVTEAACAASURBVHt9B2fzuqvegT8dR8DJd6p7Y7N7H+ac9nCpn2XWwSTy18xU51z7gfrsjzGhxp6selzSpRp8f5/xyF+p+97ftFSC0UMDJe553eDU3ygBz8jz+ro7DvcOFIOvEBmGRUqWundWgt5+kPp/9lPefd3dkSSuet+el/n8tBCCftGLMO5pVTfHPq4mjXVzX9NoLDPzIatANSaGhe7fSHR2x6eb3U+GxQ+ByzVHE3Fis3mfhaG/UK6zk93uTYRvz2SSelEN18xUv/UxIOEEff2+QNF89YbhFikjwByTXW+xamDFPkCq0e0hk6yvkdFKVbyaI6GnJBuDrWaXBQRGRNRXeUPfsttZd3GT09WDeuo9Km/O2uDTt80PoCHobfq6w9kuUtv2ZDjtPmVh5XVXg2opIdw4hUO8DZP5wU/P9X0gDFL8BCX/BG/X2x+7X8SOYdll5sOo3ylrPdvk6zdmGBpi2W0UjHlU7be7H/RLX1ahe/6MfcK3V2JEC2W1UVERhsCB153QfYxy24A63sNicNmMEF4L3V8MUzLUfT/1Hu++pFQ10GxEUdhsMOYRGHmH2jZioduEeJm24RIwhDHF716nZHvr1UmmAdzWpigns4ibLflgPv6kNNUQnnirKnNWgWosjR6Z8ZuZz+8wRH1Pfi/f8nQeqf6bjZkC01u9DMv+aGndG87/K3RxGwXJ6d76lpwBXdz3r8cY37rQhCSOoK+eBX9sy5rt++man8mfLy0C4Lyidgxf+iD8x+0bc9TCMz19Z91Nv8bigqhBlmXvwFOdrJeBNUIV03O94pDtN7qd1kJZGHXl1mFX929XYVOgBgWzWvse91/l8Id/qhmEoB4C/wEvgCTTPnuKGjz6vYWQgt+D6T4vIx8e3OnrCjH49c/KRWM1ZR8CXURm4U9Od1vtfg+9v4V4x4++EQfDTVPrbX7fG64LXDgUHj0IvdwzHNv08x4zxkGC+X39BdaY4GPsv/YDr2XeYXDoawVD2ACpemLB3BV2k4VpT4G7V8DkedZpT7wVHjsc2Eia6TlWLW9gRC2Z69DjZeq3tyIlw9vQmkXc/PsFdbmEsZKNBtU8eahVd3hojxLWW00x9G36qv9tTSJvdlVFMrgZDYbbMCnN2iA5hiRMlMvhTx+lpaOavdvXMbJPX85L+onpndty55ie8KJ7IGrDf1UlrtyvFtIxKpH/6PtJd6jQwor9akJLbZlajtOf/7lfMpCe6+3emrvEJ9+lRveNUXFz6Ne4p5VvMK2Ft5JktQ10d/gLunlCS2p24CAZ+D6g5m63QaueUOp28ZgfBOPBPJpK6y/o5ofL+K6MPN/JQ1ZdfnMZzBa3v4Xuv22Fze5tkK2stwC3lQjMA3gHts0N5hVvqSiljsODXCsMRrSIs866cQbfMkYymzlYmhs+8y6aZsbq/pv5xRyv0Gbmw+FKa0MAAhtBYVfRK1b11Ez/CcrgMYfR+nP7T2reQvvBKhRzwGW+htktC6JfFTQSjGfIPJ7UTCSEhV5SXsvOcuUnr6upYvKRF8j86AbevyiLXm1MFuJbl6p4ZfAODFmtETHil9Cyo+oGGxbh3D8EpjPC/dJaeoU8KRX6XaxE88wnlIVouB3McbZ9L1TddvA+BNltAx+4UGsu2+zWlo/54bFbHC++KnCf+bxoK21aS69vPMBCt7CW/P3vVkJmFgxzGQy3x9BfRJdPI7zUHMEy6kF3Hv0EzVisK6uN737DT2t0tUH9ZsVXqciXgt5eSz1SDEF3Oa3FFhpv1mHnkdDpxMD9xr327/0YdDrROxZh9EDMdSzUoKgRGRWuDDYbDL/Zu4iWFQW9oO941WANv1n1zk44z+uOaTcQep0d+nsagjEoO+r+Zh8UTQgLXUW2qAc9jTo6uNyukHoLsTZmJhoWh3kNEAN7stfvHaySmzG7XGxJcNlrvseNB8aIkf3lQuVPNDAegpx2UQp6UuDsNvC6EsC3x+A5brEmBniFNdou6/3b1GSkNy8JbaEbZBYot4thpVtZlGYBMH82rNXzp6i/SDEeSvN9H/U79efP4OvUnz/dRnlXYvTHnqQmrUSLIejSFXzZBqvfsDFJCSPoZoweiLkR9rHWg1j74Sz0hnKlxYs5GpuUTO/vbkwatAppPAbEp4VeX6NmSrrDCnccrKJGqkp/3bC2JGHEcFsU34izrq9W8clWi2PZkpXI1pZFLuge14aFOBmV3FgoyV/kDqxX/7udEShuobqQtiQomhjokzbPVLVyuQRbKdBYu7shD59hiftPDrHyqY55FC4K805M830wC1pDX/N3/l9VZIrhfz1e8Ah6CAu9qQXdY6FH4L5q2dH3HPAV92AusCZa2+SYk5IJE9+EayJY6bMJiE8Lff6f1BoXqdnQ/xK2H6wiG1XpL+yXB1+7Bd1qsXljUoqrHj6529cfamCzKzfI/kgF3eRysRIcwwIy1kfxjxAZPllNgS+6PHAxJiNgt0XHQH+6LUl1VQddDd//w7vf7Eaym3z7hpD3v1StxeIf32sM+kX68BVN9C4Pa5QxEpdLm36qPOFo0UmVrTHEID3X6+I6njBE3OUKPnGrqcXQI+gRTBwzxiDMK0CGFHT389BUFnpz0Md/SeBjR3wKuhEtUlWKyyX5cctB+ielKu1z1HhFxRm4MFfATEirpUntbgs90teFJaWGtqKMyICKIBZ673PVH2Bp4XcfA9fOhMf9LHFPY+N3jjlSxnAFDb7Ou6IcwHV+a2uDadAvwofvkpe8nw1R8G9EjR6Cv2so2ACgmbvdA8BNtBTp8YH7t3M5glvokRgVR4MRsWJe4yUYxhwAc8/RXPcz/aK0RJABZk2DiE9Bd1ssny3dxr76rXy78QCPds6Dfaip+cZCQ/tWeUXUINyryUB1PYNNkAhGSEF3V+aKfSpdKIvL6qEOlhfjQTf3Csb/XVn6nnwlh8+fgREJ0hCL0Pgefwsd1OxOf59jJNEpBvHSXbfCY6E7gruTGupmipT0XOVC6DAkfFqjYTYLujl/HYfBxLdMb7tyH2tqt1GCEJ8+dHflWLFtP49/rN4O0qmNO3Ji7wrvusmf3+9ddS6q6ycHj6cNhkd0QrlcSqxdEGasBD3YWixWllufC/wEUAZP68+wm5U//oRzw6f1J6utetjHPRV4rMspvqGH0WIVqRMvCLOF3owvIu8xNrKooTZ9lStszGPB0/Q53/t5/PPKvaYt9EYhri30FOGN1khLCzKzsCEI4Q1rjJSQFrpb0OvKfddMDvbd/gRrXKwsdP/zjWnekQh62/7wQAPfSp+UEvr9qUdDwljoMWB/Jad7XWHmFRetSM9TM4aNWcOaoyYGakgDcItnCqbFrqxeBBwpuV3UMrFmKkstk3LaffBr0/K3xiJVnkFRi3PMEQGhpsxDaAv9zmXe2GkI4kP3y4DRMMVylzdRBD2SQcnjibtXeV/m7M/k+XDb99bHNA0mri30VqmSicUdGdixJVSFeduJz/npvoOhjlq1ytuyt737Rkz2LsVppnUftSBS19NhyPVqerIpT5b4TI0OI+hmQU5zL6tqnJPbxTfszhCAkBa6IejHYVUomhjZQFwsN0bhiDUL3UxOe9+4fjP+C2RpGoXj8CluBNxRGLmpkj9NUGu2sCCKQbasAt8IlvrqwBjcvG4w+Ho19d+M4ee8fpbvfs8gn4WJbk/yhg2Gm7RjfqjTc30FHXxdJ9FY6JHEGB9rzFEyoUgEC91Z37w+dE1MEJ+C7rbYWqS41GqEC56J7qFPz/MVdEeNtY/Zal/QyR/u7w8WkZCcoQQ9mkHR9Fw1kzWcoEdkoR+Hgh4pcW2hG4OiISYWgXLthas7mrgnLgXdYUsmCchJdqkolk1zvcuXRoQpVrp1Xzjnz9arKVqKfAOnZydnqDXMw1ro5hccuKMOfATd9P2RWOgjf60if/zHCGKJRLDQQ4Utgte1p0loInLKCSHGCSHWCSE2CiEC3uclhOgkhJgnhFgihFguhGhAXFvjUVajRtaz7E4l5hBdaFt+L+/nCf9WCw9ZCbWlhR5E0D0PY5CH0ghdDDsoaiXopigXs+skEh96iw5ww+yje3lvcxPXYYsxPCiqOeaEFXQhhB14ATgH6AtcKYTwX/DiYeBdKeUg4ArgHzQXuxaT/r1alCnDblo3xBXi9W4G+Seotbx7nuXdZzxQVuJtNZAY9KEL81YkY4mBcIOi/i4X/3PM+QzXiMQLVuvRxAuxPCiqOeZE4nIZDmyUUm4GEEK8A1wIrDalkYBhJrYAdjdmJqPiX6MxYkayMa1ZEomg2+wqqsI8/d8j6BY+ZksLvYHiaSy7GXYlQ9P1u49WLz4wv/A5bJ7iUNzj2kI3fi+pB0U1YYmkye8AmFd92uneZ+Zx4BohxE5gNvArqwsJISYLIRYJIRaVlJQ0ILvRkVJpemFEJIJuPDBmSyiUhR6Ny8VYOzvYq6g8U9/DCK45b7ldVSSI2Yccrlve1NPEm4O4HhS1qIsaTRAaq4ZcCbwmpSwEzgXeECKw9kkpX5JSDpVSDi0oKAi4SKNzxNRRcDmDpzMw3l9o9RBZuleicLm0KFRvWR/9sPVx452HxoqLwfDxh1v8fJYzPuPcQrfFsdBpQddEQSQul12AeS3TQvc+MzcC4wCklP8TQqQB+YDfylfHGPP0/IgsdMMaN0eKuD9HKt6hHrpQ0/oHXwf7V6k3uUeSR7C2tsO5XOLRQo9rTL+XHhTVhCGSJv8noKcQoqsQIgU16Ok3a4btwBgAIUQfIA1oep9KNLjqCW+duo83hcslHCkZaqGicItUhbPYEtFCj2fCNeAajYmwgi6ldAB3AHOANahollVCiN8LIca7k90L3CyEWAa8DUyS0urtEU3LttLK4AfDxfGaMYuy8TnUoKjZ8m5yKyqcy8Wq16At9JjFR9C1ha4JTUQTi6SUs1GDneZ9j5o+rwZO9j/vWPPKt1v4fbCDLicRW6eWFnqIOPS0lqhOCk3/0IXzoyaqhX7B39SLt+MN7UPXREFczRT9aeuh4Aed9co6NfoNtqTgfnXzIJsh5FZT421WUTFNLJgNGRRNBAt9yKTmzkHTICzqokYThLhq8veUWbwuzsDlwHelwpbB0x6ND72pH7qj9aHHq6DHK9pC10RB3NSQ6jonh6tCvHTC34ce6u0rPj70SATdNFzQ5C6XMOJs1ZPQGh67hOuRaTQm4qaG7A5lnYOFhd4iMI3x8NgiFXTjPZkyMH2T0YBBUa3osYuPoGuXiyY0cSPoe8ssVkM042+hh5piH7HLxWqg9Dh0uWg3S+yiwxY1URA3gr7rUJQWeqi1o4XFxCLLQdFmdrlYWd5ho1w0MYUeFNVEQdwI+raDlSTZQgiXv4Vufu2bP0c1KNrEt7RBg6KamEUPimqiIG5qyNbSKgpz08OkMlvomcGTmUXZasEuTzq3eJqnUDX1QxfuAbfcpy30mEULuiYK4qaGbCutpFOrECINvsIWStCtHqKI1005ljNFLfJkKd5a0GMWPVNUEwVxI+jbS6vonGfhRvER3UgF3exDN98iAaf/znTMSCct9jURDbHYtIUew+iwRU3kxIXD1eF0caTGQX6WxYsOzDNCzcKW3c7iShaLc5l5/HDgtQMucSxdLpEKtRb0mEUPimqiIC6a/MpatdZ5VlqQCA+PxW0Stp5nwqWvqJdA+xPpg9McLpeGTDTRFnrsosMWNVEQF4J+pKYekGSnBonB9qy5YtpvT4UBEyApzbTT7TqJVCg9g6LN5HKJ2PLWQhCz6IlFmiiIC0GvrKxga9rVDNg+LfCgsJksadPDYbyByHJgMVIL3cKHfiz9nNpCj390lIsmCuKihqSs+wiALlunWxw1uVzMwuZ5D2WkkSIW2Jth6n+DHnAt6DGLFnRNFMTFoGjK3sUA1Ob2Ir18m+9BIUwCbX6dV7L3uD+Ruk0iXkulEYnEp9p9DHQ+KXw6zfGPHhTVREFcCLqrVk37T62zWg89mIWe7D0ecEq0lm9zrbYYJJ/XzvQ/qcmyo2li9GqLmiiIixricqiFuZJrDgYeFMLah248KFZro0Qqypb+9+PQ5aIt9NhFTyzSREFcCLqsV4JurykNPOgT5RLhLMpoRflYRrk06HVyWtBjFh22qImCuBB03IIuasosDgaJQ/ccPgofemM0BtGiB8kSC/17a6IgLmqIcNaGOGhregvdx4fe1O8UbYDFpi272EUPimqiIAEE3eRyQcCEV2H4LabjEa5YaEWrHnDCuXDx1IjzetQkwgufNV70oKgmCuIiysXuCiHo/lEu/S9Rf57DR2Gh25Pgyrcjzmej0JCHWgt/7KIHRTVREBdNfpKzFmewogSLcgnFcd21bYg4a0GPXbSFromcuKghdllHrbBYaREi8KGb04ZZbfF4oCHWtrbQYxftQ9dEwXGsXJGT7KqjTgR7W5EwPRQRRrkcz13bBjU2WtBjFh22qImC2Bf07/9JS3mYWlsQQT8WcejHEm2hJxY6bFETBbFfQz5XbxBy2NOCJAjjQz+qOPRmQFvoiYUeFNVEQewLupt6u8Xr50A9EMJiPXTzcQMZ5XrozYGOckkstIWuiYK4qSFOezCXC75x6JYJ/HcdzwKoo1wSCj0oqomCuBF0mRTK5RJhlEssoC30xEJPLNJEQdzUkGQc1gfMLpdwA6D9L230fDU6WpwTC/0KOk0UxMVMUYAUGWS2aLgoF2PfZa9D3wubJnONiR4UTSy0D10TBXEk6DVBjkQ4UzQp7eis35u+grKdDT8/UrTLJbHQceiaKIhIHYQQ44QQ64QQG4UQ9wdJc7kQYrUQYpUQ4j+Nm83w7G8/xvqACPLGIs9x4xbIwGPRUDgU+l10dNeICD0omlDoQVFNFIQVdCGEHXgBOAfoC1wphOjrl6Yn8ABwspSyH3BXE+TVktqcznzoHMnhwtHWCYQNbCFmihr75FEK+rFCTyxKLLTLRRMFkdSQ4cBGKeVmKWUd8A7g72y+GXhBSnkIQEq5v3GzGRyXy4ULG1npQdZyMbtcQgpbHAu6ttBjFz2xSBMFkQh6B2CHaXune5+ZXkAvIcRCIcT3QohxjZXBcEiXC4kgKy3Y4lwRvrEoViz0hqAt9BhGhy1qIqexBkWTgJ7AKKAQWCCEGCClPGxOJISYDEwG6NSpU6N8sXS5cEkR3EIXNtMqiiF86NLVKPk5PtGCHrNol4smCiKpIbuAjqbtQvc+MzuBWVLKeinlFmA9SuB9kFK+JKUcKqUcWlBQ0NA8++CSykLPyQjhcgm12mIioC302EUPimqiIBJB/wnoKYToKoRIAa4AZvml+RBlnSOEyEe5YDY3Yj6DIl0uhM1GakqydQIh8Ah5PPjQNYmFfuWgJgrCCrqU0gHcAcwB1gDvSilXCSF+L4QY7042BygVQqwG5gH3SSlLmyrTvhl0kWS3hx4wCrkeuuFyiWNB10IQu+hBUU0URORDl1LOBmb77XvU9FkC97j/jilSukhOSgrdHTUeilAzRePaQteCHrOYBT0ls/nyoYkJYn+URbpISgpnoQd8sLhOHAu6ttBjF7Ogp+Y0Xz40MUEcCLok2W6L0EK3ONaqh/qfmd/oWdNojhpzY5yU0nz50MQEMb+Wi0Bis9mDh3RJiVfJLRR91APQ6SToeprv/l8uhLR4sYi0hR6z6FBFTRTEvqBLl5ra31Afuj0Zep4ZuL9t/8bJ4PGAdrnELlrQNVEQ87XFa6EHEXSh49ATt9xxgBZ0TRTEfG0RuBDmNc/9kTL0TNFEIFHLHQ9oQddEQczXFgEImy24hQ7aQk/YcscBWtA1URDztUVZ6CF86BHPFI1jErXc8YD+7TRREPOCbpMSESrKBbSFnrDl1mgSi9iPcsGFTYjgloyUoaNcEoFELXe8MOwm6HNBc+dCEwPEtKBLKb0+9FCIEHHoCUGiljtOOO//mjsHmhghpl0uTpfEhkuFLQbDbL0nqqWaqOXWaBKMmBZ0h0tiFzK0hR5upmhCkKjl1mgSi5gW9HqHEwB7WJdLgvvQNRpNQhDbgu5Ur40T4WJ1Ez3KRTdkGk1CENOC7nA4ABD2MAv/J7oPPVEbMo0mwYhpQa9zC3rELpdEFbYELbZGk2jEtKA73T70sGGLiT5TVCu6RpMQxLSgO1xK0G2hBN1ntcUEJWEbMo0msYhppaurV4OiIePQzTNFExYt6BpNIhDTSud0Kh96SAsdtIWa6OXXaBKEmBb0ekPQI41yiecXQYdEC7pGkwjEtKA7HMrlYg/rUjEELUEFXVvoGk1CENOC7nRPLLLZIw1bTFS0oGs0iUBMr7bo8PjQw7lc3IIeLy6X6z+GlKzI02sLXaNJCGJb0I21XCL1occLXU9r7hxoNJrjkJj2RTicUS7Olag+dO1y0WgSgtgWdJcRhx7hoGi8uFyiJd56KBqNxpLYFnSHMVM0Qh96wqIFXaNJBGJa6ZyGyyUpUkHXFrpGo4lfYlzQ3astGoJ96//g4pcCEya8oCV6+TWaxCCmo1yMF1x4olza9AWXIzBhvIUtRkvCN2gaTWIQ4xa6EbZoKoaVeIkEnymqLXSNJiGIaUHvu+MdwH8tFyvxSnBB0xa6RpMQxK6g19dQvOs/gF8cuqWFnuAul0Rv0DSaBCEiQRdCjBNCrBNCbBRC3B8i3aVCCCmEGNp4WQyCdHk++oYtapdLAFrPNZqEIKygCyHswAvAOUBf4EohRF+LdNnAncAPjZ1JS6TT/OXWnz37tIWu0Wjin0gs9OHARinlZillHfAOcKFFuj8AfwJqGjF/wXGZBd1cjBCCnrAWuhZ0jSYRiETQOwA7TNs73fs8CCEGAx2llJ+GupAQYrIQYpEQYlFJSUnUmfXB5HLxEXFL8dKCptFo4p+jHhQVQtiAvwL3hksrpXxJSjlUSjm0oKDg6L7YHG9uttCtpvlrl0tzZ0Cj0RwDIhH0XUBH03ahe59BNtAf+FoIsRU4EZjV5AOjUblcElzQEr38Gk2CEImg/wT0FEJ0FUKkAFcAs4yDUsoyKWW+lLKLlLIL8D0wXkq5qEly7PniIIIealA0UX3o2kLXaBKCsIIupXQAdwBzgDXAu1LKVUKI3wshxjd1BoMSzOUSgNQuF22hazQJQURruUgpZwOz/fY9GiTtqKPPVgS4oghbTHj0PdFoEoHYnSlqjnIJ6UMX2uWiGzmNJiGIXUGPxkJPeEFL9PJrNIlBDAt6MB+6v3iZfehNnanjlIRv0DSaxCB2Bd0c5RJuYlGiu1y0ha7RJASxK+gRx6ELi30JhrbQNZqEIP4EPUC8dNhiwjdoGk2CELuCHmxikZ4pqtFoEpTYFfSgUS7+RdJhi7pB02gSgxgW9GCLc2mXSyBa0DWaRCB2BT0al0uiC5q20DWahCB2Bd0VZKZoyIlFiWqhazSaRCCGBd3kcvGxwK2m/ie4hZro5ddoEoTYFfSI3ymqfegJ73LSaBKE2BV0/U7RyNEWukaTEMSsoLsinlikZ4rq8ms0iUHMCrrDUe/dCGmBapeLttA1msQgZgW9vt4s6JFGuSQqiV5+jSYxiD9B1z70QBK+QdNoEoPYFXRHNBZ6grtctIWu0SQEsSvo9ZG+4CLYPo1Go4kvYlfQzRa6zwsuLIqkXS7NnQONRnMMiFlBd9YHiXKxdLk0fX6ObxL+Bmg0CUHMCrrDYXa5hJr6j/ahawtdo0kIYlfQnQ7rA/qdohZoQddoEoHYFXTzoKh55UU9KBqIttA1moQgZgXd6TT50KV5KV3tcglEC7pGkwjErKD7+NBlGAs90S3URC+/RpMgxKygu8w+9GBL6Xr2aR+6RqOJf2JW0J1mQc9oZToSyuXSpFk6ftEWukaTEMSuoDscOLDBPWsgu633gKV4aUHTaDTxT8wKusvpwEES5LT3O6JdLgFoC12jSQiSmjsDDcXldODEHnhAL5+riQPq6+vZuXMnNTU1zZ0VTTORlpZGYWEhycnJEZ8Ts4LucNQjLddtCSHoOmxREyPs3LmT7OxsunTpgtAGScIhpaS0tJSdO3fStWvXiM+LWZeL0+lECgsL3QrtcmnuHGiipKamhlatWmkxT1CEELRq1SrqHlrsCrqjHlckgl50OdpCTfTyxyZazBObhvz+EQm6EGKcEGKdEGKjEOJ+i+P3CCFWCyGWCyG+EkJ0jjonUeJ0OiCcoD+0D06+S88U1cKg0SQEYQVdCGEHXgDOAfoCVwoh+volWwIMlVIWATOAPzd2Rv2JSNCT05SYJbygJXr5NZrEIBILfTiwUUq5WUpZB7wDXGhOIKWcJ6Wscm9+DxQ2bjZ9kVIinQ6kLUIfukfQtIWu0USK3W6nuLjY8/f0008D8M0339CvXz+Ki4uprq7mvvvuo1+/ftx3333885//ZNq0aUGvuXv3biZMmNDgPD377LNUVVV5trt06cKll17q2Z4xYwaTJk0KeY2lS5cye/Zsz/Zrr71GQUEBxcXF9OvXjwkTJni+w3ysuLiYl19+ucF5PxZEEuXSAdhh2t4JjAiR/kbgM6sDQojJwGSATp06RZjFQKrqnKTgQNpTIjtBR7k0dwY0R8ETH69i9e4jjXrNvu1zeOyCfiHTpKens3Tp0oD9b731Fg888ADXXHMNAC+99BIHDx7Ebg9vYLVv354ZM2Y0LNMoQb/mmmvIyMjw7Fu8eDGrV6+mb19/x4E1S5cuZdGiRZx77rmefRMnTuTvf/87AFdddRXTp0/nhhtuCDh2vNOog6JCiGuAocAzVsellC9JKYdKKYcWFBQ0+HvKaxykUA/21Ehz1uDvigu0ha5pJF5++WXeffddHnnkEa6++mrGjx9PRUUFQ4YMYfr06Tz++OP85S9/AWDjxo2MHTuWgQMHMnjwYDZt2sTWrVvp378/oCLV7rvvPoYNG0ZRURFTp04F4Ouvv2bUqFFMmDCB3r17c/XVVyOl5LnnnmP37t2cccYZnHHGGZ4894MgdQAADPFJREFU3XvvvTz55JMBea2srOQXv/gFw4cPZ9CgQXz00UfU1dXx6KOPMn36dIqLi5k+fbrPOQ6Hg8rKSnJzc6O+NxUVFYwZM4bBgwczYMAAPvroI8+xadOmUVRUxMCBA7n22msB2LdvHxdffDEDBw5k4MCBfPfdd1F/ZwBSypB/wEnAHNP2A8ADFunGAmuA1uGuKaVkyJAhsqFs2HdEznv4VHnw2VOsEzyWo/4Mynar7Wd6Nvg7Y5q66sB7ojmuWb16dXNnQdpsNjlw4EDP3zvvvCOllPL666+X7733niddZmam5/Njjz0mn3nmGSmllMOHD5czZ86UUkpZXV0tKysr5ZYtW2S/fv2klFJOnTpV/uEPf5BSSllTUyOHDBkiN2/eLOfNmydzcnLkjh07pNPplCeeeKL85ptvpJRSdu7cWZaUlHi+r3PnznLv3r2yd+/ecsOGDfK9996T119/vZRSygceeEC+8cYbUkopDx06JHv27CkrKirkq6++Km+//XbPNV599VWZn58vBw4cKFu3bi1POeUU6XA4PMfatm0rBwwYIC+99FK5ffv2oPervr5elpWVSSmlLCkpkd27d5cul0uuXLlS9uzZ05Pv0tJSKaWUl19+uZwyZYqUUkqHwyEPHz4ccE2regAskkF0NRIL/SegpxCiqxAiBbgCmGVOIIQYBEwFxksp9x99MxOaI24LXSRF6XJJVBK9/JoGYbhcjL+JEydGfG55eTm7du3i4osvBtSsR7ObBOCLL75g2rRpFBcXM2LECEpLS9mwYQMAw4cPp7CwEJvNRnFxMVu3bg36XXa7nfvuu4+nnnoq4PpPP/00xcXFjBo1ipqaGrZv3255jYkTJ7J06VL27t3LgAEDeOYZ5WS44IIL2Lp1K8uXL+fMM8/k+uuvD5oPKSUPPvggRUVFjB07ll27drFv3z7mzp3LZZddRn5+PgB5eXkAzJ07l1tvvdVThhYtWgS9dqSEFXQppQO4A5iDssDflVKuEkL8Xggx3p3sGSALeE8IsVQIMSvI5RqFihoHKcKBLSlSl4sb7UPXaI4bpJQ8//zzngZjy5YtnHXWWQCkpnqfbbvd7vv+AwuuvfZaFixYwI4d3uE+KSXvv/++5/rbt2+nT58+Ia8jhOCCCy5gwYIFALRq1cqTl5tuuonFixcHPfett96ipKSExYsXs3TpUtq0aXPMl26IyIcupZwtpewlpewupXzSve9RKeUs9+exUso2Uspi99/40Fc8OsprHKRShy05LcIzEjzKRaM5xmRnZ1NYWMiHH34IQG1trU90CsDZZ5/Niy++SH29evvY+vXrqaysDHvd8vLygP3JycncfffdTJkyxef6zz//vOESZsmSJSGvYfDtt9/SvXt3APbs2ePZP2vWrJANQllZGa1btyY5OZl58+axbds2AEaPHs17771HaWkpAAcPHgRgzJgxvPjii4AaTygrKwtZ9kiIyZmiFbX1pODAnhKhoCe6yyHRy69pENXV1T5hi/ffHzCnMCRvvPEGzz33HEVFRYwcOZK9e/f6HL/pppvo27cvgwcPpn///txyyy1hLfHJkyczbtw4n0FRgxtvvNHn/EceeYT6+nqKioro168fjzzyCABnnHEGq1ev9hkUNQZJi4qKWLJkiSftc889R79+/Rg4cCDPPfccr732WtC8XX311SxatIgBAwYwbdo0evfuDUC/fv146KGHOP300xk4cCD33HMPAH/729+YN28eAwYMYMiQIaxevTrMHQ2PkM3khhg6dKhctGhRg859+ZvNjPlyHIX9Tyb58lcDEzzu9kU97m7xKvbDX3pCRj78dlMDcxzDOB3wB/dLQB4/eitA0/SsWbMmrHtAE/9Y1QMhxGIp5VCr9DFpoZe7fej2qF0uCYq20DWahCAml88tr3GQhiNyH7oRDdMm9ESK+EULukbTWKxYscITS26QmprKDz/80Ew58hKTgl5RW0+KiGJiUVoLmDQb2vZv2owdr2gLXaNpNAYMGGA5g/Z4ICYFXc0UdXgt70jocnLTZeh4Rwu6RpMQxKQPvaKmnuRwU/+z2gY/lqh0sBxH0Wg0cUJMWuiVNbXYkMEt9Nu+h8zWxzZTxzu3fAO5Tb5MvUajaUZiUtBratwTFIJZ6K11uFcA7YqaOwcajaaJiUmXS01VtfoQ7dR/jUYTMXo99KZdD9288mRjEXMWupSS6poqSAEiXQ9do4llPrsf9q5o3Gu2HQDnPB0yiV4PPcHXQz8WHKlxYJdq7QdtoWs0xxa9HnpwrrjiCj799FPP9qRJk5gxYwZbt27l1FNPZfDgwQwePLhx1j0PRrB1dZv6r6HroW89UCFH3z9Vre29/L3wJ2g0MYheDz321kOfOXOmvO6666SUUtbW1srCwkJZVVUlKysrZXV1tZRSyvXr10tD+8z3IhhNsR76ccWhKrUwF6AtdI2mCdHroUe3Hvo555zDvHnzqK2t5bPPPuO0004jPT2d+vp6br75ZgYMGMBll13WKItwBSPmBL16/yaG29aqjYhfQafRaI43ZJyth56WlsaoUaOYM2cO06dP9zSAU6ZMoU2bNixbtoxFixZRV1cXMg9HQ8wJevamT3ki+XW1kdGqeTOj0WgsScT10EFZ+q+++irffPMN48aNA9Q66e3atcNms/HGG2/gdDpDXuNoiDlBX5l3FpfUPk7ZpPnQYXBzZ0ejiVv0eujRrYcOcNZZZzF//nzGjh1LSoqKwrvtttt4/fXXGThwIGvXriUzMzP0jTsKYm499C9W7WXG4p28eM0Q7Da9RokmPtHroWsg+vXQYy4O/ax+bTmrn16nRaPRaPyJOUHXaDSa5kSvh67RaKJGSonQSx8fdxyr9dAb4g6PuUFRjSYRSEtLo7S0tEEPtSb2kVJSWlpKWlqkr9lUaAtdozkOKSwsZOfOnZSUlDR3VjTNRFpaGoWFhVGdowVdozkOSU5OpmvXrs2dDU2MoV0uGo1GEydoQddoNJo4QQu6RqPRxAnNNlNUCFECbGvg6fnAgUbMTiygy5wY6DInBkdT5s5SygKrA80m6EeDEGJRsKmv8Youc2Kgy5wYNFWZtctFo9Fo4gQt6BqNRhMnxKqgv9TcGWgGdJkTA13mxKBJyhyTPnSNRqPRBBKrFrpGo9Fo/NCCrtFoNHFCzAm6EGKcEGKdEGKjECK6d2Idxwgh/i2E2C+EWGnalyeE+FIIscH9P9e9XwghnnPfg+VCiJh8F58QoqMQYp4QYrUQYpUQ4k73/rgttxAiTQjxoxBimbvMT7j3dxVC/OAu23QhRIp7f6p7e6P7eJfmzH9DEULYhRBLhBCfuLfjurwAQoitQogVQoilQohF7n1NWrdjStCFEHbgBeAcoC9wpRCib/PmqtF4DRjnt+9+4CspZU/gK/c2qPL3dP9NBl48RnlsbBzAvVLKvsCJwO3u3zOey10LjJZSDgSKgXFCiBOBPwFTpJQ9gEPAje70NwKH3PunuNPFIncCa0zb8V5egzOklMWmmPOmrdtSypj5A04C5pi2HwAeaO58NWL5ugArTdvrgHbuz+2Ade7PU4ErrdLF8h/wEXBmopQbyAB+BkagZg0mufd76jkwBzjJ/TnJnU40d96jLGehW7xGA58AIp7Layr3ViDfb1+T1u2YstCBDsAO0/ZO9754pY2Uco/7816gjftz3N0Hd9d6EPADcV5ut/thKbAf+BLYBByWUhqvrDeXy1Nm9/EyoNWxzfFR8yzwW8Dl3m5FfJfXQAJfCCEWCyEmu/c1ad3W66HHCFJKKYSIyxhTIUQW8D5wl5TyiPm1a/FYbimlEygWQrQEPgB6N3OWmgwhxPnAfinlYiHEqObOzzHmFCnlLiFEa+BLIcRa88GmqNuxZqHvAjqatgvd++KVfUKIdgDu//vd++PmPgghklFi/paUcqZ7d9yXG0BKeRiYh3I5tBRCGAaWuVyeMruPtwBKj3FWj4aTgfFCiK3AOyi3y9+I3/J6kFLucv/fj2q4h9PEdTvWBP0noKd7hDwFuAKY1cx5akpmAde7P1+P8jEb+69zj4yfCJSZunExg1Cm+CvAGinlX02H4rbcQogCt2WOECIdNWawBiXsE9zJ/Mts3IsJwFzpdrLGAlLKB6SUhVLKLqjnda6U8mritLwGQohMIUS28Rk4C1hJU9ft5h44aMBAw7nAepTf8aHmzk8jluttYA9Qj/Kf3YjyHX4FbAD+C+S50wpUtM8mYAUwtLnz38Ayn4LyMy4Hlrr/zo3ncgNFwBJ3mVcCj7r3dwN+BDYC7wGp7v1p7u2N7uPdmrsMR1H2UcAniVBed/mWuf9WGVrV1HVbT/3XaDSaOCHWXC4ajUajCYIWdI1Go4kTtKBrNBpNnKAFXaPRaOIELegajUYTJ2hB12g0mjhBC7pGo9HECf8fpnGOVfgMzEwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8ea0a2-7671-4304-b29f-991292e0d393"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd33652-ba7a-4ccd-bcda-b2add9852284"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1b4d5b82-6a57-468b-f9bc-051ec55c7b09"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_421a9e9b-0c16-4dec-9289-68b38a9e6976\", \"EfficientNetB5_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}