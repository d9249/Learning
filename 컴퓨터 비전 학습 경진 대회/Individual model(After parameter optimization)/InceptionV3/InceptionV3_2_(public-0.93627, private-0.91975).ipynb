{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV3_2_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/InceptionV3_2_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40943dcf-6392-4bce-bbea-97466c9c4f20"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 27 12:31:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36422b8a-3200-43ff-94f2-a52bbc585abd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'InceptionV3_2'\n",
        "Target_model = 'InceptionV3_model'\n",
        "Target_predict = 'InceptionV3_predict'\n",
        "Target_acc = 'InceptionV3_acc'\n",
        "Target_val = 'InceptionV3_val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d146d6-57ee-41c1-f823-6795f7064431"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5e23aa-6afd-40ce-f569-e12f7e8d9730"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 46s 88ms/step - loss: 1.9326 - accuracy: 0.3800 - val_loss: 4.3109 - val_accuracy: 0.1081\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 1.1562 - accuracy: 0.6174 - val_loss: 8.9386 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10811\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.9508 - accuracy: 0.6889 - val_loss: 0.8326 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10811 to 0.75676, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.7485 - accuracy: 0.7532 - val_loss: 1.0895 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.75676\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.6775 - accuracy: 0.7805 - val_loss: 1.1959 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75676\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.6103 - accuracy: 0.7889 - val_loss: 2.0790 - val_accuracy: 0.5608\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75676\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.6342 - accuracy: 0.7932 - val_loss: 0.6299 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.75676 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.5082 - accuracy: 0.8332 - val_loss: 1.0573 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.81081\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.5369 - accuracy: 0.8263 - val_loss: 0.4368 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.81081 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.4875 - accuracy: 0.8489 - val_loss: 0.5425 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.83108\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.4260 - accuracy: 0.8621 - val_loss: 0.5815 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83108\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.4291 - accuracy: 0.8674 - val_loss: 0.5978 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83108\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.3739 - accuracy: 0.8805 - val_loss: 0.7119 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.83108\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.3612 - accuracy: 0.8768 - val_loss: 0.7487 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83108\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.4134 - accuracy: 0.8679 - val_loss: 0.3160 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.83108 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.3723 - accuracy: 0.8789 - val_loss: 0.4728 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85811\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.2925 - accuracy: 0.9016 - val_loss: 0.6613 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85811\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.3459 - accuracy: 0.8884 - val_loss: 0.5377 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85811\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.3137 - accuracy: 0.8984 - val_loss: 0.4373 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.85811 to 0.86486, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.2935 - accuracy: 0.8989 - val_loss: 2.9593 - val_accuracy: 0.4932\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.86486\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.3059 - accuracy: 0.8958 - val_loss: 0.4861 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.86486\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.2792 - accuracy: 0.9142 - val_loss: 1.0432 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86486\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.2402 - accuracy: 0.9200 - val_loss: 0.5019 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86486\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.2449 - accuracy: 0.9211 - val_loss: 0.4516 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86486\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.2564 - accuracy: 0.9195 - val_loss: 0.5226 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86486\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.2384 - accuracy: 0.9268 - val_loss: 0.7273 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86486\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.2144 - accuracy: 0.9332 - val_loss: 0.4682 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86486\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.1839 - accuracy: 0.9395 - val_loss: 0.5053 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.86486 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.2252 - accuracy: 0.9242 - val_loss: 0.6235 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87162\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.2348 - accuracy: 0.9221 - val_loss: 0.5789 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87162\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.1904 - accuracy: 0.9416 - val_loss: 0.4660 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87162\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.2277 - accuracy: 0.9326 - val_loss: 0.3545 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87162\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.1493 - accuracy: 0.9511 - val_loss: 0.4035 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.87162 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.1665 - accuracy: 0.9400 - val_loss: 0.4020 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89189\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.1717 - accuracy: 0.9489 - val_loss: 0.3187 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89189\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1722 - accuracy: 0.9395 - val_loss: 0.4111 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89189\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.1510 - accuracy: 0.9526 - val_loss: 0.4742 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89189\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.1557 - accuracy: 0.9484 - val_loss: 0.5889 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89189\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1512 - accuracy: 0.9479 - val_loss: 0.6760 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89189\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.1330 - accuracy: 0.9537 - val_loss: 0.5100 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89189\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1334 - accuracy: 0.9516 - val_loss: 0.5152 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89189\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1045 - accuracy: 0.9642 - val_loss: 0.6373 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89189\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1466 - accuracy: 0.9521 - val_loss: 0.5487 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89189\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.1175 - accuracy: 0.9579 - val_loss: 0.5153 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89189\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1154 - accuracy: 0.9553 - val_loss: 0.7410 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89189\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.1329 - accuracy: 0.9553 - val_loss: 0.6471 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89189\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.1250 - accuracy: 0.9632 - val_loss: 0.6667 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89189\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1184 - accuracy: 0.9632 - val_loss: 0.4983 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89189\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.1057 - accuracy: 0.9653 - val_loss: 0.4745 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89189\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.1247 - accuracy: 0.9626 - val_loss: 0.5605 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89189\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0846 - accuracy: 0.9716 - val_loss: 0.5055 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89189\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.0875 - accuracy: 0.9695 - val_loss: 0.5376 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89189\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0798 - accuracy: 0.9747 - val_loss: 0.3081 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.89189 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0961 - accuracy: 0.9679 - val_loss: 0.4178 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91892\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0892 - accuracy: 0.9721 - val_loss: 0.4749 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91892\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.1094 - accuracy: 0.9658 - val_loss: 0.5268 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91892\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0659 - accuracy: 0.9821 - val_loss: 0.4360 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91892\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0947 - accuracy: 0.9674 - val_loss: 0.5812 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91892\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0842 - accuracy: 0.9705 - val_loss: 0.4505 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91892\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.4905 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91892\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.5237 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91892\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.6248 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91892\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.1243 - accuracy: 0.9616 - val_loss: 1.0613 - val_accuracy: 0.7230\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91892\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0868 - accuracy: 0.9732 - val_loss: 0.3596 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91892\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.3769 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91892\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.7163 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91892\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0630 - accuracy: 0.9768 - val_loss: 0.5364 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91892\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.5505 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91892\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.5613 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91892\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.5910 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91892\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.5910 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91892\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0773 - accuracy: 0.9795 - val_loss: 0.6557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91892\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.7044 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91892\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0641 - accuracy: 0.9742 - val_loss: 0.4299 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91892\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.3018 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91892\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0532 - accuracy: 0.9863 - val_loss: 0.6139 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91892\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.7720 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0861 - accuracy: 0.9758 - val_loss: 0.5411 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.0878 - accuracy: 0.9774 - val_loss: 0.3864 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: 0.4817 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.6176 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.4633 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91892\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 19s 80ms/step - loss: 0.0678 - accuracy: 0.9779 - val_loss: 0.5586 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91892\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 0.3474 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91892\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0547 - accuracy: 0.9847 - val_loss: 0.4673 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91892\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0627 - accuracy: 0.9837 - val_loss: 0.4522 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0258 - accuracy: 0.9942 - val_loss: 0.4154 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0162 - accuracy: 0.9932 - val_loss: 0.4575 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.3813 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.5383 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.7509 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.5940 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0608 - accuracy: 0.9826 - val_loss: 0.5839 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.6079 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91892\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.6063 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91892\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.6415 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91892\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91892\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0728 - accuracy: 0.9774 - val_loss: 0.5897 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91892\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.6215 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91892\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.4153 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91892\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.6036 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91892\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0161 - accuracy: 0.9921 - val_loss: 0.3257 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00102: val_accuracy improved from 0.91892 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.4221 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00103: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0691 - accuracy: 0.9774 - val_loss: 0.4792 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93919\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0416 - accuracy: 0.9889 - val_loss: 0.4694 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93919\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.5141 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93919\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.4598 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93919\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0500 - accuracy: 0.9826 - val_loss: 0.3707 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93919\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.5162 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93919\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.5300 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93919\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.4184 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93919\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.7478 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93919\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.8049 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93919\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.4253 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93919\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.5019 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93919\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.6785 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93919\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0770 - accuracy: 0.9763 - val_loss: 0.7677 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93919\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.4225 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93919\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 0.4436 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93919\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.4252 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93919\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0148 - accuracy: 0.9932 - val_loss: 0.4416 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93919\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0472 - accuracy: 0.9874 - val_loss: 0.4102 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93919\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 19s 81ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.4008 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93919\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.4393 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93919\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.3888 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93919\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4406 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93919\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.3912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93919\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.6239 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.6466 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.4798 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.6379 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.4821 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0190 - accuracy: 0.9911 - val_loss: 0.5493 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.5200 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0207 - accuracy: 0.9911 - val_loss: 0.6620 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.2815 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.6701 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.4447 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.3576 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.6950 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.3596 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.3972 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.4994 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0282 - accuracy: 0.9932 - val_loss: 0.5934 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.6448 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.4876 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.3768 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 0.7422 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.6765 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.5074 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.3889 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.4023 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.3497 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 0.7707 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.6158 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.3757 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.5153 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4172 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.5600 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.5085 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.3958 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.6357 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.6121 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.4249 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0258 - accuracy: 0.9895 - val_loss: 0.4678 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.3921 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0257 - accuracy: 0.9937 - val_loss: 0.4305 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.2674 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00168: val_accuracy improved from 0.93919 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/InceptionV3_2.h5\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.3616 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95270\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.7598 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95270\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.4908 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95270\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.5787 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95270\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.7264 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.95270\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.3653 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95270\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.4326 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95270\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.6698 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95270\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0406 - accuracy: 0.9889 - val_loss: 0.5133 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.95270\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.7204 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95270\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.4416 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95270\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.3953 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95270\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 19s 82ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.4928 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95270\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.5345 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95270\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.4662 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95270\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.5063 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95270\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.5508 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95270\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.3747 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95270\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.6241 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95270\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.7351 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95270\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.4099 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95270\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.4205 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95270\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5408 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.95270\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.4605 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.95270\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.6048 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.95270\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.5916 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.95270\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0285 - accuracy: 0.9932 - val_loss: 0.3857 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.95270\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0236 - accuracy: 0.9900 - val_loss: 0.5265 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.95270\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.6412 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.95270\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.5832 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.95270\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.4011 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.95270\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.3630 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.95270\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4936 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.95270\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5483 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.95270\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.7600 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.95270\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.4045 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.95270\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.6608 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.95270\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.5115 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.95270\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 20s 82ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5012 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.95270\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5472 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.95270\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.5544 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.95270\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.7527 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.95270\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0194 - accuracy: 0.9968 - val_loss: 0.5355 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.95270\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6156 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.95270\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.6285 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.95270\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.5284 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.95270\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5051 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.95270\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4669 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.95270\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.95270\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 6.4472e-04 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.95270\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6001 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.95270\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5737 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.95270\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0678 - accuracy: 0.9842 - val_loss: 0.9722 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.95270\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.3842 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.95270\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.5405 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.95270\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.5180 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.95270\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.3343 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.95270\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.3844 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.95270\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.3568 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.95270\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.4672 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.95270\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.6322 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.95270\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.6134 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.95270\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.8231 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.95270\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.7484 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.95270\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.5296 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.95270\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.4845 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.95270\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5737 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.95270\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5352 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.95270\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.4189 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.95270\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 0.6000 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.95270\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.5316 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.95270\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3601 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.95270\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.4888 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.95270\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 20s 83ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 0.4219 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.95270\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4182 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.95270\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.6664 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.95270\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.5103 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.95270\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5222 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.95270\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4575 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.95270\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4099 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.95270\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.7313 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.95270\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.6614 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.95270\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.6034 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.95270\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.3841 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.95270\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.2929 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.95270\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.4466 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.95270\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.6902 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.95270\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.6437 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.95270\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.5040 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.95270\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.4970 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.95270\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5419 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.95270\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 0.4475 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.95270\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4457 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.95270\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.5296 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.95270\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 20s 84ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.6959 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.95270\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.3897 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.95270\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.4555 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.95270\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.3232 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.95270\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4866 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.95270\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4314 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.95270\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5571 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.95270\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5529 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.95270\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.4487 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.95270\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.5342 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.95270\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0637 - accuracy: 0.9879 - val_loss: 0.5601 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.95270\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4087 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.95270\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5105 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.95270\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.4240 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.95270\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.3761 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.95270\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.4218 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.95270\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.3371 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.95270\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.3333 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.95270\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.5035 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.95270\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4940 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.95270\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.6705 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.95270\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.95270\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.3357 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.95270\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.3370 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.95270\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.4724 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.95270\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 20s 86ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.8184 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.95270\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.6685 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.95270\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.5158 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.95270\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.3902 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.95270\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.5167 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.95270\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 0.5100 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.95270\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.95270\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 7.4216e-04 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 7.3291e-04 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5218 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5557 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.6530 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.5843 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 20s 85ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.5622 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5481 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5102 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.7283 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.3843 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.4480 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.3904 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4519 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.3739 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.4309 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.5061 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4007 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4051 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 8.4279e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 6.3376e-04 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 1.1486 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.8564 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.6221 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.6246 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.6728 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6339 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.4866 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5522 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.5979 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.5292 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 0.5358 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0144 - accuracy: 0.9979 - val_loss: 0.4533 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.4066 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4684 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5306 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4281 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 21s 86ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.6509 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0331 - accuracy: 0.9916 - val_loss: 0.6561 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.4982 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5121 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.5489 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6059 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.4339 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.2294 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0030 - accuracy: 0.9979 - val_loss: 0.3837 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 3.2399e-04 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.4321 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 21s 87ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5276 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4847 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 21s 88ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5542 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 0.5059 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.6909 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.4824 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.7597 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.5982 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0133 - accuracy: 0.9942 - val_loss: 0.4690 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.5735 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4419 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 6.0676e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 2.2895e-04 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.5812 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.6591 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.4556 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.4407 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.4519 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.4942 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4192 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.4938 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 8.9559e-04 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 3.6585e-04 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.5852 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0161 - accuracy: 0.9932 - val_loss: 0.7335 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.4580 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0103 - accuracy: 0.9989 - val_loss: 0.4441 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6474 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4726 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.5066 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.4388 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3694 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.4758 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 21s 89ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.7367 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.6650 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.5344 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.6167 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.6337 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.6912 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.8842 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5860 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.6078 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0036 - accuracy: 0.9979 - val_loss: 0.4214 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 4.4866e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5785 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 9.3491e-04 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.5790 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.8282 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.6169 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.6216 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5468 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0216 - accuracy: 0.9958 - val_loss: 0.6687 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5100 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 4.2184e-04 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4816 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6277 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6157 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 6.0000e-04 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.7961 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.8337 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 1.3470 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0638 - accuracy: 0.9858 - val_loss: 0.5414 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.5421 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4460 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5224 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6870 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 5.8644e-04 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 7.6670e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4012 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.8264 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.6586 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.6731 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.6088 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.6939 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4920 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5553 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 4.5069e-04 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 9.0941e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 0.4470 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.8447 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 1.0442 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.5429 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4576 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.6216 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.3921 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.5058 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.7698 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.7919 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 6.0841e-04 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 3.6650e-04 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.4379 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 2.9761e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 2.5847e-04 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 2.8289e-04 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 1.6691e-04 - accuracy: 1.0000 - val_loss: 0.6097 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 6.7441e-04 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0184 - accuracy: 0.9916 - val_loss: 0.7022 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.5268 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0052 - accuracy: 0.9968 - val_loss: 0.6285 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.8042 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 7.8949e-04 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 1.2949 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 0.7025 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.5784 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.7704 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5887 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4467 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.6641 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6505 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.6713 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.6502 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.4094 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5440 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.4485 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4725 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.5707 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.3972 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.5412 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 23s 97ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.5394 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6478 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.9443 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.8317 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.5537 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4702 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.5624 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.6023 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.4590 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4591 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5121 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4499 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 6.9298e-04 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.6633 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0085 - accuracy: 0.9984 - val_loss: 0.8085 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.5115 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.5998 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 23s 96ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.7078 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 23s 95ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.6510 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5492 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 9.5725e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.3980 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 22s 91ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4961 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.6512 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 9.6885e-04 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 7.3738e-04 - accuracy: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 22s 92ms/step - loss: 6.1504e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 22s 94ms/step - loss: 3.9727e-04 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 22s 93ms/step - loss: 2.9127e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 22s 90ms/step - loss: 1.1877e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 21s 90ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.6127 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff286d63d50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "26d1f610-c2de-4643-8a59-990a3c435494"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d2e227-8c26-4613-f625-617299d41bec"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a941253-887d-4537-e49e-6087c4364dab"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89678c61-d770-41fd-e876-d2841acd9745"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    # 'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}