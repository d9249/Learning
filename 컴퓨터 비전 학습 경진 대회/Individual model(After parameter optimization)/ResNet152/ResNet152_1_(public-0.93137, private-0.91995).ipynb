{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152_1_(public-0.93137, private-0.91995).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ResNet152_1_(public-0.93137%2C%20private-0.91995).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edee055-f6e6-451d-b421-5b1c67deaf88"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 23 18:12:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090f9adb-3eec-4ab1-c25f-2d1b674b316e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'ResNet152_1'\n",
        "Target_model = 'ResNet152_model'\n",
        "Target_predict = 'ResNet152_predict'\n",
        "Target_acc = 'ResNet152_acc'\n",
        "Target_val = 'ResNet152_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.ResNet152(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c196cdbc-525b-4aa9-9911-07ecd1f9593b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8753ba-648d-470a-94d6-d79655d4413b"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 99s 279ms/step - loss: 2.6463 - accuracy: 0.1426 - val_loss: 2.4319 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 65s 272ms/step - loss: 2.3351 - accuracy: 0.1611 - val_loss: 3.2085 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 66s 276ms/step - loss: 1.9233 - accuracy: 0.3300 - val_loss: 2.2484 - val_accuracy: 0.2635\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10135 to 0.26351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 1.5669 - accuracy: 0.4674 - val_loss: 2.1252 - val_accuracy: 0.3243\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.26351 to 0.32432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 1.5449 - accuracy: 0.4779 - val_loss: 4.0819 - val_accuracy: 0.3581\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.32432 to 0.35811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 1.1735 - accuracy: 0.6074 - val_loss: 2.5202 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35811 to 0.44595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 1.0028 - accuracy: 0.6800 - val_loss: 3.5409 - val_accuracy: 0.3041\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.44595\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.8811 - accuracy: 0.7195 - val_loss: 1.1526 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.44595 to 0.66216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.8951 - accuracy: 0.7068 - val_loss: 1.8481 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.66216\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.7332 - accuracy: 0.7579 - val_loss: 0.8667 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.66216 to 0.74324, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.6661 - accuracy: 0.7742 - val_loss: 0.6395 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.74324 to 0.81081, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.6302 - accuracy: 0.7905 - val_loss: 0.7833 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.81081\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.5741 - accuracy: 0.8074 - val_loss: 2.4287 - val_accuracy: 0.5608\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.81081\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.5628 - accuracy: 0.8021 - val_loss: 0.4516 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.81081 to 0.82432, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.5578 - accuracy: 0.8242 - val_loss: 0.8574 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.82432\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.5347 - accuracy: 0.8237 - val_loss: 0.4854 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.82432 to 0.83784, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.5243 - accuracy: 0.8226 - val_loss: 1.0402 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.83784\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.5093 - accuracy: 0.8347 - val_loss: 1.2952 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.83784\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.4718 - accuracy: 0.8479 - val_loss: 2.0167 - val_accuracy: 0.5946\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.83784\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 66s 277ms/step - loss: 0.4429 - accuracy: 0.8442 - val_loss: 0.6353 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83784\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.4125 - accuracy: 0.8568 - val_loss: 1.7454 - val_accuracy: 0.6081\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83784\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.3923 - accuracy: 0.8584 - val_loss: 0.6278 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83784\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.4160 - accuracy: 0.8663 - val_loss: 0.5263 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.83784 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.3520 - accuracy: 0.8779 - val_loss: 0.6776 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84459\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.3777 - accuracy: 0.8653 - val_loss: 2.2104 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84459\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.3440 - accuracy: 0.8853 - val_loss: 0.5402 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84459\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.3410 - accuracy: 0.8863 - val_loss: 0.4225 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84459\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.3124 - accuracy: 0.8879 - val_loss: 0.9086 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84459\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.3710 - accuracy: 0.8774 - val_loss: 0.5423 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84459\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2648 - accuracy: 0.9089 - val_loss: 10.7955 - val_accuracy: 0.3581\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84459\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.3072 - accuracy: 0.8942 - val_loss: 1.2540 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84459\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2727 - accuracy: 0.9042 - val_loss: 0.4400 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84459\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2539 - accuracy: 0.9111 - val_loss: 0.6182 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84459\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.2765 - accuracy: 0.9074 - val_loss: 0.7214 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84459\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2521 - accuracy: 0.9163 - val_loss: 0.7475 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84459\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2689 - accuracy: 0.9079 - val_loss: 0.4594 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.84459\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2119 - accuracy: 0.9268 - val_loss: 2.2640 - val_accuracy: 0.6014\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.84459\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.2335 - accuracy: 0.9184 - val_loss: 0.2642 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.84459 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.2223 - accuracy: 0.9184 - val_loss: 0.5250 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91216\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.2179 - accuracy: 0.9258 - val_loss: 0.2932 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91216\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.1801 - accuracy: 0.9374 - val_loss: 0.8352 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91216\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.2031 - accuracy: 0.9289 - val_loss: 0.5499 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91216\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.3796 - accuracy: 0.8737 - val_loss: 0.5211 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91216\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1672 - accuracy: 0.9432 - val_loss: 0.7043 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91216\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1690 - accuracy: 0.9384 - val_loss: 0.5668 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91216\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.1741 - accuracy: 0.9384 - val_loss: 0.6338 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91216\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1848 - accuracy: 0.9379 - val_loss: 0.4688 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91216\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.1436 - accuracy: 0.9511 - val_loss: 0.4765 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91216\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1437 - accuracy: 0.9542 - val_loss: 0.5380 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91216\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1606 - accuracy: 0.9505 - val_loss: 0.4977 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91216\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1419 - accuracy: 0.9532 - val_loss: 0.4377 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91216\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.1124 - accuracy: 0.9637 - val_loss: 0.5161 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91216\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.1706 - accuracy: 0.9421 - val_loss: 0.7707 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91216\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1271 - accuracy: 0.9542 - val_loss: 0.5972 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91216\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1201 - accuracy: 0.9558 - val_loss: 0.5183 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91216\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1419 - accuracy: 0.9511 - val_loss: 0.3423 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91216\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1673 - accuracy: 0.9442 - val_loss: 0.5096 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91216\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1493 - accuracy: 0.9516 - val_loss: 0.4450 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1302 - accuracy: 0.9553 - val_loss: 0.3143 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.1318 - accuracy: 0.9568 - val_loss: 0.4934 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0800 - accuracy: 0.9732 - val_loss: 0.6380 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1064 - accuracy: 0.9653 - val_loss: 1.1344 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91216\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0838 - accuracy: 0.9700 - val_loss: 0.5248 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91216\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.1359 - accuracy: 0.9553 - val_loss: 0.8495 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.1099 - accuracy: 0.9626 - val_loss: 0.3791 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0943 - accuracy: 0.9626 - val_loss: 0.4396 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.7967 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1173 - accuracy: 0.9626 - val_loss: 0.4066 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.5601 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1082 - accuracy: 0.9684 - val_loss: 0.5001 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.4594 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0831 - accuracy: 0.9768 - val_loss: 0.4808 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0692 - accuracy: 0.9747 - val_loss: 0.5369 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91216\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0637 - accuracy: 0.9789 - val_loss: 0.3394 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91216\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.6168 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91216\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.3759 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00076: val_accuracy improved from 0.91216 to 0.91892, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.4254 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91892\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0603 - accuracy: 0.9805 - val_loss: 0.6412 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91892\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.3789 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91892\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 1.0138 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91892\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.1098 - accuracy: 0.9700 - val_loss: 0.8970 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91892\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0615 - accuracy: 0.9795 - val_loss: 0.3048 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91892\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.5560 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91892\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0586 - accuracy: 0.9789 - val_loss: 0.4319 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91892\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0573 - accuracy: 0.9789 - val_loss: 0.4173 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91892\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0704 - accuracy: 0.9789 - val_loss: 0.6300 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91892\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 0.5219 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91892\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0605 - accuracy: 0.9784 - val_loss: 0.3313 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91892\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0744 - accuracy: 0.9742 - val_loss: 0.5264 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91892\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0681 - accuracy: 0.9789 - val_loss: 0.2822 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91892\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 0.3618 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91892\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.3550 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91892\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0365 - accuracy: 0.9853 - val_loss: 0.8216 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91892\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.5490 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91892\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.3037 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91892\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.4246 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91892\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0685 - accuracy: 0.9805 - val_loss: 0.5162 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91892\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0621 - accuracy: 0.9774 - val_loss: 0.6112 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91892\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.5089 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91892\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.4470 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91892\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.5028 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91892\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.3924 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91892\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.4980 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91892\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.4494 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91892\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0253 - accuracy: 0.9905 - val_loss: 0.4507 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91892\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.3361 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91892\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.4843 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91892\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0392 - accuracy: 0.9842 - val_loss: 0.5753 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91892\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0775 - accuracy: 0.9742 - val_loss: 0.4755 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91892\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.4726 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91892\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0471 - accuracy: 0.9858 - val_loss: 0.4567 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91892\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.4290 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91892\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.4830 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91892\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0615 - accuracy: 0.9795 - val_loss: 0.6051 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91892\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 0.2582 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91892\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.4039 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91892\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0560 - accuracy: 0.9789 - val_loss: 0.5130 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91892\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.3525 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91892\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0463 - accuracy: 0.9816 - val_loss: 0.4399 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91892\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.4131 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91892\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0177 - accuracy: 0.9921 - val_loss: 0.4795 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91892\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0523 - accuracy: 0.9805 - val_loss: 0.8454 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91892\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0518 - accuracy: 0.9858 - val_loss: 0.5006 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91892\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.3816 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91892\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.6102 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91892\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.5443 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91892\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.4848 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91892\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 67s 279ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.5815 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91892\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.3907 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91892\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.5189 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91892\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 0.6055 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91892\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.5009 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91892\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 66s 278ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 0.3099 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91892\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.2927 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91892\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.4055 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91892\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.9166 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91892\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0759 - accuracy: 0.9763 - val_loss: 0.4676 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91892\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0394 - accuracy: 0.9858 - val_loss: 0.3674 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91892\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0372 - accuracy: 0.9868 - val_loss: 0.5437 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91892\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.5519 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91892\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.4775 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.91892 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6248 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.4702 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0339 - accuracy: 0.9842 - val_loss: 0.5139 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0646 - accuracy: 0.9795 - val_loss: 0.7108 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.5091 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.2708 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.3834 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4585 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.4484 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.4247 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0307 - accuracy: 0.9868 - val_loss: 0.5582 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0504 - accuracy: 0.9842 - val_loss: 0.3341 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.6653 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93243\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.5263 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93243\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.4292 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93243\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.5478 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93243\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.4826 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93243\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 0.6834 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93243\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.6154 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93243\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0313 - accuracy: 0.9911 - val_loss: 0.5290 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93243\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.3854 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93243\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0479 - accuracy: 0.9884 - val_loss: 0.3704 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93243\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3416 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93243\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5184 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93243\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.5169 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93243\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.3582 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93243\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.3197 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93243\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.6318 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93243\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0179 - accuracy: 0.9911 - val_loss: 0.3219 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93243\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4379 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93243\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.5579 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93243\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0458 - accuracy: 0.9842 - val_loss: 0.5986 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93243\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.5776 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93243\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.4864 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93243\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.5556 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93243\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.6691 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93243\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0338 - accuracy: 0.9916 - val_loss: 0.3699 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93243\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0145 - accuracy: 0.9932 - val_loss: 0.4481 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93243\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.3757 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93243\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.5529 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93243\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0283 - accuracy: 0.9900 - val_loss: 0.5078 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93243\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.8069 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93243\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.3614 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93243\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.5989 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93243\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.5224 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93243\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.7189 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93243\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.5352 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93243\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93243\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 6.4704e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93243\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 1.1484 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93243\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.5054 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93243\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.3856 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93243\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.2751 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93243\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93243\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4416 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93243\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.5751 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93243\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.7602 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93243\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.4459 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93243\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93243\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4954 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93243\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.6273 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93243\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.4873 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93243\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.5344 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93243\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.5786 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93243\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.6341 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93243\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 66s 279ms/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.5605 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93243\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.5316 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93243\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93243\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3967 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93243\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 0.7318 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93243\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5755 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93243\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.6415 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93243\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93243\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.7226 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93243\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0500 - accuracy: 0.9874 - val_loss: 0.5405 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93243\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 0.4875 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93243\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.7726 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93243\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4225 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93243\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.4569 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93243\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.4110 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93243\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.5390 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93243\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.5067 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93243\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5965 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93243\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.4834 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93243\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.5075 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93243\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.6437 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93243\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.5075 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93243\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93243\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5358 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93243\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0271 - accuracy: 0.9932 - val_loss: 0.5446 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93243\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.8823 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93243\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.4956 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93243\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0236 - accuracy: 0.9911 - val_loss: 0.5183 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93243\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.5384 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93243\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.5046 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93243\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.5913 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93243\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.4489 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93243\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5617 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93243\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.5689 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93243\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.5028 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93243\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.6128 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93243\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.5257 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93243\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 0.5441 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93243\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.5998 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93243\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.5854 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93243\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.9387 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93243\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.7678 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93243\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.5604 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93243\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5783 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93243\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.6838 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93243\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4253 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93243\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.5774 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93243\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.5104 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93243\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.5710 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93243\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4520 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93243\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.7664 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93243\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93243\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.5218 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93243\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.6998 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93243\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0482 - accuracy: 0.9895 - val_loss: 0.5176 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93243\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.5801 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93243\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.5398 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93243\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0378 - accuracy: 0.9926 - val_loss: 0.3380 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93243\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.4834 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93243\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4858 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93243\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93243\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4395 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93243\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.3775 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93243\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 7.1307e-04 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93243\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 5.3348e-04 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93243\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 6.7008e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93243\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.5681 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93243\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.5092 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93243\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0317 - accuracy: 0.9932 - val_loss: 0.6028 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93243\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.4503 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93243\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.4234 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93243\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.4764 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93243\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.4169 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93243\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.4774 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93243\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4098 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93243\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.4375 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93243\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4315 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93243\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 4.7222e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93243\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 3.8782e-04 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00285: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 4.2425e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93919\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93919\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0092 - accuracy: 0.9942 - val_loss: 0.6484 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93919\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0605 - accuracy: 0.9789 - val_loss: 0.5402 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93919\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.3885 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93919\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.5900 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93919\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.5365 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93919\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.2840 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93919\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.2907 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00294: val_accuracy improved from 0.93919 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 0.2978 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.95270\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0199 - accuracy: 0.9921 - val_loss: 0.6472 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.95270\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0231 - accuracy: 0.9900 - val_loss: 0.2886 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.95270\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4179 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.95270\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.2655 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.95270\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5152 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.95270\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.4573 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.95270\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.5000 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.95270\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.3275 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.95270\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4776 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.95270\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4526 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.95270\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.4864 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.95270\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.4240 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.95270\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.5208 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.95270\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.3728 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.95270\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3585 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.95270\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.3198 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.95270\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.4150 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.95270\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.4022 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.95270\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7771 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.95270\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0567 - accuracy: 0.9889 - val_loss: 0.5928 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.95270\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.5046 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.95270\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5781 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.95270\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.3932 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.95270\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.6290 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.95270\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.4484 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.95270\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.5442 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.95270\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 0.4522 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.95270\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.5003 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.95270\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5745 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.95270\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4858 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.95270\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.6809 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.95270\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.4244 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.95270\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4519 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.95270\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 8.9366e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.95270\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 4.1061e-04 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.95270\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 4.2995e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 3.2520e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.5767 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0428 - accuracy: 0.9889 - val_loss: 0.6044 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.5825 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0331 - accuracy: 0.9937 - val_loss: 0.6123 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.4394 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.4694 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0156 - accuracy: 0.9974 - val_loss: 0.4736 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.7144 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.4377 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 9.0200e-04 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 9.2668e-04 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 2.4335e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.5606 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4214 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4641 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.4905 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 67s 284ms/step - loss: 0.0359 - accuracy: 0.9926 - val_loss: 0.4809 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.3471 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.4809 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5398 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.6170 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.5572 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6277 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.6992 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3905 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.6958 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.7108 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.4646 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3529 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4921 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4349 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5230 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.4063 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0136 - accuracy: 0.9937 - val_loss: 0.4370 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.4345 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.3319 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.6748 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.6462 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.7720 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.5183 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.4329 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4458 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.4432 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.4613 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4224 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.4285 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6556 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.3395 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 67s 280ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.5798 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5039 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4498 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4827 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.6087 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.6744 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6057 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.4604 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.2649 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.4318 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.5838 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.5556 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.5508 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4794 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4084 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.3247 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5932 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.7473 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.8286 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5901 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 8.6115e-04 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.6039 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6301 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.7370 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.7614 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.4960 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4057 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 67s 284ms/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 0.5273 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.5759 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.6367 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 1.1456 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0219 - accuracy: 0.9968 - val_loss: 0.5428 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.4427 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4553 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.5852 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.8915 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0320 - accuracy: 0.9937 - val_loss: 0.5383 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 68s 283ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.3398 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.3792 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3067 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3123 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.5218 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0144 - accuracy: 0.9937 - val_loss: 0.3581 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3728 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3811 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.3839 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 6.4918e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4139 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.5668 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4647 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.4141 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4920 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.3506 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.5420 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.5623 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.4550 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 9.1474e-04 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 3.4279e-04 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 2.9754e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.2781 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.7870 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.3299 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.4723 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.7028 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.4410 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.6438 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.7929 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.6868 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5405 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.8472 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6915 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 9.3093e-04 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 0.6479 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.5648 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0058 - accuracy: 0.9963 - val_loss: 0.6003 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 1.1798 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4792 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4423 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 2.3157e-04 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 4.6892e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.6670 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.1940 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.4243 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.6449 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.5674 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4138 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.5831 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.4042 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3416 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00478: val_accuracy improved from 0.95270 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_1.h5\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0082 - accuracy: 0.9958 - val_loss: 0.6337 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.6709 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 67s 284ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5691 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.6218 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 9.6906e-04 - accuracy: 0.9995 - val_loss: 0.6464 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 7.1929e-04 - accuracy: 0.9995 - val_loss: 0.5306 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.9108 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.4219 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4842 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 8.6809e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 67s 281ms/step - loss: 5.3303e-04 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.6571 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.8091 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.6519 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5030 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 68s 284ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.6057 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.6355 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6662 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 67s 282ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.8213 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6430 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 67s 283ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5452 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 68s 286ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.5570 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8906405cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "88b66e38-17aa-423d-c42e-c673e4413f18"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9b2f14-eee1-4e82-da47-00ee0f3b6a44"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4f15e8-4e4f-450a-ac89-d487a16c3c39"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "78a192f9-c096-45d8-e636-facf4214e3c6"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1252a77e-9d5a-433c-979b-367a6f967d9e\", \"ResNet152_1.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91fb6d7-d422-4eb1-f765-12e5e95c2c69"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93bebfd-628e-41fc-a48a-2d0aaaeff179"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}