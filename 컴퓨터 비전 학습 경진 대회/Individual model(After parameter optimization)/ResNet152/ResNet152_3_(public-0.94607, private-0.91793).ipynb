{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152_3_(public-0.94607, private-0.91793).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ResNet152_3_(public-0.94607%2C%20private-0.91793).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f33b0-b9b8-4dfd-86bc-a68efc976960"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 24 18:36:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c501c00d-b048-494a-82e7-d66881fedc2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'ResNet152_3'\n",
        "Target_model = 'ResNet152_model'\n",
        "Target_predict = 'ResNet152_predict'\n",
        "Target_acc = 'ResNet152_acc'\n",
        "Target_val = 'ResNet152_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.ResNet152(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2684d21a-8de2-44eb-ae6e-8f30b0ff447c"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2dcbb9-8b65-4602-d4b8-d610c5a9b54f"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 76s 174ms/step - loss: 2.7111 - accuracy: 0.1374 - val_loss: 3.0563 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 2.1271 - accuracy: 0.2463 - val_loss: 4.7499 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10135\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 1.7645 - accuracy: 0.3726 - val_loss: 441.6442 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10135\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 1.4319 - accuracy: 0.5105 - val_loss: 6.0800 - val_accuracy: 0.2973\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10135 to 0.29730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 1.1200 - accuracy: 0.6347 - val_loss: 3.3457 - val_accuracy: 0.4459\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29730 to 0.44595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.9707 - accuracy: 0.6837 - val_loss: 1.0302 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.44595 to 0.64865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.8460 - accuracy: 0.7237 - val_loss: 1.2316 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.64865 to 0.65541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.7832 - accuracy: 0.7316 - val_loss: 0.8000 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.65541 to 0.73649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.7612 - accuracy: 0.7495 - val_loss: 0.5121 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.73649 to 0.77703, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.7376 - accuracy: 0.7663 - val_loss: 2.1671 - val_accuracy: 0.5135\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.77703\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.6676 - accuracy: 0.7753 - val_loss: 1.0513 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.77703\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.6715 - accuracy: 0.7911 - val_loss: 0.4822 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.77703 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.6219 - accuracy: 0.7847 - val_loss: 0.7689 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.83108\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.5452 - accuracy: 0.8263 - val_loss: 0.6470 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.83108\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.5475 - accuracy: 0.8074 - val_loss: 0.5529 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.83108 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.4989 - accuracy: 0.8321 - val_loss: 0.5843 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85135\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.4846 - accuracy: 0.8416 - val_loss: 5.7797 - val_accuracy: 0.5068\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85135\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.4329 - accuracy: 0.8711 - val_loss: 0.6032 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.85135\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.5066 - accuracy: 0.8342 - val_loss: 0.7139 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.85135\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.4096 - accuracy: 0.8684 - val_loss: 0.7039 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85135\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3967 - accuracy: 0.8695 - val_loss: 0.3872 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85135\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.4164 - accuracy: 0.8505 - val_loss: 2.7798 - val_accuracy: 0.6216\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85135\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3903 - accuracy: 0.8663 - val_loss: 1.5015 - val_accuracy: 0.6689\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.85135\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3905 - accuracy: 0.8663 - val_loss: 1.4936 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85135\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3752 - accuracy: 0.8647 - val_loss: 0.4104 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.85135\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.4089 - accuracy: 0.8626 - val_loss: 0.5872 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.85135\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.3197 - accuracy: 0.8900 - val_loss: 3.0589 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.85135\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3344 - accuracy: 0.8816 - val_loss: 0.5735 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.85135\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.2944 - accuracy: 0.8953 - val_loss: 0.3912 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.85135 to 0.87838, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.2820 - accuracy: 0.9021 - val_loss: 0.3858 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.87838 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.2592 - accuracy: 0.9079 - val_loss: 0.6559 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.89189\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2534 - accuracy: 0.9111 - val_loss: 2.7010 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.89189\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3238 - accuracy: 0.8911 - val_loss: 8.8098 - val_accuracy: 0.3108\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.89189\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.3163 - accuracy: 0.8937 - val_loss: 0.3871 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.89189\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.2452 - accuracy: 0.9184 - val_loss: 6.4397 - val_accuracy: 0.3784\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.89189\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2862 - accuracy: 0.9037 - val_loss: 0.4324 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.89189\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.2761 - accuracy: 0.9053 - val_loss: 0.3311 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.89189\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2112 - accuracy: 0.9232 - val_loss: 0.3824 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.89189\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.2026 - accuracy: 0.9232 - val_loss: 0.4385 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89189\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.1985 - accuracy: 0.9289 - val_loss: 0.5022 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89189\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1902 - accuracy: 0.9374 - val_loss: 0.2462 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.89189 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1805 - accuracy: 0.9342 - val_loss: 0.3577 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89865\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2129 - accuracy: 0.9268 - val_loss: 0.4204 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89865\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2253 - accuracy: 0.9184 - val_loss: 0.7209 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89865\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1915 - accuracy: 0.9358 - val_loss: 8.0447 - val_accuracy: 0.2973\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89865\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.2465 - accuracy: 0.9189 - val_loss: 0.4025 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89865\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1716 - accuracy: 0.9432 - val_loss: 0.5784 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89865\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1360 - accuracy: 0.9516 - val_loss: 0.4981 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89865\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1561 - accuracy: 0.9379 - val_loss: 0.3915 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89865\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1427 - accuracy: 0.9495 - val_loss: 0.7980 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89865\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.1720 - accuracy: 0.9405 - val_loss: 0.3857 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89865\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1352 - accuracy: 0.9589 - val_loss: 0.3219 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89865\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1104 - accuracy: 0.9626 - val_loss: 0.3870 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89865\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0964 - accuracy: 0.9663 - val_loss: 0.5744 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89865\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1117 - accuracy: 0.9621 - val_loss: 0.2866 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.89865 to 0.90541, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.1656 - accuracy: 0.9447 - val_loss: 0.9149 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90541\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.1473 - accuracy: 0.9484 - val_loss: 0.2944 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.90541 to 0.91216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.1568 - accuracy: 0.9437 - val_loss: 0.5526 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91216\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1234 - accuracy: 0.9579 - val_loss: 0.5318 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91216\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0959 - accuracy: 0.9642 - val_loss: 0.3356 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91216\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0903 - accuracy: 0.9647 - val_loss: 0.2386 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91216\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0911 - accuracy: 0.9663 - val_loss: 0.4811 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91216\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1226 - accuracy: 0.9558 - val_loss: 0.3947 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91216\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0945 - accuracy: 0.9658 - val_loss: 0.3552 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91216\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1017 - accuracy: 0.9658 - val_loss: 0.5932 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91216\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0817 - accuracy: 0.9674 - val_loss: 0.4371 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91216\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1051 - accuracy: 0.9658 - val_loss: 0.5568 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91216\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0789 - accuracy: 0.9779 - val_loss: 0.6509 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91216\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.1192 - accuracy: 0.9642 - val_loss: 0.6965 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91216\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0990 - accuracy: 0.9626 - val_loss: 0.3541 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91216\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.3676 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91216\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 0.6792 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91216\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1119 - accuracy: 0.9637 - val_loss: 0.2410 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.91216 to 0.92568, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.4867 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.92568\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0863 - accuracy: 0.9679 - val_loss: 0.4604 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.92568\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 0.3845 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.92568\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0856 - accuracy: 0.9763 - val_loss: 0.2644 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.92568\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0864 - accuracy: 0.9716 - val_loss: 0.4376 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.92568\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0632 - accuracy: 0.9747 - val_loss: 0.4340 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.92568\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0664 - accuracy: 0.9758 - val_loss: 0.6932 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.92568\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.7419 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.92568\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0642 - accuracy: 0.9784 - val_loss: 0.4048 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.92568\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.4746 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.92568\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0648 - accuracy: 0.9763 - val_loss: 0.3986 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.92568\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.1011 - accuracy: 0.9642 - val_loss: 0.6384 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.92568\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 0.6659 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.92568\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0870 - accuracy: 0.9726 - val_loss: 0.4969 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.92568\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.4137 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.92568\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.3631 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.92568\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 0.4367 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.92568\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0766 - accuracy: 0.9768 - val_loss: 0.7597 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.92568\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.4449 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.92568\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0695 - accuracy: 0.9789 - val_loss: 0.4615 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.92568\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.3805 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.92568\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.3705 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.92568\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.6395 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.92568\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.2718 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00097: val_accuracy improved from 0.92568 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0679 - accuracy: 0.9826 - val_loss: 0.4482 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.4633 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0475 - accuracy: 0.9826 - val_loss: 0.5519 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0715 - accuracy: 0.9758 - val_loss: 0.4623 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.7378 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0668 - accuracy: 0.9768 - val_loss: 0.4721 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.4604 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93243\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.4465 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93243\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.4106 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93243\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0414 - accuracy: 0.9868 - val_loss: 0.5106 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93243\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.5121 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93243\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.5676 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 0.3902 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0367 - accuracy: 0.9868 - val_loss: 0.5124 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.8539 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.2962 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.4168 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.3680 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.6552 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0593 - accuracy: 0.9779 - val_loss: 0.5097 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.2998 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.4434 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0848 - accuracy: 0.9732 - val_loss: 0.7674 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.4286 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.3768 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.2714 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.4860 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0274 - accuracy: 0.9863 - val_loss: 0.4101 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 0.4261 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.6106 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93243\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.4376 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93243\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 0.4724 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93243\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.3846 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93243\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3835 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93243\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.7455 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93243\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0448 - accuracy: 0.9889 - val_loss: 0.5241 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93243\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 0.6112 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93243\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.4482 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93243\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.5798 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93243\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.5231 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93243\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0529 - accuracy: 0.9853 - val_loss: 0.4789 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93243\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.3542 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93243\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0453 - accuracy: 0.9842 - val_loss: 0.5557 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93243\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 38s 157ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4444 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93243\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.3233 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.8795 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.3871 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.4564 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0213 - accuracy: 0.9905 - val_loss: 0.6002 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0634 - accuracy: 0.9832 - val_loss: 0.9018 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 38s 157ms/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 0.4210 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.3706 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.4320 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.4087 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.6007 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.3769 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.2444 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00154: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.2566 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.3685 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 0.4203 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 0.4431 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0667 - accuracy: 0.9832 - val_loss: 0.5208 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.4604 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.3766 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.4986 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.3310 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.2379 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0085 - accuracy: 0.9984 - val_loss: 0.4847 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.4247 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0339 - accuracy: 0.9905 - val_loss: 0.3042 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.3671 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.5840 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.6533 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 0.5759 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0476 - accuracy: 0.9874 - val_loss: 0.4339 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.2941 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0230 - accuracy: 0.9937 - val_loss: 0.3379 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.3399 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.7077 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.3585 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.2697 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.6661 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 0.7849 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0363 - accuracy: 0.9868 - val_loss: 0.3336 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.3644 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.3625 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.4744 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.3215 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.2538 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4023 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.4479 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0437 - accuracy: 0.9895 - val_loss: 0.4673 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.4313 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.3935 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.3513 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: 0.3067 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.4490 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.3794 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.3907 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.2744 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.5442 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0586 - accuracy: 0.9837 - val_loss: 0.4215 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.4059 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 0.3264 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.6506 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0134 - accuracy: 0.9942 - val_loss: 0.2793 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.6210 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0362 - accuracy: 0.9895 - val_loss: 0.4434 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.4458 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.5682 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.4625 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4140 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 6.9420e-04 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.5242 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.3678 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.6256 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.4664 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.6332 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.4235 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0459 - accuracy: 0.9895 - val_loss: 0.3215 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.4647 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6176 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.3655 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.4543 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.4354 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.3490 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.4652 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5293 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0688 - accuracy: 0.9837 - val_loss: 0.7006 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 0.4905 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.5343 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.3697 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0087 - accuracy: 0.9958 - val_loss: 0.4356 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.5646 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.4011 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.3168 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4092 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 0.5038 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.4890 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.4713 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0538 - accuracy: 0.9863 - val_loss: 0.5456 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.3079 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.2922 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.4165 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.5080 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 9.8478e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 5.3500e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 7.1847e-04 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93919\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.3493 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93919\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0331 - accuracy: 0.9926 - val_loss: 0.4965 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93919\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 0.3812 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93919\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.6611 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93919\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.4341 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93919\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.8672 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93919\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 38s 157ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.2782 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93919\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0169 - accuracy: 0.9968 - val_loss: 0.4284 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93919\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.4662 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93919\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2839 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93919\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93919\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3670 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93919\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.4585 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93919\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.5114 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93919\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.2819 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93919\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.3578 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93919\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0211 - accuracy: 0.9916 - val_loss: 0.6907 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93919\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3161 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93919\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.3331 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93919\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5170 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93919\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.3309 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93919\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.4224 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93919\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.3641 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93919\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.1810 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00271: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.3884 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3900 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 37s 157ms/step - loss: 0.0294 - accuracy: 0.9937 - val_loss: 0.3956 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 38s 157ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.7115 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5990 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.3948 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0200 - accuracy: 0.9958 - val_loss: 0.5677 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.3071 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.5504 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.5710 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.6638 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.3348 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.2856 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 0.5355 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0276 - accuracy: 0.9937 - val_loss: 0.4690 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.3669 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.3092 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5015 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4794 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.7363 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.7770 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0358 - accuracy: 0.9895 - val_loss: 0.6668 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0188 - accuracy: 0.9916 - val_loss: 0.7463 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4592 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5673 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4244 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5365 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.7202 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4612 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 5.1578e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.3811 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5740 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.3197 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.5552 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.5176 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.3665 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0091 - accuracy: 0.9958 - val_loss: 0.4058 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.6753 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.2285 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3068 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.3523 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.4247 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.9465 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.4980 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.5381 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.7147 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.5553 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6324 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4703 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0149 - accuracy: 0.9979 - val_loss: 0.4992 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4088 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4331 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4627 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0439 - accuracy: 0.9895 - val_loss: 0.6605 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.4587 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.6047 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.3078 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2553 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00330: val_accuracy improved from 0.94595 to 0.95270, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152_3.h5\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.95270\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.3259 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.95270\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 4.3582e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.95270\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 4.3138e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.95270\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 5.6970e-04 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.95270\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.5985 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.95270\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.5504 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.95270\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.6044 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.95270\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.95270\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4060 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.95270\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 7.0988e-04 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95270\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.6080 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95270\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5140 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95270\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.6945 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95270\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0134 - accuracy: 0.9937 - val_loss: 0.4707 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95270\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.8439 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95270\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.4102 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95270\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4969 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95270\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.3328 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95270\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.6888 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95270\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.7303 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95270\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.7207 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95270\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5883 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95270\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.6211 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95270\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 1.0809 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95270\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.6570 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95270\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95270\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.8120 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95270\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.3906 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95270\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4797 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95270\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95270\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2605 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95270\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 3.1034e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95270\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 4.3441e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95270\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 1.6807e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95270\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 1.7073e-04 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95270\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.6370 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95270\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0483 - accuracy: 0.9884 - val_loss: 0.3709 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95270\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.6093 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95270\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.4447 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95270\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4695 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95270\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.4716 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95270\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.4311 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95270\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3437 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95270\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.2688 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95270\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3226 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95270\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.3872 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95270\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 5.3070e-04 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95270\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 5.8022e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95270\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 3.5583e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95270\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.3247 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95270\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.6759 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95270\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.6015 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95270\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.5653 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95270\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.7019 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95270\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95270\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.7762 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95270\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.5115 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95270\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.5927 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95270\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.5679 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95270\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.4136 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95270\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.6598 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95270\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5179 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95270\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.8025 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95270\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0116 - accuracy: 0.9984 - val_loss: 0.5036 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95270\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6987 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95270\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.7704 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95270\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.6927 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95270\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.7408 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95270\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.8821 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95270\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.7323 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95270\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.5367 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95270\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.4210 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95270\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4796 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95270\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.6725 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95270\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.4593 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95270\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.3987 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95270\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 0.4112 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95270\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.3997 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95270\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 4.7453e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95270\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 2.4096e-04 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95270\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 0.4215 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95270\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 0.6744 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95270\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.6424 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95270\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.6186 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95270\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.8072 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95270\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0083 - accuracy: 0.9958 - val_loss: 0.4526 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95270\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.4760 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95270\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 7.5326e-04 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95270\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4494 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95270\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6342 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95270\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 5.0026e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95270\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4835 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95270\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.8139 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95270\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.5293 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95270\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.8177 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95270\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.4818 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95270\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.6361 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95270\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4217 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95270\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4871 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95270\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 4.9247e-04 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95270\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 1.8666e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95270\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.6380 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95270\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5486 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95270\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.6981 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95270\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.3756 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95270\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 8.4219e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95270\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 3.1943e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95270\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.6413 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95270\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.5540 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95270\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.6963 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95270\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.4130 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95270\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.6052 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95270\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.4635 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95270\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 0.5721 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95270\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4821 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95270\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.6791 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95270\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5055 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95270\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.5576 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95270\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.6226 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95270\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.5683 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95270\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4801 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95270\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.4441 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95270\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95270\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 9.7656e-04 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95270\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.5603 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95270\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 9.4706e-04 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95270\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 7.3489e-04 - accuracy: 1.0000 - val_loss: 0.5359 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95270\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.4927 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95270\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0448 - accuracy: 0.9879 - val_loss: 0.4553 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95270\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5577 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95270\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4626 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95270\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5672 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95270\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 0.5804 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95270\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 39s 162ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95270\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 7.2443e-04 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95270\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.5356 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95270\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.5666 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95270\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.6320 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95270\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.4490 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95270\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6217 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95270\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.3676 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95270\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4923 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95270\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 8.0164e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95270\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.4741 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95270\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.5799 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95270\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95270\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95270\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.7549 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95270\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.8881 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95270\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.6237 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95270\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6312 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95270\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.4801 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95270\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 2.0857e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95270\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.7986 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95270\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95270\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 4.7518e-04 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95270\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 1.6858e-04 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95270\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4043 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95270\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.7672 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95270\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0315 - accuracy: 0.9947 - val_loss: 0.4456 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95270\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.6270 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95270\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 1.1861 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95270\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.5524 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95270\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.5394 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95270\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 38s 159ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.7646 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95270\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 38s 160ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.5477 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95270\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5097 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95270\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 5.4376e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95270\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 38s 161ms/step - loss: 4.0177e-04 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8064eff90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3b594b8d-b63e-44fc-ff99-d802185078d5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb8fd7d-dfc7-4227-9e8c-54b9da039d77"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcb586c-2ffb-4071-c5e7-f0dad76fc7de"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1729b09a-6e5c-4e8b-ade6-c2a0f273d069"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f2e3e839-e1b3-4734-b65e-903a0d0c5a67\", \"ResNet152_3.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d004029-e3f8-4e5b-9d48-2fb970ce7a6c"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf70d675-8ea4-45f0-aba9-592a9dffe196"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    }
  ]
}