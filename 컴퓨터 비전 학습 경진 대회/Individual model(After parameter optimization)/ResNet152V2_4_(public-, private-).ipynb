{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152V2_4_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/ResNet152V2_4_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f525286a-28e2-4c63-c2c8-91fb5bdbd44a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 27 17:47:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043253a6-1958-4590-94a5-7f57a0435540"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'ResNet152V2_4'\n",
        "Target_model = 'ResNet152V2_model'\n",
        "Target_predict = 'ResNet152V2_predict'\n",
        "Target_acc = 'ResNet152V2_acc'\n",
        "Target_val = 'ResNet152V2_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.ResNet152V2(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38531f62-fd94-4a90-8d25-080b12445af2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b18b66-a922-470e-80b3-6d8913150a09"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 76s 179ms/step - loss: 2.1761 - accuracy: 0.2500 - val_loss: 6.4213 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 1.5185 - accuracy: 0.4742 - val_loss: 3.9535 - val_accuracy: 0.2095\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.20946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 1.2290 - accuracy: 0.5947 - val_loss: 5.5059 - val_accuracy: 0.2095\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.20946\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 1.0354 - accuracy: 0.6516 - val_loss: 3.7136 - val_accuracy: 0.3581\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.20946 to 0.35811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.9357 - accuracy: 0.6979 - val_loss: 1.0490 - val_accuracy: 0.6824\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.35811 to 0.68243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.8754 - accuracy: 0.7063 - val_loss: 1.1375 - val_accuracy: 0.5946\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.68243\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.8320 - accuracy: 0.7116 - val_loss: 2.8456 - val_accuracy: 0.3851\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.68243\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.7349 - accuracy: 0.7526 - val_loss: 1.9940 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.68243\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.7502 - accuracy: 0.7584 - val_loss: 8.5702 - val_accuracy: 0.1149\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.68243\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.6723 - accuracy: 0.7768 - val_loss: 0.6229 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.68243 to 0.83108, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.6241 - accuracy: 0.7979 - val_loss: 0.7440 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.83108\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.5633 - accuracy: 0.8105 - val_loss: 0.6180 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.83108\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.5399 - accuracy: 0.8142 - val_loss: 0.5157 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.83108 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.5405 - accuracy: 0.8189 - val_loss: 0.5311 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.84459\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.5422 - accuracy: 0.8211 - val_loss: 0.8103 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.84459\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4585 - accuracy: 0.8532 - val_loss: 0.5485 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.84459\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.4450 - accuracy: 0.8463 - val_loss: 2.6645 - val_accuracy: 0.3986\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.84459\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3927 - accuracy: 0.8711 - val_loss: 7.5200 - val_accuracy: 0.2027\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84459\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.3692 - accuracy: 0.8742 - val_loss: 0.8136 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.84459\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.3987 - accuracy: 0.8611 - val_loss: 0.4455 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.84459\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.4246 - accuracy: 0.8605 - val_loss: 0.4174 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.84459 to 0.85135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.3621 - accuracy: 0.8784 - val_loss: 0.9485 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85135\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.3119 - accuracy: 0.8979 - val_loss: 0.5489 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.85135\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3513 - accuracy: 0.8889 - val_loss: 0.4544 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85135\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.3562 - accuracy: 0.8811 - val_loss: 0.4627 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.85135 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.3261 - accuracy: 0.8842 - val_loss: 0.9032 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.87162\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2681 - accuracy: 0.9074 - val_loss: 0.6050 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.87162\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2701 - accuracy: 0.9084 - val_loss: 0.4232 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.87162\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2809 - accuracy: 0.9105 - val_loss: 0.6237 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.87162\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2480 - accuracy: 0.9179 - val_loss: 0.7618 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.87162\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2769 - accuracy: 0.9074 - val_loss: 0.6196 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.87162\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2450 - accuracy: 0.9158 - val_loss: 0.8465 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.87162\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2618 - accuracy: 0.9147 - val_loss: 1.4497 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.87162\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2005 - accuracy: 0.9295 - val_loss: 0.5759 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.87162\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2263 - accuracy: 0.9232 - val_loss: 0.7061 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.87162\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.2601 - accuracy: 0.9116 - val_loss: 0.5189 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.87162\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.2575 - accuracy: 0.9089 - val_loss: 2.5959 - val_accuracy: 0.5270\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.87162\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1905 - accuracy: 0.9353 - val_loss: 0.3569 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.87162 to 0.89189, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.1722 - accuracy: 0.9395 - val_loss: 0.3958 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.89189\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.2017 - accuracy: 0.9263 - val_loss: 0.5959 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.89189\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1847 - accuracy: 0.9384 - val_loss: 0.4944 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.89189\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1678 - accuracy: 0.9358 - val_loss: 0.4853 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.89189\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1892 - accuracy: 0.9316 - val_loss: 0.3709 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.89189\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1688 - accuracy: 0.9400 - val_loss: 0.5465 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89189\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1366 - accuracy: 0.9537 - val_loss: 0.6489 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89189\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1738 - accuracy: 0.9458 - val_loss: 1.7957 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89189\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1507 - accuracy: 0.9516 - val_loss: 0.5912 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89189\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1389 - accuracy: 0.9532 - val_loss: 0.4439 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89189\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1328 - accuracy: 0.9547 - val_loss: 0.6459 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89189\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1383 - accuracy: 0.9511 - val_loss: 0.2957 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.89189 to 0.93243, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1742 - accuracy: 0.9426 - val_loss: 0.4839 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93243\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1409 - accuracy: 0.9553 - val_loss: 0.3995 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93243\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1363 - accuracy: 0.9537 - val_loss: 3.0696 - val_accuracy: 0.5338\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93243\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1093 - accuracy: 0.9605 - val_loss: 0.4871 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.93243\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1334 - accuracy: 0.9532 - val_loss: 0.4806 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93243\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0867 - accuracy: 0.9716 - val_loss: 0.6382 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.93243\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.1182 - accuracy: 0.9558 - val_loss: 3.3335 - val_accuracy: 0.5068\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.93243\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1008 - accuracy: 0.9668 - val_loss: 0.4741 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93243\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0944 - accuracy: 0.9674 - val_loss: 0.4392 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93243\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1369 - accuracy: 0.9463 - val_loss: 0.5972 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93243\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.5135 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.93243\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0990 - accuracy: 0.9611 - val_loss: 0.3405 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.93243\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1068 - accuracy: 0.9674 - val_loss: 0.3296 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93243\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.3108 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93243\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0766 - accuracy: 0.9721 - val_loss: 0.4560 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93243\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1114 - accuracy: 0.9647 - val_loss: 0.5322 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93243\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0913 - accuracy: 0.9668 - val_loss: 0.3161 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93243\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0938 - accuracy: 0.9653 - val_loss: 0.8137 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93243\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0994 - accuracy: 0.9637 - val_loss: 1.3630 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93243\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0966 - accuracy: 0.9695 - val_loss: 0.4528 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93243\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0756 - accuracy: 0.9753 - val_loss: 0.5087 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93243\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0683 - accuracy: 0.9753 - val_loss: 0.7059 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93243\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.1262 - accuracy: 0.9547 - val_loss: 0.5696 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93243\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.5126 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93243\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0816 - accuracy: 0.9689 - val_loss: 0.4538 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93243\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0752 - accuracy: 0.9711 - val_loss: 0.3428 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93243\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0472 - accuracy: 0.9805 - val_loss: 0.3103 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93243\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0703 - accuracy: 0.9726 - val_loss: 0.4411 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93243\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0645 - accuracy: 0.9821 - val_loss: 0.4500 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93243\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0649 - accuracy: 0.9779 - val_loss: 0.5398 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93243\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.7308 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93243\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1049 - accuracy: 0.9600 - val_loss: 0.4278 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93243\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.3748 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93243\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.1096 - accuracy: 0.9684 - val_loss: 0.4859 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93243\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.4365 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93243\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0714 - accuracy: 0.9742 - val_loss: 0.5094 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93243\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 39s 163ms/step - loss: 0.0351 - accuracy: 0.9916 - val_loss: 0.5932 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93243\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.4231 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93243\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.6595 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93243\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0858 - accuracy: 0.9711 - val_loss: 0.3878 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93243\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.3209 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93243\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0657 - accuracy: 0.9763 - val_loss: 0.5806 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93243\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.1009 - accuracy: 0.9611 - val_loss: 0.5212 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93243\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0479 - accuracy: 0.9811 - val_loss: 0.3836 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93243\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.3740 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93243\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.7023 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93243\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0627 - accuracy: 0.9784 - val_loss: 0.6188 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93243\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0434 - accuracy: 0.9826 - val_loss: 0.6559 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93243\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0317 - accuracy: 0.9911 - val_loss: 0.4121 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93243\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.6247 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93243\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.7072 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93243\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.3967 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93243\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0605 - accuracy: 0.9758 - val_loss: 0.4659 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93243\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.4670 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93243\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 0.3023 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93243\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0341 - accuracy: 0.9911 - val_loss: 0.2707 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93243\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.4719 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93243\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.5845 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93243\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.5839 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93243\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.3703 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93243\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0848 - accuracy: 0.9774 - val_loss: 0.5109 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93243\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0458 - accuracy: 0.9816 - val_loss: 0.5150 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93243\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 0.4497 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93243\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.5086 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93243\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0453 - accuracy: 0.9847 - val_loss: 0.3818 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93243\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.3943 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93243\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.4407 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93243\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0702 - accuracy: 0.9768 - val_loss: 0.5817 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93243\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 0.3462 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93243\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.3769 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93243\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0580 - accuracy: 0.9821 - val_loss: 0.4645 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93243\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.5008 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93243\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.4194 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93243\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.3621 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93243\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0909 - accuracy: 0.9753 - val_loss: 0.8736 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93243\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 0.3851 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93243\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5223 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93243\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.5200 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93243\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.4926 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93243\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 0.5079 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93243\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.3952 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93243\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.3982 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93243\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0368 - accuracy: 0.9847 - val_loss: 0.4828 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93243\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 0.4181 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93243\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.4338 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93243\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 0.4089 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93243\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.5697 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93243\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.5122 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93243\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0567 - accuracy: 0.9858 - val_loss: 0.6365 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93243\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0267 - accuracy: 0.9884 - val_loss: 0.2648 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93243\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.3930 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93243\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.7017 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93243\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.3602 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93243\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0257 - accuracy: 0.9895 - val_loss: 0.3581 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93243\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.5008 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93243\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0759 - accuracy: 0.9768 - val_loss: 0.5120 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93243\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: 0.8512 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93243\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.2605 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93243\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 0.8237 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93243\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0320 - accuracy: 0.9916 - val_loss: 0.4245 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93243\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.4728 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93243\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0199 - accuracy: 0.9926 - val_loss: 0.5982 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93243\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.6952 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93243\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.3640 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93243\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.7907 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93243\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.5622 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93243\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0270 - accuracy: 0.9889 - val_loss: 0.5176 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93243\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0388 - accuracy: 0.9905 - val_loss: 0.4179 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93243\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0279 - accuracy: 0.9895 - val_loss: 0.4578 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93243\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.4589 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93243\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.6434 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93243\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.5200 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93243\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0413 - accuracy: 0.9853 - val_loss: 0.6059 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93243\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 0.5391 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93243\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 0.7548 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93243\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4645 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93243\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.5281 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93243\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.3696 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93243\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.5244 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93243\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.5796 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93243\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.3586 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93243\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.5715 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93243\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.6172 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93243\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 2.4071 - val_accuracy: 0.6149\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93243\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.4334 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93243\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 39s 165ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5016 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93243\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0637 - accuracy: 0.9763 - val_loss: 1.1836 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93243\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 39s 164ms/step - loss: 0.0508 - accuracy: 0.9889 - val_loss: 0.5706 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93243\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.4333 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93243\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5566 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93243\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 39s 166ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.4997 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93243\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.6240 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93243\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.4335 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93243\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.7151 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93243\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.6065 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93243\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.3639 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93243\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.4578 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93243\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.4748 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93243\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.5712 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93243\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.3809 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93243\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.3860 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93243\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.4375 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93243\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.8686 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93243\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.5232 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93243\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.6223 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93243\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 0.5492 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93243\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.5198 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93243\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.4948 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93243\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.5684 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93243\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0259 - accuracy: 0.9905 - val_loss: 0.7547 - val_accuracy: 0.8176\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93243\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0212 - accuracy: 0.9905 - val_loss: 0.6707 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93243\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5243 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93243\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.7530 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93243\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.4928 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93243\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.5246 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93243\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.3941 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93243\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.7106 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93243\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5859 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93243\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.4496 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93243\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.6350 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93243\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0236 - accuracy: 0.9900 - val_loss: 0.6514 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93243\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.3246 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93243\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.4250 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93243\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.4985 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93243\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0385 - accuracy: 0.9858 - val_loss: 0.5138 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93243\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.4529 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93243\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.6099 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93243\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.5065 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93243\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0386 - accuracy: 0.9911 - val_loss: 0.5153 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93243\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5418 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93243\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.6736 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93243\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.5805 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93243\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.6029 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93243\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0189 - accuracy: 0.9916 - val_loss: 0.6058 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93243\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.4703 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93243\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.5953 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93243\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.5464 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93243\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.3762 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93243\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 40s 166ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.4698 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93243\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4683 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93243\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.6444 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93243\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.4865 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93243\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.4523 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93243\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.7255 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93243\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.6954 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93243\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.5820 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93243\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4327 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93243\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93243\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6031 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93243\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.6610 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93243\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0419 - accuracy: 0.9863 - val_loss: 0.5781 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93243\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5329 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93243\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0344 - accuracy: 0.9858 - val_loss: 0.4593 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93243\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.4821 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93243\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.4057 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93243\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.3675 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93243\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.4411 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93243\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4798 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93243\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0344 - accuracy: 0.9889 - val_loss: 0.4785 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93243\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.3971 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93243\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5115 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93243\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.7167 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93243\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4521 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93243\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.4718 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93243\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.7076 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93243\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93243\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.7249 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93243\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.9788 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93243\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.5411 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93243\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0361 - accuracy: 0.9916 - val_loss: 0.6127 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93243\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0211 - accuracy: 0.9916 - val_loss: 0.3929 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93243\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.3772 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93243\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4315 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93243\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.4654 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93243\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0214 - accuracy: 0.9968 - val_loss: 0.4164 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93243\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.3847 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93243\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.8441 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93243\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.6559 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93243\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.4264 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93243\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.5125 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93243\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.3733 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93243\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0219 - accuracy: 0.9916 - val_loss: 0.4435 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93243\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.5410 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93243\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.4367 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93243\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.4158 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93243\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.5485 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93243\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.5554 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93243\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.4253 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93243\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.5208 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93243\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4334 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93243\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5141 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93243\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.6915 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93243\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.7661 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93243\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.4692 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93243\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5420 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93243\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.4646 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93243\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5053 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93243\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.4703 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93243\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.4579 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93243\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.3820 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93243\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7460 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93243\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.6713 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93243\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.3996 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93243\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0266 - accuracy: 0.9889 - val_loss: 0.9014 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93243\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0295 - accuracy: 0.9874 - val_loss: 0.6118 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93243\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4738 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93243\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.5359 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93243\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.3879 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93243\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4938 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93243\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4077 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93243\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.4931 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93243\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.3780 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93243\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4370 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93243\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5243 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93243\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0301 - accuracy: 0.9932 - val_loss: 0.4576 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93243\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.2775 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00306: val_accuracy improved from 0.93243 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0077 - accuracy: 0.9968 - val_loss: 0.4085 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93919\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93919\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 5.8391e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93919\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.5764 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93919\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93919\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4053 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93919\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 0.7101 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93919\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.4265 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93919\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.4082 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93919\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3865 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93919\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4347 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93919\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 40s 167ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.6422 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93919\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.4976 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93919\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.6485 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93919\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 0.5705 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93919\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.4811 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93919\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.6941 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93919\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.4991 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93919\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.4365 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93919\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.4701 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93919\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.6499 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93919\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4185 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93919\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4775 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93919\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.4378 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93919\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4085 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93919\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4240 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93919\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.7180 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93919\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.5861 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93919\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.4315 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93919\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4787 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93919\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.4188 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93919\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.2563 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93919\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.2478 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93919\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 5.4573e-04 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00340: val_accuracy improved from 0.93919 to 0.95946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/ResNet152V2_4.h5\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 42s 178ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.3759 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.95946\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.3922 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.95946\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.5483 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.95946\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.3593 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.95946\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.8824 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.95946\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0170 - accuracy: 0.9926 - val_loss: 0.4399 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.95946\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0175 - accuracy: 0.9968 - val_loss: 0.4066 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.95946\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 40s 168ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.4526 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.95946\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4179 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.95946\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.95946\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4784 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.95946\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.4735 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.95946\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.95946\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.5112 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.95946\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.5387 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.95946\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.7292 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.95946\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.9143 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.95946\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.4795 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.95946\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4119 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.95946\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.3289 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.95946\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.4041 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.95946\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4536 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.95946\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4888 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.95946\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.8075 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.95946\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.5374 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.95946\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.4028 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.95946\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4613 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.95946\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 40s 169ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.5617 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.95946\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.4829 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.95946\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.5888 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.95946\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5543 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.95946\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.4236 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.95946\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.4775 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.95946\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.3262 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.95946\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6876 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.95946\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3572 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.95946\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5487 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.95946\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5306 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.95946\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.4189 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.95946\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.5417 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.95946\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 0.5149 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.95946\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.7273 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.95946\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.6896 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.95946\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.4190 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.95946\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.5602 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.95946\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.5928 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.95946\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5089 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.95946\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.8031 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.95946\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4441 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.95946\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5669 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.95946\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.3762 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.95946\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.5720 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.95946\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.95946\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 4.4809e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.95946\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0246 - accuracy: 0.9953 - val_loss: 0.5103 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.95946\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.6468 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.95946\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0176 - accuracy: 0.9968 - val_loss: 0.6256 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.95946\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5503 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.95946\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5728 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.95946\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 0.7277 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.95946\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.5937 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.95946\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 0.4730 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.95946\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 40s 170ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.6749 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.95946\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 41s 170ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.4452 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.95946\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.5563 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.95946\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5255 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.95946\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5552 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.95946\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.6044 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.95946\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4692 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.95946\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 9.6688e-04 - accuracy: 1.0000 - val_loss: 0.5495 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.95946\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.95946\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.6123 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.95946\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.4281 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.95946\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.4617 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.95946\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.6557 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.95946\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.6626 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.95946\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4878 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.95946\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.6583 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.95946\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 42s 174ms/step - loss: 6.6155e-04 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.95946\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 1.1764 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.95946\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.8344 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.95946\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.5874 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.95946\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.95946\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 5.7488e-04 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.95946\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 3.3876e-04 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.95946\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.9115 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.95946\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 41s 171ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.5219 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.95946\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4498 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.95946\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.8245 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.95946\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.7883 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.95946\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 42s 174ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5439 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.95946\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 9.6248e-04 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.95946\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9322 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.95946\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.8127 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.95946\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5621 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.95946\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.4924 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.95946\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4791 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.95946\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.4955 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.95946\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.7233 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.95946\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0116 - accuracy: 0.9947 - val_loss: 0.3666 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.95946\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.6890 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.95946\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.95946\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.5386 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.95946\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5035 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.95946\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.1896 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.95946\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.3778 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.95946\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.5009 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.95946\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.6139 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.95946\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.6101 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.95946\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.6682 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.95946\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.7397 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.95946\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.4166 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.95946\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.6347 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.95946\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.7314 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.95946\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 0.5156 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.95946\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.6007 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.95946\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5717 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.95946\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.5435 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.95946\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 42s 174ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.6097 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.95946\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3258 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.95946\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.7480 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.95946\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.6768 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.95946\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.3528 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.95946\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.3345 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.95946\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.8255 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.95946\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.5360 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.95946\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4923 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.95946\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.5358 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.95946\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.4607 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.95946\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 9.3654e-04 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.95946\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.8422 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.95946\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 8.4699e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.95946\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.6596 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.95946\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5983 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.95946\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.7634 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.95946\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.95946\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0093 - accuracy: 0.9958 - val_loss: 0.6128 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.95946\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 42s 176ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3694 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.95946\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 3.3099e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.95946\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 6.5656e-04 - accuracy: 1.0000 - val_loss: 0.5602 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.95946\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 3.6504e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.95946\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 2.3876e-04 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.95946\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.7713 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.95946\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.8994 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.95946\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5527 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.95946\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.6169 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.95946\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.6796 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.95946\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.8653 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.95946\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 42s 176ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.6106 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.95946\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 42s 176ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.7199 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.95946\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.6069 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.95946\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 42s 175ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4028 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.95946\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 42s 176ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.9085 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.95946\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.4582 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.95946\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.95946\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.4175 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.95946\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 41s 173ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.5394 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.95946\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.5617 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.95946\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 41s 172ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.3820 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.95946\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 41s 174ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4398 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.95946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f08ca28d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "410640fb-43ff-4ed4-aff6-86c64d92f95f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47f853d-bd21-4c85-954f-ec2be375bded"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01638c6e-7828-448a-8bc1-ff1653b566ae"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6fae3133-f47d-41a9-b53e-b6c3bcccffe1"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1283f1b0-f59a-4c68-b55d-3cea93e2fd43\", \"ResNet152V2_4.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc9ce3-a005-4d7e-e4a6-8b776acc4adf"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e85797d-b3c4-4811-87a7-80397320dfbe"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # \n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    #  ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr \n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com \n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    # 'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': False, 'detail': 'Over max submission count of Daily.       .'}\n"
          ]
        }
      ]
    }
  ]
}