{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_1_(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Xception_1_(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yI4jO4W5lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00493e10-5e9c-44a7-a09b-bdc8af0d0414"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 28 05:26:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0efb1fe-d274-4579-bbcf-efe5bfc42925"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTkw3fo6icZm"
      },
      "source": [
        "model_save = 'Xception_1'\n",
        "Target_model = 'Xception_model'\n",
        "Target_predict = 'Xception_predict'\n",
        "Target_acc = 'Xception_acc'\n",
        "Target_val = 'Xception_val'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "Target_model =  tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "Target_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c75c62-bd7c-4edb-c22e-17718eaf471e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale = 1./255, \n",
        "    validation_split = 0.075,\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.00,\n",
        "    height_shift_range = 0.05 )\n",
        "\n",
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1900 images belonging to 10 classes.\n",
            "Found 148 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe86eb3-0f7e-4085-bf79-26af5e9938af"
      },
      "source": [
        "Target_model.fit_generator(train_generator, epochs = 500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "238/238 [==============================] - 40s 71ms/step - loss: 1.9844 - accuracy: 0.3368 - val_loss: 5.7448 - val_accuracy: 0.1014\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10135, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 2/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 1.1808 - accuracy: 0.6100 - val_loss: 4.7107 - val_accuracy: 0.1622\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10135 to 0.16216, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 3/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.9859 - accuracy: 0.6800 - val_loss: 2.2999 - val_accuracy: 0.4865\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.16216 to 0.48649, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 4/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.7795 - accuracy: 0.7458 - val_loss: 1.0009 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.48649 to 0.76351, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 5/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.7303 - accuracy: 0.7600 - val_loss: 0.7936 - val_accuracy: 0.7432\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.76351\n",
            "Epoch 6/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.6482 - accuracy: 0.7979 - val_loss: 1.1393 - val_accuracy: 0.6959\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.76351\n",
            "Epoch 7/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.6228 - accuracy: 0.7989 - val_loss: 1.1151 - val_accuracy: 0.6554\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.76351\n",
            "Epoch 8/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.5201 - accuracy: 0.8358 - val_loss: 0.7744 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.76351 to 0.78378, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 9/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.5198 - accuracy: 0.8347 - val_loss: 0.8116 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.78378 to 0.79730, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 10/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.4651 - accuracy: 0.8516 - val_loss: 0.4924 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.79730 to 0.84459, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 11/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.4367 - accuracy: 0.8679 - val_loss: 0.5791 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.84459\n",
            "Epoch 12/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.3825 - accuracy: 0.8753 - val_loss: 0.4532 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84459\n",
            "Epoch 13/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.4461 - accuracy: 0.8605 - val_loss: 1.4652 - val_accuracy: 0.6351\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84459\n",
            "Epoch 14/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.4322 - accuracy: 0.8600 - val_loss: 0.8035 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.84459\n",
            "Epoch 15/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.3699 - accuracy: 0.8721 - val_loss: 0.4160 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.84459 to 0.85811, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 16/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3189 - accuracy: 0.9021 - val_loss: 0.5621 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85811\n",
            "Epoch 17/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3217 - accuracy: 0.8879 - val_loss: 0.7503 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.85811\n",
            "Epoch 18/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.3382 - accuracy: 0.8953 - val_loss: 0.4049 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.85811 to 0.87162, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 19/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3191 - accuracy: 0.8911 - val_loss: 0.7258 - val_accuracy: 0.7905\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.87162\n",
            "Epoch 20/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.3045 - accuracy: 0.9042 - val_loss: 0.6993 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.87162\n",
            "Epoch 21/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2576 - accuracy: 0.9174 - val_loss: 0.2707 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.87162 to 0.89865, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 22/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.3024 - accuracy: 0.9032 - val_loss: 0.4610 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.89865\n",
            "Epoch 23/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2487 - accuracy: 0.9216 - val_loss: 0.3766 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.89865\n",
            "Epoch 24/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2389 - accuracy: 0.9205 - val_loss: 0.6324 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.89865\n",
            "Epoch 25/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2642 - accuracy: 0.9158 - val_loss: 0.4790 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.89865\n",
            "Epoch 26/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1980 - accuracy: 0.9358 - val_loss: 0.8417 - val_accuracy: 0.7568\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.89865\n",
            "Epoch 27/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1962 - accuracy: 0.9389 - val_loss: 0.4818 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.89865\n",
            "Epoch 28/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.2526 - accuracy: 0.9211 - val_loss: 0.4951 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.89865\n",
            "Epoch 29/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2595 - accuracy: 0.9089 - val_loss: 0.9059 - val_accuracy: 0.7703\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.89865\n",
            "Epoch 30/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2185 - accuracy: 0.9289 - val_loss: 0.2538 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.89865 to 0.93919, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 31/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.1570 - accuracy: 0.9495 - val_loss: 0.3097 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.93919\n",
            "Epoch 32/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1825 - accuracy: 0.9384 - val_loss: 0.3361 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93919\n",
            "Epoch 33/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1712 - accuracy: 0.9437 - val_loss: 0.6207 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.93919\n",
            "Epoch 34/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1555 - accuracy: 0.9453 - val_loss: 0.3045 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93919\n",
            "Epoch 35/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1403 - accuracy: 0.9542 - val_loss: 0.5413 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93919\n",
            "Epoch 36/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.2109 - accuracy: 0.9284 - val_loss: 0.3851 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.93919\n",
            "Epoch 37/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 0.3543 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93919\n",
            "Epoch 38/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1347 - accuracy: 0.9563 - val_loss: 0.4697 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93919\n",
            "Epoch 39/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1597 - accuracy: 0.9489 - val_loss: 0.4058 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93919\n",
            "Epoch 40/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1350 - accuracy: 0.9563 - val_loss: 0.5023 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93919\n",
            "Epoch 41/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1664 - accuracy: 0.9458 - val_loss: 0.6425 - val_accuracy: 0.7973\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93919\n",
            "Epoch 42/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1365 - accuracy: 0.9542 - val_loss: 0.4678 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93919\n",
            "Epoch 43/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1057 - accuracy: 0.9626 - val_loss: 0.5824 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.93919\n",
            "Epoch 44/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1025 - accuracy: 0.9647 - val_loss: 0.5072 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.93919\n",
            "Epoch 45/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1424 - accuracy: 0.9553 - val_loss: 0.8850 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.93919\n",
            "Epoch 46/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.1508 - accuracy: 0.9484 - val_loss: 0.5869 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.93919\n",
            "Epoch 47/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1191 - accuracy: 0.9621 - val_loss: 0.4178 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.93919\n",
            "Epoch 48/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0853 - accuracy: 0.9774 - val_loss: 1.0893 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.93919\n",
            "Epoch 49/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1113 - accuracy: 0.9647 - val_loss: 0.7063 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.93919\n",
            "Epoch 50/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1066 - accuracy: 0.9647 - val_loss: 0.6783 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.93919\n",
            "Epoch 51/500\n",
            "238/238 [==============================] - 15s 64ms/step - loss: 0.0895 - accuracy: 0.9716 - val_loss: 0.4181 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93919\n",
            "Epoch 52/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.3506 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93919\n",
            "Epoch 53/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1032 - accuracy: 0.9668 - val_loss: 0.7504 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93919\n",
            "Epoch 54/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.1242 - accuracy: 0.9642 - val_loss: 0.4077 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.93919\n",
            "Epoch 55/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0889 - accuracy: 0.9721 - val_loss: 0.4834 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93919\n",
            "Epoch 56/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0585 - accuracy: 0.9821 - val_loss: 0.5970 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.93919\n",
            "Epoch 57/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0946 - accuracy: 0.9653 - val_loss: 0.3767 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.93919\n",
            "Epoch 58/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0970 - accuracy: 0.9695 - val_loss: 0.4682 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93919\n",
            "Epoch 59/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0715 - accuracy: 0.9753 - val_loss: 0.6996 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93919\n",
            "Epoch 60/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.1130 - accuracy: 0.9637 - val_loss: 0.5376 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93919\n",
            "Epoch 61/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0904 - accuracy: 0.9700 - val_loss: 0.2893 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.93919\n",
            "Epoch 62/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.3488 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.93919\n",
            "Epoch 63/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0763 - accuracy: 0.9779 - val_loss: 0.5475 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93919\n",
            "Epoch 64/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0694 - accuracy: 0.9753 - val_loss: 0.3232 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.93919\n",
            "Epoch 65/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.4390 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93919\n",
            "Epoch 66/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0964 - accuracy: 0.9647 - val_loss: 0.3833 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93919\n",
            "Epoch 67/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0651 - accuracy: 0.9763 - val_loss: 0.5650 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93919\n",
            "Epoch 68/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0747 - accuracy: 0.9758 - val_loss: 0.4127 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.93919\n",
            "Epoch 69/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.5472 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93919\n",
            "Epoch 70/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.5740 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93919\n",
            "Epoch 71/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.3390 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93919\n",
            "Epoch 72/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.5114 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93919\n",
            "Epoch 73/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0732 - accuracy: 0.9742 - val_loss: 0.6120 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93919\n",
            "Epoch 74/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.5557 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93919\n",
            "Epoch 75/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0678 - accuracy: 0.9763 - val_loss: 0.6250 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93919\n",
            "Epoch 76/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0612 - accuracy: 0.9763 - val_loss: 0.5061 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93919\n",
            "Epoch 77/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0616 - accuracy: 0.9800 - val_loss: 0.5323 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93919\n",
            "Epoch 78/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0366 - accuracy: 0.9863 - val_loss: 0.7651 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93919\n",
            "Epoch 79/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.4110 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93919\n",
            "Epoch 80/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0530 - accuracy: 0.9858 - val_loss: 0.6714 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93919\n",
            "Epoch 81/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0824 - accuracy: 0.9732 - val_loss: 0.7619 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93919\n",
            "Epoch 82/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.4240 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93919\n",
            "Epoch 83/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0264 - accuracy: 0.9900 - val_loss: 0.5371 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93919\n",
            "Epoch 84/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0691 - accuracy: 0.9789 - val_loss: 0.5529 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93919\n",
            "Epoch 85/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0374 - accuracy: 0.9889 - val_loss: 0.4282 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93919\n",
            "Epoch 86/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0325 - accuracy: 0.9879 - val_loss: 0.3239 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93919\n",
            "Epoch 87/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0704 - accuracy: 0.9753 - val_loss: 0.3353 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93919\n",
            "Epoch 88/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 0.4519 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93919\n",
            "Epoch 89/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 0.3862 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93919\n",
            "Epoch 90/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0402 - accuracy: 0.9853 - val_loss: 0.4194 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93919\n",
            "Epoch 91/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.3853 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93919\n",
            "Epoch 92/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.4655 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93919\n",
            "Epoch 93/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.3767 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93919\n",
            "Epoch 94/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.4972 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93919\n",
            "Epoch 95/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0718 - accuracy: 0.9789 - val_loss: 0.4506 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93919\n",
            "Epoch 96/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0531 - accuracy: 0.9837 - val_loss: 0.4471 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93919\n",
            "Epoch 97/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.4395 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93919\n",
            "Epoch 98/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.4601 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93919\n",
            "Epoch 99/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.5034 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93919\n",
            "Epoch 100/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.3921 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93919\n",
            "Epoch 101/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.6565 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93919\n",
            "Epoch 102/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.4963 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93919\n",
            "Epoch 103/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0254 - accuracy: 0.9937 - val_loss: 0.4513 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93919\n",
            "Epoch 104/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.6944 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93919\n",
            "Epoch 105/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0799 - accuracy: 0.9774 - val_loss: 0.3822 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93919\n",
            "Epoch 106/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.3761 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93919\n",
            "Epoch 107/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.3987 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93919\n",
            "Epoch 108/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.4170 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93919\n",
            "Epoch 109/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.3892 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93919\n",
            "Epoch 110/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.3997 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93919\n",
            "Epoch 111/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0733 - accuracy: 0.9747 - val_loss: 0.4463 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93919\n",
            "Epoch 112/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 0.6543 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93919\n",
            "Epoch 113/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.6232 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93919\n",
            "Epoch 114/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.4675 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93919\n",
            "Epoch 115/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.4238 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93919\n",
            "Epoch 116/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.5284 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93919\n",
            "Epoch 117/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.4586 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93919\n",
            "Epoch 118/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 0.4639 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93919\n",
            "Epoch 119/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.5475 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93919\n",
            "Epoch 120/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.4478 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93919\n",
            "Epoch 121/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.6065 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93919\n",
            "Epoch 122/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.6491 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93919\n",
            "Epoch 123/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0292 - accuracy: 0.9889 - val_loss: 0.4936 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93919\n",
            "Epoch 124/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.4120 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93919\n",
            "Epoch 125/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.6143 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93919\n",
            "Epoch 126/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.6262 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93919\n",
            "Epoch 127/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.5975 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93919\n",
            "Epoch 128/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.5192 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93919\n",
            "Epoch 129/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.4060 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93919\n",
            "Epoch 130/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 0.4059 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93919\n",
            "Epoch 131/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.4589 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93919\n",
            "Epoch 132/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0410 - accuracy: 0.9905 - val_loss: 0.4686 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93919\n",
            "Epoch 133/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.5168 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93919\n",
            "Epoch 134/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.5786 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93919\n",
            "Epoch 135/500\n",
            "238/238 [==============================] - 15s 65ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.6108 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93919\n",
            "Epoch 136/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.5977 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93919\n",
            "Epoch 137/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.5444 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93919\n",
            "Epoch 138/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.5841 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93919\n",
            "Epoch 139/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.3697 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93919\n",
            "Epoch 140/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0431 - accuracy: 0.9858 - val_loss: 0.5284 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93919\n",
            "Epoch 141/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.4904 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93919\n",
            "Epoch 142/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.4737 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.93919\n",
            "Epoch 143/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.5926 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.93919\n",
            "Epoch 144/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.4565 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.93919\n",
            "Epoch 145/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.4919 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93919\n",
            "Epoch 146/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.5909 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93919\n",
            "Epoch 147/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.6882 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93919\n",
            "Epoch 148/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.5996 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93919\n",
            "Epoch 149/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.5619 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93919\n",
            "Epoch 150/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.5956 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93919\n",
            "Epoch 151/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.4324 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93919\n",
            "Epoch 152/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.5840 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93919\n",
            "Epoch 153/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.3135 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93919\n",
            "Epoch 154/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.6338 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93919\n",
            "Epoch 155/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.6105 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93919\n",
            "Epoch 156/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.2900 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93919\n",
            "Epoch 157/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.3907 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93919\n",
            "Epoch 158/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.4714 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93919\n",
            "Epoch 159/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93919\n",
            "Epoch 160/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.5051 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93919\n",
            "Epoch 161/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0639 - accuracy: 0.9811 - val_loss: 0.7049 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93919\n",
            "Epoch 162/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.5737 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93919\n",
            "Epoch 163/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.4164 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93919\n",
            "Epoch 164/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.6012 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93919\n",
            "Epoch 165/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.5331 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93919\n",
            "Epoch 166/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.3608 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93919\n",
            "Epoch 167/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.4374 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93919\n",
            "Epoch 168/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.3791 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93919\n",
            "Epoch 169/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.5300 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93919\n",
            "Epoch 170/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.5008 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93919\n",
            "Epoch 171/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.4216 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93919\n",
            "Epoch 172/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.2746 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93919\n",
            "Epoch 173/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.4938 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93919\n",
            "Epoch 174/500\n",
            "238/238 [==============================] - 16s 65ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4082 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93919\n",
            "Epoch 175/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.4172 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93919\n",
            "Epoch 176/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.2893 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93919\n",
            "Epoch 177/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.2881 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93919\n",
            "Epoch 178/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.4337 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93919\n",
            "Epoch 179/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.3231 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93919\n",
            "Epoch 180/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.4667 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93919\n",
            "Epoch 181/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.5521 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93919\n",
            "Epoch 182/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5370 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93919\n",
            "Epoch 183/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.6046 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93919\n",
            "Epoch 184/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 0.3873 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93919\n",
            "Epoch 185/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.4425 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93919\n",
            "Epoch 186/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 0.5502 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93919\n",
            "Epoch 187/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.6556 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93919\n",
            "Epoch 188/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.5534 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93919\n",
            "Epoch 189/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.5115 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93919\n",
            "Epoch 190/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.5937 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93919\n",
            "Epoch 191/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.5749 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93919\n",
            "Epoch 192/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.6831 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93919\n",
            "Epoch 193/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.4677 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93919\n",
            "Epoch 194/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.4651 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93919\n",
            "Epoch 195/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.5584 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93919\n",
            "Epoch 196/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.4419 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93919\n",
            "Epoch 197/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.3754 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93919\n",
            "Epoch 198/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.4604 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93919\n",
            "Epoch 199/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 0.6318 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93919\n",
            "Epoch 200/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.3843 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93919\n",
            "Epoch 201/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.5298 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93919\n",
            "Epoch 202/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4554 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93919\n",
            "Epoch 203/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.5383 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93919\n",
            "Epoch 204/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.7248 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93919\n",
            "Epoch 205/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.4889 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93919\n",
            "Epoch 206/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 0.4806 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93919\n",
            "Epoch 207/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.5075 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93919\n",
            "Epoch 208/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.4843 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93919\n",
            "Epoch 209/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5389 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93919\n",
            "Epoch 210/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0169 - accuracy: 0.9926 - val_loss: 0.5858 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93919\n",
            "Epoch 211/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.4709 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93919\n",
            "Epoch 212/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0134 - accuracy: 0.9937 - val_loss: 0.4093 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93919\n",
            "Epoch 213/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.5946 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93919\n",
            "Epoch 214/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.3951 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93919\n",
            "Epoch 215/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.5350 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93919\n",
            "Epoch 216/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 0.3551 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93919\n",
            "Epoch 217/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.5398 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93919\n",
            "Epoch 218/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4977 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93919\n",
            "Epoch 219/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4889 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93919\n",
            "Epoch 220/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5852 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93919\n",
            "Epoch 221/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0303 - accuracy: 0.9942 - val_loss: 0.4798 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93919\n",
            "Epoch 222/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.3348 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93919\n",
            "Epoch 223/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.7497 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93919\n",
            "Epoch 224/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0402 - accuracy: 0.9911 - val_loss: 0.5522 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93919\n",
            "Epoch 225/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.6922 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93919\n",
            "Epoch 226/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.5299 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93919\n",
            "Epoch 227/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93919\n",
            "Epoch 228/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93919\n",
            "Epoch 229/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.5442 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93919\n",
            "Epoch 230/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.7671 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93919\n",
            "Epoch 231/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.7035 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93919\n",
            "Epoch 232/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93919\n",
            "Epoch 233/500\n",
            "238/238 [==============================] - 16s 66ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.8065 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93919\n",
            "Epoch 234/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.5481 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93919\n",
            "Epoch 235/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.4654 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93919\n",
            "Epoch 236/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.4732 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93919\n",
            "Epoch 237/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93919\n",
            "Epoch 238/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.6235 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93919\n",
            "Epoch 239/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.6505 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93919\n",
            "Epoch 240/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.4805 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93919\n",
            "Epoch 241/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.4363 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93919\n",
            "Epoch 242/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0344 - accuracy: 0.9937 - val_loss: 0.5650 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93919\n",
            "Epoch 243/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.5475 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93919\n",
            "Epoch 244/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.5650 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93919\n",
            "Epoch 245/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.2770 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93919\n",
            "Epoch 246/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4529 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93919\n",
            "Epoch 247/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.3991 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00247: val_accuracy improved from 0.93919 to 0.94595, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/Xception_1.h5\n",
            "Epoch 248/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.4211 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.94595\n",
            "Epoch 249/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4062 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.94595\n",
            "Epoch 250/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0410 - accuracy: 0.9889 - val_loss: 0.5898 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.94595\n",
            "Epoch 251/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 0.3218 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.94595\n",
            "Epoch 252/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.6131 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.94595\n",
            "Epoch 253/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4678 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.94595\n",
            "Epoch 254/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.3849 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.94595\n",
            "Epoch 255/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.4800 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.94595\n",
            "Epoch 256/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 0.5467 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.94595\n",
            "Epoch 257/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.5120 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.94595\n",
            "Epoch 258/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.5902 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.94595\n",
            "Epoch 259/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.8393 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.94595\n",
            "Epoch 260/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.4546 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.94595\n",
            "Epoch 261/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.4656 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.94595\n",
            "Epoch 262/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.3901 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.94595\n",
            "Epoch 263/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.3431 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.94595\n",
            "Epoch 264/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.94595\n",
            "Epoch 265/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4021 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.94595\n",
            "Epoch 266/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.4220 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.94595\n",
            "Epoch 267/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.7530 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.94595\n",
            "Epoch 268/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.6977 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.94595\n",
            "Epoch 269/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.4451 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.94595\n",
            "Epoch 270/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5474 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.94595\n",
            "Epoch 271/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.4789 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.94595\n",
            "Epoch 272/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.4294 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.94595\n",
            "Epoch 273/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0296 - accuracy: 0.9953 - val_loss: 0.6827 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.94595\n",
            "Epoch 274/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.4854 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.94595\n",
            "Epoch 275/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.3604 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.94595\n",
            "Epoch 276/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 5.6083e-04 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.94595\n",
            "Epoch 277/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 9.1185e-04 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.94595\n",
            "Epoch 278/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.6792 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.94595\n",
            "Epoch 279/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 0.3166 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.94595\n",
            "Epoch 280/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.5930 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.94595\n",
            "Epoch 281/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.8550 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.94595\n",
            "Epoch 282/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.6718 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.94595\n",
            "Epoch 283/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.5035 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.94595\n",
            "Epoch 284/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.4875 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.94595\n",
            "Epoch 285/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.6984 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.94595\n",
            "Epoch 286/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0238 - accuracy: 0.9953 - val_loss: 0.6063 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.94595\n",
            "Epoch 287/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.6805 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.94595\n",
            "Epoch 288/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5169 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.94595\n",
            "Epoch 289/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.4989 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.94595\n",
            "Epoch 290/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5795 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.94595\n",
            "Epoch 291/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.5533 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.94595\n",
            "Epoch 292/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0067 - accuracy: 0.9968 - val_loss: 0.8790 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.94595\n",
            "Epoch 293/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.5966 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.94595\n",
            "Epoch 294/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.5585 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.94595\n",
            "Epoch 295/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.6622 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.94595\n",
            "Epoch 296/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.4465 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.94595\n",
            "Epoch 297/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4297 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.94595\n",
            "Epoch 298/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.5266 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.94595\n",
            "Epoch 299/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.5613 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.94595\n",
            "Epoch 300/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.6215 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.94595\n",
            "Epoch 301/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.5959 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.94595\n",
            "Epoch 302/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.4966 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.94595\n",
            "Epoch 303/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6611 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.94595\n",
            "Epoch 304/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4016 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.94595\n",
            "Epoch 305/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4107 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.94595\n",
            "Epoch 306/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.4311 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.94595\n",
            "Epoch 307/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6920 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.94595\n",
            "Epoch 308/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5191 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.94595\n",
            "Epoch 309/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.9549 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.94595\n",
            "Epoch 310/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.7381 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.94595\n",
            "Epoch 311/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.5806 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.94595\n",
            "Epoch 312/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.4283 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.94595\n",
            "Epoch 313/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.3966 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.94595\n",
            "Epoch 314/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.3632 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.94595\n",
            "Epoch 315/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.4645 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.94595\n",
            "Epoch 316/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.3908 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.94595\n",
            "Epoch 317/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.4127 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.94595\n",
            "Epoch 318/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5557 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.94595\n",
            "Epoch 319/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4622 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.94595\n",
            "Epoch 320/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.2670e-04 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.94595\n",
            "Epoch 321/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.6912 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.94595\n",
            "Epoch 322/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.7238 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.94595\n",
            "Epoch 323/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.6614 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.94595\n",
            "Epoch 324/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0484 - accuracy: 0.9889 - val_loss: 0.6937 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.94595\n",
            "Epoch 325/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.8251 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.94595\n",
            "Epoch 326/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.6082 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.94595\n",
            "Epoch 327/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.94595\n",
            "Epoch 328/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.94595\n",
            "Epoch 329/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4093 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.94595\n",
            "Epoch 330/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.5040 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.94595\n",
            "Epoch 331/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.5721 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.94595\n",
            "Epoch 332/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5844 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.94595\n",
            "Epoch 333/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0071 - accuracy: 0.9963 - val_loss: 0.7291 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.94595\n",
            "Epoch 334/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6451 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.94595\n",
            "Epoch 335/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.4257 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.94595\n",
            "Epoch 336/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4617 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.94595\n",
            "Epoch 337/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.94595\n",
            "Epoch 338/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5020 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.94595\n",
            "Epoch 339/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3329 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.94595\n",
            "Epoch 340/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 2.7551e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.94595\n",
            "Epoch 341/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 2.3064e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.94595\n",
            "Epoch 342/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 4.0520e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.94595\n",
            "Epoch 343/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.4364 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.94595\n",
            "Epoch 344/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.3320 - val_accuracy: 0.9392\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.94595\n",
            "Epoch 345/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.4059 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.94595\n",
            "Epoch 346/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.3692 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.94595\n",
            "Epoch 347/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.6310 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.94595\n",
            "Epoch 348/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0052 - accuracy: 0.9968 - val_loss: 0.4693 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.94595\n",
            "Epoch 349/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.6113 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.94595\n",
            "Epoch 350/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 7.5409e-04 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.94595\n",
            "Epoch 351/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.5882e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.94595\n",
            "Epoch 352/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 4.1820e-04 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.94595\n",
            "Epoch 353/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 3.6857e-04 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.94595\n",
            "Epoch 354/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 4.9063e-04 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.94595\n",
            "Epoch 355/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4521 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.94595\n",
            "Epoch 356/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.5980 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.94595\n",
            "Epoch 357/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0425 - accuracy: 0.9921 - val_loss: 0.8175 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.94595\n",
            "Epoch 358/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0122 - accuracy: 0.9947 - val_loss: 0.7493 - val_accuracy: 0.8378\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.94595\n",
            "Epoch 359/500\n",
            "238/238 [==============================] - 16s 67ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 0.7387 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.94595\n",
            "Epoch 360/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.7019 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.94595\n",
            "Epoch 361/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.6115 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.94595\n",
            "Epoch 362/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6218 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.94595\n",
            "Epoch 363/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6000 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.94595\n",
            "Epoch 364/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.7573 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.94595\n",
            "Epoch 365/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.8666 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.94595\n",
            "Epoch 366/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.5890 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.94595\n",
            "Epoch 367/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6220 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.94595\n",
            "Epoch 368/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 7.5789e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.94595\n",
            "Epoch 369/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.5090 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.94595\n",
            "Epoch 370/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0366 - accuracy: 0.9932 - val_loss: 0.7000 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.94595\n",
            "Epoch 371/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.5582 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.94595\n",
            "Epoch 372/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5090 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.94595\n",
            "Epoch 373/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.94595\n",
            "Epoch 374/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4258 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.94595\n",
            "Epoch 375/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 8.7642e-04 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.94595\n",
            "Epoch 376/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.0701 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.94595\n",
            "Epoch 377/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0432 - accuracy: 0.9916 - val_loss: 0.4404 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.94595\n",
            "Epoch 378/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.3303 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.94595\n",
            "Epoch 379/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.6495 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.94595\n",
            "Epoch 380/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.94595\n",
            "Epoch 381/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6560 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.94595\n",
            "Epoch 382/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.6818 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.94595\n",
            "Epoch 383/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0128 - accuracy: 0.9984 - val_loss: 0.6957 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.94595\n",
            "Epoch 384/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0282 - accuracy: 0.9937 - val_loss: 0.6799 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.94595\n",
            "Epoch 385/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.5743 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.94595\n",
            "Epoch 386/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.4464 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94595\n",
            "Epoch 387/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5250 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94595\n",
            "Epoch 388/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 8.7550e-04 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94595\n",
            "Epoch 389/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6038 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94595\n",
            "Epoch 390/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.5684 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94595\n",
            "Epoch 391/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.5268 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94595\n",
            "Epoch 392/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.6062 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94595\n",
            "Epoch 393/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 7.1269e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94595\n",
            "Epoch 394/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4033 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94595\n",
            "Epoch 395/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0188 - accuracy: 0.9926 - val_loss: 0.8766 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94595\n",
            "Epoch 396/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.5634 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94595\n",
            "Epoch 397/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.5890 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94595\n",
            "Epoch 398/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.8982 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94595\n",
            "Epoch 399/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 0.6301 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.94595\n",
            "Epoch 400/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.5201 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94595\n",
            "Epoch 401/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.4548 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94595\n",
            "Epoch 402/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.7333 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94595\n",
            "Epoch 403/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 1.0287 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94595\n",
            "Epoch 404/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.6824 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94595\n",
            "Epoch 405/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.6446 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94595\n",
            "Epoch 406/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4659 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94595\n",
            "Epoch 407/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 7.1410e-04 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94595\n",
            "Epoch 408/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 0.6758 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94595\n",
            "Epoch 409/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.7860 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94595\n",
            "Epoch 410/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.5249 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94595\n",
            "Epoch 411/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.6865 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94595\n",
            "Epoch 412/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.8188 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94595\n",
            "Epoch 413/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.9366 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94595\n",
            "Epoch 414/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.7697 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94595\n",
            "Epoch 415/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94595\n",
            "Epoch 416/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94595\n",
            "Epoch 417/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.6223 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94595\n",
            "Epoch 418/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.8557 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94595\n",
            "Epoch 419/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6999 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94595\n",
            "Epoch 420/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7850 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94595\n",
            "Epoch 421/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.8004 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94595\n",
            "Epoch 422/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.7943 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94595\n",
            "Epoch 423/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.8950 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94595\n",
            "Epoch 424/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.7670 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94595\n",
            "Epoch 425/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 1.1910 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94595\n",
            "Epoch 426/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.8689 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94595\n",
            "Epoch 427/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.8420 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94595\n",
            "Epoch 428/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94595\n",
            "Epoch 429/500\n",
            "238/238 [==============================] - 16s 68ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.9309 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94595\n",
            "Epoch 430/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.5109 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94595\n",
            "Epoch 431/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.6416 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94595\n",
            "Epoch 432/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.4229 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94595\n",
            "Epoch 433/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.8880 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94595\n",
            "Epoch 434/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.8140 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94595\n",
            "Epoch 435/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.6076 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94595\n",
            "Epoch 436/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.7225 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94595\n",
            "Epoch 437/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.6024 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94595\n",
            "Epoch 438/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.5904 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94595\n",
            "Epoch 439/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.7842 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94595\n",
            "Epoch 440/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 0.6690 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94595\n",
            "Epoch 441/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 1.0903 - val_accuracy: 0.8581\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94595\n",
            "Epoch 442/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.6132 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94595\n",
            "Epoch 443/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 9.0783e-04 - accuracy: 0.9995 - val_loss: 0.5325 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94595\n",
            "Epoch 444/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.8257 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94595\n",
            "Epoch 445/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.7243 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94595\n",
            "Epoch 446/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.6672 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94595\n",
            "Epoch 447/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.7295 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94595\n",
            "Epoch 448/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 3.5454e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94595\n",
            "Epoch 449/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.7460 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94595\n",
            "Epoch 450/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.7935 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94595\n",
            "Epoch 451/500\n",
            "238/238 [==============================] - 17s 72ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.7992 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94595\n",
            "Epoch 452/500\n",
            "238/238 [==============================] - 17s 71ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.8241 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94595\n",
            "Epoch 453/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.8401 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94595\n",
            "Epoch 454/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.7602 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94595\n",
            "Epoch 455/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.0707e-04 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94595\n",
            "Epoch 456/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 4.6011e-04 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94595\n",
            "Epoch 457/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 1.2357e-04 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94595\n",
            "Epoch 458/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 7.7780e-05 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94595\n",
            "Epoch 459/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.8208 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94595\n",
            "Epoch 460/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.7096 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94595\n",
            "Epoch 461/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.9086 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94595\n",
            "Epoch 462/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.6823 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94595\n",
            "Epoch 463/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.7644 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94595\n",
            "Epoch 464/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.6610 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94595\n",
            "Epoch 465/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 0.7263 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94595\n",
            "Epoch 466/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.6581 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94595\n",
            "Epoch 467/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94595\n",
            "Epoch 468/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.7331 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94595\n",
            "Epoch 469/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.7603 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94595\n",
            "Epoch 470/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.6009 - val_accuracy: 0.8784\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94595\n",
            "Epoch 471/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.5904 - val_accuracy: 0.9324\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94595\n",
            "Epoch 472/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.6225 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94595\n",
            "Epoch 473/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.5537 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94595\n",
            "Epoch 474/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.4917 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94595\n",
            "Epoch 475/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.6162 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94595\n",
            "Epoch 476/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.5091 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94595\n",
            "Epoch 477/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4988 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94595\n",
            "Epoch 478/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.5538 - val_accuracy: 0.9122\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94595\n",
            "Epoch 479/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.6786 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94595\n",
            "Epoch 480/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.5077 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94595\n",
            "Epoch 481/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.4482 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94595\n",
            "Epoch 482/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.5381 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94595\n",
            "Epoch 483/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.5743 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94595\n",
            "Epoch 484/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.6503 - val_accuracy: 0.8716\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94595\n",
            "Epoch 485/500\n",
            "238/238 [==============================] - 16s 69ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.5814 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94595\n",
            "Epoch 486/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94595\n",
            "Epoch 487/500\n",
            "238/238 [==============================] - 17s 69ms/step - loss: 6.3593e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94595\n",
            "Epoch 488/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.6471 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94595\n",
            "Epoch 489/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.9052 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94595\n",
            "Epoch 490/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.7061 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94595\n",
            "Epoch 491/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6063 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94595\n",
            "Epoch 492/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94595\n",
            "Epoch 493/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 3.8675e-04 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94595\n",
            "Epoch 494/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.7343 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94595\n",
            "Epoch 495/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.6804 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94595\n",
            "Epoch 496/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.7029 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94595\n",
            "Epoch 497/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 0.8893 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94595\n",
            "Epoch 498/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.8472 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94595\n",
            "Epoch 499/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.6959 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94595\n",
            "Epoch 500/500\n",
            "238/238 [==============================] - 17s 70ms/step - loss: 6.5303e-04 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe59a46ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f0c9315e-2be7-4b00-d0bd-3e644a4da547"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Target_model.history.history[\"accuracy\"], label = Target_acc)\n",
        "plt.plot(Target_model.history.history[\"val_accuracy\"], label = Target_val)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "Target_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/'+ model_save +'.h5', compile=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b51e93-a420-44f2-8f9c-d07e7076ccf7"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff1510d-c01a-495e-ec2c-3a6a600d275f"
      },
      "source": [
        "Target_predict = Target_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"model_predict\"] = Target_predict"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['model_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4a4f01da-519a-441c-8997-0e303e80b688"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_78d6e6b3-1cea-4778-a5dd-89f637509d5d\", \"Xception_1.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZ06MWjdN2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f07af5f-cf75-4870-81f7-b58f92bbe642"
      },
      "source": [
        "!pip install /content/drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/DACON_submit_api/dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKDp3mdOZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32421df5-7aef-420c-bac7-0643bde3ad44"
      },
      "source": [
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "result = dacon_submit_api.post_submission_file(\n",
        "    # 파일경로\n",
        "    '/content/drive/MyDrive/DACON_CVLC/Submission/'+ model_save +'.csv', \n",
        "    # d9249@kyonggi.ac.kr\n",
        "    # 대회 ID\n",
        "    '235626',\n",
        "    # d9249@kyonggi.ac.kr 팀이릉\n",
        "    # 'iDeal9',\n",
        "    # dodo9249@gmail.com 팀이름\n",
        "    # 'iDeal96',\n",
        "    # d9249.acc001@gmail.com\n",
        "    # 'iDeal01',\n",
        "    # meanideal96@gamil.com\n",
        "    # 'iDeal02',\n",
        "    # dodo402298@gmail.com\n",
        "    'mean01',\n",
        "    # d9249.acc002@gmail.com\n",
        "    # 'mean02',\n",
        "    # memo\n",
        "    'd9249_kyonggi_ac_kr' )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': False, 'detail': 'Over max submission count of Daily. 일일 제출 가능한 최대 횟수가 초과 되었습니다.'}\n"
          ]
        }
      ]
    }
  ]
}