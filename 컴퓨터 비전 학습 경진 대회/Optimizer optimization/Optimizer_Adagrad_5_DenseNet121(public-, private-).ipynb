{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizer_Adagrad_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNPATcgXi+DS7rxJE5+K1Kj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Optimizer_Adagrad_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e98835-7193-4810-d0e2-850dc65e958f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 12 18:04:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5698280f-8881-46e7-be3b-d6dbe9b76935"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4bb08b-56d5-48a4-b8eb-164167e66ba1"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81dedb99-2204-41f9-b795-773a7c987059"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 51s 456ms/step - loss: 2.3109 - accuracy: 0.1382 - val_loss: 2.3064 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 18s 353ms/step - loss: 2.2456 - accuracy: 0.1547 - val_loss: 2.3211 - val_accuracy: 0.1256\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.11084 to 0.12562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 357ms/step - loss: 2.2135 - accuracy: 0.1857 - val_loss: 2.3967 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.12562\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 19s 360ms/step - loss: 2.1804 - accuracy: 0.2052 - val_loss: 2.4355 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.12562\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 19s 364ms/step - loss: 2.1600 - accuracy: 0.2290 - val_loss: 2.5487 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.12562\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 2.1324 - accuracy: 0.2418 - val_loss: 2.6092 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.12562\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 2.1139 - accuracy: 0.2564 - val_loss: 2.6231 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.12562\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 2.0863 - accuracy: 0.2832 - val_loss: 2.5641 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.12562\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 2.0621 - accuracy: 0.3015 - val_loss: 2.5743 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.12562\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 2.0394 - accuracy: 0.3197 - val_loss: 2.6285 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.12562\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 2.0113 - accuracy: 0.3234 - val_loss: 2.7195 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.12562\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.9905 - accuracy: 0.3496 - val_loss: 2.9678 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.12562\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.9701 - accuracy: 0.3490 - val_loss: 2.8919 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.12562\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 1.9489 - accuracy: 0.3660 - val_loss: 2.6908 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.12562\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.9150 - accuracy: 0.3825 - val_loss: 2.5951 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.12562\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.8947 - accuracy: 0.3910 - val_loss: 2.3690 - val_accuracy: 0.1330\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.12562 to 0.13300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.8671 - accuracy: 0.4062 - val_loss: 2.0702 - val_accuracy: 0.2562\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.13300 to 0.25616, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.8387 - accuracy: 0.4263 - val_loss: 1.9388 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.25616 to 0.33005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.8115 - accuracy: 0.4330 - val_loss: 1.8959 - val_accuracy: 0.3498\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.33005 to 0.34975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.7826 - accuracy: 0.4428 - val_loss: 1.7797 - val_accuracy: 0.4557\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.34975 to 0.45567, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.7619 - accuracy: 0.4604 - val_loss: 1.7879 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.45567\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.7364 - accuracy: 0.4665 - val_loss: 1.7359 - val_accuracy: 0.3842\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.45567\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.7142 - accuracy: 0.4909 - val_loss: 1.6937 - val_accuracy: 0.4680\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.45567 to 0.46798, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.6817 - accuracy: 0.5079 - val_loss: 1.6926 - val_accuracy: 0.4384\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.46798\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.6596 - accuracy: 0.5091 - val_loss: 1.6743 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.46798 to 0.49015, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.6430 - accuracy: 0.5091 - val_loss: 1.6409 - val_accuracy: 0.4655\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.49015\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 1.6160 - accuracy: 0.5158 - val_loss: 1.6284 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.49015\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.5833 - accuracy: 0.5420 - val_loss: 1.6671 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.49015\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.5529 - accuracy: 0.5518 - val_loss: 1.6060 - val_accuracy: 0.4310\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.49015\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.5377 - accuracy: 0.5518 - val_loss: 1.5326 - val_accuracy: 0.5172\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.49015 to 0.51724, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.5270 - accuracy: 0.5445 - val_loss: 1.5227 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.51724 to 0.53448, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.4883 - accuracy: 0.5761 - val_loss: 1.4946 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.53448 to 0.54433, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.4630 - accuracy: 0.5713 - val_loss: 1.4728 - val_accuracy: 0.5148\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.54433\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.4466 - accuracy: 0.5828 - val_loss: 1.4657 - val_accuracy: 0.5493\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.54433 to 0.54926, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.4273 - accuracy: 0.5804 - val_loss: 1.4577 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.54926\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 1.3985 - accuracy: 0.6035 - val_loss: 1.4355 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.54926\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.3741 - accuracy: 0.6072 - val_loss: 1.3837 - val_accuracy: 0.5542\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.54926 to 0.55419, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.3488 - accuracy: 0.6169 - val_loss: 1.4046 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.55419\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.3310 - accuracy: 0.6188 - val_loss: 1.4023 - val_accuracy: 0.5542\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.55419\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.2973 - accuracy: 0.6261 - val_loss: 1.3614 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.55419 to 0.57635, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.2807 - accuracy: 0.6389 - val_loss: 1.3050 - val_accuracy: 0.5616\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.57635\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 1.2616 - accuracy: 0.6382 - val_loss: 1.3357 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.57635 to 0.59852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.2352 - accuracy: 0.6510 - val_loss: 1.2947 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.59852\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 1.2191 - accuracy: 0.6541 - val_loss: 1.2788 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.59852\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.2022 - accuracy: 0.6535 - val_loss: 1.2496 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.59852 to 0.62315, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.1876 - accuracy: 0.6620 - val_loss: 1.2189 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.62315\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.1593 - accuracy: 0.6626 - val_loss: 1.2103 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.62315\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.1448 - accuracy: 0.6790 - val_loss: 1.2151 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62315\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.1190 - accuracy: 0.6797 - val_loss: 1.2779 - val_accuracy: 0.5911\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62315\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.0894 - accuracy: 0.6967 - val_loss: 1.1713 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.62315 to 0.62562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.0791 - accuracy: 0.6961 - val_loss: 1.2042 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.62562 to 0.63300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 1.0725 - accuracy: 0.7016 - val_loss: 1.1898 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.63300\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 1.0300 - accuracy: 0.7028 - val_loss: 1.1098 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.63300 to 0.66502, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.0239 - accuracy: 0.7138 - val_loss: 1.1744 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.66502\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 1.0142 - accuracy: 0.7138 - val_loss: 1.1477 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.66502\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.9879 - accuracy: 0.7345 - val_loss: 1.1004 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.66502 to 0.69212, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.9680 - accuracy: 0.7308 - val_loss: 1.1674 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.69212\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.9667 - accuracy: 0.7284 - val_loss: 1.1933 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.69212\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.9398 - accuracy: 0.7253 - val_loss: 1.0795 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.69212\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.9363 - accuracy: 0.7363 - val_loss: 1.0496 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.69212\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.9101 - accuracy: 0.7485 - val_loss: 1.0604 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.69212\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.9044 - accuracy: 0.7412 - val_loss: 1.0718 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.69212\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.8737 - accuracy: 0.7649 - val_loss: 1.0868 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.69212\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.8656 - accuracy: 0.7655 - val_loss: 1.0162 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.69212\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.8359 - accuracy: 0.7814 - val_loss: 1.0212 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.69212\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.8283 - accuracy: 0.7698 - val_loss: 1.0039 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.69212\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.8126 - accuracy: 0.7801 - val_loss: 0.9563 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.69212 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.8096 - accuracy: 0.7661 - val_loss: 0.9813 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.71182\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.7924 - accuracy: 0.7820 - val_loss: 0.9977 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.71182\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.7737 - accuracy: 0.7990 - val_loss: 1.0102 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.71182\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.7593 - accuracy: 0.7929 - val_loss: 1.0055 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.71182\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.7406 - accuracy: 0.7978 - val_loss: 0.9248 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.71182\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.7208 - accuracy: 0.8130 - val_loss: 1.0109 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.71182\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.7158 - accuracy: 0.8112 - val_loss: 0.9748 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.71182\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.7058 - accuracy: 0.8124 - val_loss: 0.9521 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.71182\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.7066 - accuracy: 0.8088 - val_loss: 0.9024 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.71182\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.6807 - accuracy: 0.8197 - val_loss: 0.9612 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.71182\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.6725 - accuracy: 0.8161 - val_loss: 0.8804 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.71182 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.6470 - accuracy: 0.8289 - val_loss: 0.8730 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.72167\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.6649 - accuracy: 0.8234 - val_loss: 0.8766 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.72167\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.6263 - accuracy: 0.8477 - val_loss: 0.8540 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00081: val_accuracy improved from 0.72167 to 0.72660, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.6109 - accuracy: 0.8496 - val_loss: 0.8806 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.72660\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.6059 - accuracy: 0.8441 - val_loss: 0.9317 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.72660\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.6066 - accuracy: 0.8410 - val_loss: 0.8790 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.72660\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.5800 - accuracy: 0.8587 - val_loss: 0.9279 - val_accuracy: 0.7044\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.72660\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5720 - accuracy: 0.8557 - val_loss: 0.8557 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00086: val_accuracy improved from 0.72660 to 0.73153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.5726 - accuracy: 0.8532 - val_loss: 0.8511 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.73153\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5608 - accuracy: 0.8557 - val_loss: 0.8684 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.73153\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.5292 - accuracy: 0.8770 - val_loss: 0.8491 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.73153\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5399 - accuracy: 0.8703 - val_loss: 0.8363 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.73153\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5415 - accuracy: 0.8678 - val_loss: 0.7717 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.73153 to 0.75616, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5157 - accuracy: 0.8691 - val_loss: 0.7887 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.75616\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.5000 - accuracy: 0.8788 - val_loss: 0.8300 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.75616\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.4873 - accuracy: 0.8861 - val_loss: 0.8173 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.75616\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.4773 - accuracy: 0.8934 - val_loss: 0.8078 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.75616\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.4799 - accuracy: 0.8800 - val_loss: 0.7509 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.75616\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.4771 - accuracy: 0.8739 - val_loss: 0.8246 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.75616\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.4471 - accuracy: 0.8940 - val_loss: 0.8989 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.75616\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.4496 - accuracy: 0.8965 - val_loss: 0.8114 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.75616\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.4426 - accuracy: 0.8861 - val_loss: 0.8205 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.75616\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.4459 - accuracy: 0.8910 - val_loss: 0.7841 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.75616\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.4278 - accuracy: 0.9062 - val_loss: 0.7426 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.75616\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.4230 - accuracy: 0.9044 - val_loss: 0.8045 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.75616\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.4128 - accuracy: 0.9044 - val_loss: 0.7966 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.75616\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.4041 - accuracy: 0.9019 - val_loss: 0.7856 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.75616\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3984 - accuracy: 0.9062 - val_loss: 0.8193 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.75616\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3954 - accuracy: 0.9038 - val_loss: 0.7222 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.75616\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3638 - accuracy: 0.9275 - val_loss: 0.7770 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.75616\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.3709 - accuracy: 0.9239 - val_loss: 0.8094 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.75616\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3576 - accuracy: 0.9287 - val_loss: 0.8039 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.75616\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3530 - accuracy: 0.9184 - val_loss: 0.7546 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00111: val_accuracy improved from 0.75616 to 0.75862, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3495 - accuracy: 0.9269 - val_loss: 0.7144 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.75862\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3439 - accuracy: 0.9257 - val_loss: 0.7639 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.75862\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3376 - accuracy: 0.9263 - val_loss: 0.6977 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00114: val_accuracy improved from 0.75862 to 0.79064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3196 - accuracy: 0.9330 - val_loss: 0.7966 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.79064\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3269 - accuracy: 0.9287 - val_loss: 0.7772 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.79064\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.3244 - accuracy: 0.9281 - val_loss: 0.7472 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.79064\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.3114 - accuracy: 0.9373 - val_loss: 0.8274 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.79064\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.3104 - accuracy: 0.9306 - val_loss: 0.7300 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.79064\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.2901 - accuracy: 0.9488 - val_loss: 0.6871 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.79064\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.2973 - accuracy: 0.9300 - val_loss: 0.7511 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.79064\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.3018 - accuracy: 0.9367 - val_loss: 0.7730 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.79064\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2904 - accuracy: 0.9385 - val_loss: 0.7113 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.79064\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2588 - accuracy: 0.9549 - val_loss: 0.8145 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.79064\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.2672 - accuracy: 0.9501 - val_loss: 0.7406 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.79064\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2589 - accuracy: 0.9537 - val_loss: 0.8106 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.79064\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2574 - accuracy: 0.9562 - val_loss: 0.7128 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.79064\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2545 - accuracy: 0.9537 - val_loss: 0.7638 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.79064\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.2402 - accuracy: 0.9543 - val_loss: 0.6949 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.79064\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2493 - accuracy: 0.9562 - val_loss: 0.7268 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.79064\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2342 - accuracy: 0.9653 - val_loss: 0.8306 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.79064\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.2307 - accuracy: 0.9616 - val_loss: 0.8237 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.79064\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2301 - accuracy: 0.9543 - val_loss: 0.7088 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.79064\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.2148 - accuracy: 0.9653 - val_loss: 0.6558 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.79064\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.2256 - accuracy: 0.9488 - val_loss: 0.8281 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.79064\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.2230 - accuracy: 0.9592 - val_loss: 0.7561 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.79064\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.2180 - accuracy: 0.9592 - val_loss: 0.7534 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.79064\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.1974 - accuracy: 0.9635 - val_loss: 0.7133 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.79064\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.2062 - accuracy: 0.9653 - val_loss: 0.8427 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.79064\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1944 - accuracy: 0.9762 - val_loss: 0.7598 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.79064\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1856 - accuracy: 0.9714 - val_loss: 0.7020 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.79064\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1956 - accuracy: 0.9665 - val_loss: 0.7424 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.79064\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1709 - accuracy: 0.9762 - val_loss: 0.7322 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.79064\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1868 - accuracy: 0.9695 - val_loss: 0.7543 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.79064\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1994 - accuracy: 0.9592 - val_loss: 0.7384 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.79064\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1780 - accuracy: 0.9708 - val_loss: 0.7192 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.79064\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1626 - accuracy: 0.9793 - val_loss: 0.8434 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.79064\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1817 - accuracy: 0.9647 - val_loss: 0.8032 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.79064\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1717 - accuracy: 0.9744 - val_loss: 0.7189 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.79064\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1604 - accuracy: 0.9762 - val_loss: 0.7360 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.79064\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1594 - accuracy: 0.9762 - val_loss: 0.7938 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.79064\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1468 - accuracy: 0.9848 - val_loss: 0.7345 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.79064\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1643 - accuracy: 0.9769 - val_loss: 0.8087 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.79064\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1572 - accuracy: 0.9720 - val_loss: 0.7318 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.79064\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1344 - accuracy: 0.9860 - val_loss: 0.6759 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.79064\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1529 - accuracy: 0.9787 - val_loss: 0.7106 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.79064\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1353 - accuracy: 0.9805 - val_loss: 0.6917 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.79064\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1549 - accuracy: 0.9720 - val_loss: 0.6644 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.79064\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.1360 - accuracy: 0.9823 - val_loss: 0.7511 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.79064\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1383 - accuracy: 0.9811 - val_loss: 0.7623 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.79064\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1425 - accuracy: 0.9811 - val_loss: 0.7081 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.79064\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1329 - accuracy: 0.9799 - val_loss: 0.7068 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.79064\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1416 - accuracy: 0.9756 - val_loss: 0.8450 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.79064\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1307 - accuracy: 0.9842 - val_loss: 0.7573 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.79064\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1308 - accuracy: 0.9829 - val_loss: 0.7082 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.79064\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.1306 - accuracy: 0.9811 - val_loss: 0.7398 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.79064\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.1184 - accuracy: 0.9836 - val_loss: 0.9242 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.79064\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1150 - accuracy: 0.9884 - val_loss: 0.7212 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.79064\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1133 - accuracy: 0.9884 - val_loss: 0.7092 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.79064\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1247 - accuracy: 0.9829 - val_loss: 0.7679 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.79064\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1176 - accuracy: 0.9829 - val_loss: 0.8168 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.79064\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.1095 - accuracy: 0.9872 - val_loss: 0.7016 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.79064\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1116 - accuracy: 0.9872 - val_loss: 0.7543 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.79064\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.1023 - accuracy: 0.9854 - val_loss: 0.6447 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.79064\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1103 - accuracy: 0.9811 - val_loss: 0.7428 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.79064\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.1120 - accuracy: 0.9823 - val_loss: 0.7659 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.79064\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.1072 - accuracy: 0.9909 - val_loss: 0.7443 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.79064\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.1121 - accuracy: 0.9829 - val_loss: 0.7158 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.79064\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1048 - accuracy: 0.9903 - val_loss: 0.7354 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.79064\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.1001 - accuracy: 0.9872 - val_loss: 0.7460 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.79064\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0931 - accuracy: 0.9927 - val_loss: 0.7378 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.79064\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0961 - accuracy: 0.9909 - val_loss: 0.6883 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.79064\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0968 - accuracy: 0.9884 - val_loss: 0.6610 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00183: val_accuracy improved from 0.79064 to 0.80049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0896 - accuracy: 0.9896 - val_loss: 0.7288 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.80049\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0926 - accuracy: 0.9866 - val_loss: 0.7237 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.80049\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0846 - accuracy: 0.9915 - val_loss: 0.7728 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.80049\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0894 - accuracy: 0.9903 - val_loss: 0.7417 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.80049\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0844 - accuracy: 0.9903 - val_loss: 0.6845 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.80049\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0898 - accuracy: 0.9884 - val_loss: 0.7145 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.80049\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0864 - accuracy: 0.9866 - val_loss: 0.7545 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.80049\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0922 - accuracy: 0.9854 - val_loss: 0.7482 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.80049\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0841 - accuracy: 0.9909 - val_loss: 0.7241 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.80049\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0765 - accuracy: 0.9933 - val_loss: 0.7646 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.80049\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0801 - accuracy: 0.9951 - val_loss: 0.7020 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.80049\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0836 - accuracy: 0.9909 - val_loss: 0.7363 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.80049\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0782 - accuracy: 0.9927 - val_loss: 0.6497 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.80049\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0795 - accuracy: 0.9915 - val_loss: 0.7427 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.80049\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0758 - accuracy: 0.9939 - val_loss: 0.7774 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.80049\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0731 - accuracy: 0.9927 - val_loss: 0.7699 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.80049\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0768 - accuracy: 0.9896 - val_loss: 0.6986 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.80049\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0750 - accuracy: 0.9921 - val_loss: 0.7782 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.80049\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0725 - accuracy: 0.9933 - val_loss: 0.7782 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.80049\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0791 - accuracy: 0.9872 - val_loss: 0.7556 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.80049\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0730 - accuracy: 0.9909 - val_loss: 0.7948 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.80049\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0709 - accuracy: 0.9903 - val_loss: 0.7903 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.80049\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0622 - accuracy: 0.9963 - val_loss: 0.7644 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.80049\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0655 - accuracy: 0.9945 - val_loss: 0.7424 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.80049\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0618 - accuracy: 0.9970 - val_loss: 0.7284 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.80049\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0637 - accuracy: 0.9951 - val_loss: 0.7362 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.80049\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0626 - accuracy: 0.9945 - val_loss: 0.7531 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.80049\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0721 - accuracy: 0.9878 - val_loss: 1.0407 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.80049\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0635 - accuracy: 0.9957 - val_loss: 0.7176 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.80049\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0629 - accuracy: 0.9933 - val_loss: 0.7093 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.80049\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0659 - accuracy: 0.9939 - val_loss: 0.8763 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.80049\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0681 - accuracy: 0.9933 - val_loss: 0.7383 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.80049\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0598 - accuracy: 0.9939 - val_loss: 0.8405 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.80049\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0568 - accuracy: 0.9939 - val_loss: 0.6918 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.80049\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0676 - accuracy: 0.9933 - val_loss: 0.7310 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.80049\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0545 - accuracy: 0.9945 - val_loss: 0.7637 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.80049\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0572 - accuracy: 0.9970 - val_loss: 0.8489 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.80049\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0573 - accuracy: 0.9927 - val_loss: 0.7172 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.80049\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0611 - accuracy: 0.9945 - val_loss: 0.7029 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.80049\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0566 - accuracy: 0.9970 - val_loss: 0.7207 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.80049\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0555 - accuracy: 0.9976 - val_loss: 0.6780 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.80049\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0578 - accuracy: 0.9957 - val_loss: 0.7697 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.80049\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0576 - accuracy: 0.9927 - val_loss: 0.7154 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.80049\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0467 - accuracy: 0.9970 - val_loss: 0.7850 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.80049\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0541 - accuracy: 0.9945 - val_loss: 0.7172 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.80049\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0587 - accuracy: 0.9921 - val_loss: 0.7878 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.80049\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0502 - accuracy: 0.9951 - val_loss: 0.7305 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.80049\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0567 - accuracy: 0.9945 - val_loss: 0.7360 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.80049\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0497 - accuracy: 0.9951 - val_loss: 0.7605 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.80049\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0475 - accuracy: 0.9976 - val_loss: 0.6773 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.80049\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0547 - accuracy: 0.9933 - val_loss: 0.8086 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.80049\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0573 - accuracy: 0.9927 - val_loss: 0.7236 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.80049\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0462 - accuracy: 0.9963 - val_loss: 0.7543 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.80049\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0435 - accuracy: 0.9988 - val_loss: 0.6904 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.80049\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0458 - accuracy: 0.9982 - val_loss: 0.6700 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.80049\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0460 - accuracy: 0.9951 - val_loss: 0.6226 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.80049\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0464 - accuracy: 0.9970 - val_loss: 0.7138 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.80049\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0578 - accuracy: 0.9933 - val_loss: 0.8173 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.80049\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0529 - accuracy: 0.9939 - val_loss: 0.7006 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.80049\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0456 - accuracy: 0.9970 - val_loss: 0.7707 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.80049\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0400 - accuracy: 0.9988 - val_loss: 0.7781 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.80049\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0424 - accuracy: 0.9976 - val_loss: 0.8218 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.80049\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0470 - accuracy: 0.9951 - val_loss: 0.7782 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.80049\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0404 - accuracy: 0.9982 - val_loss: 0.7221 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.80049\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0478 - accuracy: 0.9915 - val_loss: 0.7061 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.80049\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0404 - accuracy: 0.9982 - val_loss: 0.7694 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.80049\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0419 - accuracy: 0.9970 - val_loss: 0.7753 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.80049\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0374 - accuracy: 0.9970 - val_loss: 0.7195 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.80049\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0479 - accuracy: 0.9945 - val_loss: 0.7514 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.80049\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0474 - accuracy: 0.9951 - val_loss: 0.7123 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.80049\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 19s 373ms/step - loss: 0.0436 - accuracy: 0.9976 - val_loss: 0.7189 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.80049\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0418 - accuracy: 0.9970 - val_loss: 0.7630 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.80049\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0386 - accuracy: 0.9976 - val_loss: 0.7171 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.80049\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0443 - accuracy: 0.9970 - val_loss: 0.7290 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.80049\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0401 - accuracy: 0.9976 - val_loss: 0.7149 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.80049\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0452 - accuracy: 0.9927 - val_loss: 0.8189 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.80049\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0395 - accuracy: 0.9982 - val_loss: 0.7256 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.80049\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0346 - accuracy: 0.9988 - val_loss: 0.7311 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.80049\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0378 - accuracy: 0.9970 - val_loss: 0.7606 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.80049\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0401 - accuracy: 0.9963 - val_loss: 0.8280 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.80049\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0345 - accuracy: 0.9982 - val_loss: 0.7663 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.80049\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0428 - accuracy: 0.9970 - val_loss: 0.7758 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.80049\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0371 - accuracy: 0.9963 - val_loss: 0.7555 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.80049\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0406 - accuracy: 0.9951 - val_loss: 0.8044 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.80049\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0394 - accuracy: 0.9970 - val_loss: 0.7046 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.80049\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0392 - accuracy: 0.9982 - val_loss: 0.6983 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.80049\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0399 - accuracy: 0.9957 - val_loss: 0.7576 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.80049\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0470 - accuracy: 0.9963 - val_loss: 0.6968 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00271: val_accuracy improved from 0.80049 to 0.80296, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0384 - accuracy: 0.9982 - val_loss: 0.7566 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.80296\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0391 - accuracy: 0.9951 - val_loss: 0.7704 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.80296\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0329 - accuracy: 0.9982 - val_loss: 0.7019 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.80296\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0380 - accuracy: 0.9970 - val_loss: 0.9936 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.80296\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 19s 366ms/step - loss: 0.0422 - accuracy: 0.9951 - val_loss: 0.8613 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.80296\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0329 - accuracy: 0.9982 - val_loss: 0.9445 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.80296\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0370 - accuracy: 0.9970 - val_loss: 0.7401 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.80296\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0333 - accuracy: 0.9988 - val_loss: 0.6976 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.80296\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0369 - accuracy: 0.9957 - val_loss: 0.8571 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.80296\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0368 - accuracy: 0.9963 - val_loss: 0.6425 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.80296\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0443 - accuracy: 0.9933 - val_loss: 0.7509 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.80296\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0333 - accuracy: 0.9988 - val_loss: 0.6711 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.80296\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0294 - accuracy: 0.9994 - val_loss: 0.7260 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.80296\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0343 - accuracy: 0.9963 - val_loss: 0.8072 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.80296\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0421 - accuracy: 0.9957 - val_loss: 1.1969 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.80296\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0404 - accuracy: 0.9933 - val_loss: 0.6615 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.80296\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0370 - accuracy: 0.9963 - val_loss: 0.7691 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.80296\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0348 - accuracy: 0.9957 - val_loss: 0.7616 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.80296\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0368 - accuracy: 0.9957 - val_loss: 0.6970 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.80296\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0329 - accuracy: 0.9982 - val_loss: 0.7060 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.80296\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0298 - accuracy: 0.9988 - val_loss: 0.7694 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.80296\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0319 - accuracy: 0.9988 - val_loss: 0.6954 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.80296\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0430 - accuracy: 0.9927 - val_loss: 0.6844 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.80296\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0371 - accuracy: 0.9963 - val_loss: 0.7468 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.80296\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0315 - accuracy: 0.9976 - val_loss: 0.7347 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.80296\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0403 - accuracy: 0.9951 - val_loss: 0.6211 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.80296\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0283 - accuracy: 0.9988 - val_loss: 0.6930 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.80296\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0297 - accuracy: 0.9982 - val_loss: 0.7546 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.80296\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0297 - accuracy: 0.9970 - val_loss: 0.7259 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.80296\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0357 - accuracy: 0.9982 - val_loss: 0.7884 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.80296\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0318 - accuracy: 0.9970 - val_loss: 0.6827 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.80296\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0367 - accuracy: 0.9945 - val_loss: 0.7256 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.80296\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0338 - accuracy: 0.9963 - val_loss: 0.9041 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.80296\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0291 - accuracy: 0.9988 - val_loss: 0.8146 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.80296\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0364 - accuracy: 0.9957 - val_loss: 0.7287 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.80296\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0351 - accuracy: 0.9963 - val_loss: 0.6498 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.80296\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0357 - accuracy: 0.9963 - val_loss: 0.9483 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.80296\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0326 - accuracy: 0.9976 - val_loss: 0.7181 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.80296\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0338 - accuracy: 0.9976 - val_loss: 0.6897 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.80296\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0264 - accuracy: 0.9988 - val_loss: 0.7267 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.80296\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0296 - accuracy: 0.9970 - val_loss: 0.7224 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.80296\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0302 - accuracy: 0.9988 - val_loss: 0.6745 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.80296\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0285 - accuracy: 0.9976 - val_loss: 0.7274 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.80296\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0268 - accuracy: 0.9976 - val_loss: 0.6648 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.80296\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0285 - accuracy: 0.9976 - val_loss: 0.7092 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.80296\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0249 - accuracy: 0.9994 - val_loss: 0.7079 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.80296\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0303 - accuracy: 0.9976 - val_loss: 0.7165 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.80296\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0291 - accuracy: 0.9976 - val_loss: 0.7056 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.80296\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0252 - accuracy: 0.9988 - val_loss: 0.6977 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.80296\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0240 - accuracy: 0.9994 - val_loss: 0.7450 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.80296\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0275 - accuracy: 0.9982 - val_loss: 0.7628 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.80296\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0264 - accuracy: 0.9970 - val_loss: 0.7209 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.80296\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0220 - accuracy: 0.9988 - val_loss: 0.8084 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.80296\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0269 - accuracy: 0.9982 - val_loss: 0.7915 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.80296\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0261 - accuracy: 0.9982 - val_loss: 0.8565 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.80296\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0325 - accuracy: 0.9970 - val_loss: 0.7370 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.80296\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0318 - accuracy: 0.9957 - val_loss: 0.7237 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.80296\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0296 - accuracy: 0.9957 - val_loss: 0.6709 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.80296\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0267 - accuracy: 0.9982 - val_loss: 0.7393 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.80296\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0263 - accuracy: 0.9988 - val_loss: 0.6983 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.80296\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0254 - accuracy: 0.9994 - val_loss: 0.7089 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.80296\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0270 - accuracy: 0.9976 - val_loss: 0.6993 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.80296\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.80296\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0237 - accuracy: 0.9988 - val_loss: 0.7282 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.80296\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0254 - accuracy: 0.9988 - val_loss: 0.6992 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.80296\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0272 - accuracy: 0.9982 - val_loss: 0.6528 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00337: val_accuracy improved from 0.80296 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0250 - accuracy: 0.9994 - val_loss: 0.6902 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.82020\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0240 - accuracy: 0.9970 - val_loss: 0.8039 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.82020\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0257 - accuracy: 0.9994 - val_loss: 0.6323 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.82020\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0269 - accuracy: 0.9976 - val_loss: 0.7022 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.82020\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0225 - accuracy: 0.9976 - val_loss: 0.7192 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.82020\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0250 - accuracy: 0.9976 - val_loss: 0.7118 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.82020\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0241 - accuracy: 0.9982 - val_loss: 0.6917 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.82020\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0270 - accuracy: 0.9988 - val_loss: 0.7847 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.82020\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0238 - accuracy: 0.9982 - val_loss: 0.6772 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.82020\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0251 - accuracy: 0.9982 - val_loss: 0.8093 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.82020\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0230 - accuracy: 0.9988 - val_loss: 0.6802 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.82020\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0256 - accuracy: 0.9976 - val_loss: 0.7871 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.82020\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0246 - accuracy: 0.9982 - val_loss: 0.7245 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.82020\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.82020\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0240 - accuracy: 0.9976 - val_loss: 0.6864 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.82020\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0244 - accuracy: 0.9976 - val_loss: 0.6997 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.82020\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0216 - accuracy: 0.9982 - val_loss: 0.7731 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.82020\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.0233 - accuracy: 0.9976 - val_loss: 0.7479 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.82020\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0225 - accuracy: 0.9976 - val_loss: 0.7370 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.82020\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0276 - accuracy: 0.9976 - val_loss: 0.7628 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.82020\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0304 - accuracy: 0.9951 - val_loss: 0.8742 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.82020\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0212 - accuracy: 0.9994 - val_loss: 0.7077 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.82020\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0297 - accuracy: 0.9945 - val_loss: 0.8148 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.82020\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0248 - accuracy: 0.9988 - val_loss: 0.7498 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.82020\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0228 - accuracy: 0.9994 - val_loss: 0.7092 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.82020\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0225 - accuracy: 0.9988 - val_loss: 0.6853 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.82020\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0215 - accuracy: 0.9970 - val_loss: 0.8028 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.82020\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0214 - accuracy: 0.9994 - val_loss: 0.7005 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.82020\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0301 - accuracy: 0.9963 - val_loss: 0.7656 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.82020\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0225 - accuracy: 0.9982 - val_loss: 0.7041 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.82020\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0223 - accuracy: 0.9994 - val_loss: 0.6884 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.82020\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.0213 - accuracy: 0.9988 - val_loss: 0.6970 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.82020\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.8030 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.82020\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0206 - accuracy: 0.9982 - val_loss: 0.7026 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.82020\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.82020\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0229 - accuracy: 0.9988 - val_loss: 0.9141 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.82020\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0202 - accuracy: 0.9988 - val_loss: 0.7019 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.82020\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0211 - accuracy: 0.9994 - val_loss: 0.7913 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.82020\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0226 - accuracy: 0.9982 - val_loss: 0.7528 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.82020\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0214 - accuracy: 0.9976 - val_loss: 0.9318 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.82020\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0224 - accuracy: 0.9982 - val_loss: 0.7303 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.82020\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.82020\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0216 - accuracy: 0.9994 - val_loss: 0.7213 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.82020\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0200 - accuracy: 0.9994 - val_loss: 0.7850 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.82020\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0222 - accuracy: 0.9988 - val_loss: 0.6711 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.82020\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0207 - accuracy: 0.9982 - val_loss: 0.7285 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.82020\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0219 - accuracy: 0.9988 - val_loss: 0.7169 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.82020\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0202 - accuracy: 0.9982 - val_loss: 0.7320 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.82020\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0234 - accuracy: 0.9982 - val_loss: 0.7938 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.82020\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 0.6570 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.82020\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0221 - accuracy: 0.9982 - val_loss: 0.7130 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.82020\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.82020\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0194 - accuracy: 0.9988 - val_loss: 0.7869 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.82020\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 0.7163 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.82020\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.6732 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.82020\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0186 - accuracy: 0.9982 - val_loss: 0.7500 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.82020\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 0.6953 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.82020\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0182 - accuracy: 0.9982 - val_loss: 0.7113 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.82020\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0223 - accuracy: 0.9976 - val_loss: 0.7512 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.82020\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0214 - accuracy: 0.9976 - val_loss: 0.7396 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.82020\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0180 - accuracy: 0.9994 - val_loss: 0.7402 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.82020\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0178 - accuracy: 0.9982 - val_loss: 0.7009 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.82020\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0190 - accuracy: 0.9994 - val_loss: 0.6889 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.82020\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0188 - accuracy: 0.9988 - val_loss: 0.7646 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.82020\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0233 - accuracy: 0.9970 - val_loss: 0.7177 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.82020\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0165 - accuracy: 0.9982 - val_loss: 0.7539 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.82020\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0177 - accuracy: 0.9994 - val_loss: 0.6318 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.82020\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0239 - accuracy: 0.9982 - val_loss: 0.7035 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.82020\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0205 - accuracy: 0.9976 - val_loss: 0.7275 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.82020\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.82020\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0219 - accuracy: 0.9970 - val_loss: 0.7432 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.82020\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.0253 - accuracy: 0.9970 - val_loss: 0.8022 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.82020\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.7944 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.82020\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0169 - accuracy: 0.9982 - val_loss: 0.7092 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.82020\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0179 - accuracy: 0.9988 - val_loss: 0.8891 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.82020\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0177 - accuracy: 0.9994 - val_loss: 0.7416 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.82020\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.7025 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.82020\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0224 - accuracy: 0.9988 - val_loss: 0.8231 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.82020\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0291 - accuracy: 0.9957 - val_loss: 0.7139 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.82020\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.7854 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.82020\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0167 - accuracy: 0.9988 - val_loss: 0.7077 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.82020\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0177 - accuracy: 0.9988 - val_loss: 0.7583 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.82020\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0249 - accuracy: 0.9976 - val_loss: 0.8131 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.82020\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0228 - accuracy: 0.9982 - val_loss: 0.8624 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.82020\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0182 - accuracy: 0.9982 - val_loss: 0.7281 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.82020\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.82020\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0183 - accuracy: 0.9976 - val_loss: 0.6824 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.82020\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0180 - accuracy: 0.9982 - val_loss: 0.7315 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.82020\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0185 - accuracy: 0.9994 - val_loss: 0.7449 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.82020\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.7493 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.82020\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.7613 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.82020\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0216 - accuracy: 0.9982 - val_loss: 0.7478 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.82020\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0263 - accuracy: 0.9963 - val_loss: 0.7381 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.82020\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0184 - accuracy: 0.9994 - val_loss: 0.6473 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.82020\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.7600 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.82020\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0148 - accuracy: 0.9994 - val_loss: 0.7687 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.82020\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0154 - accuracy: 0.9994 - val_loss: 0.7966 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.82020\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.82020\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0181 - accuracy: 0.9976 - val_loss: 0.6383 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.82020\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 0.7075 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.82020\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0161 - accuracy: 0.9994 - val_loss: 0.6847 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.82020\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0193 - accuracy: 0.9994 - val_loss: 0.7585 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.82020\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.7437 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.82020\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0179 - accuracy: 0.9982 - val_loss: 0.7060 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.82020\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0142 - accuracy: 0.9994 - val_loss: 0.6369 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.82020\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0147 - accuracy: 0.9994 - val_loss: 0.7103 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.82020\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.7186 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.82020\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 0.7189 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.82020\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0138 - accuracy: 0.9994 - val_loss: 0.6312 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.82020\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.6598 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.82020\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0174 - accuracy: 0.9982 - val_loss: 0.6929 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.82020\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 0.6685 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.82020\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.6754 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.82020\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.82020\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0222 - accuracy: 0.9976 - val_loss: 0.6995 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.82020\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.82020\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0146 - accuracy: 0.9994 - val_loss: 0.7848 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.82020\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0174 - accuracy: 0.9982 - val_loss: 0.7036 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.82020\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.8043 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.82020\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0175 - accuracy: 0.9988 - val_loss: 0.6595 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.82020\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.7360 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.82020\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 0.6745 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.82020\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 0.8288 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.82020\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0178 - accuracy: 0.9988 - val_loss: 0.6839 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.82020\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0158 - accuracy: 0.9994 - val_loss: 0.7318 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.82020\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0159 - accuracy: 0.9982 - val_loss: 0.7517 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.82020\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 0.8128 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.82020\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.7275 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.82020\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 0.8191 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.82020\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.7149 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.82020\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.7237 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.82020\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.6916 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.82020\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0172 - accuracy: 0.9982 - val_loss: 0.7007 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.82020\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0175 - accuracy: 0.9988 - val_loss: 0.7322 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.82020\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0217 - accuracy: 0.9970 - val_loss: 0.7426 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.82020\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.82020\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0134 - accuracy: 0.9982 - val_loss: 0.7195 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.82020\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.7119 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.82020\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0169 - accuracy: 0.9988 - val_loss: 0.6940 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.82020\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.7188 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.82020\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.6974 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.82020\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.82020\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0155 - accuracy: 0.9988 - val_loss: 0.6974 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.82020\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0161 - accuracy: 0.9988 - val_loss: 0.6672 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.82020\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0169 - accuracy: 0.9982 - val_loss: 0.7333 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.82020\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0155 - accuracy: 0.9988 - val_loss: 0.7083 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.82020\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.82020\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.7200 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.82020\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.6337 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.82020\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.82020\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.82020\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.82020\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0137 - accuracy: 0.9994 - val_loss: 0.6533 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.82020\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.82020\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0122 - accuracy: 0.9994 - val_loss: 0.7292 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.82020\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 0.6876 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.82020\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.82020\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0126 - accuracy: 0.9994 - val_loss: 0.7765 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.82020\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 19s 374ms/step - loss: 0.0143 - accuracy: 0.9988 - val_loss: 0.6650 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.82020\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.82020\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 19s 369ms/step - loss: 0.0127 - accuracy: 0.9994 - val_loss: 0.6623 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.82020\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 0.0120 - accuracy: 0.9994 - val_loss: 0.7031 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.82020\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.7110 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.82020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f78ec35ac90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ee40bebd-4a00-464a-a06f-58924f97827d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/OP_Adagrad_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52d0d3f-daf8-42e1-9b5e-de63cf0e58a3"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf98973a-f34d-40b5-fbfd-3288f266e7d1"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b0c4fda7-9e09-48e7-f328-6a757fbb6056"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      8\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0a8b9d81-b887-42f4-97c4-90fc6ed82962"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Adagrad_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Optimizer_Adagrad_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a04c2d30-2d22-4cc9-b896-4aef28b8ce58\", \"Optimizer_Adagrad_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}