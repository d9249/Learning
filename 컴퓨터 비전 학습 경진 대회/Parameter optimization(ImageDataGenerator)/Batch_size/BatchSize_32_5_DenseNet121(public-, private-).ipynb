{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchSize_32_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6mujOnjWlp5AYx3Rre36e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/BatchSize_32_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97ef8fe-167d-49b8-8b57-e434f2c11b31"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep  5 10:00:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b986d7c0-0965-4a85-af1a-653af14d7c25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b073c0-7471-4172-d889-3b33453f4b62"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79ab644-ae71-4cf3-fb5e-8cf95f5ca8a9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size, color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), batch_size = batch_size,  color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8a9549-c94a-4351-d45e-43ac25808983"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs = 500, validation_data = val_generator, callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 480ms/step - loss: 1.8536 - accuracy: 0.3544 - val_loss: 6.9835 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10591, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 1.2022 - accuracy: 0.5981 - val_loss: 13.7395 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10591\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.9805 - accuracy: 0.6730 - val_loss: 13.6059 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10591\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.8285 - accuracy: 0.7308 - val_loss: 22.8822 - val_accuracy: 0.0837\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.10591\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.6804 - accuracy: 0.7667 - val_loss: 9.8927 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.10591\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.6701 - accuracy: 0.7722 - val_loss: 10.2932 - val_accuracy: 0.1232\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.10591 to 0.12315, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.5494 - accuracy: 0.8106 - val_loss: 5.2355 - val_accuracy: 0.2709\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.12315 to 0.27094, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.5146 - accuracy: 0.8343 - val_loss: 6.1293 - val_accuracy: 0.2685\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.27094\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.4865 - accuracy: 0.8490 - val_loss: 4.5210 - val_accuracy: 0.4236\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.27094 to 0.42365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.4267 - accuracy: 0.8557 - val_loss: 2.1618 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.42365 to 0.55911, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.4149 - accuracy: 0.8593 - val_loss: 1.7668 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.55911 to 0.58374, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.4042 - accuracy: 0.8551 - val_loss: 0.9449 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.58374 to 0.72414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 21s 392ms/step - loss: 0.3636 - accuracy: 0.8758 - val_loss: 0.8364 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.72414 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.3482 - accuracy: 0.8837 - val_loss: 1.1108 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79310\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.3392 - accuracy: 0.8861 - val_loss: 2.1082 - val_accuracy: 0.5739\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79310\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.3060 - accuracy: 0.8916 - val_loss: 0.6328 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.79310 to 0.81281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.2668 - accuracy: 0.9135 - val_loss: 0.5274 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.81281 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.2988 - accuracy: 0.9007 - val_loss: 0.7305 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84236\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.2873 - accuracy: 0.8977 - val_loss: 0.6603 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.84236\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1961 - accuracy: 0.9330 - val_loss: 0.3944 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.84236 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2115 - accuracy: 0.9342 - val_loss: 0.5944 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.86700\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.2370 - accuracy: 0.9202 - val_loss: 0.8310 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86700\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.2301 - accuracy: 0.9269 - val_loss: 1.1720 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86700\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1868 - accuracy: 0.9415 - val_loss: 0.6849 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86700\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1951 - accuracy: 0.9336 - val_loss: 0.5239 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86700\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1785 - accuracy: 0.9373 - val_loss: 0.5599 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86700\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1409 - accuracy: 0.9531 - val_loss: 0.5041 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86700\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.1911 - accuracy: 0.9318 - val_loss: 0.8424 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86700\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.1833 - accuracy: 0.9361 - val_loss: 0.5302 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86700\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1397 - accuracy: 0.9513 - val_loss: 0.7534 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86700\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1709 - accuracy: 0.9428 - val_loss: 0.9948 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.86700\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1257 - accuracy: 0.9549 - val_loss: 0.8513 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86700\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1412 - accuracy: 0.9537 - val_loss: 0.8937 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86700\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1765 - accuracy: 0.9385 - val_loss: 1.5835 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86700\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1416 - accuracy: 0.9482 - val_loss: 0.7464 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86700\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1165 - accuracy: 0.9555 - val_loss: 0.7086 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86700\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1409 - accuracy: 0.9537 - val_loss: 0.5571 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86700\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1271 - accuracy: 0.9562 - val_loss: 1.2910 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86700\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0965 - accuracy: 0.9671 - val_loss: 0.6658 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86700\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0855 - accuracy: 0.9714 - val_loss: 0.6716 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86700\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0756 - accuracy: 0.9689 - val_loss: 0.5989 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.86700\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1318 - accuracy: 0.9580 - val_loss: 1.0020 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86700\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1063 - accuracy: 0.9677 - val_loss: 2.7351 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86700\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1141 - accuracy: 0.9610 - val_loss: 0.7513 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86700\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1090 - accuracy: 0.9622 - val_loss: 0.4937 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.86700 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0713 - accuracy: 0.9738 - val_loss: 0.7265 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.87192\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 0.4571 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.87192 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0899 - accuracy: 0.9629 - val_loss: 0.8342 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89655\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.1873 - accuracy: 0.9336 - val_loss: 1.4855 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89655\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1203 - accuracy: 0.9562 - val_loss: 0.6639 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89655\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.5099 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89655\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0573 - accuracy: 0.9817 - val_loss: 0.5946 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89655\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0408 - accuracy: 0.9896 - val_loss: 0.5754 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89655\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0598 - accuracy: 0.9793 - val_loss: 0.5648 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89655\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0670 - accuracy: 0.9781 - val_loss: 0.6517 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89655\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0938 - accuracy: 0.9683 - val_loss: 0.7207 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89655\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1148 - accuracy: 0.9562 - val_loss: 0.6687 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89655\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1098 - accuracy: 0.9629 - val_loss: 1.4336 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89655\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0625 - accuracy: 0.9781 - val_loss: 1.3646 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89655\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0882 - accuracy: 0.9714 - val_loss: 0.6394 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89655\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0608 - accuracy: 0.9775 - val_loss: 0.4644 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89655\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0907 - accuracy: 0.9750 - val_loss: 2.9320 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89655\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1438 - accuracy: 0.9543 - val_loss: 0.5322 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89655\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0888 - accuracy: 0.9635 - val_loss: 0.6827 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89655\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1243 - accuracy: 0.9586 - val_loss: 1.6371 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89655\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 0.8782 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89655\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.5395 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89655\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.4671 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89655\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.5049 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89655\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.5836 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89655\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0809 - accuracy: 0.9695 - val_loss: 0.8227 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89655\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 0.4664 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.89655 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.6112 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90148\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0523 - accuracy: 0.9769 - val_loss: 0.5229 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90148\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.3805 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.90148 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 0.7126 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91133\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1044 - accuracy: 0.9647 - val_loss: 0.7502 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91133\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0758 - accuracy: 0.9738 - val_loss: 0.8696 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91133\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0504 - accuracy: 0.9848 - val_loss: 0.6245 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91133\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0397 - accuracy: 0.9854 - val_loss: 0.5624 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91133\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0483 - accuracy: 0.9860 - val_loss: 0.5015 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91133\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.5021 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91133\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0642 - accuracy: 0.9787 - val_loss: 0.6765 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91133\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0495 - accuracy: 0.9842 - val_loss: 0.6321 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91133\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 0.5651 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91133\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0631 - accuracy: 0.9750 - val_loss: 0.5856 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91133\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.5212 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91133\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.4705 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91133\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.6246 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91133\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4961 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91133\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.4283 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91133\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.3660 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.91133 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.4054 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91872\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.5433 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91872\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0296 - accuracy: 0.9884 - val_loss: 0.5710 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91872\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0518 - accuracy: 0.9866 - val_loss: 0.6421 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91872\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0839 - accuracy: 0.9732 - val_loss: 1.8482 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91872\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0954 - accuracy: 0.9665 - val_loss: 1.2265 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91872\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.4800 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91872\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.5318 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91872\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.6426 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91872\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0557 - accuracy: 0.9823 - val_loss: 1.0465 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91872\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1221 - accuracy: 0.9659 - val_loss: 0.9390 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91872\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 0.6398 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91872\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.5080 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91872\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.5679 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91872\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.7219 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91872\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.3956 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91872\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.4532 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91872\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.5881 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91872\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.5064 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91872\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.6156 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91872\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0868 - accuracy: 0.9708 - val_loss: 1.3291 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91872\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0989 - accuracy: 0.9695 - val_loss: 1.2359 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91872\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0715 - accuracy: 0.9781 - val_loss: 0.7339 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91872\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.9081 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91872\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.6234 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91872\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0609 - accuracy: 0.9762 - val_loss: 0.4427 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91872\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.5803 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91872\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.5258 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91872\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.5151 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91872\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4571 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91872\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4165 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91872\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.4247 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91872\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91872\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.4068 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.4455 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.7950 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0481 - accuracy: 0.9842 - val_loss: 0.9933 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.5732 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91872\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 0.6757 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91872\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 1.3005 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91872\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0784 - accuracy: 0.9720 - val_loss: 1.6175 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91872\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0885 - accuracy: 0.9671 - val_loss: 4.6763 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91872\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.4762 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91872\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.4273 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91872\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.7473 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91872\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0656 - accuracy: 0.9817 - val_loss: 0.9030 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91872\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0892 - accuracy: 0.9689 - val_loss: 0.9148 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91872\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 0.5358 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91872\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0301 - accuracy: 0.9866 - val_loss: 0.9356 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91872\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.6717 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91872\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5173 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91872\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.3970 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91872\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.3812 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91872\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4235 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91872\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.4251 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91872\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.3922 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00148: val_accuracy improved from 0.91872 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4029 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92118\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.3770 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92118\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.4803 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92118\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.6698 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92118\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0329 - accuracy: 0.9860 - val_loss: 1.6961 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92118\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0376 - accuracy: 0.9848 - val_loss: 0.9450 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92118\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.6973 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92118\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0351 - accuracy: 0.9860 - val_loss: 0.4878 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92118\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0388 - accuracy: 0.9842 - val_loss: 0.6010 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92118\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.8023 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92118\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.5992 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92118\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.5847 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92118\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.4819 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92118\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.4558 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92118\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5218 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92118\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.5815 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92118\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5928 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92118\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0764 - accuracy: 0.9787 - val_loss: 0.5671 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92118\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 0.8415 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92118\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5218 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92118\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0194 - accuracy: 0.9976 - val_loss: 0.3945 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92118\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0235 - accuracy: 0.9903 - val_loss: 0.7309 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92118\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.3845 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92118\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5284 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92118\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3735 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92118\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.3944 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92118\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00175: val_accuracy improved from 0.92118 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4042 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93103\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0941 - accuracy: 0.9732 - val_loss: 1.0170 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93103\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.5556 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93103\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.5603 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93103\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.5497 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93103\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.4844 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93103\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 0.5107 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93103\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 1.2870 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93103\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0690 - accuracy: 0.9817 - val_loss: 1.0276 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93103\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0690 - accuracy: 0.9793 - val_loss: 1.8440 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93103\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.7558 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93103\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.4517 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93103\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.6744 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93103\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.5390 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93103\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.4522 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93103\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.4224 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93103\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.4957 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93103\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3828 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93103\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.4432 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93103\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.4651 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93103\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3892 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93103\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5094 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93103\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.5157 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93103\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.6148 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93103\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.7583 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93103\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.5910 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93103\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0126 - accuracy: 0.9945 - val_loss: 0.7693 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93103\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.6206 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93103\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.4270 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93103\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5267 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93103\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5076 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93103\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4580 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93103\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 2.0142 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93103\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1091 - accuracy: 0.9708 - val_loss: 1.1173 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93103\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.5705 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93103\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.8687 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93103\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.5972 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93103\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.6450 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93103\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.6404 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93103\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4330 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93103\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6076 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93103\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.5520 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93103\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.4726 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93103\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0100 - accuracy: 0.9951 - val_loss: 0.4947 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93103\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93103\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4566 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93103\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5015 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93103\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.4723 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93103\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.6050 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93103\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.6888 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93103\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4591 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93103\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4662 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93103\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93103\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.9116e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93103\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93103\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4434 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93103\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.5246 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93103\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5260 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93103\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5273 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93103\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.6721 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93103\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0367 - accuracy: 0.9878 - val_loss: 1.3904 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93103\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 1.2642 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93103\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.6070 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93103\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5058 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93103\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 0.6158 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93103\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.4587 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93103\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.4758 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93103\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 0.7134 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93103\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.6888 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93103\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93103\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4970 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93103\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93103\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.4948 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93103\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93103\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 1.4356 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93103\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1358 - accuracy: 0.9647 - val_loss: 1.5512 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93103\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0759 - accuracy: 0.9787 - val_loss: 0.7207 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93103\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0457 - accuracy: 0.9823 - val_loss: 0.5045 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93103\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.5112 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93103\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.5742 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93103\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.4422 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93103\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93103\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4660 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93103\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93103\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 9.1443e-04 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93103\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 6.2414e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93103\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 8.6608e-04 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93103\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 4.2620e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00263: val_accuracy improved from 0.93103 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 4.1463e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93596\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 6.2609e-04 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93596\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.1602e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93596\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93596\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.6393 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93596\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.7407 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93596\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.7691 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93596\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 1.3505 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93596\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.8713 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93596\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0348 - accuracy: 0.9903 - val_loss: 0.5257 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93596\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5255 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93596\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.4946 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93596\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0694 - accuracy: 0.9805 - val_loss: 0.6478 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93596\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 1.1345 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93596\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.5113 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93596\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.4762 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93596\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.5175 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93596\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4455 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93596\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93596\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93596\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4908 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93596\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4831 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93596\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 8.0272e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93596\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 6.2420e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93596\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.1717 - accuracy: 0.9495 - val_loss: 1.7096 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93596\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.7774 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93596\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.6261 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93596\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4994 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93596\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3865 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93596\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93596\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3410 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93596\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.3755 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93596\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93596\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.2790e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93596\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4569 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93596\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93596\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93596\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4349 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93596\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.3577e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93596\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 6.0059e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93596\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 6.0823e-04 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93596\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 5.4931e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93596\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 5.8157e-04 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93596\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 8.4058e-04 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93596\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 5.2244e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00308: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.0777e-04 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93842\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 4.5509e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93842\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 3.1505e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93842\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 1.9998e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93842\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4107 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93842\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 6.9772e-04 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93842\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.5517e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93842\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 4.5776e-04 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93842\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 3.7431e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93842\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93842\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4897 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93842\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0292 - accuracy: 0.9878 - val_loss: 1.3704 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93842\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 1.1273 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93842\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0615 - accuracy: 0.9823 - val_loss: 0.8928 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93842\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.8421 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93842\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.4891 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93842\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.5954 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93842\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0112 - accuracy: 0.9951 - val_loss: 0.6332 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93842\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4820 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93842\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.4785 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93842\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.4332 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93842\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.7477 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93842\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.4750 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93842\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4347 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93842\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4341 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93842\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4320 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93842\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5038 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93842\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.5402 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93842\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4691 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93842\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.7756 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93842\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.7095 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93842\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.6447 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93842\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.5236 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93842\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5543 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93842\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.4323 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93842\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 21s 392ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.6130 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93842\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0087 - accuracy: 0.9957 - val_loss: 0.5038 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93842\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.5732 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93842\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.7865 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93842\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.6448 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93842\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93842\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.4573 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93842\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4363 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93842\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.6754e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93842\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 6.3740e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93842\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 6.0969e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93842\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 7.7306e-04 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93842\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 3.0145e-04 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93842\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 7.0388e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93842\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 5.1264e-04 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93842\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 5.8306e-04 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93842\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4686 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93842\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 4.3215e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93842\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 1.1403 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93842\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.7997 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93842\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.8281 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93842\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 3.3422 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93842\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 0.9489 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93842\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0684 - accuracy: 0.9805 - val_loss: 0.7954 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93842\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.8056 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93842\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.5481 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93842\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.3853 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93842\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.3851 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93842\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93842\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3933 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93842\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93842\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93842\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 5.5578e-04 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93842\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3308 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93842\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 6.2734e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93842\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 7.6063e-04 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93842\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.4412 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93842\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93842\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 4.4023e-04 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93842\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 8.2085e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93842\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.7259e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93842\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 3.6904e-04 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00385: val_accuracy improved from 0.93842 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 3.6615e-04 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.94335\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 2.1909e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.94335\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 1.5447e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.94335\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 8.9828e-04 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.94335\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 2.8766e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.94335\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 5.9373e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.94335\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 1.3288e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.94335\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 2.5914e-04 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.94335\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 2.1778e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.94335\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 5.8006e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.94335\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 1.7274e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.94335\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 1.3292e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.94335\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 2.3825e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.94335\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 1.0799e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00399: val_accuracy improved from 0.94335 to 0.94828, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 2.7624e-04 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.94828\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 6.8312e-05 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.94828\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 1.4205e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.94828\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 1.2371e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94828\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 1.0084e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94828\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 7.1112e-05 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94828\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 1.1589e-04 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94828\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 4.6823e-05 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94828\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 1.0134e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94828\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 1.5863e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94828\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 9.9355e-05 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94828\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 7.9827e-05 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94828\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 7.8393e-05 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94828\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 3.2775e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94828\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 2.9928e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94828\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 1.0639e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94828\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 8.0534e-05 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94828\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 1.0945e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94828\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 1.1125e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94828\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0300 - accuracy: 0.9945 - val_loss: 0.9000 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94828\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1319 - accuracy: 0.9653 - val_loss: 2.2527 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94828\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1381 - accuracy: 0.9616 - val_loss: 1.2348 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94828\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 0.9115 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94828\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.7685 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94828\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5676 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94828\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4022 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94828\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0527 - accuracy: 0.9872 - val_loss: 0.8349 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94828\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.4860 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94828\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.4087 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94828\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5046 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94828\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 394ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4923 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94828\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.5045 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94828\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.6250 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94828\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6119 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94828\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.5617 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94828\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.6076 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94828\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.5004 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94828\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 1.0577 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94828\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.4312 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94828\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4147 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94828\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94828\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.4600e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94828\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 6.9226e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94828\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 8.0567e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94828\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4825 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94828\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.1733e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94828\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.5099e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94828\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 3.1087e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94828\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 396ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3878 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94828\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4576 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94828\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94828\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 7.7645e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94828\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.5613e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94828\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 9.0788e-04 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94828\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4583 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94828\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.5976 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94828\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.6714 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94828\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0874 - accuracy: 0.9762 - val_loss: 1.1455 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94828\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.6345 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94828\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 1.0019 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94828\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.4618 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94828\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.4082 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94828\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.5626 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94828\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.3961 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94828\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4190 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94828\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94828\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.3791e-04 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94828\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 8.1577e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94828\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 4.3669e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94828\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 5.2505e-04 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94828\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.8417 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94828\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0399 - accuracy: 0.9909 - val_loss: 0.5390 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94828\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5456 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94828\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4567 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94828\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4212 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94828\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5399 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94828\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4641 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94828\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.5153 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94828\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 1.1341 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94828\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0590 - accuracy: 0.9823 - val_loss: 0.5593 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94828\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.4570 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94828\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 1.0862 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94828\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.6831 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94828\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5312 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94828\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.4328 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94828\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.5838 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94828\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94828\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 397ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 1.2246 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94828\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.5539 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94828\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.6230 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94828\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4794 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94828\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94828\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.6367 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94828\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.5606 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94828\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4491 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94828\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5956 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94828\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.6173 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94828\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 6.8574e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94828\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 5.3607e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94828\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5846 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94828\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa4c267710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "92e8cc1a-840b-432e-83f8-5213c29cb5ac"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/BS_32_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab42b14-a420-4fa5-ae56-d3eac6907359"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8be1a6-973f-469a-c3c5-36ab87ec0c13"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c497360b-9c82-4d6c-9f5f-8ebd06731150"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1775979e-4946-4ebe-c70a-0b0884f2f81d"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/BatchSize_32_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_82f6291b-9749-4352-91e5-4ed87c412bc4\", \"BatchSize_32_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}