{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HeightShiftRange_030_2_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMP1qIK2sGR7Y9IF0BelzNk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/HeightShiftRange_030_2_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3d6bf5-4db5-47d0-c3a6-bf728337536c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  3 09:51:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b023122-2bb8-4461-e234-eef7282214c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450455fa-4110-4307-8733-b9d14c6502dc"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c906e3-de80-47b5-f6ae-0174ac1f0406"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.3)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eae8fde-6b2f-40ca-95f9-015d3274f743"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 472ms/step - loss: 2.0144 - accuracy: 0.2747 - val_loss: 4.2951 - val_accuracy: 0.0813\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.08128, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 1.4252 - accuracy: 0.5006 - val_loss: 8.2407 - val_accuracy: 0.1404\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.08128 to 0.14039, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 1.1256 - accuracy: 0.6255 - val_loss: 4.0928 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.14039\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 20s 374ms/step - loss: 1.0576 - accuracy: 0.6279 - val_loss: 8.6626 - val_accuracy: 0.1059\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.14039\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 20s 374ms/step - loss: 0.8810 - accuracy: 0.7010 - val_loss: 8.8342 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.14039\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.8707 - accuracy: 0.7192 - val_loss: 7.4113 - val_accuracy: 0.2044\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.14039 to 0.20443, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.7638 - accuracy: 0.7351 - val_loss: 6.4989 - val_accuracy: 0.2537\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.20443 to 0.25369, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.6730 - accuracy: 0.7631 - val_loss: 4.2343 - val_accuracy: 0.3054\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.25369 to 0.30542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.6415 - accuracy: 0.7838 - val_loss: 2.9790 - val_accuracy: 0.3128\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.30542 to 0.31281, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.5661 - accuracy: 0.7996 - val_loss: 0.9975 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.31281 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.5633 - accuracy: 0.8100 - val_loss: 0.8688 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.71182 to 0.73645, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.5610 - accuracy: 0.8057 - val_loss: 2.0449 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.73645\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.5128 - accuracy: 0.8197 - val_loss: 1.3600 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.73645\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.4579 - accuracy: 0.8404 - val_loss: 0.8677 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.73645 to 0.75862, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.4888 - accuracy: 0.8270 - val_loss: 1.6143 - val_accuracy: 0.5813\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.75862\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.4793 - accuracy: 0.8386 - val_loss: 0.7980 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.75862 to 0.77833, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.4068 - accuracy: 0.8557 - val_loss: 0.7692 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.77833\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.4236 - accuracy: 0.8563 - val_loss: 0.8141 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.77833\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.4230 - accuracy: 0.8630 - val_loss: 1.1288 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77833\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.3442 - accuracy: 0.8764 - val_loss: 1.1982 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77833\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.3132 - accuracy: 0.8952 - val_loss: 0.6759 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.77833 to 0.79064, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.3275 - accuracy: 0.8837 - val_loss: 0.9329 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.79064\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.3357 - accuracy: 0.8825 - val_loss: 0.8489 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.79064\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.2717 - accuracy: 0.9093 - val_loss: 0.6449 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.79064 to 0.82266, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.2544 - accuracy: 0.9086 - val_loss: 0.8840 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.82266\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.2811 - accuracy: 0.9068 - val_loss: 0.7884 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.82266\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.3046 - accuracy: 0.8983 - val_loss: 0.9806 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.82266\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.2370 - accuracy: 0.9214 - val_loss: 0.6246 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.82266\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.2735 - accuracy: 0.8995 - val_loss: 0.8607 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.82266\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.2703 - accuracy: 0.9074 - val_loss: 0.5088 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.82266 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.2166 - accuracy: 0.9300 - val_loss: 0.5967 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84236\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.2364 - accuracy: 0.9196 - val_loss: 0.6710 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84236\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.2474 - accuracy: 0.9190 - val_loss: 0.8617 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84236\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.2103 - accuracy: 0.9361 - val_loss: 0.8278 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84236\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1850 - accuracy: 0.9312 - val_loss: 0.8679 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84236\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1913 - accuracy: 0.9367 - val_loss: 0.7823 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.84236\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.2092 - accuracy: 0.9257 - val_loss: 0.6726 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.84236\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.2045 - accuracy: 0.9251 - val_loss: 0.7763 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.84236\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.2119 - accuracy: 0.9269 - val_loss: 0.5997 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.84236\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.2511 - accuracy: 0.9147 - val_loss: 1.0216 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.84236\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1732 - accuracy: 0.9434 - val_loss: 0.7226 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.84236\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1973 - accuracy: 0.9294 - val_loss: 0.7320 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.84236\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.2485 - accuracy: 0.9141 - val_loss: 0.9255 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.84236\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1590 - accuracy: 0.9488 - val_loss: 0.4783 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.84236 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1340 - accuracy: 0.9537 - val_loss: 0.4575 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.84975 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1578 - accuracy: 0.9428 - val_loss: 0.6645 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.87192\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1453 - accuracy: 0.9513 - val_loss: 0.5095 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.87192\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.1340 - accuracy: 0.9501 - val_loss: 0.6365 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.87192\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.1852 - accuracy: 0.9373 - val_loss: 0.9065 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.87192\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1432 - accuracy: 0.9543 - val_loss: 0.5523 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.87192\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1241 - accuracy: 0.9525 - val_loss: 0.5374 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.87192\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1567 - accuracy: 0.9458 - val_loss: 0.5121 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.87192\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1589 - accuracy: 0.9452 - val_loss: 0.8675 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.87192\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1608 - accuracy: 0.9434 - val_loss: 0.4872 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.87192\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1460 - accuracy: 0.9513 - val_loss: 0.6390 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.87192\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1548 - accuracy: 0.9519 - val_loss: 0.6512 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.87192\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1374 - accuracy: 0.9507 - val_loss: 0.4227 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.87192 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1246 - accuracy: 0.9525 - val_loss: 0.7952 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.88424\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1219 - accuracy: 0.9598 - val_loss: 0.5694 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.88424\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1090 - accuracy: 0.9671 - val_loss: 0.5440 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.88424\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0955 - accuracy: 0.9659 - val_loss: 0.7304 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.88424\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1047 - accuracy: 0.9653 - val_loss: 0.5386 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.88424\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0765 - accuracy: 0.9732 - val_loss: 0.4191 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.88424 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1033 - accuracy: 0.9629 - val_loss: 0.6182 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90640\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1131 - accuracy: 0.9580 - val_loss: 0.9373 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90640\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1414 - accuracy: 0.9507 - val_loss: 0.6530 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90640\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0980 - accuracy: 0.9683 - val_loss: 0.4931 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90640\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0879 - accuracy: 0.9720 - val_loss: 0.5663 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90640\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1197 - accuracy: 0.9641 - val_loss: 0.8780 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90640\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1699 - accuracy: 0.9409 - val_loss: 0.6357 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90640\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1407 - accuracy: 0.9537 - val_loss: 0.5736 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90640\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1064 - accuracy: 0.9677 - val_loss: 0.7671 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90640\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1259 - accuracy: 0.9531 - val_loss: 0.8119 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90640\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1116 - accuracy: 0.9616 - val_loss: 0.7080 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90640\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1079 - accuracy: 0.9610 - val_loss: 0.5883 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90640\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0976 - accuracy: 0.9683 - val_loss: 0.6997 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90640\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0740 - accuracy: 0.9720 - val_loss: 0.4521 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90640\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0712 - accuracy: 0.9793 - val_loss: 0.6729 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90640\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1054 - accuracy: 0.9647 - val_loss: 0.9232 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90640\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1201 - accuracy: 0.9574 - val_loss: 0.7557 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90640\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1485 - accuracy: 0.9519 - val_loss: 0.5651 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90640\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0945 - accuracy: 0.9653 - val_loss: 0.5704 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90640\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0708 - accuracy: 0.9762 - val_loss: 0.4361 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90640\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0773 - accuracy: 0.9744 - val_loss: 0.7839 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90640\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.1741 - accuracy: 0.9464 - val_loss: 1.2654 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90640\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1048 - accuracy: 0.9677 - val_loss: 0.7138 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90640\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0820 - accuracy: 0.9702 - val_loss: 0.4727 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90640\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0703 - accuracy: 0.9775 - val_loss: 0.4037 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90640\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.5394 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90640\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.4835 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90640\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0508 - accuracy: 0.9854 - val_loss: 0.3699 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90640\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0841 - accuracy: 0.9714 - val_loss: 0.6444 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90640\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0803 - accuracy: 0.9695 - val_loss: 0.5732 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90640\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1240 - accuracy: 0.9580 - val_loss: 1.0162 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90640\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.6223 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90640\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0802 - accuracy: 0.9769 - val_loss: 0.7204 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90640\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 0.6354 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90640\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.8066 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90640\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.6234 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90640\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0870 - accuracy: 0.9720 - val_loss: 1.0532 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90640\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0818 - accuracy: 0.9732 - val_loss: 0.5672 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90640\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.5515 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90640\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0585 - accuracy: 0.9769 - val_loss: 0.6201 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90640\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0430 - accuracy: 0.9872 - val_loss: 0.4456 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90640\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.5502 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90640\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0678 - accuracy: 0.9750 - val_loss: 0.5775 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90640\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1042 - accuracy: 0.9616 - val_loss: 1.4634 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.90640\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1190 - accuracy: 0.9635 - val_loss: 0.7992 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.90640\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1143 - accuracy: 0.9629 - val_loss: 0.6585 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.90640\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0889 - accuracy: 0.9665 - val_loss: 0.5176 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.90640\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 0.7132 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.90640\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.4408 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.90640\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0599 - accuracy: 0.9799 - val_loss: 0.5893 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.90640\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 0.8247 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.90640\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0595 - accuracy: 0.9848 - val_loss: 0.4072 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.90640\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.5007 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.90640\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0590 - accuracy: 0.9823 - val_loss: 0.6820 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.90640\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.5961 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.90640\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 1.0788 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.90640\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0940 - accuracy: 0.9689 - val_loss: 0.6375 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90640\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1018 - accuracy: 0.9616 - val_loss: 1.5778 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90640\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1310 - accuracy: 0.9598 - val_loss: 0.7105 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90640\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 0.7967 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90640\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0699 - accuracy: 0.9793 - val_loss: 0.5178 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.90640\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0265 - accuracy: 0.9939 - val_loss: 0.3550 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90640\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.4208 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90640\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.4629 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90640\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.5268 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90640\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0425 - accuracy: 0.9842 - val_loss: 0.5163 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90640\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.6504 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90640\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0376 - accuracy: 0.9903 - val_loss: 0.5025 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90640\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.5668 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90640\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.5695 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90640\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.7803 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90640\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 0.8923 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90640\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0857 - accuracy: 0.9689 - val_loss: 1.1288 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90640\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0590 - accuracy: 0.9805 - val_loss: 1.1950 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90640\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0781 - accuracy: 0.9744 - val_loss: 0.8223 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90640\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.5492 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90640\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0559 - accuracy: 0.9805 - val_loss: 0.6327 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90640\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.8076 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.90640\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0388 - accuracy: 0.9896 - val_loss: 0.8266 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90640\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.5985 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.90640\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.5659 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90640\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.5833 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90640\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.9058 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90640\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0987 - accuracy: 0.9720 - val_loss: 0.8963 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90640\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0541 - accuracy: 0.9799 - val_loss: 0.8487 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.90640\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.5692 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.90640\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1524 - accuracy: 0.9537 - val_loss: 0.7581 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.90640\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.4294 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.90640\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.4635 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.90640\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0533 - accuracy: 0.9799 - val_loss: 0.6331 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.90640\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.8567 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.90640\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.4381 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.90640\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0332 - accuracy: 0.9866 - val_loss: 0.5829 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.90640\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.5329 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.90640\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.6274 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.90640\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.5682 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.90640\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0425 - accuracy: 0.9836 - val_loss: 0.7582 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.90640\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.7107 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.90640\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0432 - accuracy: 0.9884 - val_loss: 0.7367 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.90640\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.6710 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.90640\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.7768 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.90640\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0249 - accuracy: 0.9909 - val_loss: 0.6313 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.90640\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0309 - accuracy: 0.9848 - val_loss: 0.7779 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.90640\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 0.8042 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.90640\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0605 - accuracy: 0.9805 - val_loss: 0.8066 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.90640\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0533 - accuracy: 0.9854 - val_loss: 0.5987 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.90640\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 1.4902 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.90640\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 0.6140 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.90640\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.6272 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.90640\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0530 - accuracy: 0.9848 - val_loss: 0.6011 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.90640\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.5800 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.90640\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0715 - accuracy: 0.9793 - val_loss: 0.5944 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.90640\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.6375 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.90640\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0911 - accuracy: 0.9738 - val_loss: 1.5099 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.90640\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1130 - accuracy: 0.9647 - val_loss: 1.3404 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.90640\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1028 - accuracy: 0.9671 - val_loss: 2.1221 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.90640\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.5895 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.90640\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.6392 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.90640\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.5232 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.90640\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.5257 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.90640\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.5849 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.90640\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0378 - accuracy: 0.9829 - val_loss: 0.4892 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.90640\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 1.1417 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.90640\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.5287 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.90640\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0433 - accuracy: 0.9836 - val_loss: 0.7677 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.90640\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.6053 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.90640\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.4980 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.90640\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.4449 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.90640\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.4879 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.90640\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.4928 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.90640\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.5865 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.90640\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0375 - accuracy: 0.9903 - val_loss: 0.6296 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.90640\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.5875 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.90640\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.5706 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.90640\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.4087 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.90640\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.5070 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.90640\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.5979 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.90640\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.8359 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.90640\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0201 - accuracy: 0.9909 - val_loss: 0.5474 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.90640\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0405 - accuracy: 0.9836 - val_loss: 0.8468 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.90640\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 2.9560 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.90640\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1033 - accuracy: 0.9702 - val_loss: 1.0993 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.90640\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0610 - accuracy: 0.9732 - val_loss: 0.8452 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.90640\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.6956 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.90640\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.6120 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.90640\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.5127 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.90640\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0476 - accuracy: 0.9878 - val_loss: 0.7431 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.90640\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.5156 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.90640\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.5231 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.90640\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0208 - accuracy: 0.9903 - val_loss: 0.5908 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.90640\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.5001 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.90640\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 20s 397ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.5297 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.90640\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.4647 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.90640\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.6079 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.90640\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.5211 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.90640\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.5320 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.90640\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.5353 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.90640\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.6383 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.90640\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0352 - accuracy: 0.9860 - val_loss: 0.7674 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.90640\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0275 - accuracy: 0.9896 - val_loss: 0.8122 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.90640\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.6715 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.90640\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0361 - accuracy: 0.9903 - val_loss: 0.7290 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.90640\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.5832 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.90640\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.7691 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.90640\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.6476 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.90640\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 0.7870 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.90640\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.6904 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.90640\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.8409 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.90640\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.8291 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.90640\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0523 - accuracy: 0.9805 - val_loss: 0.6807 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.90640\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.5709 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.90640\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.8124 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.90640\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.5613 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.90640\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.4414 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00237: val_accuracy improved from 0.90640 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.5528 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.91133\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.5373 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.91133\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 0.6219 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.91133\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.7757 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.91133\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.6735 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.91133\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.8310 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.91133\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.7018 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.91133\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.7676 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.91133\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.9427 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.91133\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0331 - accuracy: 0.9915 - val_loss: 0.7800 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.91133\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.6048 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.91133\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.8539 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.91133\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0698 - accuracy: 0.9805 - val_loss: 1.3638 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.91133\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 1.2051 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.91133\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.6863 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.91133\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.7012 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.91133\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0341 - accuracy: 0.9860 - val_loss: 0.7249 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.91133\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 0.6859 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.91133\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.5743 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.91133\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.6095 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.91133\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.5930 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.91133\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.7102 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.91133\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0330 - accuracy: 0.9842 - val_loss: 0.9226 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.91133\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.5746 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.91133\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.9349 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.91133\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.8014 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.91133\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.6148 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.91133\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.5471 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.91133\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.5406 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.91133\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.5517 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.91133\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.5364 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.91133\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.8992 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.91133\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.7944 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.91133\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0159 - accuracy: 0.9976 - val_loss: 0.7001 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.91133\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.6989 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.91133\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5539 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.91133\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.6521 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.91133\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.7465 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.91133\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7315 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.91133\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.7163 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.91133\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.9972 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.91133\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.5593 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.91133\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.5288 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.91133\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.4102 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.91133\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.5862 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.91133\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.6705 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.91133\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0183 - accuracy: 0.9921 - val_loss: 0.6341 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.91133\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0403 - accuracy: 0.9903 - val_loss: 0.6486 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.91133\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6590 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.91133\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.6013 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.91133\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5805 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.91133\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.9632 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.91133\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0568 - accuracy: 0.9866 - val_loss: 0.6967 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.91133\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 1.1625 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.91133\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.6356 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.91133\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.6109 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.91133\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6124 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.91133\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0147 - accuracy: 0.9915 - val_loss: 0.5620 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.91133\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.7300 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.91133\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.6626 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.91133\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.5975 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.91133\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.7781 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.91133\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0756 - accuracy: 0.9817 - val_loss: 2.2101 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.91133\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.8337 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.91133\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.6328 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.91133\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.7421 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.91133\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0506 - accuracy: 0.9817 - val_loss: 0.5812 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.91133\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.5350 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.91133\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.7548 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.91133\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 0.4539 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.91133\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5457 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.91133\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.5506 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.91133\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0234 - accuracy: 0.9909 - val_loss: 0.5430 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.91133\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.5695 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.91133\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0201 - accuracy: 0.9909 - val_loss: 0.7644 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.91133\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.8683 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.91133\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.7917 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.91133\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.7037 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.91133\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.6468 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.91133\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.7759 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.91133\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.6457 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.91133\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.5343 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.91133\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0102 - accuracy: 0.9951 - val_loss: 0.5751 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.91133\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0117 - accuracy: 0.9933 - val_loss: 0.7970 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.91133\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.6930 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.91133\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4581 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.91133\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.9382 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.91133\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.6062 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.91133\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.8327 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.91133\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 1.2099 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.91133\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.8843 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.91133\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.7264 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.91133\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0232 - accuracy: 0.9896 - val_loss: 0.7077 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.91133\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.5204 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.91133\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.7486 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.91133\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5580 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.91133\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.8543 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.91133\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0379 - accuracy: 0.9896 - val_loss: 0.7263 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.91133\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0398 - accuracy: 0.9927 - val_loss: 0.6323 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.91133\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.7030 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.91133\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.6645 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.91133\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.7104 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.91133\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.4912 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.91133\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.6871 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.91133\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5858 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.91133\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.6780 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.91133\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6321 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.91133\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.5750 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.91133\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.4216 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.91133\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5620 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.91133\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.4548 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.91133\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 1.1112 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.91133\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 1.2706 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.91133\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.6809 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.91133\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0178 - accuracy: 0.9921 - val_loss: 0.5348 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.91133\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.8226 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.91133\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.9610 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.91133\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.7937 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.91133\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.5171 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.91133\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.7176 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.91133\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.4861 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.91133\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.7034 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.91133\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.7235 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.91133\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.7117 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.91133\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0559 - accuracy: 0.9860 - val_loss: 0.7234 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.91133\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0365 - accuracy: 0.9848 - val_loss: 0.7113 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.91133\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.6541 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.91133\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.5961 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.91133\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5501 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.91133\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4469 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.91133\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.4713 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.91133\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.6551 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.91133\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.6282 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.91133\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.6162 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.91133\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.7433 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.91133\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.8175 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.91133\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.6152 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.91133\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0219 - accuracy: 0.9909 - val_loss: 0.7967 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.91133\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6483 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.91133\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.6465 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.91133\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.6891 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.91133\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.8136 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.91133\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.5881 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.91133\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.7217 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.91133\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.6942 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.91133\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.6736 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.91133\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 0.7308 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.91133\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.8131 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.91133\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 0.9534 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.91133\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.6972 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.91133\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0168 - accuracy: 0.9927 - val_loss: 0.8641 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.91133\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.7145 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.91133\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.6603 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.91133\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.8128 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.91133\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6122 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.91133\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0183 - accuracy: 0.9921 - val_loss: 0.9299 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.91133\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.8815 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.91133\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.7277 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.91133\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.9196 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.91133\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0285 - accuracy: 0.9927 - val_loss: 1.0966 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.91133\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.9179 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.91133\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.6583 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.91133\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5607 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.91133\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.6667 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.91133\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.8709 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.91133\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.6766 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.91133\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.9797 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.91133\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.7046 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.91133\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6413 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.91133\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5186 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.91133\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5074 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.91133\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 0.4377 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.91133\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00410: val_accuracy improved from 0.91133 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4552 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.91379\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6487 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.91379\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6183 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.91379\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 0.6014 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.91379\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.7031 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.91379\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.5685 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.91379\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0085 - accuracy: 0.9957 - val_loss: 0.7248 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.91379\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0170 - accuracy: 0.9927 - val_loss: 0.8485 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.91379\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.6679 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.91379\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.8006 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.91379\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 0.7560 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.91379\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.5733 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.91379\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6536 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.91379\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.6237 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.91379\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6583 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.91379\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.6828 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.91379\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.6217 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.91379\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.7015 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.91379\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6737 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.91379\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.6212 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.91379\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0069 - accuracy: 0.9957 - val_loss: 0.7598 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.91379\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.7071 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.91379\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0112 - accuracy: 0.9939 - val_loss: 0.7588 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.91379\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.7927 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.91379\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.9810 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.91379\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.7936 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.91379\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.8061 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.91379\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.9077 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.91379\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.7478 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.91379\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 1.0018 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.91379\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.8272 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.91379\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 1.4651 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.91379\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 1.6227 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.91379\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.6749 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.91379\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.6038 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.91379\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5553 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.91379\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.91379\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.7288 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.91379\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0100 - accuracy: 0.9951 - val_loss: 0.5489 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.91379\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.5221 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.91379\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5517 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.91379\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.6174 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.91379\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.5231 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.91379\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.5250 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.91379\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.6338 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.91379\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.7044 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.91379\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.6924 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.91379\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.6192 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.91379\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.6603 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.91379\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.6084 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.91379\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6465 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.91379\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.7351 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.91379\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5894 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.91379\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.91379\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5877 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.91379\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6941 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.91379\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5951 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.91379\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0498 - accuracy: 0.9890 - val_loss: 1.6741 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.91379\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0756 - accuracy: 0.9781 - val_loss: 1.1726 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.91379\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 0.8511 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.91379\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0336 - accuracy: 0.9909 - val_loss: 0.7288 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.91379\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5724 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.91379\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.6986 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.91379\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6216 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.91379\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.6758 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.91379\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.7749 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.91379\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.8194 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.91379\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.7206 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.91379\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.7212 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.91379\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.7364 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.91379\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.7567 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.91379\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.7323 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.91379\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.6723 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.91379\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.6142 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.91379\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5292 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.91379\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.9943 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.91379\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.5993 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.91379\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.8722 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.91379\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.7457 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.91379\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0080 - accuracy: 0.9963 - val_loss: 0.5994 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.91379\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6606 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.91379\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5986 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.91379\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.6598 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.91379\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.8118 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.91379\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.7401 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.91379\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.7157 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.91379\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.6682 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.91379\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.91379\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6228 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.91379\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.5946 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.91379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35327f0a90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7c79b55d-fc23-49f8-bace-40f87d8c7788"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/HSR_030_2_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09bf712-ca74-4f8d-9ad3-b9ff56fdedc2"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75bf6792-2b63-4303-f1cf-2c6145a12ee7"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ad67170f-36e5-4b98-e6c7-656fcdbbec6a"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d603bc72-5307-4c0b-90c1-bdd6265ee011"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_030_2_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/HeightShiftRange_030_2_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_65bc9248-bce9-4c0b-95d6-acbe4847f57b\", \"HeightShiftRange_030_2_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}