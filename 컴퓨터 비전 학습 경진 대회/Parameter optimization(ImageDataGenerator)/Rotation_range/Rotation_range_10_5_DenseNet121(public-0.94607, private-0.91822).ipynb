{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_range_10_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOSG3TrgDphZ8zki22B26l7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Rotation_range_10_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc08d1e5-1288-4d03-a6b5-2fbb00b52c65"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 24 20:23:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a5154a-ab46-4876-df53-656dadb4bf00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8269534-e80b-485c-f411-06de4f041257"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980e798d-3328-4a91-d724-ed12d4f72793"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7a7d36-8fb6-4d8c-b4ba-a75b5d3d14dd"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 38s 261ms/step - loss: 1.8291 - accuracy: 0.3618 - val_loss: 3.4047 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.1265 - accuracy: 0.6066 - val_loss: 5.4902 - val_accuracy: 0.0862\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09852\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.9840 - accuracy: 0.6724 - val_loss: 10.8402 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.09852\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.7955 - accuracy: 0.7418 - val_loss: 9.6959 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.09852 to 0.11084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.6994 - accuracy: 0.7704 - val_loss: 19.8313 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11084\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.5822 - accuracy: 0.8057 - val_loss: 6.4540 - val_accuracy: 0.2192\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11084 to 0.21921, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.5898 - accuracy: 0.8039 - val_loss: 4.8795 - val_accuracy: 0.2857\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.21921 to 0.28571, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.5038 - accuracy: 0.8350 - val_loss: 5.8683 - val_accuracy: 0.2759\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.28571\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.5071 - accuracy: 0.8307 - val_loss: 1.5591 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.28571 to 0.61084, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4200 - accuracy: 0.8587 - val_loss: 2.9965 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.61084\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.4072 - accuracy: 0.8575 - val_loss: 0.8944 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.61084 to 0.74138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3470 - accuracy: 0.8855 - val_loss: 0.9726 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.74138\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3440 - accuracy: 0.8886 - val_loss: 1.1664 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.74138\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3592 - accuracy: 0.8758 - val_loss: 1.5903 - val_accuracy: 0.6034\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.74138\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3080 - accuracy: 0.8952 - val_loss: 0.8813 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.74138 to 0.74384, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3371 - accuracy: 0.8837 - val_loss: 2.0883 - val_accuracy: 0.5862\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.74384\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2931 - accuracy: 0.8959 - val_loss: 0.7335 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.74384 to 0.80542, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2519 - accuracy: 0.9117 - val_loss: 0.7069 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80542\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2766 - accuracy: 0.9062 - val_loss: 0.5720 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.80542 to 0.83005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2707 - accuracy: 0.9013 - val_loss: 0.7064 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83005\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2599 - accuracy: 0.9111 - val_loss: 1.1448 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83005\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2241 - accuracy: 0.9196 - val_loss: 0.5449 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.83005 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2308 - accuracy: 0.9184 - val_loss: 0.7264 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83990\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2151 - accuracy: 0.9269 - val_loss: 0.5714 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83990\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1919 - accuracy: 0.9318 - val_loss: 0.9540 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83990\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1834 - accuracy: 0.9385 - val_loss: 0.7289 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83990\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1731 - accuracy: 0.9373 - val_loss: 0.5202 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.83990 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1820 - accuracy: 0.9287 - val_loss: 0.5067 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.85468 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1497 - accuracy: 0.9501 - val_loss: 0.4981 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86207\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1540 - accuracy: 0.9476 - val_loss: 0.4159 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.86207 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1543 - accuracy: 0.9470 - val_loss: 0.7719 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.88424\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1288 - accuracy: 0.9549 - val_loss: 0.6038 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.88424\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1450 - accuracy: 0.9519 - val_loss: 0.9744 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.88424\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1251 - accuracy: 0.9598 - val_loss: 0.4587 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.88424\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1353 - accuracy: 0.9555 - val_loss: 0.7336 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.88424\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1739 - accuracy: 0.9397 - val_loss: 0.7863 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.88424\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1214 - accuracy: 0.9574 - val_loss: 0.5779 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.88424\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1981 - accuracy: 0.9324 - val_loss: 2.2976 - val_accuracy: 0.5542\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.88424\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1660 - accuracy: 0.9415 - val_loss: 1.0114 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.88424\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1182 - accuracy: 0.9604 - val_loss: 0.4496 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88424\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1349 - accuracy: 0.9574 - val_loss: 0.5627 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88424\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.9148 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88424\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1295 - accuracy: 0.9555 - val_loss: 0.4614 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.88424\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0941 - accuracy: 0.9683 - val_loss: 0.4974 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.88424\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0877 - accuracy: 0.9714 - val_loss: 0.5580 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.88424\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1133 - accuracy: 0.9641 - val_loss: 0.6741 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88424\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0965 - accuracy: 0.9629 - val_loss: 0.5426 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88424\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0737 - accuracy: 0.9744 - val_loss: 0.4680 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.88424 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0704 - accuracy: 0.9762 - val_loss: 0.5889 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89409\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0691 - accuracy: 0.9756 - val_loss: 0.5089 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89409\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0646 - accuracy: 0.9738 - val_loss: 0.4057 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89409\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0559 - accuracy: 0.9823 - val_loss: 0.4347 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00052: val_accuracy improved from 0.89409 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0328 - accuracy: 0.9921 - val_loss: 0.5372 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89655\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.6832 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89655\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0919 - accuracy: 0.9665 - val_loss: 0.9047 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89655\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1069 - accuracy: 0.9641 - val_loss: 0.8534 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89655\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1052 - accuracy: 0.9641 - val_loss: 0.9486 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89655\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1398 - accuracy: 0.9519 - val_loss: 1.0649 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89655\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0767 - accuracy: 0.9695 - val_loss: 0.4405 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89655\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0619 - accuracy: 0.9762 - val_loss: 0.4170 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.89655 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.5069 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90640\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.8519 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90640\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.5540 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90640\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0671 - accuracy: 0.9805 - val_loss: 0.5692 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90640\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0932 - accuracy: 0.9647 - val_loss: 6.6556 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90640\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0769 - accuracy: 0.9726 - val_loss: 0.6775 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90640\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0893 - accuracy: 0.9671 - val_loss: 0.6161 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90640\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1080 - accuracy: 0.9610 - val_loss: 1.1131 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90640\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1924 - accuracy: 0.9428 - val_loss: 6.4304 - val_accuracy: 0.4113\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90640\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1759 - accuracy: 0.9507 - val_loss: 0.9235 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90640\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0939 - accuracy: 0.9708 - val_loss: 0.5408 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90640\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 0.4371 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00072: val_accuracy improved from 0.90640 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.4252 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90887\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0341 - accuracy: 0.9872 - val_loss: 0.3714 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00074: val_accuracy improved from 0.90887 to 0.91133, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.4112 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91133\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0583 - accuracy: 0.9823 - val_loss: 1.0505 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91133\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0397 - accuracy: 0.9878 - val_loss: 0.3770 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.91133 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0324 - accuracy: 0.9915 - val_loss: 0.4835 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91626\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.4487 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91626\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.5034 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91626\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.3787 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91626\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0516 - accuracy: 0.9823 - val_loss: 0.7446 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91626\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.6184 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91626\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0568 - accuracy: 0.9793 - val_loss: 0.4725 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91626\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1074 - accuracy: 0.9695 - val_loss: 1.1828 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91626\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 0.6703 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91626\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0506 - accuracy: 0.9775 - val_loss: 0.7953 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91626\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.5418 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91626\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0301 - accuracy: 0.9927 - val_loss: 0.5322 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91626\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.5019 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91626\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.6333 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91626\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0335 - accuracy: 0.9903 - val_loss: 0.5962 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91626\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0304 - accuracy: 0.9884 - val_loss: 0.8496 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91626\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 0.5972 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91626\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 0.7922 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91626\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0890 - accuracy: 0.9714 - val_loss: 0.6343 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91626\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1583 - accuracy: 0.9507 - val_loss: 2.2949 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91626\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0973 - accuracy: 0.9695 - val_loss: 0.6733 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91626\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.5401 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91626\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 0.5302 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91626\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 0.5389 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91626\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.3765 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91626\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.3919 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91626\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.6393 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91626\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.5011 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91626\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4215 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91626\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4140 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91626\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6903 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91626\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.4211 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91626\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.5123 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91626\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0641 - accuracy: 0.9781 - val_loss: 0.6687 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91626\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0625 - accuracy: 0.9769 - val_loss: 0.8595 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91626\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0439 - accuracy: 0.9836 - val_loss: 0.8419 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91626\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0392 - accuracy: 0.9836 - val_loss: 0.5771 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91626\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.6992 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91626\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0557 - accuracy: 0.9799 - val_loss: 1.1416 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91626\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0669 - accuracy: 0.9744 - val_loss: 0.7142 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91626\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 0.5862 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91626\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0682 - accuracy: 0.9769 - val_loss: 0.6663 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91626\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0654 - accuracy: 0.9775 - val_loss: 0.5292 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91626\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0433 - accuracy: 0.9842 - val_loss: 0.5223 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91626\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.4962 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91626\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.7683 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91626\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.4475 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91626\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.4866 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91626\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.6732 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91626\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0233 - accuracy: 0.9903 - val_loss: 0.6420 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91626\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0336 - accuracy: 0.9909 - val_loss: 0.5395 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91626\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 0.6130 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91626\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.6473 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91626\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.4760 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91626\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.9151 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91626\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1128 - accuracy: 0.9665 - val_loss: 0.6778 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91626\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0919 - accuracy: 0.9769 - val_loss: 1.4275 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91626\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1025 - accuracy: 0.9708 - val_loss: 0.5651 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91626\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.4606 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91626\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.6039 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91626\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.4558 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91626\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.4105 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91626\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3744 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00140: val_accuracy improved from 0.91626 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.3872 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.92118\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4783 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.92118\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3960 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.92118\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.92118\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4397 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.92118\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.4557 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.92118\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0328 - accuracy: 0.9927 - val_loss: 0.5404 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.92118\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.5535 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.92118\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 0.5973 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.92118\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 1.8944 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.92118\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0734 - accuracy: 0.9732 - val_loss: 0.7780 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.92118\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.7619 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.92118\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.5236 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92118\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.5272 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92118\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4529 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92118\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.5487 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92118\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.7496 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92118\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.6022 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92118\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.5872 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92118\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.5898 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92118\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0163 - accuracy: 0.9933 - val_loss: 0.4906 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92118\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.8034 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92118\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0134 - accuracy: 0.9939 - val_loss: 0.5367 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92118\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6604 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92118\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.6524 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92118\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 0.5012 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92118\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.5292 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92118\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.6157 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92118\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.5056 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92118\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 0.7811 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92118\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 1.0427 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92118\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.6042 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92118\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 0.4969 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92118\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.5481 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92118\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.7017 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92118\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.5406 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92118\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.3660 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92118\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.5042 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92118\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.5621 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92118\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.4521 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92118\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.4770 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92118\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6030 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92118\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0219 - accuracy: 0.9903 - val_loss: 0.6120 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92118\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.5577 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92118\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.5483 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92118\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.5418 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92118\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.5946 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92118\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92118\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.7683 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92118\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.5634 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92118\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.6020 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92118\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.6132 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92118\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.6292 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92118\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.6858 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92118\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0736 - accuracy: 0.9781 - val_loss: 4.3110 - val_accuracy: 0.5197\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92118\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 0.8524 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92118\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0427 - accuracy: 0.9896 - val_loss: 0.6667 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92118\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.7976 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92118\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.5914 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92118\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.5162 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92118\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.5358 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92118\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5602 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92118\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.6265 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92118\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.6452 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92118\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.4123 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00205: val_accuracy improved from 0.92118 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.7431 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92611\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0170 - accuracy: 0.9927 - val_loss: 0.5856 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92611\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.6778 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92611\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0531 - accuracy: 0.9878 - val_loss: 0.6243 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92611\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.5849 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92611\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.4442 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92611\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.4989 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92611\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92611\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92611\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4679 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92611\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4286 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00216: val_accuracy improved from 0.92611 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.4768 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00219: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3944 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93350\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.5703 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93350\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.6811 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93350\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.5714 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93350\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 1.1707 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93350\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1389 - accuracy: 0.9616 - val_loss: 4.6389 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93350\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0696 - accuracy: 0.9787 - val_loss: 1.2302 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93350\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.9547 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93350\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0512 - accuracy: 0.9787 - val_loss: 0.8135 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93350\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.5097 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93350\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93350\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93350\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93350\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4314 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93350\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4460 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93350\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.4974 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93350\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.6097 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93350\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0780 - accuracy: 0.9793 - val_loss: 1.8955 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93350\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.5996 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93350\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0561 - accuracy: 0.9860 - val_loss: 0.5511 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93350\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.4900 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93350\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.5198 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93350\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5773 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93350\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.4966 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93350\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93350\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.5069 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93350\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5393 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93350\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.4860 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93350\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4858 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93350\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.4478 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93350\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93350\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00251: val_accuracy improved from 0.93350 to 0.93596, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.7498e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93596\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.3708e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93596\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4984 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93596\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9976 - val_loss: 0.4792 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93596\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93596\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5452 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93596\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.6060 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93596\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4804 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93596\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4592 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93596\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5046 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93596\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.4361 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93596\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.5395 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93596\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5154 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93596\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.4460 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93596\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5557 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93596\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.6830e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93596\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 4.9815e-04 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93596\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.3612e-04 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93596\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.5456 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93596\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5655 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93596\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.8566 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93596\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0597 - accuracy: 0.9836 - val_loss: 0.8528 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93596\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1022 - accuracy: 0.9683 - val_loss: 1.3011 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93596\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0660 - accuracy: 0.9787 - val_loss: 1.0107 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93596\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.6473 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93596\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0148 - accuracy: 0.9933 - val_loss: 0.5873 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93596\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.4923 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93596\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4589 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93596\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3692 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93596\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4592 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93596\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93596\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4483 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93596\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3704 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93596\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93596\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.7346e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93596\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93596\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 5.6557e-04 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93596\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.2298e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93596\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 7.3967e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93596\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.1520e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93596\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93596\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5888 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93596\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.8277 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93596\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 1.2415 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93596\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0866 - accuracy: 0.9671 - val_loss: 1.8271 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93596\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 1.1949 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93596\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.8549 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93596\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.4528 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93596\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.3599 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93596\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6790 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93596\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.6577 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93596\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.5607 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93596\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0421 - accuracy: 0.9884 - val_loss: 0.4101 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93596\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.4139 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93596\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.3991 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93596\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.4092 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93596\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4005 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93596\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4125 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93596\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.7297 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93596\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.5000 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93596\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4876 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93596\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.6689 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93596\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.4604 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93596\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4361 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93596\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4570 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93596\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4542 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93596\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.4451 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93596\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0256 - accuracy: 0.9957 - val_loss: 0.4800 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93596\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5092 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93596\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.5433 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93596\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4437 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93596\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.4003e-04 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93596\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 7.0549e-04 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93596\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 4.6947e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93596\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 6.1695e-04 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93596\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4225 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93596\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4531 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93596\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4183 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93596\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4317 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93596\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.3780 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93596\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3745 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93596\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.6228 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93596\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4376 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93596\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.8429e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00335: val_accuracy improved from 0.93596 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.5691 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93842\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.2963e-04 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93842\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.3769e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93842\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4437 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93842\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 5.7338e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93842\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.6010e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93842\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93842\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5906 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93842\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4866 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93842\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.6636 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93842\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0678 - accuracy: 0.9817 - val_loss: 1.3714 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93842\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0863 - accuracy: 0.9750 - val_loss: 1.1167 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93842\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0321 - accuracy: 0.9884 - val_loss: 0.8569 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93842\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.7746 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93842\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.4500 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93842\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.4625 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93842\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.5564 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93842\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.6864 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93842\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.6679 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93842\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.6038 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93842\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 0.7261 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93842\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0187 - accuracy: 0.9915 - val_loss: 0.6507 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93842\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.6024 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93842\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93842\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4236 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93842\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93842\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 9.9599e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93842\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93842\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.5233e-04 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93842\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.2088e-04 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93842\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93842\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5157 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93842\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4287 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93842\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.8993e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93842\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.7931e-04 - accuracy: 0.9994 - val_loss: 0.4573 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93842\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93842\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 8.3187e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93842\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 4.4697e-04 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93842\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 3.9407e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93842\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.7902 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93842\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.8133 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93842\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.6437 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93842\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.7159 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93842\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6733 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93842\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.4339 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93842\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5913 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93842\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.6312 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93842\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5151 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93842\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.8752 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93842\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.9867 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93842\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 0.8874 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93842\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.6264 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93842\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0169 - accuracy: 0.9927 - val_loss: 0.5120 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93842\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.3570 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93842\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.5571 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93842\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5122 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93842\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.4863 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93842\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.3632 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93842\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.4557 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93842\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.5366 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93842\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.5790 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93842\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5257 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93842\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4590 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93842\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4053 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93842\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.5896 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93842\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4284 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93842\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4666 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93842\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.5515 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93842\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.6440 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93842\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.7364 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93842\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.7476 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93842\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.6227 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93842\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.6823 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93842\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.8087 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93842\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.6607 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93842\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.6728 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93842\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4463 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93842\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0445 - accuracy: 0.9878 - val_loss: 0.9704 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93842\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.9402 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93842\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.7482 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93842\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.6783 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93842\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.5602 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93842\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5231 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93842\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93842\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.5807 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93842\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 0.4796 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93842\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4562 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93842\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93842\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5028 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93842\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5026 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93842\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.6112e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93842\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.6422e-04 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93842\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 2.2842e-04 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93842\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 2.9015e-04 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93842\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5263 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93842\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5690 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93842\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.5252 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93842\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4985 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93842\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4276 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93842\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.6312 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93842\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0491 - accuracy: 0.9890 - val_loss: 0.7675 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93842\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.7776 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93842\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5410 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93842\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.5574 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93842\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4184 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93842\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 5.9198e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93842\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.4807e-04 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93842\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.7994e-04 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93842\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4705 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93842\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.2677e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93842\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.5517 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93842\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.6881e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93842\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.4853e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93842\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.1669e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93842\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 5.6897e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93842\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 3.3117e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93842\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.4126e-04 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93842\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.5609e-05 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93842\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.5095e-05 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93842\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0901e-04 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93842\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.2467e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93842\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.3582e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93842\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.3983e-05 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93842\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.9952e-05 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93842\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 1.0543e-04 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93842\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.6123e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93842\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.5187e-04 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9433\n",
            "\n",
            "Epoch 00462: val_accuracy improved from 0.93842 to 0.94335, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.4515e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94335\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 8.8707e-05 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94335\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.2600e-05 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94335\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.4225e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94335\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 12s 229ms/step - loss: 6.6913e-05 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94335\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.4331e-05 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94335\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 5.0727e-05 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94335\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.4586e-04 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94335\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.5842e-05 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94335\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.7418e-05 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94335\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 4.9292e-05 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94335\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 2.9504e-05 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94335\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.8503e-05 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94335\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.5959e-05 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94335\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0274 - accuracy: 0.9945 - val_loss: 1.4781 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94335\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.1292 - accuracy: 0.9641 - val_loss: 1.9062 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94335\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1181 - accuracy: 0.9665 - val_loss: 0.8558 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94335\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.5792 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94335\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.5914 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94335\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.5470 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94335\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4533 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94335\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.5154 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94335\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5335 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94335\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94335\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4883 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94335\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4787 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94335\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5107 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94335\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.7320 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94335\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6827 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94335\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4214 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94335\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3806 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94335\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.8759e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94335\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 7.6051e-04 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94335\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 8.9281e-04 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94335\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.4149e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94335\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.1887e-04 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94335\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.5845e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94335\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 4.5638e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73abe9a8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aea2a66b-d63e-4f35-a5e4-63439f2a23f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_10_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1849235-9235-4499-9bfe-76ea25b24025"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404ee9d6-68a8-4b5c-ce7d-158af900d873"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c1bea888-77a3-492a-d671-ec0a935963bf"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "db0a27db-8362-4cd0-8907-f3a71261d01e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_10_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c1076145-bc28-4e35-93ea-b5122a6abeee\", \"Rotation_range_10_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}