{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_range_15_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZGPyUZiDbqjx73dCohxHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Rotation_range_15_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71182d7d-a452-450b-f2d4-49875fca773c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 24 22:56:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a0c625-4ab4-4950-969f-668b38e4a33d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc81cc02-b8c4-4e63-eda7-8ad724bc2f2e"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36493ab1-c5ad-449b-8341-08a2c3e9057d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=15,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e9026a-0611-47c4-8a06-67fc50736955"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 44s 301ms/step - loss: 1.9066 - accuracy: 0.3082 - val_loss: 6.6330 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 1.3048 - accuracy: 0.5463 - val_loss: 4.1275 - val_accuracy: 0.0911\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.10099\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 1.0038 - accuracy: 0.6577 - val_loss: 5.7055 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.10099 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.8587 - accuracy: 0.7229 - val_loss: 12.5576 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.7571 - accuracy: 0.7442 - val_loss: 13.1721 - val_accuracy: 0.0764\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.6932 - accuracy: 0.7698 - val_loss: 4.2792 - val_accuracy: 0.1749\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.11330 to 0.17488, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.6484 - accuracy: 0.7893 - val_loss: 5.3487 - val_accuracy: 0.2315\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.17488 to 0.23153, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.5140 - accuracy: 0.8313 - val_loss: 6.5633 - val_accuracy: 0.2488\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.23153 to 0.24877, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.5407 - accuracy: 0.8289 - val_loss: 2.5282 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.24877 to 0.53448, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.5059 - accuracy: 0.8319 - val_loss: 1.6937 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.53448 to 0.57635, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.4596 - accuracy: 0.8490 - val_loss: 1.4859 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.57635 to 0.62069, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.4335 - accuracy: 0.8508 - val_loss: 2.0452 - val_accuracy: 0.5419\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.62069\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.4052 - accuracy: 0.8654 - val_loss: 0.8847 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.62069 to 0.70690, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.3919 - accuracy: 0.8703 - val_loss: 0.5628 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.70690 to 0.81527, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.3202 - accuracy: 0.8995 - val_loss: 0.7551 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.81527\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.3477 - accuracy: 0.8837 - val_loss: 0.8660 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.81527\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.3252 - accuracy: 0.8898 - val_loss: 0.9209 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.81527\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.3312 - accuracy: 0.8873 - val_loss: 0.6029 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.81527 to 0.81773, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.2999 - accuracy: 0.8959 - val_loss: 0.6676 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.81773\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.2891 - accuracy: 0.8946 - val_loss: 0.5793 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.81773 to 0.83005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.2922 - accuracy: 0.8983 - val_loss: 1.4434 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83005\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.2671 - accuracy: 0.9111 - val_loss: 0.5561 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.83005 to 0.83744, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.2367 - accuracy: 0.9239 - val_loss: 0.6616 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83744\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.2115 - accuracy: 0.9312 - val_loss: 0.6982 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83744\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.2007 - accuracy: 0.9318 - val_loss: 0.7133 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83744\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.2073 - accuracy: 0.9306 - val_loss: 0.4382 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.83744 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.1865 - accuracy: 0.9348 - val_loss: 0.8015 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84975\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.2536 - accuracy: 0.9117 - val_loss: 0.7090 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84975\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.2189 - accuracy: 0.9312 - val_loss: 1.3561 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84975\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.2128 - accuracy: 0.9269 - val_loss: 0.6328 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84975\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1693 - accuracy: 0.9458 - val_loss: 0.5381 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.84975 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.1325 - accuracy: 0.9543 - val_loss: 0.6296 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85468\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1950 - accuracy: 0.9239 - val_loss: 0.7435 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.85468\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.2837 - accuracy: 0.9074 - val_loss: 1.6597 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.85468\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1888 - accuracy: 0.9342 - val_loss: 0.7083 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.85468\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.1400 - accuracy: 0.9531 - val_loss: 0.7360 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.85468\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1566 - accuracy: 0.9482 - val_loss: 0.5334 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.85468 to 0.87438, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.1144 - accuracy: 0.9580 - val_loss: 0.3429 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.87438 to 0.90394, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.1175 - accuracy: 0.9598 - val_loss: 0.6786 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.90394\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1339 - accuracy: 0.9525 - val_loss: 0.5395 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.90394\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1907 - accuracy: 0.9361 - val_loss: 1.5762 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.90394\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1689 - accuracy: 0.9403 - val_loss: 1.5338 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.90394\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1720 - accuracy: 0.9403 - val_loss: 0.4512 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.90394\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1134 - accuracy: 0.9622 - val_loss: 0.5149 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90394\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.1176 - accuracy: 0.9653 - val_loss: 0.5753 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90394\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.1090 - accuracy: 0.9659 - val_loss: 0.6306 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90394\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.1320 - accuracy: 0.9543 - val_loss: 0.5342 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90394\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1030 - accuracy: 0.9702 - val_loss: 0.4497 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90394\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0729 - accuracy: 0.9793 - val_loss: 0.3495 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90394\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0806 - accuracy: 0.9738 - val_loss: 0.4497 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90394\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0973 - accuracy: 0.9702 - val_loss: 0.6728 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.90394\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.3989 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.90394\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.4994 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.90394\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.1549 - accuracy: 0.9501 - val_loss: 0.8873 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.90394\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.1330 - accuracy: 0.9562 - val_loss: 0.7468 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.90394\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0821 - accuracy: 0.9695 - val_loss: 1.1691 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.90394\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.1551 - accuracy: 0.9458 - val_loss: 0.6087 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.90394\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1001 - accuracy: 0.9616 - val_loss: 0.4169 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.90394\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1127 - accuracy: 0.9610 - val_loss: 0.5007 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90394\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.1734 - accuracy: 0.9446 - val_loss: 0.8773 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.90394\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0790 - accuracy: 0.9732 - val_loss: 0.5941 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.90394\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0762 - accuracy: 0.9726 - val_loss: 0.6546 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.90394\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0702 - accuracy: 0.9750 - val_loss: 0.5750 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.90394\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0684 - accuracy: 0.9762 - val_loss: 0.8238 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.90394\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0631 - accuracy: 0.9762 - val_loss: 0.6355 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.90394\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0864 - accuracy: 0.9695 - val_loss: 0.7230 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.90394\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0951 - accuracy: 0.9683 - val_loss: 0.8964 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.90394\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0695 - accuracy: 0.9750 - val_loss: 0.5069 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90394\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.5290 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90394\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.1016 - accuracy: 0.9653 - val_loss: 0.9686 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90394\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0692 - accuracy: 0.9769 - val_loss: 0.6289 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90394\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0593 - accuracy: 0.9769 - val_loss: 0.4824 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90394\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0686 - accuracy: 0.9829 - val_loss: 0.5731 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90394\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0927 - accuracy: 0.9695 - val_loss: 0.4577 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90394\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0434 - accuracy: 0.9848 - val_loss: 0.6143 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90394\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 0.5800 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90394\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.5528 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90394\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0592 - accuracy: 0.9799 - val_loss: 0.5713 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90394\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0508 - accuracy: 0.9829 - val_loss: 0.4371 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90394\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0377 - accuracy: 0.9854 - val_loss: 0.4311 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90394\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 0.4900 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90394\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.6631 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90394\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.4359 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90394\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 0.6877 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90394\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0736 - accuracy: 0.9726 - val_loss: 0.7586 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90394\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 1.0749 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90394\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0695 - accuracy: 0.9744 - val_loss: 0.9598 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90394\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.1424 - accuracy: 0.9574 - val_loss: 0.7628 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90394\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0458 - accuracy: 0.9823 - val_loss: 0.6871 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90394\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0516 - accuracy: 0.9793 - val_loss: 0.5734 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90394\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0536 - accuracy: 0.9775 - val_loss: 0.6275 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90394\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.4980 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00092: val_accuracy improved from 0.90394 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0474 - accuracy: 0.9817 - val_loss: 0.6609 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90887\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.8534 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90887\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 0.7647 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90887\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 0.5496 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90887\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0772 - accuracy: 0.9762 - val_loss: 1.1516 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90887\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 0.6297 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90887\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0525 - accuracy: 0.9799 - val_loss: 0.5018 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90887\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.4574 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90887\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.4625 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90887\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.5237 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90887\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.4777 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90887\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.4962 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90887\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.5709 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90887\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0894 - accuracy: 0.9702 - val_loss: 1.3348 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90887\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0828 - accuracy: 0.9732 - val_loss: 0.9556 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.90887\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.6926 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.90887\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.4944 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.90887\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 0.9494 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.90887\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 0.5889 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.90887\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.4770 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.90887\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5798 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.90887\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.6890 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.90887\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 1.0058 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.90887\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.9031 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.90887\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.7789 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.90887\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.5768 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.90887\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.6647 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.90887\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 1.5374 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90887\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.7013 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90887\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.6197 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90887\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.1294 - accuracy: 0.9598 - val_loss: 1.2504 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90887\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0824 - accuracy: 0.9744 - val_loss: 0.9048 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.90887\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.5150 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90887\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.4390 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90887\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.9213 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90887\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0756 - accuracy: 0.9762 - val_loss: 0.5336 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90887\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0310 - accuracy: 0.9872 - val_loss: 0.4871 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90887\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.4895 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90887\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.4683 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90887\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0645 - accuracy: 0.9829 - val_loss: 2.2901 - val_accuracy: 0.6847\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90887\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 13s 253ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.6152 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90887\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 1.2015 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90887\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0215 - accuracy: 0.9951 - val_loss: 0.6271 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90887\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.6878 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90887\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.5807 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90887\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4185 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90887\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 0.3997 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00139: val_accuracy improved from 0.90887 to 0.91626, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.4520 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91626\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.4901 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91626\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.4683 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91626\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5698 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91626\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6251 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91626\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 13s 252ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.4819 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91626\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5282 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91626\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 12s 233ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.4187 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91626\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.4684 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91626\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.6157 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91626\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.7825 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91626\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 1.2117 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91626\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0852 - accuracy: 0.9738 - val_loss: 0.8950 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91626\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0800 - accuracy: 0.9744 - val_loss: 0.6706 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91626\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.7258 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91626\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 0.4886 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91626\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0510 - accuracy: 0.9823 - val_loss: 0.4852 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91626\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 12s 234ms/step - loss: 0.0409 - accuracy: 0.9903 - val_loss: 0.6457 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91626\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.5867 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91626\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.4462 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91626\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.5419 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91626\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.4987 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91626\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.4824 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91626\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.5733 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91626\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.5194 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91626\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.6901 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91626\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.6768 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91626\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.6090 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91626\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.5781 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91626\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5325 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91626\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5261 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91626\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 12s 235ms/step - loss: 0.0189 - accuracy: 0.9921 - val_loss: 0.6348 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91626\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.6327 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91626\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.6283 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91626\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 1.5804 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91626\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.7268 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91626\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.9570 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91626\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0402 - accuracy: 0.9884 - val_loss: 0.6993 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91626\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.6064 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91626\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0481 - accuracy: 0.9829 - val_loss: 1.1853 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91626\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0975 - accuracy: 0.9695 - val_loss: 1.2230 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91626\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0963 - accuracy: 0.9738 - val_loss: 1.9100 - val_accuracy: 0.6675\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.91626\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.6099 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.91626\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.5523 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.91626\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.5956 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.91626\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5886 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.91626\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.5875 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.91626\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.5245 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.91626\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.7148 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.91626\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.6271 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.91626\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4964 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.91626\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4471 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00191: val_accuracy improved from 0.91626 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.5997 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.91872\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.5251 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.91872\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.4950 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.91872\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3927 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.91872\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4719 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.91872\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5010 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.91872\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.4492 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00198: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4110 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92365\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4340 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92365\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.4824 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92365\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.6915 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92365\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.8046 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92365\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0404 - accuracy: 0.9890 - val_loss: 0.7714 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92365\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7081 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92365\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0255 - accuracy: 0.9903 - val_loss: 0.9053 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92365\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0488 - accuracy: 0.9854 - val_loss: 0.7224 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92365\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.8580 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92365\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.6262 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92365\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.5826 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92365\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.6773 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92365\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0569 - accuracy: 0.9817 - val_loss: 1.6243 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92365\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 1.1554 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92365\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0251 - accuracy: 0.9945 - val_loss: 0.5257 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92365\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.6264 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92365\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.4171 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92365\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4668 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92365\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0061 - accuracy: 0.9963 - val_loss: 0.4857 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92365\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.5798 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92365\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.8126 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92365\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.5828 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92365\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5340 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92365\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.5789 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92365\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4976 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92365\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6178 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92365\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.6234 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92365\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 12s 240ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.6226 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92365\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.6353 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92365\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.6405 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92365\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.4163 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92365\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92365\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.7675 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92365\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6043 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92365\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92365\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 12s 239ms/step - loss: 0.0141 - accuracy: 0.9939 - val_loss: 0.7952 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92365\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.7436 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92365\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 1.0304 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92365\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0620 - accuracy: 0.9781 - val_loss: 1.1542 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92365\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.7617 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92365\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 12s 236ms/step - loss: 0.0672 - accuracy: 0.9805 - val_loss: 0.8679 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92365\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 0.8733 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92365\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.8155 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92365\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.6911 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92365\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.6754 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92365\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.4452 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92365\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.4204 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92365\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4596 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92365\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.3935 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92365\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.7750 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92365\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 12s 237ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.8386 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92365\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0524 - accuracy: 0.9829 - val_loss: 0.8338 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92365\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.6964 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92365\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.4842 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92365\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4840 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92365\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.7333 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92365\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0178 - accuracy: 0.9921 - val_loss: 0.5558 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92365\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.5458 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92365\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.5690 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92365\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92365\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 12s 238ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92365\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92365\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.3881 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92365\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4414 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92365\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4848 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92365\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4947 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92365\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5205 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92365\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92365\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 5.1094e-04 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92365\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 4.7598e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00269: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 3.3190e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 8.9472e-04 - accuracy: 0.9994 - val_loss: 0.4246 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5286 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.8868 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0327 - accuracy: 0.9909 - val_loss: 0.8493 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 0.0195 - accuracy: 0.9909 - val_loss: 0.6282 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.6459 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.7907 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.6877 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.6816 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 2.1882 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92857\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.9614 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92857\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.7692 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92857\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.7384 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92857\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.7301 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92857\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.5540 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92857\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.5479 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92857\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.7996 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92857\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.5868 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92857\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5056 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92857\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.6951 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92857\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.4543 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92857\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4332 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92857\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.6777 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92857\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.8382 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92857\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.7511 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92857\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0286 - accuracy: 0.9927 - val_loss: 0.6013 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92857\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5646 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92857\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5441 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92857\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4467 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92857\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0047 - accuracy: 0.9970 - val_loss: 0.5256 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92857\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5766 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92857\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92857\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6456 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92857\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92857\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4590 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92857\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3989 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92857\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 6.2037e-04 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92857\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 7.5354e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92857\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 1.9030 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92857\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.1010 - accuracy: 0.9708 - val_loss: 2.1864 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92857\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0329 - accuracy: 0.9915 - val_loss: 0.6172 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92857\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 6.6007 - val_accuracy: 0.3818\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92857\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 1.2028 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92857\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5732 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92857\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 13s 239ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.5857 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92857\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 1.3475 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92857\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.6156 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92857\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.6690 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92857\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.5153 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92857\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.4599 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92857\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92857\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4195 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92857\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4319 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92857\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4173 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92857\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 13s 240ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4262 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92857\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 6.0814e-04 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92857\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4881 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92857\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5968 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92857\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.5314 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92857\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5481 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92857\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92857\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4727 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92857\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0804 - accuracy: 0.9799 - val_loss: 0.9446 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92857\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0397 - accuracy: 0.9896 - val_loss: 0.5732 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92857\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.4357 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92857\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.4446 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92857\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.5160 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92857\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0377 - accuracy: 0.9915 - val_loss: 1.0722 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92857\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 1.3471 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92857\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.6898 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92857\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.4220 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92857\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5542 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92857\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0054 - accuracy: 0.9970 - val_loss: 0.6105 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92857\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4750 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92857\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4023 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92857\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 7.2901e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92857\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.4958 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92857\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.4797 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92857\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4633 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92857\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4577 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92857\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4260 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.92857\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4462 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92857\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92857\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 3.9833e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92857\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4232 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92857\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4969 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92857\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0683 - accuracy: 0.9823 - val_loss: 1.9299 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92857\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0881 - accuracy: 0.9726 - val_loss: 0.8268 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92857\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.7013 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92857\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5402 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92857\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.4621 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92857\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.6378 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92857\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6135 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92857\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.4874 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.92857\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.4713 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.92857\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5521 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.92857\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.4709 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.92857\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4783 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.92857\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4848 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.92857\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 7.3252e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.92857\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4612 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.92857\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.4653 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.92857\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.4403 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.92857\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5082 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.92857\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.92857\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5523 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.92857\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.5592 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.92857\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.7010 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.92857\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.4866 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.92857\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.5022 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.92857\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.4556 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.92857\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4181 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.92857\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.92857\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.92857\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 5.1594e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.92857\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5968 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.92857\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 4.4810e-04 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.92857\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 3.4187e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.92857\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 7.3700e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.92857\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 3.2287e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00390: val_accuracy improved from 0.92857 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 9.4594e-04 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93103\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4622 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93103\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93103\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6053 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93103\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.7784 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93103\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.9397 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93103\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0276 - accuracy: 0.9927 - val_loss: 1.2388 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93103\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0854 - accuracy: 0.9769 - val_loss: 1.1792 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93103\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0522 - accuracy: 0.9860 - val_loss: 0.8146 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93103\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.5400 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93103\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5703 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93103\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.5497 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93103\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4775 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93103\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.5351 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93103\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5364 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93103\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5017 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93103\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93103\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4451 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93103\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.4517 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93103\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.6510 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93103\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5696 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93103\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.5463 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93103\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.4494 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93103\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.7166 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93103\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.9763 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93103\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 14s 259ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.6960 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93103\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.5345 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93103\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.7896 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93103\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.7360 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93103\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.6510 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93103\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6688 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93103\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6114 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93103\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 8.6877e-04 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93103\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93103\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 8.2842e-04 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93103\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 6.0699e-04 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93103\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 5.7265e-04 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93103\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6292 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93103\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 1.0877 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93103\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 13s 243ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.5281 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93103\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.6722 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93103\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.7006 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93103\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.5940 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93103\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 13s 242ms/step - loss: 8.0569e-04 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93103\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5199 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93103\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5510 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93103\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 5.2579e-04 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93103\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93103\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.5512 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93103\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.6621 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93103\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5326 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93103\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.8590 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93103\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.7682 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93103\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.8347 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93103\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.7020 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93103\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.6719 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93103\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.7326 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93103\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0381 - accuracy: 0.9903 - val_loss: 1.0415 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93103\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0641 - accuracy: 0.9805 - val_loss: 1.8897 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93103\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.9567 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93103\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.6257 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93103\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.4663 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93103\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4877 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93103\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.5796 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93103\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.7438 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93103\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.5047 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93103\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5648 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93103\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93103\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 7.7840e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93103\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 9.7318e-04 - accuracy: 0.9994 - val_loss: 0.3913 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93103\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 1.0927 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93103\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 13s 244ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.9136 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93103\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.6361 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93103\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 0.5595 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93103\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5980 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93103\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.7063 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93103\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.6941 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93103\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.5086 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93103\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.5083 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93103\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4640 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93103\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4996 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93103\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5447 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93103\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5603 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93103\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93103\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 6.7637e-04 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93103\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93103\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 9.8852e-04 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93103\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 4.9180e-04 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93103\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 4.4375e-04 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93103\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 6.2043e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93103\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.2218e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93103\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 2.4785e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93103\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 6.1205e-04 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93103\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4961 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93103\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 4.0088e-04 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93103\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5342 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93103\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 6.6761e-04 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93103\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 3.8169e-04 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93103\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 13s 245ms/step - loss: 1.6248e-04 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93103\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 6.3019e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93103\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 2.9167e-04 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93103\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 1.7404e-04 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93103\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 1.9235e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93103\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 1.5873e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93103\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 1.3888e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93103\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 1.9903e-04 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93103\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 1.0484e-04 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93103\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 1.2910e-04 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93103\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 5.6650e-05 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93103\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 13s 250ms/step - loss: 6.4438e-05 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc0fb575e10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3f24cfc3-4cb4-410b-e4f5-03ddb3edb161"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_15_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd66fd9d-1a21-4f88-edee-bce7bcdf32fe"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a67c709-2e5d-4a49-eed4-3c271d3de10f"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "63b20da8-ab57-4386-98bc-1c18f9c8e514"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "875cc828-a868-448e-9f08-9bea9609d53e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_15_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_15_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1fd81ba6-0e82-41ca-b6c5-f35942c2fc21\", \"Rotation_range_15_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}