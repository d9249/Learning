{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_range_25_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOR3pR/ShWK5ifW8meN+/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Rotation_range_25_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7f7f5c-cf99-4c79-8ec0-d2d45c70547f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 25 11:48:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cf0ad1-d6a8-415b-f7bb-77b205433d4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbff939-7db3-4e61-abd5-4cc3693d1045"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3530ed-2255-44cd-b8c6-dc46347d7121"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=25,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842ad66f-91c6-441b-a607-0fa80633b3b1"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 53s 476ms/step - loss: 1.9312 - accuracy: 0.3082 - val_loss: 7.7044 - val_accuracy: 0.0936\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09360, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 20s 375ms/step - loss: 1.3128 - accuracy: 0.5536 - val_loss: 4.1685 - val_accuracy: 0.0468\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.09360\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 20s 377ms/step - loss: 1.0617 - accuracy: 0.6529 - val_loss: 10.9358 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.09360 to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 20s 377ms/step - loss: 0.8744 - accuracy: 0.7095 - val_loss: 9.7364 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.09852 to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.8746 - accuracy: 0.7089 - val_loss: 9.7825 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.7932 - accuracy: 0.7406 - val_loss: 11.8485 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.11330\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.6825 - accuracy: 0.7716 - val_loss: 6.5029 - val_accuracy: 0.2266\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.11330 to 0.22660, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.6007 - accuracy: 0.7875 - val_loss: 7.0438 - val_accuracy: 0.2414\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.22660 to 0.24138, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.5690 - accuracy: 0.8063 - val_loss: 4.6732 - val_accuracy: 0.3473\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.24138 to 0.34729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.5328 - accuracy: 0.8276 - val_loss: 1.7132 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.34729 to 0.60099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.5230 - accuracy: 0.8283 - val_loss: 1.5478 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.60099 to 0.62808, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.4546 - accuracy: 0.8514 - val_loss: 1.9809 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.62808\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.4490 - accuracy: 0.8477 - val_loss: 1.0701 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.62808 to 0.72167, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.4181 - accuracy: 0.8660 - val_loss: 1.7073 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.72167\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.3813 - accuracy: 0.8685 - val_loss: 0.9986 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.72167 to 0.73399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.3768 - accuracy: 0.8691 - val_loss: 1.0778 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.73399\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.3887 - accuracy: 0.8733 - val_loss: 1.2680 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.73399\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.4392 - accuracy: 0.8441 - val_loss: 0.6548 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.73399 to 0.83251, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.3256 - accuracy: 0.8934 - val_loss: 0.9414 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.83251\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.3155 - accuracy: 0.8898 - val_loss: 0.8196 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.83251\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.3076 - accuracy: 0.8922 - val_loss: 2.1433 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83251\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.3119 - accuracy: 0.8971 - val_loss: 1.4553 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83251\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.2917 - accuracy: 0.9032 - val_loss: 0.7388 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83251\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.2902 - accuracy: 0.8965 - val_loss: 0.7265 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83251\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.2684 - accuracy: 0.9111 - val_loss: 1.1081 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83251\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.3727 - accuracy: 0.8660 - val_loss: 2.3157 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83251\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.2956 - accuracy: 0.9013 - val_loss: 0.8096 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.83251\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.2816 - accuracy: 0.8965 - val_loss: 0.6256 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.83251\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.2548 - accuracy: 0.9147 - val_loss: 0.7404 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.83251\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.2670 - accuracy: 0.9141 - val_loss: 0.5417 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.83251 to 0.85222, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.2206 - accuracy: 0.9239 - val_loss: 0.4900 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.85222 to 0.85714, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.2252 - accuracy: 0.9245 - val_loss: 0.6770 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85714\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1874 - accuracy: 0.9354 - val_loss: 0.5774 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.85714\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.2619 - accuracy: 0.9111 - val_loss: 1.0491 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.85714\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.2103 - accuracy: 0.9257 - val_loss: 1.1623 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.85714\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.2187 - accuracy: 0.9245 - val_loss: 0.5670 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.85714\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1921 - accuracy: 0.9379 - val_loss: 0.3851 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.85714 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.1931 - accuracy: 0.9385 - val_loss: 0.3956 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.87685 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1865 - accuracy: 0.9367 - val_loss: 0.3824 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.88424 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.1532 - accuracy: 0.9507 - val_loss: 0.4797 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.88670\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1532 - accuracy: 0.9446 - val_loss: 1.1721 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.88670\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1556 - accuracy: 0.9495 - val_loss: 0.3986 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.88670\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.1384 - accuracy: 0.9543 - val_loss: 0.4013 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.88670 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 21s 392ms/step - loss: 0.1189 - accuracy: 0.9592 - val_loss: 0.5158 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.89409\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.1641 - accuracy: 0.9415 - val_loss: 0.5053 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89409\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.1315 - accuracy: 0.9458 - val_loss: 0.5865 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89409\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.2029 - accuracy: 0.9354 - val_loss: 1.3663 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89409\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.2025 - accuracy: 0.9324 - val_loss: 0.8441 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89409\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.1588 - accuracy: 0.9434 - val_loss: 1.1373 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.89409\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.1434 - accuracy: 0.9519 - val_loss: 0.8071 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.89409\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.1404 - accuracy: 0.9501 - val_loss: 0.4986 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.89409\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.1015 - accuracy: 0.9647 - val_loss: 0.5158 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.89409\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0937 - accuracy: 0.9702 - val_loss: 0.4461 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.89409\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0963 - accuracy: 0.9659 - val_loss: 0.5041 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.89409\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1218 - accuracy: 0.9592 - val_loss: 1.1940 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89409\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1268 - accuracy: 0.9568 - val_loss: 0.8556 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89409\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0934 - accuracy: 0.9720 - val_loss: 0.3944 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89409\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.1110 - accuracy: 0.9598 - val_loss: 0.4427 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89409\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.1069 - accuracy: 0.9647 - val_loss: 0.5081 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89409\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.1106 - accuracy: 0.9616 - val_loss: 0.4691 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89409\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1144 - accuracy: 0.9604 - val_loss: 0.6097 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89409\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0835 - accuracy: 0.9702 - val_loss: 0.4664 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89409\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0787 - accuracy: 0.9738 - val_loss: 0.7190 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89409\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0654 - accuracy: 0.9762 - val_loss: 0.3850 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.89409 to 0.89655, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 395ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 1.2555 - val_accuracy: 0.6527\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89655\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0891 - accuracy: 0.9732 - val_loss: 2.8358 - val_accuracy: 0.5049\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89655\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0824 - accuracy: 0.9695 - val_loss: 1.1460 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89655\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0839 - accuracy: 0.9689 - val_loss: 0.6897 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.89655\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.1402 - accuracy: 0.9598 - val_loss: 1.1222 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.89655\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.1272 - accuracy: 0.9586 - val_loss: 0.8555 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.89655\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.1467 - accuracy: 0.9464 - val_loss: 2.3505 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.89655\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.1036 - accuracy: 0.9580 - val_loss: 0.6198 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.89655\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.4953 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.89655\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0587 - accuracy: 0.9805 - val_loss: 0.5341 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.89655\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 0.4399 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.89655 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.5709 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90640\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0762 - accuracy: 0.9720 - val_loss: 0.7440 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90640\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0560 - accuracy: 0.9775 - val_loss: 1.7675 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90640\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0658 - accuracy: 0.9799 - val_loss: 1.8338 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90640\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.1107 - accuracy: 0.9635 - val_loss: 0.6685 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90640\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0985 - accuracy: 0.9665 - val_loss: 0.8410 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90640\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.4665 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90640\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.1126 - accuracy: 0.9683 - val_loss: 0.6636 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90640\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 0.6940 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90640\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 1.0855 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90640\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 0.4970 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90640\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 0.4165 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00087: val_accuracy improved from 0.90640 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 1.3668 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91379\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 0.8707 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91379\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0852 - accuracy: 0.9708 - val_loss: 1.0308 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91379\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0857 - accuracy: 0.9671 - val_loss: 0.5740 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91379\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0467 - accuracy: 0.9872 - val_loss: 0.5687 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91379\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.5195 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91379\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0559 - accuracy: 0.9793 - val_loss: 0.6305 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91379\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0743 - accuracy: 0.9720 - val_loss: 1.2749 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91379\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0461 - accuracy: 0.9823 - val_loss: 0.9491 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91379\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0850 - accuracy: 0.9647 - val_loss: 0.4320 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91379\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0697 - accuracy: 0.9750 - val_loss: 0.6040 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91379\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 1.7595 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.1097 - accuracy: 0.9659 - val_loss: 3.2418 - val_accuracy: 0.4409\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 1.9487 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 1.0539 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0517 - accuracy: 0.9805 - val_loss: 0.7465 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.1543 - accuracy: 0.9531 - val_loss: 1.0678 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 21s 410ms/step - loss: 0.0770 - accuracy: 0.9732 - val_loss: 1.7132 - val_accuracy: 0.6305\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.7846 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0409 - accuracy: 0.9829 - val_loss: 0.5339 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.6401 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.5397 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.6136 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.3671 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0380 - accuracy: 0.9890 - val_loss: 0.6749 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0468 - accuracy: 0.9817 - val_loss: 0.5677 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91379\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0413 - accuracy: 0.9836 - val_loss: 0.7175 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91379\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0384 - accuracy: 0.9896 - val_loss: 0.4985 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91379\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.6537 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91379\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.5895 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91379\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.4483 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91379\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0380 - accuracy: 0.9903 - val_loss: 1.3705 - val_accuracy: 0.6921\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91379\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.5883 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91379\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.6401 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91379\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.4917 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91379\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.7440 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91379\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0415 - accuracy: 0.9836 - val_loss: 1.1233 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91379\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.1967 - accuracy: 0.9434 - val_loss: 2.9626 - val_accuracy: 0.5493\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91379\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.1293 - accuracy: 0.9568 - val_loss: 1.6558 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91379\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0567 - accuracy: 0.9836 - val_loss: 0.9234 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91379\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.5745 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91379\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 1.1182 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91379\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.9978 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91379\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0522 - accuracy: 0.9799 - val_loss: 3.5168 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91379\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.1037 - accuracy: 0.9689 - val_loss: 1.8469 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91379\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0588 - accuracy: 0.9787 - val_loss: 0.7927 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91379\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 0.4437 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91379\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5747 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91379\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.4531 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91379\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5465 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91379\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.4084 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91379\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6125 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91379\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 1.0621 - val_accuracy: 0.7315\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91379\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 2.4750 - val_accuracy: 0.5123\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91379\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91379\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 1.3380 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91379\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.5102 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91379\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.6274 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91379\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0407 - accuracy: 0.9836 - val_loss: 1.6402 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91379\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0391 - accuracy: 0.9842 - val_loss: 5.0168 - val_accuracy: 0.4113\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91379\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0838 - accuracy: 0.9738 - val_loss: 1.0400 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91379\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0729 - accuracy: 0.9756 - val_loss: 1.1376 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91379\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0467 - accuracy: 0.9842 - val_loss: 1.7826 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91379\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 1.0366 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91379\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0695 - accuracy: 0.9744 - val_loss: 0.9710 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91379\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 1.0443 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91379\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0581 - accuracy: 0.9836 - val_loss: 0.7396 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91379\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0850 - accuracy: 0.9720 - val_loss: 1.1371 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.91379\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.4879 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.91379\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0610 - accuracy: 0.9836 - val_loss: 0.7688 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.91379\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.6027 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.91379\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.4066 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.91379\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0654 - accuracy: 0.9817 - val_loss: 1.3443 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.91379\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 2.0868 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.91379\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.1267 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.91379\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.8323 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.91379\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 1.6027 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.91379\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.6724 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.91379\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0271 - accuracy: 0.9866 - val_loss: 0.5237 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.91379\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 2.0608 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.91379\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0846 - accuracy: 0.9762 - val_loss: 1.4238 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.91379\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0842 - accuracy: 0.9702 - val_loss: 0.4995 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.91379\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.5193 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.91379\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0325 - accuracy: 0.9872 - val_loss: 0.6094 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.91379\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.3942 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.91379\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0232 - accuracy: 0.9909 - val_loss: 0.4002 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.91379\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 2.2829 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.91379\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.8848 - val_accuracy: 0.5665\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.91379\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.9910 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.91379\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8290 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.91379\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.5493 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.91379\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.6449 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.91379\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.6208 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.91379\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.3237 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00181: val_accuracy improved from 0.91379 to 0.92118, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.4132 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92118\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.4561 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92118\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0258 - accuracy: 0.9903 - val_loss: 0.8107 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92118\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.5886 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92118\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0347 - accuracy: 0.9872 - val_loss: 1.6009 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92118\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5650 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92118\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 1.1623 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92118\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 1.1281 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92118\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.8587 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92118\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0379 - accuracy: 0.9909 - val_loss: 1.0979 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92118\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0825 - accuracy: 0.9720 - val_loss: 1.7335 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92118\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.9269 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92118\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0412 - accuracy: 0.9842 - val_loss: 0.8679 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92118\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.4647 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92118\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 1.5702 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92118\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.6330 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92118\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5812 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92118\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.5087 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92118\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.4220 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92118\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.4414 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92118\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.5371 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92118\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5513 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92118\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5411 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92118\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4624 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92118\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5351 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92118\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 0.4269 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92118\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 3.2100 - val_accuracy: 0.4557\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92118\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 1.5991 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92118\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.8822 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92118\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 1.1256 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92118\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.5267 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92118\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.6066 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92118\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.5930 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92118\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0379 - accuracy: 0.9878 - val_loss: 1.3116 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92118\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.1055 - accuracy: 0.9659 - val_loss: 1.8631 - val_accuracy: 0.5369\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92118\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0399 - accuracy: 0.9836 - val_loss: 1.9645 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92118\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.5360 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92118\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 21s 410ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.0889 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92118\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 1.1323 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92118\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.3910 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92118\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.3287 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00222: val_accuracy improved from 0.92118 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.4096 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92365\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4976 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92365\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.6510 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92365\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.5689 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92365\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 0.8176 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92365\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0489 - accuracy: 0.9866 - val_loss: 1.1448 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92365\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.1169 - accuracy: 0.9695 - val_loss: 1.3252 - val_accuracy: 0.6995\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92365\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0950 - accuracy: 0.9720 - val_loss: 3.5375 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92365\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 2.2379 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92365\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 1.3137 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92365\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.6350 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92365\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.5087 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92365\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.5004 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92365\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.6224 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92365\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.4285 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92365\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4114 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92365\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4297 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92365\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4582 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92365\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0062 - accuracy: 0.9963 - val_loss: 0.4982 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92365\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4516 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92365\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.8397 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92365\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.5182 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92365\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.5096 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92365\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.4701 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92365\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.5646 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92365\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7211 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92365\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.7008 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92365\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0168 - accuracy: 0.9933 - val_loss: 0.6658 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92365\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.5465 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92365\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0953 - accuracy: 0.9720 - val_loss: 1.5004 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92365\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0536 - accuracy: 0.9848 - val_loss: 0.6253 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92365\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.4080 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92365\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.8279 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92365\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.5408 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92365\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0131 - accuracy: 0.9939 - val_loss: 0.6548 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92365\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5339 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92365\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4272 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00259: val_accuracy improved from 0.92365 to 0.92611, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5378 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92611\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5774 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92611\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.5579 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92611\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.7790 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92611\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92611\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5346 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92611\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5092 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92611\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 1.1962 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92611\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 1.2178 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92611\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.5533 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92611\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0258 - accuracy: 0.9903 - val_loss: 1.0585 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92611\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.8021 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92611\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.5436 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92611\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.6932 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92611\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.8283 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92611\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.5440 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92611\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0246 - accuracy: 0.9903 - val_loss: 0.7141 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92611\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.5460 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92611\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.5899 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92611\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4853 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92611\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.9828 - val_accuracy: 0.6084\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92611\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.8967 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92611\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 1.3542 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92611\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.7206 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92611\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.5499 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92611\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.7343 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92611\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4878 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92611\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 4.3429 - val_accuracy: 0.3990\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92611\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 4.2098 - val_accuracy: 0.4754\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92611\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 1.1142 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92611\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 1.0441 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92611\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0452 - accuracy: 0.9829 - val_loss: 1.5752 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92611\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0334 - accuracy: 0.9854 - val_loss: 1.6994 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92611\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.5600 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92611\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.7894 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92611\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5435 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92611\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4847 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92611\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0334 - accuracy: 0.9909 - val_loss: 1.1891 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92611\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.7537 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92611\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0538 - accuracy: 0.9817 - val_loss: 0.6355 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92611\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.5417 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92611\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.4770 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92611\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0382 - accuracy: 0.9909 - val_loss: 0.7970 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92611\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.7239 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92611\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5955 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92611\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.5704 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92611\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.4415 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92611\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4594 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92611\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.5429 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92611\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.5621 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92611\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 4.6113 - val_accuracy: 0.3966\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92611\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 2.3485 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92611\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.5684 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92611\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 4.5223 - val_accuracy: 0.3842\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92611\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 1.2065 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92611\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.5213 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92611\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.5796 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92611\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.9299 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92611\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 1.0467 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92611\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 1.1491 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92611\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.6123 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92611\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.3665 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92611\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.4916 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92611\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0142 - accuracy: 0.9933 - val_loss: 5.6160 - val_accuracy: 0.3867\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92611\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 4.5038 - val_accuracy: 0.4507\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92611\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.6842 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92611\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.5334 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92611\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.7001 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92611\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.7010 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92611\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3902 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92611\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4491 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92611\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.4847 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92611\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.8658 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92611\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0112 - accuracy: 0.9945 - val_loss: 0.9569 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92611\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.7253 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92611\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.6042 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92611\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.5564 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92611\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.5439 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92611\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0334 - accuracy: 0.9933 - val_loss: 1.1527 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92611\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.9632 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92611\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.5138 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92611\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 1.0942 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92611\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.6910 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92611\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.8268 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92611\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.9453 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92611\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.8340 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92611\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 1.0234 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92611\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.7193 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92611\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 0.4460 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92611\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.7490 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92611\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.7914 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92611\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5655 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.92611\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.7232 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92611\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 2.2043 - val_accuracy: 0.5616\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92611\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 1.0922 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92611\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 1.0673 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92611\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.7592 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92611\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 1.3990 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92611\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 2.5179 - val_accuracy: 0.5936\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92611\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 1.4349 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92611\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.3767 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92611\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.6973 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92611\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.5936 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92611\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 1.5780 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92611\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.8185 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.92611\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 1.1562 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.92611\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.7851 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.92611\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5600 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.92611\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.5584 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.92611\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.4953 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.92611\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2100 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.92611\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4872 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.92611\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.92611\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4649 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.92611\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.92611\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 6.8052e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.92611\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 1.4047 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.92611\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.5338 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.92611\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0591 - accuracy: 0.9854 - val_loss: 1.1820 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.92611\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0524 - accuracy: 0.9799 - val_loss: 1.0574 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.92611\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0390 - accuracy: 0.9842 - val_loss: 6.2053 - val_accuracy: 0.4039\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.92611\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 5.4442 - val_accuracy: 0.3966\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.92611\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5011 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.92611\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.5236 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.92611\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.8218 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.92611\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.8778 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.92611\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.7142 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.92611\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.4397 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.92611\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.92611\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6617 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.92611\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.7126 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.92611\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7555 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.92611\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 2.4077 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.92611\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0073 - accuracy: 0.9963 - val_loss: 3.2457 - val_accuracy: 0.5296\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.92611\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4321 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.92611\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 2.0097 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.92611\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5605 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.92611\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4806 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.92611\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.0779 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.92611\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 1.4612 - val_accuracy: 0.7069\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.92611\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0790 - accuracy: 0.9793 - val_loss: 4.0875 - val_accuracy: 0.4606\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.92611\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 3.6190 - val_accuracy: 0.5345\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.92611\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.5300 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.92611\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.4781 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.92611\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0159 - accuracy: 0.9933 - val_loss: 0.4793 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.92611\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.6577 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.92611\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5907 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.92611\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.8311 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.92611\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 391ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.1670 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.92611\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.4853 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.92611\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.7219 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.92611\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.6488 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.92611\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 1.2079 - val_accuracy: 0.7389\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.92611\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.7136 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.92611\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.8483 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.92611\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 4.2222 - val_accuracy: 0.4261\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.92611\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 3.0659 - val_accuracy: 0.5197\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.92611\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.6739 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.92611\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.8655 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.92611\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.6066 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.92611\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.8466 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.92611\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.4357 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.92611\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.7845 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.92611\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 13.8124 - val_accuracy: 0.1847\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.92611\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.8610 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.92611\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 2.2976 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.92611\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.4078 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.92611\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.8215 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.92611\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.5113 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.92611\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 21s 393ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5278 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.92611\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6416 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.92611\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.92611\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.8435 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.92611\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.6794 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.92611\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.5634 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.92611\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 393ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.4295 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.92611\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 389ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5068 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.92611\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5776 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.92611\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 21s 405ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.6467 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.92611\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4869 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.92611\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.6703 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.92611\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.5175 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.92611\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.2689 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.92611\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.5114 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.92611\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 21s 408ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 2.1532 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.92611\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.0343 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.92611\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0143 - accuracy: 0.9945 - val_loss: 0.9091 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.92611\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.5688 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.92611\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.6779 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.92611\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0351 - accuracy: 0.9921 - val_loss: 4.4069 - val_accuracy: 0.3621\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.92611\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 21s 403ms/step - loss: 0.0777 - accuracy: 0.9817 - val_loss: 5.2017 - val_accuracy: 0.3695\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.92611\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 1.9830 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.92611\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.5075 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.92611\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.4505 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.92611\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5828 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.92611\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 21s 398ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4477 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.92611\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4414 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.92611\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.9602 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.92611\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0409 - accuracy: 0.9909 - val_loss: 1.4288 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.92611\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 21s 402ms/step - loss: 0.0270 - accuracy: 0.9890 - val_loss: 0.7112 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.92611\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 21s 404ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.5907 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.92611\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5907 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.92611\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 21s 408ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.6384 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.92611\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4643 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.92611\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 21s 406ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.2541 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.92611\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.7367 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.92611\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 3.4099 - val_accuracy: 0.4729\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.92611\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 7.7640e-04 - accuracy: 1.0000 - val_loss: 2.3760 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.92611\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 5.6481e-04 - accuracy: 1.0000 - val_loss: 1.2881 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.92611\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 7.0730e-04 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.92611\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 3.8034e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.92611\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 3.6174e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.92611\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 1.5285e-04 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.92611\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 5.7498e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.92611\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 5.3136e-04 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.92611\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 3.2731e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00475: val_accuracy improved from 0.92611 to 0.93842, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 2.9233e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93842\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 2.1786e-04 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93842\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.0282 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93842\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.6092 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93842\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93842\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.8285 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93842\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 21s 401ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.8322 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93842\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.9859 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93842\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 21s 407ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 1.3681 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93842\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 21s 395ms/step - loss: 0.0188 - accuracy: 0.9909 - val_loss: 0.8326 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93842\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.9877 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93842\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.8600 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93842\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.5741 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93842\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 2.1650 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93842\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 6.2473 - val_accuracy: 0.3300\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93842\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 392ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3456 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93842\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 8.2026e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93842\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93842\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 5.8747e-04 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93842\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 4.0079e-04 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93842\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 390ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5524 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93842\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 21s 394ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6891 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93842\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 1.5959 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93842\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 21s 399ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.6440 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93842\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 21s 400ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 1.1834 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c1c79bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b1cd3976-cb2a-4414-bde5-329a4b68474f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a96a4fb-2ccc-43a7-bbd6-0fd396bfedee"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "146cbee8-e0e8-42ef-e56e-f91b38ce682e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8eab8bb3-e679-4183-a4fe-18ba4e0d18c6\", \"Rotation_range_25_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8eab8bb3-e679-4183-a4fe-18ba4e0d18c6\", \"Rotation_range_25_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}