{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rotation_range_25_3_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNzxClA9otfgnfvDBN39RID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/Rotation_range_25_3_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883e49e0-ddaf-4720-c489-4393576eaf9c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 25 14:43:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa20b26b-3e92-4a99-e1a9-ac33673ee996"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f3c726-5cb5-4209-eb76-5d8212f709ad"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7939ee05-19b8-4720-a888-f0c13ed19768"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=25,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5290b1c-e2ce-445f-c4de-127c4de80eb0"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 38s 258ms/step - loss: 1.9932 - accuracy: 0.2893 - val_loss: 8.8506 - val_accuracy: 0.1010\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.10099, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.3749 - accuracy: 0.5189 - val_loss: 6.3708 - val_accuracy: 0.1330\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.10099 to 0.13300, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 1.0800 - accuracy: 0.6334 - val_loss: 12.1026 - val_accuracy: 0.1108\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.13300\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.9236 - accuracy: 0.6985 - val_loss: 12.5376 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.13300\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.8256 - accuracy: 0.7278 - val_loss: 11.3270 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.13300\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.7868 - accuracy: 0.7351 - val_loss: 5.2355 - val_accuracy: 0.2044\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.13300 to 0.20443, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.6238 - accuracy: 0.7856 - val_loss: 5.6023 - val_accuracy: 0.2340\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.20443 to 0.23399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.6546 - accuracy: 0.7844 - val_loss: 5.8192 - val_accuracy: 0.3005\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.23399 to 0.30049, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.5599 - accuracy: 0.8118 - val_loss: 2.1768 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.30049 to 0.58867, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.5126 - accuracy: 0.8307 - val_loss: 1.6914 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.58867\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.5118 - accuracy: 0.8301 - val_loss: 1.2989 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.58867 to 0.63793, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.4770 - accuracy: 0.8337 - val_loss: 0.9563 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.63793 to 0.68966, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.4675 - accuracy: 0.8490 - val_loss: 3.0096 - val_accuracy: 0.4483\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.68966\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.4575 - accuracy: 0.8441 - val_loss: 1.3444 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.68966\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.4228 - accuracy: 0.8544 - val_loss: 0.9325 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.68966 to 0.71182, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3955 - accuracy: 0.8678 - val_loss: 0.9998 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71182\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.4372 - accuracy: 0.8581 - val_loss: 11.2337 - val_accuracy: 0.1232\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71182\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.3689 - accuracy: 0.8770 - val_loss: 1.0069 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71182\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3433 - accuracy: 0.8934 - val_loss: 1.2499 - val_accuracy: 0.6823\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71182\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.3195 - accuracy: 0.8861 - val_loss: 0.5716 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.71182 to 0.82020, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.3022 - accuracy: 0.8916 - val_loss: 0.6074 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.82020 to 0.83005, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3137 - accuracy: 0.8983 - val_loss: 0.4876 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.83005 to 0.84236, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3205 - accuracy: 0.8928 - val_loss: 0.4954 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.84236 to 0.84975, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2781 - accuracy: 0.8989 - val_loss: 0.8641 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84975\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2891 - accuracy: 0.9038 - val_loss: 2.2177 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84975\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.3326 - accuracy: 0.8873 - val_loss: 0.9284 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84975\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2854 - accuracy: 0.9013 - val_loss: 0.8423 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84975\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.2448 - accuracy: 0.9239 - val_loss: 0.8200 - val_accuracy: 0.7734\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84975\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2327 - accuracy: 0.9208 - val_loss: 0.5082 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84975\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1858 - accuracy: 0.9348 - val_loss: 0.4573 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84975\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1833 - accuracy: 0.9361 - val_loss: 0.7323 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84975\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1968 - accuracy: 0.9391 - val_loss: 0.9234 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.84975\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.2081 - accuracy: 0.9294 - val_loss: 1.2502 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.84975\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.3046 - accuracy: 0.8928 - val_loss: 0.6995 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.84975\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2220 - accuracy: 0.9263 - val_loss: 0.6422 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.84975\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2017 - accuracy: 0.9324 - val_loss: 0.4282 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.84975 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1750 - accuracy: 0.9415 - val_loss: 0.5664 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86207\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.2178 - accuracy: 0.9245 - val_loss: 0.7710 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86207\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1701 - accuracy: 0.9379 - val_loss: 0.5893 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86207\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1669 - accuracy: 0.9488 - val_loss: 0.6562 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86207\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1721 - accuracy: 0.9464 - val_loss: 0.4866 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.86207\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1756 - accuracy: 0.9409 - val_loss: 0.7452 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86207\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1631 - accuracy: 0.9440 - val_loss: 0.4739 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86207\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1727 - accuracy: 0.9397 - val_loss: 0.6219 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.86207 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1172 - accuracy: 0.9586 - val_loss: 0.6587 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86946\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1512 - accuracy: 0.9513 - val_loss: 0.4365 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.86946\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1338 - accuracy: 0.9519 - val_loss: 0.7442 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.86946\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1241 - accuracy: 0.9586 - val_loss: 0.5336 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.86946\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1373 - accuracy: 0.9531 - val_loss: 0.4475 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.86946\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1008 - accuracy: 0.9702 - val_loss: 0.4969 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.86946\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1329 - accuracy: 0.9488 - val_loss: 0.6576 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.86946\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1876 - accuracy: 0.9318 - val_loss: 1.5894 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.86946\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1190 - accuracy: 0.9592 - val_loss: 0.5895 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.86946\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1097 - accuracy: 0.9659 - val_loss: 0.4041 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.86946 to 0.87931, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0814 - accuracy: 0.9769 - val_loss: 0.5058 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.87931\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1023 - accuracy: 0.9659 - val_loss: 0.9031 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.87931\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1005 - accuracy: 0.9659 - val_loss: 0.5072 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.87931\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1462 - accuracy: 0.9513 - val_loss: 1.0595 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.87931\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1465 - accuracy: 0.9476 - val_loss: 0.5785 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.87931\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1046 - accuracy: 0.9604 - val_loss: 0.5040 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.87931\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.8028 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.87931\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0838 - accuracy: 0.9726 - val_loss: 0.4556 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.87931 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0757 - accuracy: 0.9702 - val_loss: 0.5255 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.88424\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0718 - accuracy: 0.9744 - val_loss: 0.5270 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.88424\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.1625 - accuracy: 0.9470 - val_loss: 0.8581 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.88424\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1015 - accuracy: 0.9695 - val_loss: 0.5941 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.88424\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 0.3563 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00067: val_accuracy improved from 0.88424 to 0.90148, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0783 - accuracy: 0.9750 - val_loss: 0.8783 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.90148\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0704 - accuracy: 0.9726 - val_loss: 0.5481 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90148\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0789 - accuracy: 0.9726 - val_loss: 0.6251 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90148\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0915 - accuracy: 0.9702 - val_loss: 0.9505 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90148\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0942 - accuracy: 0.9683 - val_loss: 0.6633 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90148\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1235 - accuracy: 0.9562 - val_loss: 0.5930 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90148\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0797 - accuracy: 0.9726 - val_loss: 0.6782 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90148\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.5085 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90148\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0938 - accuracy: 0.9714 - val_loss: 0.5623 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90148\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0840 - accuracy: 0.9781 - val_loss: 1.2589 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90148\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0651 - accuracy: 0.9787 - val_loss: 0.7410 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90148\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 0.4069 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90148\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.7872 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90148\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 0.6590 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90148\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0758 - accuracy: 0.9744 - val_loss: 0.6927 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90148\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.5202 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90148\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0743 - accuracy: 0.9756 - val_loss: 0.4928 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90148\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0476 - accuracy: 0.9817 - val_loss: 0.7549 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90148\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0823 - accuracy: 0.9659 - val_loss: 0.6319 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90148\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0876 - accuracy: 0.9683 - val_loss: 0.6738 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90148\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0653 - accuracy: 0.9799 - val_loss: 0.5339 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90148\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.5477 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90148\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0467 - accuracy: 0.9836 - val_loss: 0.5695 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90148\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.6438 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90148\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.5154 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90148\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0928 - accuracy: 0.9702 - val_loss: 1.6717 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90148\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.1574 - accuracy: 0.9501 - val_loss: 1.9138 - val_accuracy: 0.6330\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90148\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0929 - accuracy: 0.9714 - val_loss: 0.6791 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90148\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.5317 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90148\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0830 - accuracy: 0.9702 - val_loss: 0.6880 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90148\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 0.5264 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90148\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.5309 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90148\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.9597 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90148\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.5991 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90148\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 0.6964 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90148\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0675 - accuracy: 0.9720 - val_loss: 0.9376 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90148\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0779 - accuracy: 0.9744 - val_loss: 0.6623 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90148\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0796 - accuracy: 0.9708 - val_loss: 0.6803 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90148\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.4907 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90148\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.4956 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00107: val_accuracy improved from 0.90148 to 0.90640, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.6319 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.90640\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 0.5697 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.90640\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 0.4118 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.90640\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0637 - accuracy: 0.9805 - val_loss: 0.9537 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.90640\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0519 - accuracy: 0.9817 - val_loss: 0.4309 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.90640\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.8102 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.90640\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 0.4890 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.90640\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0889 - accuracy: 0.9738 - val_loss: 0.9197 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.90640\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.6332 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.90640\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.5525 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.90640\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.7099 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.90640\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0432 - accuracy: 0.9836 - val_loss: 2.4175 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.90640\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.9388 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.90640\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.7820 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.90640\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.4909 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.90640\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0474 - accuracy: 0.9811 - val_loss: 0.6147 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.90640\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.4903 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.90640\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.5274 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.90640\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.6415 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.90640\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 0.7703 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.90640\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.6172 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.90640\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.6723 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.90640\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.4965 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.90640\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.5147 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.90640\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0304 - accuracy: 0.9927 - val_loss: 0.4822 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.90640\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.8301 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.90640\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0649 - accuracy: 0.9744 - val_loss: 0.7952 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.90640\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.6679 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.90640\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.4956 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.90640\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 0.7202 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.90640\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0523 - accuracy: 0.9848 - val_loss: 0.4688 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.90640\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0758 - accuracy: 0.9762 - val_loss: 1.6244 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.90640\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0644 - accuracy: 0.9775 - val_loss: 0.5211 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.90640\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0286 - accuracy: 0.9890 - val_loss: 0.4852 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00141: val_accuracy improved from 0.90640 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.5304 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.90887\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.4615 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.90887\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.5867 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.90887\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0435 - accuracy: 0.9896 - val_loss: 0.7168 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.90887\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.5918 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.90887\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0840 - accuracy: 0.9738 - val_loss: 1.4106 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.90887\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.9217 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.90887\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.8150 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.90887\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0475 - accuracy: 0.9823 - val_loss: 0.4873 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.90887\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.7237 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.90887\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.3523 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00152: val_accuracy improved from 0.90887 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.3211 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.92857\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0276 - accuracy: 0.9951 - val_loss: 0.4492 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.92857\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.9777 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.92857\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.9314 - val_accuracy: 0.7463\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92857\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.8713 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92857\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0201 - accuracy: 0.9963 - val_loss: 0.4250 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92857\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0666 - accuracy: 0.9805 - val_loss: 0.8793 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92857\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.8315 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92857\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.4793 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92857\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0622 - accuracy: 0.9756 - val_loss: 0.7581 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92857\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.7564 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92857\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.5785 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92857\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.5110 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92857\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.7643 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92857\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.5419 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92857\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.4240 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92857\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.4059 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92857\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.3787 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92857\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.9081 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92857\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.5701 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92857\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 1.4845 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92857\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 1.0976 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92857\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 0.6028 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92857\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.4574 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92857\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.7170 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92857\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.5106 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92857\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.8016 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92857\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.5567 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92857\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.6407 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92857\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.7032 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92857\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.6720 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92857\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 1.1306 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92857\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.1018 - accuracy: 0.9695 - val_loss: 1.0522 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92857\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0746 - accuracy: 0.9781 - val_loss: 0.6336 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92857\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.4687 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92857\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0231 - accuracy: 0.9909 - val_loss: 0.5922 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92857\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.5836 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92857\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.7234 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92857\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.7611 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92857\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.7299 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92857\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.6923 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92857\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 1.1495 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92857\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.5103 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92857\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.6980 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92857\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.4371 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92857\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0467 - accuracy: 0.9872 - val_loss: 0.6601 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92857\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.5972 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92857\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 2.6190 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92857\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.8589 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92857\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.3345 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92857\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0407 - accuracy: 0.9829 - val_loss: 0.9017 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92857\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0374 - accuracy: 0.9872 - val_loss: 0.4994 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92857\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.7146 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92857\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.7577 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92857\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0696 - accuracy: 0.9799 - val_loss: 0.6272 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92857\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0235 - accuracy: 0.9903 - val_loss: 1.1136 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92857\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0275 - accuracy: 0.9933 - val_loss: 0.5784 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92857\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0263 - accuracy: 0.9872 - val_loss: 2.6833 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92857\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.8481 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92857\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.5167 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92857\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.9400 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92857\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.7785 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92857\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.5290 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92857\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.7899 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92857\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 0.8844 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92857\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.5874 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92857\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.4693 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92857\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0120 - accuracy: 0.9927 - val_loss: 0.4754 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92857\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5368 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92857\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5173 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92857\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.9424 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92857\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.8704 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92857\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 1.0473 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92857\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5765 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92857\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.5078 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92857\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.9392 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92857\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5314 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92857\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92857\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.8378 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92857\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0281 - accuracy: 0.9896 - val_loss: 0.5175 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92857\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0271 - accuracy: 0.9896 - val_loss: 0.5812 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92857\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 1.7223 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92857\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.7601 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92857\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0200 - accuracy: 0.9909 - val_loss: 0.8898 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92857\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.6568 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92857\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.8672 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92857\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.0477 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92857\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6303 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92857\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 0.5006 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92857\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.5640 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92857\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.6640 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92857\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.9058 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92857\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.7784 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92857\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.5087 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92857\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.4856 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92857\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.7649 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92857\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.5803 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92857\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.4926 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92857\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.6837 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.92857\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.5549 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.8380 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.7863 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.7734 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.5561 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.9632 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.6586 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 1.3337 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0630 - accuracy: 0.9781 - val_loss: 0.7180 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 1.6750 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.7538 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0680 - accuracy: 0.9769 - val_loss: 0.8517 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0371 - accuracy: 0.9909 - val_loss: 1.0758 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0255 - accuracy: 0.9890 - val_loss: 0.6723 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.7083 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4663 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5438 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 9.6751e-04 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4243 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5661 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.6865 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.6372 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.4594 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.5324 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92857\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.5480 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92857\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5874 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92857\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6348 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92857\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0854 - accuracy: 0.9750 - val_loss: 3.1927 - val_accuracy: 0.5271\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92857\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 14.5627 - val_accuracy: 0.2438\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92857\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0867 - accuracy: 0.9756 - val_loss: 1.1483 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92857\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.7552 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92857\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0609 - accuracy: 0.9817 - val_loss: 1.0313 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92857\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 1.0738 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92857\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.6498 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92857\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.4190 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92857\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.5071 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92857\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0114 - accuracy: 0.9951 - val_loss: 0.5118 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92857\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.6013 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92857\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.3926 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92857\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5719 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92857\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.4587 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92857\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.6153 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92857\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4368 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92857\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3939 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92857\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.5657 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92857\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4401 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92857\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92857\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92857\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.3944 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92857\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92857\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5355 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92857\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4309 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92857\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4411 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92857\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0041 - accuracy: 0.9970 - val_loss: 1.1689 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92857\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.6489 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92857\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4819 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92857\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.6425 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92857\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.7334 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92857\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.6376 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92857\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.6677 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92857\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.6964 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92857\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 3.3466 - val_accuracy: 0.4951\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92857\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0521 - accuracy: 0.9805 - val_loss: 0.7888 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92857\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0344 - accuracy: 0.9848 - val_loss: 0.9637 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92857\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.7501 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92857\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.6111 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92857\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.6784 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92857\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0600 - accuracy: 0.9860 - val_loss: 0.7230 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92857\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.5403 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92857\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.6155 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92857\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 11s 208ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5111 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92857\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.4802 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92857\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.4847 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92857\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4483 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92857\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4988 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92857\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.3994 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92857\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.3762 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92857\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3537 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92857\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.7532 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92857\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.6382 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92857\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92857\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5765 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92857\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5079 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92857\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4763 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92857\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 0.4734 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92857\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.4776 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92857\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.3765 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92857\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92857\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3817 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92857\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6660 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92857\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.6488 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92857\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.7453 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92857\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.5751 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92857\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.6102 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92857\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.5586 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.92857\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92857\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92857\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 11.3131 - val_accuracy: 0.2635\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92857\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 9.0905 - val_accuracy: 0.3177\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92857\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 5.5875 - val_accuracy: 0.3473\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92857\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.7373 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92857\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.7976 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92857\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.9310 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92857\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.7073 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92857\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.6876 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92857\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.7085 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92857\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.5989 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92857\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4323 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00364: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.9652 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93350\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 1.2219 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93350\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.4952 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93350\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5805 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93350\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.0168 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93350\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.5882 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93350\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 1.4254 - val_accuracy: 0.7438\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93350\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 1.0275 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93350\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0195 - accuracy: 0.9915 - val_loss: 1.3869 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93350\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.6497 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93350\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4773 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93350\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93350\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93350\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0051 - accuracy: 0.9970 - val_loss: 0.4323 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93350\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93350\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.5417 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93350\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 1.0737 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93350\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.4331 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93350\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.4128 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93350\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.9578 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93350\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5475 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93350\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4007 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93350\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4168 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93350\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3749 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93350\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4281 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93350\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93350\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 0.5087 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93350\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.8043 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93350\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.8643 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93350\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.4840 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93350\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.5366 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93350\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4527 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93350\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6040 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93350\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.6636 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93350\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.5895 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93350\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.8457 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.93350\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.9447 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93350\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0260 - accuracy: 0.9909 - val_loss: 0.6525 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.93350\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.6955 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.93350\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 2.8239 - val_accuracy: 0.5764\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.93350\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 2.2019 - val_accuracy: 0.5936\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.93350\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0219 - accuracy: 0.9909 - val_loss: 3.2801 - val_accuracy: 0.5394\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.93350\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5963 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.93350\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.9461 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.93350\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6994 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.93350\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.5678 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.93350\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 1.3892 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.93350\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.93350\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4136 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.93350\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6288 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.93350\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 2.5012 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.93350\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.7337 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93350\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4025 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93350\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93350\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.8027 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93350\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 9.0021 - val_accuracy: 0.3202\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93350\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0300 - accuracy: 0.9939 - val_loss: 1.5473 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93350\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.9033 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93350\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.8917 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93350\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 1.0401 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93350\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.8589 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93350\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.6649 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93350\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4894 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93350\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5622 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93350\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.4480 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93350\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93350\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.4808 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93350\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.7735 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93350\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0661 - accuracy: 0.9823 - val_loss: 5.1766 - val_accuracy: 0.4926\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93350\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 1.0152 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93350\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.7543 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93350\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.7546 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93350\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.8449 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93350\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5540 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93350\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.6263 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93350\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4718 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93350\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.5002 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93350\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5919 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93350\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5972 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93350\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93350\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6077 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93350\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 11s 204ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.0576 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93350\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 11s 203ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.8736 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93350\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 1.5523 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93350\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.8952 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93350\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.9577 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93350\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.9245 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93350\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.6204 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93350\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.6467 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93350\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.6513 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93350\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 11s 209ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93350\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.8459e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93350\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 3.9706e-04 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93350\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 6.3723e-04 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93350\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 1.6796e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93350\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 3.1007e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93350\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.4221e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93350\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.4937e-04 - accuracy: 0.9994 - val_loss: 0.4517 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93350\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 6.0149e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93350\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93350\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 2.6943 - val_accuracy: 0.6133\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93350\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.1716 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93350\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 1.0253 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93350\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.5226 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93350\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6280 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93350\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 1.9224 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93350\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.7244 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93350\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.7632 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93350\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.8849 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93350\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0135 - accuracy: 0.9945 - val_loss: 0.9664 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93350\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.7046 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93350\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.9502 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93350\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 6.9982 - val_accuracy: 0.3695\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93350\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 3.1218 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93350\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.7491 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93350\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0222 - accuracy: 0.9909 - val_loss: 0.5413 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93350\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 0.8442 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93350\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0145 - accuracy: 0.9933 - val_loss: 0.7174 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93350\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.7974 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93350\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5435 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93350\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0086 - accuracy: 0.9951 - val_loss: 0.6363 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93350\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93350\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93350\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.4776 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93350\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.8326e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93350\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4985 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93350\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.5503 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93350\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4737 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93350\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.5286 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93350\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5269 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93350\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 11s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93350\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 8.9987e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93350\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6219 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93350\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 3.4579e-04 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93350\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 7.5681e-04 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93350\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 11s 207ms/step - loss: 4.0104e-04 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3061b9d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "88cf5ad5-abb0-4bfb-a901-d4bcf8df447a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOxdeZgUxd1+a2Z29r5YlnO57/tGUEFUFFS8NVGjRuOVxCOJV8xnEtFEo8YkxiOoMZFEo8YYD6IoiOItCigghyKnLMeysLD3NTP1/VFd3dU91TM9s7M73Uu9z7PPzE73dNd0V7/11vv7VRWhlEJBQUFBwfvwpbsACgoKCgqpgSJ0BQUFhU4CRegKCgoKnQSK0BUUFBQ6CRShKygoKHQSBNJ14q5du9L+/fun6/QKCgoKnsTq1asPUEpLZdvSRuj9+/fHqlWr0nV6BQUFBU+CELLTbpuyXBQUFBQ6CRShKygoKHQSKEJXUFBQ6CRQhK6goKDQSaAIXUFBQaGTIC6hE0L+TgjZTwhZb7OdEEIeIoRsIYSsI4RMTH0xFRQUFBTiwYlCXwhgboztpwAYov1dDWBB24uloKCgoJAo4uahU0rfJ4T0j7HLmQD+Sdk8vCsIIUWEkJ6U0r0pKqOCR9AcCqOiuhl9S3JScrxQOAIfIfD5SNx9wxGKtzdVYGxZEXoUZqElFMHhxhZs2V+H7Aw/JvQtjvn9SISiNRJBZsCP8kMN6JafhWAgtt5pDoXx4upyVFQ36Z91L8zC9IEl6F2cjU+3VeGYwV3hj1H+1nAE+6qb8OXuajS1hhEM+LCtsh6ZAR8ogJLcIHoVZaOxJYxQJILxfYpxsL4Zg0rzkJXhjzreyh1V6FOcg4CfICvDj4+3HEBuZgDbDtSjICuAkT0L0CU3iFfW7MGEvkWYqF2X/TVNeGHVLvTpkoN5Y3uZykwpRXMogqwMPyIRigilCPjZtWlsCeOlL8pxqL4FRTlBTO5fjN5F2Vi/uwYt4Qjqm0Oobw6htimE08f1QtDvw+HGFvgIQZ8u8npS3dCKz3ZUoaElhOrGVvQqzEbAT7Blfx2G9cjHhL7FyMs0qKupNYw31u9Fl9xMjOxZgNL8TP3zPYcb2e+rbcaGPTXoU5yNod3z8dW+Gkzp3wXfVjXo2yBMJZ6XFUBTawTfndIH3QuysPNgPboXZOFwQyt6FGbZ3s8t+2vx2rq9CAZ8KCvOQVbAh8LsDHyx6zAoZXUmEqE4cUR3jOtTZHucZJGKgUW9AewS/i/XPosidELI1WAqHn379k3BqRXaG1+WV+P+JV8BAH4+dzjW764GBXDhVHb/tuyvw//W7kGGn+Dx97ehtimEt286DoNK8wAAOw7U489vf4NQhKJPcTYumd4PPQuzAQBffHsImytq8dGWg3hrYwWGds/D2LIinDyqO2YMKcWY+Usxa1gp/vK9iSCEEQylFI2tYRAQZAcZoW3YU42b/7MOm/bWICfoxz1nj8GvXl2P2qaQ/jt23HsamlrDiFCKvdVNePy9rWhoCWNSv2Ks2nEI739TiXCE4qSR3fG/tXswslcBjh7UFfXNIfQuzsag0jzMGdVDP97Wyjqct+BjHGpoBQAQYvBBMOBD/5IcbK6oQ6/CLORlBfDa9TP0BmLDnmrc/+bXmNC3CIcbWrHw4x0J35eZQ0vxzx9MBQAcqm/Bv1ftwh+XbkZLOKLvk+EnaA1Hr3eQE/SjoSUMHwFOGN4dpflBLN1QgYP1LQCAZZv24+ELJ2DtrsNYvfMQnl6xE99WNeCB88di7a5qvLpmN66cMRBXzRiIS//+KVbuOOSozPe+8RUIAZpDEQR8BBP7FmNQtzzcdeYofLqtCm9u2IuaxhDe2liBxtaw7XGOG1qKhZdPwZvr9+GXr6xHVUOLfu275Abx8W0n4P9e/hJL1u9DfYv9cazQqpjI63j8va0Y2iMfazRCBthz8P2j+yEcobj95fWYNawUzaEI7n3jK1Q3tjo6T7eCrHYhdOJkgQtNob9GKR0t2fYagHsppR9q/78N4OeU0pjDQCdPnkzVSFED2w/UI+Aj6FGYhQx/tDKsqm9BZsCHXEGZhMIR+H1EJzsA2FXVgMbWMP67uhxzRvfAq1/sxtGDu6JHQRZ6FWXjjfV78eLqctxz9hiM7l2of+/dr/djwbtbMalfMS6d3h89CrPQ1BrG+LuWoqk1AitW/XI2KAXmPPg+qjQiKM3PRGVtMwBg2Y0zMag0D999YgU+215l+u7zV0/Dv1fuwstf7AYA5GUGMKhbHtbuOgwAmNi3CI9fMhlT7l4GAOhdlI1J/YqR4fdhc0UtQhGKTXtrMLJnAc6Z2Bv3LN6EiFaNC7ICqGkKoVdhFk4d0xNPfrgdAPDgd8fjgaVfI+AjqKpvQY1A9gBw9oTe2LS3Bl/tq5Xen8yAD5/+34l4c/0+5GQGsODdrfh6Xw2euGQyZo/sDoCp/M+/PYT/e/lLhMIUxblB1DeH8NW+Wrx78yz075oLAPju45/gU8s1+c2ZozCxXzEqappw9KCuaGwJgxCgurEV/17JlHO/LjlYt7saz3/2LQ7UteDDnx+Pn/17DZZ/XQkAKMzOQFlxNsb0LkRZcTb2VDfh6EEl2HO4Ea1hitK8TDz54TZ0L8jCT2cPwW9f34Qvvj2MnKAf0weW4MaTh+I/q8qx8OMd+OVpI/Db1zcBkBMdAEzuV4xVOw/ht2eNxrAe+Xj6k51YtHYPAOCWOcMwsW8x8rMCKMzOwP7aZtz7xiYUZGVgeM98rNx+CJ/tqDLdM45Zw0pxwZQ+2HO4CbNHdMeWylpkBfzoVpCF3y3ehLe/2m8qx4S+Rbji2AH4yfNrEI5Q3HjSUPzxrc0oK87GNccNQnNrGEU5QYzqVYDyQ434aMsBHDesFC+s3IXJ/btgVK8CTOhbhMyAX/udFAfrW/Dl7mpc9Y9VyMrw49jBXbG3uhFry6sBAF3zgijIysC2A/Wma5QV8OOB88chw0/QJTeIUISisrYZE/sVIy8YQFbQp58nWRBCVlNKJ0u3pYDQHwfwLqX0Oe3/rwHMime5HMmETik1kTAA9L/tdQBAj4IsvHLtMVHduv63vY6Bpbl456ZZuO7Zz/HG+n0IRyh+cuIQ1DWHcOHUvnhz/V48sHSzozKcMa4XxvUpwqxhpSjKzsCx9y0HIUBDSxgluUFcc9xA7DnchIUf78Afzh+Hm/6zNuoYfh9BOELxjx9MxeR+xcjNDOCSv32KD745gJ6FWbj/vLG45G+f4c4zRmFItzzc/J+12FPdZCL+hZdPwbSBJQj6fXjty734ZOsB/HvlLtxx+ijcsWhDzN8Q9Pt0RXrGuF644tgBaA1H8Nxnu/DT2UPQp0sONuypxmkPfRj13VvmDENxThALP96OZ6+ahq55mWgNR1BR04TeRdmoaw7hy93V+GpvLZpDEdz35lcY2bMAG/fW6Me4/oTBuOnkYTHLuGLbQVzwxAo8c8VRKM3PxMH6Zlz0109xzcyBePz9bQCAV649BuMTUGv/+nQnbn95Pc6bVIYXV5frnz95qdG4OMGh+hZ8sOUAThvTU7dYln+9H5c/tRIAs3t+OW8EzhjXGyt3VOGCJ1YAYI31/EUb8eGWAxjRswCvXX+s/v35izag/FAjnvy+lG+i8Odl3+CR5d9gZM8CDOuRj4+3HsQr1x6DrnmZ0v3DEYon3t+G17/cg/rmMP599TR0K2DPCr/WADCsez7e/OmMqOcsUWzZX4e8zID+PF737Od4bR2jNr+P4NpZg/DQO1sAAO/ePAt9u+Q4sgjbgvYm9NMAXAfgVABHAXiIUjo13jGPVEL//NtD+PEzn+OO00eipqkVEQrMGNIVx963XN/nB8cMwK9PHwmAkf/HWw/ie09+CgBY/cvZmHz3sii1VJSTgUiE6kpn2sAuWLGtCj0Ls7CvpgmUAhdM6YPeRdlYurECX+6u1r9bVpyN8kONePaqoxAKU1z6989Mx155+2w8/9m3+MNb0Y1FcU4GVt4+W/dUm0NhvLByF371KiPjnoVZWH7zLGRl+BEKRzDv4Q91FfzqtcdEdTu3VdZhzoPvm6yC/KyAbp8M75GPrytqcfdZYzBrWCmOvvcdAMAXvzoJxblB6TVfV34YtU0hjC0rxEdbDuK9zZW4+6zRjh88Simm3vO23ggBjMxvPGloXMLYVdWAGfcvR98uOfi2qgEAu96vXX8szvnLxzhY34I1vz4pIeJZvbMK5y74BAAwvk8RZgzpioff2YL1d84xecvJoKKmCUfd8zYA4PZTR+CqmQMBsGsw+o4l6N81F6/fMAOHG1rw6PItuHR6f1svvKNRVd+Cib95CwDwzBVH4dghXVN+joaWEKrqW1Dd2AoCgpG9CvD6ur2obw7hO1P6pPx8MsQi9Lh3nxDyHIBZALoSQsoB3AEgAwAopY8BWAxG5lsANAC4PDXFdi8O1DVjc0Utjh4UXWF2H27EhU+swL3njjFtbwlF8MtXvsQLq5ii+tG/Pte3zdAq3uwR3bBlfx027KlGQ0sIuw81YunGCvx+ydf6vm9trAClwGvXH4v1u6tx20tfAgAOa17ur+aNRCRCcfbE3pj822W44tgBOGF4N+w53KRX8P21zfhyd7VOlOWHGkEIMLFvMbIy/CjOydC94aMGdEFpfiauP3EIrjthMCrrmjH17rf18pw4ortO5gCQGfBjUr8u+v9/vXSyHrwL+H2YObQUX+2rRcBHMLxnftT1G1iah1/PG4n5/9uI644fjF1VDbhl7jBM/x0j7sU3zEBVQ0uUgrMjcwAYW2Y0GnNH98Dc0T1s95WBEILpA0t0OwEAfjxrsCMS7qkpO07mAPC3709BUU4Qi64/Vj9+IhjZk1kq+6qbcM/ZYzCyV4GjxsUJuuVnokcBEwHHD++mf04Iwce/OBEZfnaOopwgbj9tZJvPl0p0yQ3ilNE9MG1gSbuQOQDkBAPICQZQJsTYTxvbs13OlQycZLlcGGc7BXBtykrkAVz21GdYv7sGa+84GYXZGQiFI3h6xU68sKocpfmZ+LaqARf99VP88rQRuHhaP7y6Zjd+/l9GvEO65aFfSS6WbarQj/fBNweQnxnA45dMxq9eXY/X1u7BDxauxIptVci0ZFrc9tKX6F6QiVG9CjCyZwHG9SlCl9ygrqouO7q/3v3deNccZGf4QQjBQC1ICbAIPsAUWI/CLFz21EqcOqanTrw9C7NxqKEVvz9vLM6e0Fv/HiEE3fKzsOzG47DrUAMuf2ol5o6KJseh3dm5BnbNNfn0ANCnmAVEexRm2XqJl0zvj3MmlpniBUt+OhPZGX74fMRE5k9cMgkNCQS+ksVZE3rphN6zMEsPyMZDwBIP2XrPqfr9SVZNZwf9WPqzmThQ26JnFKWCzPlxlt10HJpaw1GNZmF2RkrO0Z5YcPGkdBchrUjb9Llew+PvbcWitXvw+g0zsH4381E/2XoQc0f3wFsbK3Dn/zYCADZpkYPeRdn47eub8OLqct1i6F2UjSU/ncmO9/42jOiZjx//63M0tIQxdUAX+H0EI3oW4NlPv8WKbSxg1ByKDkjOHFIKQggIAUb0LADALICJfYtN6WY5QfntvWbmQOQG/ThnYhmCAR8+vu0EXUkCwEMXjsffP9qBsyb0jiIkABjcLQ+DSnPx3x9N19PeRAT8Piz92Ux0L4hO7yrQSOGoASXSsnHkWshuWI9oNQ8AJ0salPbACcO7475zx2BwtzxTD8QJXvzhdIQjFF3zM2OmMCaCnGAAfUva5/HNywy02bpRSA/UXXOI373BUve27K/TP/vhM6vxwa3HY9VOc9rWuRPL8MD5Y/HWxgpc/fRqAMAdp4/EGeN66b7tj2YNAgBM6leMD745gHnjWLdtUGmufpxjBpdgXXk1XvrR0cjw+9CzKAsrtx/C6N4FUeWLF5wTUZQTxHUnDNH/71WUbdo+uFs+7jl7TMxjEEJiEtvQ7nICPmlkd/zgmAG44cTBjsvrFnx3SnKptpP7J9YAKCgkC0XoMVB+qAGVtc2mNMIHlnwNHwEund4fCz/egT+//Q1eXF2OqQO6oKk1jHXl1SgrzgYhxKQeJ/frghJJ5P6es8dg58EG3fPrV2IQ+r3njEXvomxT8K69vMGOQk4woAd8FRQUUgtF6DFw0V8/NQWzAODNDfswdUAX/PK0EXjus2/1tLEfHTcIDyxlwcuyYkPx+ggQocymkKFPlxxTlkBPwaboWZjV7ilQCgoKnQdqtkULqhtaUVHDhnJbyZyjrDgbAb8PwzX/+vhhpTh+eDe0ajnRvQVCX/yTGbjn7DGOg2gigcv8awUFBQU7KIVuwc0vrsVbGyvw5KWT9YEzvzhlOI4bVoozHvkILaGIHuw7c1wvrN11GEO1gF0XLXWuW76hsof3KMDwHtGedyx876i+0mCogoKCQiwc0YROKUVTawTZQT/W767G0o0VeGsjSye88p9s0NMdp4/E5ccMAAB0zQ1iT3UTummT/1x+TH90yQ3iuKFsAe4/fXc8Xlu71xTYTAZ3xwlIKigoKMhwxBL6gbpmXP3PVdhzuAkf/Px4zHvYGB5+wvBueEebL2JkT0NdF2RnYE91k67QCSE4S8jT7lmYrY+sU1BQUOhoHLGE/pPnv8Dn37LJoD7dZp4o6f9OHYG/XzYFew43mlL6CrJYDrU1R1pBoVMj3Ao8NAGY+ztgxOnpLo1CDByRUbdQOIJVOw7hzPFs3uebLRNPDdRmxbPmZ988Zxi65AYx1jL6sVOjYiOwcB6w78t0l8SdCIeAitiTiDlCqAX455lAeQfMb/TGz4HHZwLVu53tX7sPqN7Fvpcu1FUCNR2wxEJLA3Dgm/Y/TzvhiCN0SilOf+QjNIciOH5YN3TLz8S+miYMFHxvu1TBqQO64PMYk0B1SuxeDez4AHj2gvj71u5jai5VaDzEHjA34917gAVHA1veBt78BbB5aXLHqdwEbHsXWHSD8VlTNfDiD4DDu2y/ZovWRqC2Qr7t08eAvWuBXZ86O1YLmyIWfof1ftNrwCvXsvl2q3ezRu/wruj5d52c979XAYd2An8czv7aE001wH++Dzwymb33II44Qq9pDGGTNgXquD5FKM5hlXRg1zw8fskkvPGTGeksnvsQ0eaprimP/UBGIsAfhgHPxZz6JzHc1x947JjUHc8JImGgtSn+fhzb3mWvz5wDrPgL8Oz58b+z6zNghWWlxlCLdv4QEGoGDn/LGon1/wUWXee8PAD7/ms/A/4wFHjh+8axAfNvO/yts+M1MWsSAZuVehoPAf/7CfD894CvFgP//h6w5hmgbj/wyBTgbycBD44GNryU2O/46nXgyxeAd35j1MNIO87b89B44ButQf52RWrFRCTMjhdqBp4+B/jmrdQdW8ARR+i7DrGbdNnR/TGgay6Kc5kvXpIbxJxRPfS5URQ0iIq7br/9fg0H2OuWt1Kr0qu2te37iarCFy4F7hbmFF/3ArBPuj66/fHjlflvJwFv3mb+LifNA18Dv+0GPDgGWDaffbY3ei76mHhkMrD2OfZ+4ytA1VZjW90+471TQm/khC5R6Jv+xxre1QuBr14DPnnU2LZ3LdBaD+zRZhbdu469Vn4NrP5H/PPuZwtsICQ0QlXbo/dL9B7L8Pk/gYaDxv/Png88dmzyx4tEWLlWPQXs/4r1tO7pCRzcAmx9m/W+2gFHHKGXH2JrDJ4zkWWnFGkKvUveEWSjyLDuBaD+QPTnYWMOcFR+Zf/9GmNqWVQnYRFwzC9k3fVU4eFJwDPnOt//q9fYK1eCL10Vu5dQJ9gac+9lr1XbgXv7Ai9eEftcnMQBoMEcmEdBb+DwTu0fwsjl8Zlxiw9Ko4maN7DhVuDd+4zPE1XofsmiEzs+Mt73GAMcFPzn3WweI13Z8+P8ZTrwvxsY6cUCbwgOCg3S/o3mfZbcDvymlN2vVU9Fq+pwKyPrxhjL5LU0AIuuj/68aiuzeyo3s96SU0TCwOMzmDh47afAX45iDStgNFKlzudeSgRHFKFv2FONFdtYK1xWzIbbZ2h+eYmXfPGnTgNeuxHY8WFs1ewUVdsZcb38w+htYaG7XrMHePlHwN9Ojt6vVlB+Yhc/Gax5JrH9v3wReGhitOoJtbCHcsuy+MdYvZCpYo6GKtY9joVQM1CjBRbHXQQMO5W9r9nNyrL+xdjfr9vPLIrWRqBRIPQZNwM/WGIQYSTMgtJOlLp4H3qOY6+c0Jf+Clj7LHvfZZBB6FXbgddvBu7sAiy+NfqYukLPBDa+yjxxDnHa3t6TzA3c3jVAViFw+WIgs4D1XCo2AlRrLJvjqFTuYx/aCRSUsfdWQv/kESDSyuy+137KbC8RS3/FyPq/V9r3nKwB/24jgRN+yd5vfw94dAqz1Jxg33rg94OBivXApkXR2/euAUCAkvaZnO6IIPTGljB2VTXgwidWYOHHO5CtLeIAAHxhHO6ltxk1e4EHhrFupQyVm1nEPllEIsDOD4FVfwMWnsbSyZwqLTvUatkDMhUjknOklRGCLJhWK2QghOMQIaXA3+YAGy0VPlGrpmIjI95PHmXE/YnlYXaamROJMA9YvI6bFkWrZiv4bz7jEeDsBUBBLwDEnD0Sy/PdvAR4/kJgyf+Zu/vZRUBRH+DC54D+Mwz/mP+mhybYl+2AVu9GnQMcp2Wl8EZ5+3vGfr0nGeVffDOw8q+MaGUZO1xZ7/iAqc7ldxvbqrUl8C5/EyiyzEZZvRvI78XONewU1nAsmG5st1PNkQjw5GxDodMwQDSqshJ6X+149doz5bOkFO/Xfs+WZcACSU/rrTuAp89i76dcxV6P/Rlw1I9il9EO79/P7vmgE+TbP36Y3duMbPn2NqJTE3okQtHQEsLlCz/DjPuX68uzDemepy8IENH8t4A/RZNgbXiZ+ZQr/ybf/ugU4OGJyR//kMVDbKljylKmrp2gerfxkORIpnkVFXokFL2dQyT0v88FDrB1FtHaFO171lUAu1YAL1xi/rxZWKDZiS+6YDrw9zlM4QKa+hGwP046YeVmpjYbJeT4+o2sjHZoPAQ8plkgBdqKNf4MIK+7WQlaVaFI8Jv+x16/ecvcmGRpKywNOgEom8waUo4lt7NjblvO1Pi/zjeyWdb/l6U+Asz+ydLSa8MtrGE+sJkR/dz7gO6jgOYaZmdsfQeYdi3Q71gAkuveeNj8/9eLjftbsxsYOAvoNx0o6mfer+EgkKXFpHJLoxuhg9vkmTh71wDlK43/acTw0bllwREJAz3HCx9Yyi/22lolQc6PHmSf5/cETnsAmF8NjP2O0YBQwRaK12MDmF8+YAZwwXNA16HG56MEhT/x+/GPkyQ6NaE/9v5WjPz1En2xCA5xitpe2sIOKVuNhad4BWMM/29uQ0rUvnXyz9c+JyfBTx4FNmj+3ep/AB/92exd/mkk8PpN7H2WJL9eJHSxq11/0JwxIarS1gZg2R3Auv+wAOND483nlPUowiHgv4LnHKvx+OJfRoN5YDP7iypDk7n7Tym7N83afPZNNaxx/e8PDHVnBbcvfJK6sXmJYRnkC0uQFfY2VDLAFK1IQqISL9fWbq3eBaz7t/F5trDOqi9gvha8QSc+1sP5Zinw9l3ssxd/wF4zcoD87kaaYbiVBeMiIWYLTfuhUeZvljLSGnE6s09kdajJQuiVXwGPTAIO7WDXnNsh2ZbFThoOMKuFl8lKqP86l2XiWGH1qyNhg0wPbjFva65livdMrXdmtd2s/4uKu9lY2wBdLCO8fdpkeiKhy1IZ6w+ymE9LPfD+79m97zoUyMgCrv0MuGENMP06w44DgAkXRx8nRejUhP7KF8YDfuvcYfjZbFZ5RL/8ppOH4Q/nj9PnY0ka3JpodUDobQHv4krL0GyQbiTCKuyS/2O5tQDw3v3AW79m6lOGcKuZpHevZjnLXK2ISvH3A5k65qjaGt3dfelK4/2btxnHlhH6ni+YUhR/ix1e/bH5N9AwkFkIVHwJrNE84r/PAd75rbFPawNw/yDgd9pUDZzEN75qH4fgvY4MySLIYk62SOi5pebft38j8JyQw2/XeIjIshA6lTSGDVVGA7xtOfCFGHfQept+rSGKtBq9sO7aXPT52lz9O7WgZskg7bsaoW9eCqzX0gzt7MP6g0yc8AYoYAmahlsMhR7MMY7d35Ia/MUz5uDqoR3m7aJCpxFzo9NSxxqNCd8DckrkhD7pcuCcJ9n/Hz9ibBMDuNaUTL3OC9deJsSW381iPmufM+pblwHaMQh7P+dus1jKlC/+kgp0akLP1tbIvP6EwfjxrMG4auYAXDKtH2440VitJyvDj3MnlSW2JqNVxXz7KfDbUhZ42a9lggTl85/bIhJm6jnegAZr91fEo1OB32sP5lNzDfICGAHUlLNMhTXPsooqVm6AjVL8XZnhPf/1BKbqMrTGyaqa964BPn2cWQAHvmHdeA7r9fzscWCl9lDp2RswrmWm5XqFEwys9pnKXl/5kVE2EZ8+BoQ0a2bNs+brKKb1ieAjE5urowOrok0jKtNgbrTvyi2hz582MoUmx8iAsSp0GeoPAC2aRVWzG3hVyAy6QCN33ujs38hGefoCQIlW93kjtOMjVldzS80K/dnzgRcvZxkgdr1Cn4/VW15GWZ46J7IMQeAMOM68z6vXAgsFBRsVg6Hmz8Tnr7nGIMisQjOhU8r+z+0KjDmP+e1iT4iPCC3sa2QocRCZQj8cLTT4drFMg09CFIKCKJAJhBSh0xI6pRRbK+vx/en99OXZcoIB/Oas0fo0t0mhoQq4swhY+7zxGU/P+vI/wOY32HuuVpbNZ6l4QOwA2VevMfW8/J7Y57d2f0Uc3mlsFwOXxf0Nku49kT0c25YDS283f7+mnKm5x441Bxh5ZZQFLd+4VQvSHQC6jxY2SBpIXjZx5CNXrOKDA5gzTrZ/YLy389aL+8s/5+C2BMBIv15Q5VZFOPo89irGBaypjw0aaQ89xdx4yRrySEhLjbvOsEWGWB76ufeyXgYQrdBlqN9vtgw4jr3RCMhxQn/7LnZ/ImEjl5wr9MYqZjcQAnbPLNd3+/us/LmSHiy3g3gZZSNJM0WFrkHvDdggZDOwK6AFEkUSba4VCL2IEfjuzzGmKPUAACAASURBVJk4aalj+2YVst/XbaTZ9uEZSj/+BCi1WD/8norC4ulz2BiBb8WkAO16cbFz/C+NmIoIMQiaogW9Zei0hL6/thl1zSEMslkpKGlwD/Pla9hr42E2bNsKfoM//BN7DbWYW/ev32DpTdxz53nc8QYcxFLo+rmtDQdhoxMBoN/R7DVeCpw4QIR7yPFG6YmETiRVa/VC4J4yc6P08cPs2ljVf4tAVv+Yx4J98wuBP8qWryPAJCHQ5GQ0oejFWgl94Cz2WrMbtmisAoL5wEXPmz+3I3Rrdz3HspTgpMuYFwyYu+d+m9hOfaV2jYhZ/Yrqz/pdkZQz8428cp6dQnzRDeYHf2DbRQ+Yg1Jmd8VU6IKHzsEbExkqNrBgtQwZ/PhaGVsbGGHza84V+l+PB5480XiW9F5CttFbAliMJLMguncIGA2cWFf5e9mzw59LsXdlKns7WbAWdEpCb2wJY/4iluEwqDRJQq/eDSw4NtrvbRC6038exyrO5/+M/r6VoBoPmZXHu79jD+VuLTWLB/ZEBfHSNSytSpwsKJZC57AOEGptZCM4e00ACjXS4ClhdigU7BoaYQ97JE5aYXeBbGUeeH0lswnqDxhk8vFDzIqJFQQFjCH2tXuit+V1Z4Na5vyO/e9kFN4BgTSsWTjcQok1eVXDQSCnOPpzGTlEwtFWmug3n7+Qkc33XgTO/ZtBgoC9Qq+rNNRpiRDQ8wmPtFUxf19IEyWEWREAkNfN+IxGzKR3YDMwZE50wBMw6rNO6LEUukBouaXA+f8Apl4Tvf+Co81BZRFcoddVsHvGeyh2lsvCecbngBGY5Y1WzR5z/MMKn1+etlgjiWPpjYcNoQfbz2YR0SkJ/bH3tuKN9SxDwW4tzyhUbTcru9ULWZDNOkRZzFI4tCM66s5htScaDppJjg8s4HZNhRa0+nox65431wHrnmdpVU+datgUThS6aBUArLKVr2LeJa/8u+MRepnxnnerw60s8GSHrsLoN97wWP1SgD1UPHAEsF5KOA6hxwLv4nJ1JI5a9QeBWb+I/s4B4b4d+Masijl5Wb1cMSDdUCW/Fk4VekY2U+k5JcCos43fMeY8834+m6ULv/2YxQWCecB3/8UGwhx3G3CUkL4qEnqfaUC3EeZj8N+cqxE6t1zE7KCmapbOKsub5sTPyxjLQxcJPacEGHWWEfdwCq7Q/zKdZU7xNFfeaGQVmp8P3pvmdZ6TKm+IavfF7i0Qn/l556guN0av8sahKZ5CV4SeNPYcNhQGX10oJg7tZBXk3d8Zn/HK8uGfzF2sBov6tYM1qHdgs5kg+BDlvWtYpeCpbeEWFhwVB3jU72eTGzXXsopjp9o4rIQeamRd46I+xoMVy04AzIosEmK2SyQUraSJQDiiOuXKRvbANNcyO4D/jpa6+Ao9FrIs3rOYvUD8wKzbolMyxX1CjUCpMJOf3UP5p1GsUQuHWKphtiRvX5bdFGqOVnqBTODGjcCNErtOhCxlUrROws1AcT9g5i3A8b8wn1+0XKS/SfNyuVLnQVFT1g9ldUFG6FygOPHQOaH5AsZ9kqXJRhVRqF9cofPG8fWfaefQCDuQJe8Z5nU3l4E/e7X7Yit04pdPZ7z+v2wsifiM8kbQTqErQk8em/axGz6wa66z7BVOgFuXs9dIxOhC0TCw8HQ2oOPjR+TznXCIDx8PhHH85/vANmGkHg+eNlQxcm2uBk7WRuA11xiZBf2E0W2Nh5gCiVUJAbPCEpFbGjud0pcBnP5n9t40oCgM+LUAWLiVjaIb8x22jSt5f9Cs0LhSyhMmuuJormXnuvkb9sDX7TfsnG4yjzwOuCrmpCXrNRGL0rWmD4pza8jsBY5IiA3pr/wKGDw7ers0JY2ah+QDjJwCmdGpflbIGm+x9xRrNKtIsFKi0dSl3kBoCt16bbK7yAmJZw3plovkt/BGnte7nBLDFrISuizgLR6TK3R+vu3vs/rTSxtYRHzm2AsATLnSyL7ijRK3XeocKPSWOm3AlIRHREuO319bhd4+I0Ot6HSEvvjLvVi/uwY/mjUIb92odfcpZRaKXQ43D0wSHyObu4qNOS8ARrafPMKyQmLNnSIOfV75JPDGLebtPG1PRFO1oc57T2QPXiTEMlYCWUCxYE1se5f1EGQBRxF2Q+hjEfqgE4EffqAF5/qah/zzwFckxIg+I9sgwMIy4KfrgZ9tNJMPbxDtCN2fwbryJYNZA8QVeixLxw56l1t7mEzkqZGEzLoQ7RFRocfKEw63Gg3mxEslx7S5vjKF7gTiNeUNjemaxhhR64uj0Hm2CCd0rtCtvaXsYvk14eMK+LWVTd7FGwL+KgaDMwvM+1rJGDA3SlyhlwrW0ZXLDFImPmOeGA5RIPAytDZqNl+LfHQ0B/9dPcfJ60+o0biGnFvsFHo7ZraI6FSEvrmiFj/+F/OGjxtaCj9fqGLXp2yujrd+bez81xOBf2kqkz9sxBd/sqtY2SGiQq2vtAz2gDyfd+8aZvUQH1MSvgBTxNyjFQNNfDrVY3/GUtzsyM/Ovsgttc+Pz8w3PFZ/ptke4pZLWMtGCWQaxynozaycvFJzpeXqLdeSzQGwB5eTTV53Np0oTwuUNUbD58kbBrHsgEFasoZTpnTFno6o0AMx1FQkZDR2MlIWr+9P1xvDvK3BbKeKzS+U+4q3gKveiW+5cfj80JWljGg4GelKWVPo1hTS7GJ5vXn5auE8lrJy8AaOv4r1wdoTEqd+4JApdKoN97/8TfN9k5Gm2BBxQn90ihFnsSNg8XiiPSiKqYaDhh/fXMNSZ2M1ED3HASfdZb89BehUhL5hjxHhntBXuFHr/8te9eAPgN2rgG+WsPdi4IPPr2EFf/grYkz4JIvyO8Hu1axyZxWyhyMSYoSe3cWsUBoOslF2ky8HfvGtMZueFbaE3tVeQYp+ayDTTKw8KMotJH+G0ZUWs2FksLMv+MOf1838uUxJ5veQp81x9cUfWmsqIGB0462WCz8uhzj7nT9g7G+1BRbfDCzXRgTKiFUkvqI+RndfDNYRXwKkLOyX35NNdOVU7RFi1B/ZdZ2p9SD1tEVNoVutj+xiefaOrIxWWBW6SOj53YHxwjB42aA6kdC5YAo1sXvXb7p5X1nPVbwfYiPKU1XtLBLxeMRv1AdR8dcfNGcEzbzVPogNANe8DxzzE/vtKUCnIvRNe2sR8BGsvH02MgPChd3xIXvlJGLNqOCEvmsFm4NEBtOgGRvYregy5Upzl16GGTezV1+AKZDGKtbaW3OJrQQogx2hZxWZCV2c1EjsnvszzMGlSIhdO155/UHjOAUJEPo1wgAhfj4xRgAAx0mmbw1kRV/bmzYbg3N49kIgCJz2B8uXueUiqeo5WoNJ/MZ8JBz84bcSOhcH/kw5sfKy8OvCSUG0XALZzklZJEtObiJx/fAjxAQndJkSHfsdNhmVnibJBxZJCD0Yw4aKRei8ngQy2XW2NrpnPcrSNQH50HrRxuH3JNQiz8+XEbpMoQPGylIxFbrGIT6/QdRij6DhgDkVWTb4qoPRaQj9s+1VePmL3RjeMx+lYmZL42HDo+aenzXDQ5aaBGizz2noMsB4OOwqsEwFAsDYC+TBvsnaqMEBxwHTfmQcIxLR8py7RGcOiNaD3ahJ2cCanK6MRMQBDuf9HRipTR0qdpf9mdGj9XwZxjw1/qDxgBdaiNAKkRBFhcQfSOsq8sH8aG86Iyfa3iA+o2EWr5E1eBdLoWfmM8Ip6hNtF/DzyVS/9ZwieObLlCuMcgJmssqwafhlEBtaa7c/IwfoEUdo8OscS4lyEKLxuaVeZRW2QaFnG8c+9X7zADAOfq1lGSomD53v1yT366WELpRblgvuWKFr74O5wKkPsPcNlgnqcpOI/6QYnYLQW8MRXPDEJ6isbcYPj7MMK971GXTFwX3dqMFCNoQ+aBbQ5yj2PphnqEQ7H9rqPXJkZEVX+kmXG5ZJdpGh2Hw+e8sFkHvJVlUqPhg5JcBP1gHXadORirZQySDjgbcqdOvgHKvl0mcqC6BaFbaIQLZZWYvv+fUI5rBBJvrnfvODOXQucPT10Qrd5zcyY2QPvRWyrnBmAbuXsmkD+Pnm/Ume4WFnr+V3B27dzobgA8IkT0Kvya4nJ4NYbl5HdKJx8PjGUuhWEB+Yh24hdH8gdqA4FqGLv1XMOIk6L+TPj3g/eR0NNcsbVKnlYqPQOWJdF37tfYJFRvzA1KuA3pNZxps4ENCu8e9AODTy3I3yQ42IUODqmQMxb2wv88Ytyxix5HQxWlNrtosdoWfkmImH3+BgnnzEpjXCzhHIjq70voBZaYmfh1vY8XNKJJaLJMMhX/zNxMja4f8XW+apPuqHxvB2/pBYPXQrofsDRuX1B1k3nac42iFoUdYyhQ6YbSR/hllNn/kXdi6rqiXE8PlNtoQNWcoUejCPBS3FQU76cbRylw4HznyUTVQlQqYQOcTAGK8zYq/JricnQyxrIRFCd6LQAW02QwmxxppsLpZv7MRa0ifCkjw/Yv3h1yLUJG9Q4yl0WSDaqUL3CfYLP25Lvbknm0yGVorRKQh9+wGW7jRnlES97vgA6H8MmzmPX3wrWdnl8mbkGGolI1cgd5vAYkyFbqn0PsGTFgmd+Jl/TiOMGKx+uCxvVqzcPr+xfiEAnP1Y9P6nCOtKcqvBZ7FcZAqdB/bs7AYrMnLt1bOpRyCWP2B+MPlvk01vGnai0LmHLqnqmfnAMTfIyx7IYuouI0uu+u3mWLFCptDt6okMsnLrROOALHk5HSl0PtuixMqLSehtpBG90ZNcF1PdEKYDdqzQ4xB6rNiA6KHz93pjrMUbxKBoe02ZnQA6heWy/QBTjgO6SipdUzUjwYws4+JbV8ZpOCivsMFc4+EL5iRP6AGJ5eIPAEPnsAoyWVB/voARQBMnUMrrAXznn0B/wdc/Vhsp12ui+fs8RnD6n6Nn9bPCJyN0i+Uy5x7NQxeConYYPs94b1XoYjqg33I+sTzig8nPZT0n8bNUScCsjOwUuhgULdSyOqwP+KATjayLQKbhicoIPZYqNZWTE7qgPp3Mia6fR0aWFuslFhJS6DxtUULosqCyvq2NhC6bqpbDJAKEax6X0LVrJD6rMvKO9btEi8uq0InPPE+7uH8a4YjQCSFzCSFfE0K2EEJuk2zvSwhZTgj5ghCyjhAiyTFrP+w8WI/8rIC+TqgJ4VZGRoFsc84oR6iJEXqvCdHfzcgxKpmo0GUBotHnxiZ0q6LzZTDv9o4qNrGU/rlPGFKdYXwvkAmMPNN8nIGzWJaCqYvvwH6wlgOItly4Srv8DWD6tWy7aLnY4YJ/sfgAwK6faE34AzYNSAyFrisjy8NCfGzukrMWsPUq9bJbfrM1KDrlKmDwifKyX/ISy7oAWH3hWQuy6+hkiTzxvJGQ8T7emqsiYip0J4QeYPfASd67nrYo1GMnvbE2E7p2b2WWi7VuxCqXeD2ufBu46AVzvfEHgMsWG/+f8vs45ZIERcVXSo1eonU91TQhbo0ghPgBPArgFAAjAVxICLGmbPwSwAuU0gkALgBgWa23fbGvugm9CrPlw/zDWoqTqNDFEWn1B9g+vcZHfzcjGzqxWT10EdeuZBkjtpaLjYcugy8gELrfub1x3lPAj1eYVYyT0Yi8glqDogDLeeaL8Pr8zggdEILHuZLskWzJ+WIRuk0V9fnZPR1/kfmhjRcU9fmdKanj/w84UUthlfrlTgmdB/zC8edsl6HNhB507p/L0hYdiYIEYgKxvi/LzpJ56NbPOcTbWljGesBWiHVt6MnOyuXzC0JEEBg0wu7rlKuAnzpckLyd4aRpnQpgC6V0GwAQQp4HcCYAcfltCoAnsxYCkMxx2n6oqG1GtwKbB5mPcgxkCQpdsFx4gFScKTCnK8sxFS0XU4DUQujc55V5gIA5j1X/LEbqI59HxRcA/A6JY/Q50cdNRDlZ0xYBFhDUs28yDB84nn+cr8UyZPnwgUw2ha5f0oDw92I32K5LbEdmUQRkUejE7+y6DBCWSZORh1MfnF+/iLZy/bl/ix7yHgtSQk/QcnHin/PjxlLo5zzJbK4+RwF3C7GcRIK80vPGCoqKmVE2IkA/jgMhIMab4gkTseH0CfVH30bZM9/WBi2FcPLE9wYgLDGDcgBHWfaZD2ApIeR6ALkAJLMWAYSQqwFcDQB9+6aui7K/pglDutmkDIVbGVmJk9vLCD23KzB7PtB9DFuzErAERQVCtz7gvNLFesijFLpNJTApdOE7jkcHCsd1MtWufl6J+hEHBcXr7orgg6hkc+fwrr8Ty0X8LVaLw45EbBU6V1g+YMZtLAVz/EXyfe2+mwzEoCgh0dPjxkNbs1xyShKY6U/ioYuEOlYbjGO9F+L1+e4zbK4bvvC4E5gWZNbKUDKYTbJmqhsJeOh210b8XqxMJUAeFNXLICj0tjZoKUSqgqIXAlhIKS0DcCqApwmJvqKU0icopZMppZNLS1MzqioSodhf24zutgqde+h2Cl1rq3JKWJBxiNAWZQgL24rdLutDxkkkEUIXh5qb9rMq9ASnE5BN5hQTksmreNdX9Ob9cdSRiK7acl7Vu6K3cYKwO55I6Mmkw9kGRQWFlVvCvHLHWQmSXpLDjpPZTkgiaCa7BokQ+ukPAec84excsiwXaXqg5XeIdW7E6SzfPBGIgeNAJnD0DUag20TA8SwXkdBtrrUpI8qpQvdHiwziY5cpEo4dWO1gOJEeuwH0Ef4v0z4TcQWAuQBAKf2EEJIFoCuAODNdtR1LN1YgHKHoXiB5kCNaTq0/aFHoNcYEVHxmPrEbrKvybIOkCYnudnH4EyD07GLggmcNbzpqP3/0SjCJgH+n/wxg+GkJfFF4AHiMIdsm2BpvpCP3irtog7wGnwQMmKl9V+ahC+8JkROWdUCVLaFbHnQ9KOqgkbCDVOEm4aEnc+62euiJjF7UBxYJ9diRhy4p43Wrna9uL2a5UIuFYcpyscmM0o/jRKEnIEzEOqNbjxIP3WMKfSWAIYSQAYSQIFjQc5Fln28BnAgAhJARALIAJJCblTx+8RKbwbB/iURt6SMJAxaFXmcMZuGDisRhwZyQApnGBEYlg80ZGlcIq8DzSjcrKgHIgDhsu9/R9oRE/Ib37PMJFdCp5aK9DpiZWBoVkRC6OGxffJjiebI+P5sJ77LX2f8Xv2jke+sKPYaFE5XzC9Y48cWPY8GJQk8UXQYYAVIOx1kuYh56Mgo9FnGlOk2Ok5Tw22LVaQ5ZQ9V1sBFLift9QaHz5Q71bTYxoXhD/x1ZLg57v2KdMY0BoJpC9xChU0pDAK4DsATAJrBslg2EkLsIIWdou90E4CpCyFoAzwG4jFKnNb5tyM7wY1SvAswYIvHQdesigynDUBP0lcKthC6qsAueZcGr3K6sCzm/WpsJUYh095li7M9v6Ohz2L4y6JUxzkNorcCJWi78qjtV9/w2ibeLjzQVFZaobJysNNNvunz1c974meYosZCWTE0TEj3viwxR1ysFCh1gUxCYDus0KCpYLk4UtRVtHViUCKyWy83fsFTZeGhz2qIw9F8ndEngNyUKXagfjidIE8rjcg/d0Z2glC4GsNjy2a+F9xsBxJjUo/3Q0BrG7H7FNimLXKFnmKfebK41psPllouo7PJK5cErWQ61U8jmU5buJ1SOZAidP4xORzLKwBffFT1mUeG2ZUQcJ3TTYCLLNbFToE4IMd5DmuzDF3U9E1Xo4eQIWDbHeCKWS0KwBkWTmBEyqdMKWS5RCt3yPHDE9dAdWC5xIZnYTfTQeazJSwrdzaCUoq4phLxMmwqlWxcBw7s9uJV5532ns5tSqc3E6GTgRVKEzlt2TugJEI4vYFRAp2TAlaOsqx7zvMLxBx3PXouEOWD48bIK26YMecMZq3x2D2MyBDbauuhyklXe+tB2mOXSgYRunW3R6fFTNvQ/FH1eO3KPZ7nYkWzCAslyLHGkqKy8aYan53JpDkUQilDkZdn8DFGhc+z5gr2WTWaDDw5/y26yk1ZWH2jg8LLdtksSTElEoScwsIiDSrJWEsXMW9hMiuK8MX6B0NsCfSh/jGuo51lbP0/wN92yVQh282MmeV2iGiCHhM4bEBpOzvJuax56QrCsWOTYkkhRHjpXvMRn8xvFUZ8yy0XYbjsgLQGhI5t6WRy5LJbXJfA0odc2sRYy31ah89n4MoyLv+tT9tp9FNBlICN0xwu4WtS2Hc5+gq3/mSVkzjj20C0KPWH1k6zlIpTL54+eBIyXo62EzhV6LGK1I4hEHxzZ8nfJko/1PiSs0JNNW4xBXO2i0G0m54qFVHnoXICZiNnmfbKWSzI9NFuF3hq9Pc1wT9OSBOqaGaHbK3RhAQRe6b54mtktmfmM0IEEBl5oiFcpxn0XOHuB+TOn1ok1KJqsvZGo5RL3eKkidO1BDLfY79MWDz0ekj1GFGklYbkkFRRtYx56QrB46I4tlxQN/ed1gvjZ1AvZxeZVtUyiI8akZUCKro2g0PmhxbqpWy7uIXRPK/Q6XaHbkJeYthgWLvrRWgodz21OVM3yyjTyTGNtQqffiVfRrN27RJOFaKIK3eHx+URVsmXCEgFX6I4I3QKnxHHVO2wRbdMx22i5WC2ihCfnSjIoyr8jpk22m4cO89D/ZJbJS+q8vNFrNf4fMBP4+Q5tgRrLftb30u0pyADS7UuJN098wnz8itBTgtpmdkHtFbqQtmgaGKNZLHwkZSgGuYggFsvlO/90Xthk0xZ5euWUq5ydRw+KJnhr4z0Ao84G3voVUNfG4QXiMmK2ZbFJy3P6kPaeZL8tVZYLXzIwHsSBRcnmjVtTYdtboVtTPeMhZUFRiSdtEjg29ov+WTsZDnE9dEXoKQFX6LZZLmFhMilr9gggEHoMcpEhqbRFoSLE3M+iBrIK7HPbpYixoIP0fNwKivMwFPUB5j1oLJuXLHRCj6XQU+Shp/IYooWVyP2wzuWSCrRbHrrPMjlXjOMTnyAe2hoUtXroDpR2PIWeEkgSDFzuoXub0DUPPd9OoUeEJcpk3aakCb0NQ7gT9dATRaKWy3G3sp7MhIvj7ysuxJEsElHoKfXQrQNDEkSyKtR0vlQTensERYWRorHq6u37gN9qvcdU5aFHZIRuR+4drdCtlh2RN0BphqcJfXNFHfw+guJcm9Q+MW1RRpQdqtAdWi6ynkRC4KrCIaFnFwGnPZDEeZLE5CuAvWuNOIYMsaZFaCuSTltM8ntOUukSPmY7KfRELBe7OVaSgR4UleR12zWIHaHQZSnAprlc3DewyLOETinFy1+UY9bQUhRkxQmK+qyWi0WhJ4qkCD3JLJdEoSt0l97a7KL4sQdbDz0FD2wqiDmh76U4UGc9ZioRNR96moKipikf7NR6R1gu/LiyuVxsfP40w6VPfXwcbmhFRU0zrplpMw86IE9bBIwbkCyhJ3MDkx1YlDASVOhuwfWfS9Ll2iNtsYMfPtIelkuqlbl+YCSVttjW+xIzDz2RoKjD63LtZ85mkUSsLBcS/ZkL4FlC31/LFoGwXakIMLJc/IHoATtA8jnV7Wm5tJXQE05bdAlKBhnvbRf/SMGD09EPX3so9JTPssgPyxW6Aw/d+r22nlcMMtoq8RRZLqXD4u8DyBs2IhFmLlLo7nHzE0SlRuileRJCr9rGVq0XLRcZofPPxjsICAJoU2AtmTz0Nnno7qlkCcN2Lpc2EEe7DZePd14bQkrZMVMJi4feXg2H9NR+edqidcZN/X0HWy7WKTxSPogpNfCsQq+sY4HMbrKFLR6awBZXmPUL9r9d2iIA/PpQ4kTRptkWExz6nyj06XM9ptBFuNFDT8X5Uh0UTTWiFHoHEpU4UMeuVxOvceyItEWZQvfYikWuxP4aTaHn21guVVstaYtisDHJm2EdWJQI/E4tlzYGRVMxfW660ak8dA8FRROdnOsHS4CdH6fm1D6/jeWSxiwXWRl8ErHhIsvFs4ReWduM7Aw/coOWi8m7bYAlbbGtVoaAZCqOrGWPtV+y50l2+lw3wXZgUSrSFtv40AfzOvZ8HXVMflwKGGmLcQi97zT2l5Jz++Vpi7ZqvQ1B0UQh62XZplamF54l9Kr6FpTkBaMXtmhtMN7/T8t1tg79byuhtwWJWC5tqaBuTVt0gkRGBzo/qPbahoW0rv888UB6PBJKBu1quWirBnWkfw4w5asrdDtRk66h/7Ieg1LoKUV9Swi5QUvxKzYCdRXRO/szXBCVdqh62tra64MhPHtr29dDbwvETBynaJe0xfa2XGj7qV3bU9t46E5y0mN91haYBhZZgqJKoacWDS1hZFvtlgXT5TvbjRRNGG2o5E4Ha7SZiD2ahy7CzkNvy4PT0QSlnzcOCbX1mKmEOB96h2cD+YXpaG288g4f+i9On2sZ+u9SD9094dkE0dgSRo6V0O0QlbaYhhvgNLe3rZXDq3noImzTFj1YXdslKNqejRNNk+Xit1mCLpGgaAd46NKBRe6pl+4pSYJocEroRf2AjCxLpDoNhM4XpR52Wuz92ly2TmC52K5YlCaV3Ra05+RcqYaYtugWy8WkhC37y46RSsRcgi7dFq4cnn3qG1vDyLZ66DLMuIm9pjsoWtCTrXGZ3SX2fm320JOcD91NsPXQ3fPgOIanFLqQtpgWyyURD70Dg6LSZ9KdQ/89rNBDyMkQLqTdCjJ67rhYSdJEdrld43fP2lo2nkbWGQi9PfLQE10Bqq1o15GiqZ4PXfDQ05HlIlsBqD2G/juGOMAqRl10kdDw7FMfFRQNNct35BdeNjlX0mhHUmhr2S54Fji4FQjYTCnsBbSLh66Cog4ODCPLJZ1BURuyTNd86NJ1XZVCTymigqItdTZ7WiemR/JBjHxtDdJEF5VOBG2tHJn5QK/x8fdzM1RQ1PkxUwnic6GHnkaFLvPQZedyUb30pEJvCUUQilAzodstXtyW4fpWzL0XKJvK2DRX+gAAHpNJREFUFrBtL3jZKkkV7Dx0Fykhx/DS5Fx8YFFaLBc/0KrNjuqWPHRZGWQTlylCbxsaW9jwflNQtLnWZu82zJBoRTAXmHhJ248TCzlxgqZHAtrTQ+9opGrkr4iOmMslHZaLdD70BIb+p7wRkuShy8rlIqHhwScEaGhlXlu2GBS1I3TdQ3fPRY+Jon7pLkH60a4jRdMYFHW7h25KW2yfU9if22fjoadx6L8+c2k8y8U93OJJhd6gKXSz5WLjoVtHeLkdhWXpLkH60R4e+qn3A5l5wJCTkz9GMvDS5FzifOgdrdBNc7k4UOUdOttinEFMLhKLnlTohuXiQKEjhR56RyAQYwWmIwW2A4vaUF0Ly4Bznuj462ubpdGWY6ZgorFYx03HSFGT5eLk/nfEbItC2uKpv2fxs+6jo8/lIrHoEZYzo7FVotBb6+U7R600ouB6dCYP3UtBUQiE3tFZLnZD/01Il0InQO9JwJVvycviIm7xJKG3hNhoyMyASOiN8p1TmeXSUfjRx+Z53Y806B66zedeQntMn9uea4oCaQqK2qQtmvZJU9qitCwqbTFlaAkzQs/wCze4xUah63no7rnocdF9VLpLkF7YEZ+LlJBj8AWQU0mS7TVSFGm2XEwjM6U7CW87cGCRtCjuVOgeYjkDXKFn+IXix1PoXpzY6UiFIw/VQ0g1AbentQAAkTQodCdrr6YrKCoti8pySRlaNYUeDDgg9HQN+VZIHp3JQwfs0zDberxUQ7dcwh0vgGJZGCf9hs1RlK750KUc4mGFTgiZSwj5mhCyhRBym80+3yGEbCSEbCCEPJvaYprRGpYp9Ab5zl4lgSMZ7ZqHngbIli1r0/HaOSgaCaPDhZBpoI7l9x1zA9BnKjo8KHrBs8C4C4GC3rHP5SWFTgjxA3gUwEkAygGsJIQsopRuFPYZAuAXAI6hlB4ihHRrrwIDQGuItZxmhW5H6Eqhew6daS4XwIMKXVkuANicSGc/llxZ0gQnJZkKYAuldBultAXA8wDOtOxzFYBHKaWHAIBSuj+1xTRDGhS1I3RluXgPndZycflI0XSmLdouDG3aSXjbEXnoMRCrR5FGOClJbwC7hP/Ltc9EDAUwlBDyESFkBSFkruxAhJCrCSGrCCGrKisrkysxjKBoMJGgqIJ3YOdJusirTAg+mwYqWbRXnXarhy7dx0WE7iLLJVVNSwDAEACzAFwI4K+EkCLrTpTSJyilkymlk0tLS5M+WZSH3lQNVGyU7+xVVXdEwyYzyav30iuWSzrTFhurhGI4sFyk2zuyfng3KLobQB/h/zLtMxHlABZRSlsppdsBbAYj+HZBVJbLP88CavfY7K0UeqeB1wnd7UFRXaGnYT70qu1CORxYLtLNacpD95hCXwlgCCFkACEkCOACAIss+7wCps5BCOkKZsFsS2E5TWgJs6BowKdd1D2f2++sLBcPQyl0+fHaq04LWS4dfa0bDgjF8IBC9+rAIkppCMB1AJYA2ATgBUrpBkLIXYSQM7TdlgA4SAjZCGA5gFsopQfbq9Ct4QiCfh8Iv6h5PWLsrQjde7BbH9Y9D05C0FeKT7FCTzWxp3NyLlM5ksxyUgOLnA0sopQuBrDY8tmvhfcUwI3aX7ujJRQxZ7gU9wfq9gl78GlA4V1VpyDx0D3aOHvGctGOS9Og0E/5PfDGLeZyRMFFCt3kobuHY9xTkgTQGo4gQ8xBL+pj3sHUenZMmRRSCLtJkbxO6F4JikbSkOVy1NVCMbxgubiTOt1ZqjjglosOPpPitGvZa3tMWarQgYg15BpARm6HlSQlSHnaIlfSnWg+dFM5PKDQXSouPDmXS0uImof9R8LMdinWlm+zy1e96D9AdlQ2pYLbwO9fRnb0trMe04aBewheU+jpGClqKobHPHQXwZuEHo6Yh/3TCAtMyEbkie+HdvDyYwrJoWQwMOsXwPiLoreNv7Djy9NWpHqkaIfMh+5ChR7XcknTwCIXwZOE3moNivIgjk+WTeDOrpFCDBACzJLOAedNpHpyrnZDGtMWAXadaDj5NMB0BUVdBHc2M3HQKlPoPr+QHhZniLCCQkeivdIMU410e+jBPF4Q+fa4108pdHeWKg5awpFoD92k0FVQVMFFaLcVhtoJNJKeogZz2Gu4Rb7dVR66O++lJwm91UrolGoeusRycWlLqnAEQWoFtgUpzm7hME3OlYbnZvZ89prTxWYHN2W5uJNXPOmht4QiyAkKReezw8kUuktbUoUjCPoyiCkmgZSPFNXKly4PfdwF7M8ObspDdyk8eQVaw9QSFNXSrKTZBIrQFdIMz1guLklbtIWLCN2V18ezhG4TFFUKXcGNSPVcLu0Ft6Qt2kF56HHhSUJvCUcQkAVFZelhLm1JFY4geFGhu7GsbrJcXMor7ixVHIQj1Jg6FzAGFqksFwU3wmtpi+ny0ONCDSyKB3eWKg7CEQo/kXnoGqGbFpx1+UOk0PmR8iyX9oLbLRcXEbpLhaJ3Cd2q0O08dJdeeIUjCF6xXMS0RTeW1U2qWO91uWcudKCzEDqf7lNPDxM9dBdWTIUjC16xXLye5dKRaK9U1DbCXaVxiAil8Mk8dD2bQFkuCi5CyhU6J5MUq8N0rinqBG4qU8onXEsNPDmwKNpD51kuMiXkokqgcGQi1Qq91wRg+nXAUdek5ng6PB4U5Rgws32LAcBoVN11nbxL6DIPnUPloSu4CalWcz4fMOfu1BxLhLgEnRvh5Fm+6Wsgq7ADyqIUesoQoYCPWD10mznQXXbBFY5AeC0omo4l6JzASZnyYy0Yn0LworiMX9xVGodgCl34gE/OJV0Y2oUVU+HIgifTFt1IDS66fi5V6O4qjUOEo4KimqKgEkJ3/UOk0OnhNYXu1ZGiHQmd0NNbDCs8SegR2cAiOw/dbVdc4ciDZ9IWNSiF7gDuDIq6qzQOEaayPHQfDMtFzeWi4CK4tHseBa9PztWRcOk9dVdpHCASoaDWoCjPQ+eWi2lyLhdWTIUjC16xXMS0RTeW1U3PshpYlBqENdIORHnodpktLqoECkcmvGK5EBUUdQyl0FODcIQRevRIUdFyUUFRBRfBJ5nW2ZVwu+XipjIphZ4SRDSFbh5YRNlD03MC+/+YG4xtLrvgCkcgXJoREQVxYJEbnxs3lcmlCt1zA4u4QvdHDSwiQG4JML8aaKpJU+kUFCRw6cMfBbenLbqpTMpDTw0iEfYqnZyLQ1kuCm6CbCUtV8LlyQRuKpNL4yKeI3QeFBXXiI4OiqrJuRRcBNm0zm6E66eddlGZlEJPDXTLJdbkXGpNUQU3wWtpi1HvXQJXPcuK0FMCHhT1SQcWaXC90lA4ouCVuVzcPiDPTdfPpXERd5XGAaRBUX1yLg0qD13BTXDpwx8NlwshN5VJWS6pgTwP3Zpm5fKKqXBkwSuWi4o9OYdLG2lHpSGEzCWEfE0I2UIIuS3GfucSQighZHLqimiGnoceNTmXCooquBTEI5aLij0lAI8qdEKIH8CjAE4BMBLAhYSQkZL98gH8BMCnqS6kiJCm0AP+WB66WuBCwUXwokJ3feOTZlAtf9pl/OKkNFMBbKGUbqOUtgB4HsCZkv1+A+A+AE0pLF8UItxykU3OpUNVTAUXwaV+axTcHhR1E3RCdxe/OLlrvQHsEv4v1z7TQQiZCKAPpfT1WAcihFxNCFlFCFlVWVmZcGEBIQ895uRcynJRcBG8kuXi9rRFN8HDCj0mCCE+AH8EcFO8fSmlT1BKJ1NKJ5eWliZ1vrCdQjctcKEUuoKLoCyXzgfZ6mgugJPS7AbQR/i/TPuMIx/AaADvEkJ2AJgGYFF7BUb50H9doUfitJQuu+AKRyBcOkw8GspycQwPK/SVAIYQQgYQQoIALgCwiG+klFZTSrtSSvtTSvsDWAHgDErpqvYosGG58ALEu7Buf4gUOj1c9tDbQlmVCcCjCp1SGgJwHYAlADYBeIFSuoEQchch5Iz2LqAVUZZLPEJ3vSpS6PTQ0xbd9fBHQ1kujuFShe5o+lxK6WIAiy2f/dpm31ltL5Y9ouZDp2H26rILq6CgwyuWi/LQncOlhO6u0jhA1NB/fmFNk3MJcNkFVzgC4ZWgqMpycY78Hux1wMz0lsMCzy1wEbEO/Y/EUehKaSikGz4vKnQlhGKiy0DgJ2uBwr7pLokJniP0qDx0vetjo9CV0lBIN7yi0NXCMImhuH+6SxAFzzXDIet86CooquB2uHQip2gohe51eO6uRZSHruA1eGVyLpW26Hl4ju2iVizSPXS7CqgqpkKa4RXLRSyfPyN9xVBIGp4jdH3Foqg8dDuF7vaHSKHTw4tpi7nJTc2hkF54jtDD1qH/cfPQXf4QKXR+6Hag2+uiUL687ukrhkLS8B6h2w39Vx66glvhxelzFaF7Ei6vYdGImg9d5aEruB1esVxMCr1b+oqhkDQ8R+hRQVGVh67gdhCPWC5i8fhISAVPwXuEbhsUVQpdwaXwikIXn6GckvSVIx5Gn5fuErgWnhspGrFV6DYPi9t9S4XOD8/UQeEZsotJpRvzq9NdAlfDKzVNB1foAWseum1Q1OWqSKHzw+eR6XPVs+J5uLyGRSNsnZzLpdNYKijo8Irl4naPXyEuPMeC0dPn8iwXl3YRFRS8MlLU9Q2OQjx4ltB1hd7axF4zstJUIgWFOFAKXaGD4DlCj1qxqLWevWbkpqlECgpxoBS6QgfBc4RelB3EoNJcIyja0sBegznpK5SCQix4bfpcJY48C8+lLX5nSh98Z0of44NWjdAzFKEruBResVx4+YKK0L0Kt0uG+FCEruB2eG1yLkXonoX3CV1ZLgpuh1cUeriZvSpC9yy8T+h6UFQRuoJL4ZWgqC6OFKF7FZ2A0BtZDro/mO6SKCjI4ZWgKF+lqOvQ9JZDIWl4LigahZYGpijc3p1VOHLhFculbDJw3t+BYaemuyQKScL7hN5aD2Rkp7sUCgr28IrlAgCjz013CRTaAJf3AR2gpUH55wruhj45V3qLodD54X1Cb21UQRwFd8NLCl3B0+gEhK4sFwWXo9tIYMTpQM/x6S6JQieH9z10ZbkouB3ZRcB3n0l3KRSOAHif0Jtr1IK2Cp0era2tKC8vR1NTU7qLotBByMrKQllZGTIyMhx/x/uEXlcB9Dsm3aVQUGhXlJeXIz8/H/379wdxe/qjQptBKcXBgwdRXl6OAQMGOP6etz30UDPQeAjI657ukigotCuamppQUlKiyPwIASEEJSUlCffIvE3o9ZXsVVkuCkcAFJkfWUjmfnub0Osq2Gt+j/SWQ0FBQcEFcETohJC5hJCvCSFbCCG3SbbfSAjZSAhZRwh5mxDSL/VFlaBuP3tVCl1BQUEhPqETQvwAHgVwCoCRAC4khIy07PYFgMmU0rEAXgRwf6oLKgUn9NzSDjmdgsKRCr/fj/Hjx2PUqFEYN24c/vCHPyASiXTIuRcuXAifz4d169bpn40ePRo7duyI+b0HH3wQDQ0N+v+33347+vTpg7y8PNN+f/zjHzFy5EiMHTsWJ554Inbu3Klvmzt3LoqKijBv3rzU/Jh2hpMsl6kAtlBKtwEAIeR5AGcC2Mh3oJQuF/ZfAeDiVBbSFnxxi2Be7P0UFDoR7vzfBmzcU5PSY47sVYA7Th9luz07Oxtr1qwBAOzfvx8XXXQRampqcOedd6a0HHYoKyvD3XffjX//+9+Ov/Pggw/i4osvRk4OG6dy+umn47rrrsOQIUNM+02YMAGrVq1CTk4OFixYgFtvvVU/zy233IKGhgY8/vjjqfsx7QgnlktvALuE/8u1z+xwBYA3ZBsIIVcTQlYRQlZVVlY6L6Udwi3sVU2dq6DQYejWrRueeOIJPPLII6CUIhwO45ZbbsGUKVMwduxYnfzeffddzJo1C+eddx6GDx+O733ve6DaIu+33XabropvvvlmAEBlZSXOPfdcTJkyBVOmTMFHH32kn3PevHnYsGEDvv7666jyLF26FNOnT8fEiRNx/vnno66uDg899BD27NmD448/HscffzwAYNq0aejZs2fU948//nid9KdNm4by8nJ924knnoj8/HxH1+Wuu+7ClClTMHr0aFx99dX6b92yZQtmz56NcePGYeLEidi6dSsA4L777sOYMWMwbtw43HZblJOdHCilMf8AnAfgSeH/SwA8YrPvxWAKPTPecSdNmkTbjHfvp/SOAkpDLdHb7ihgfwoKnQAbN25M6/lzc3OjPissLKT79u2jjz/+OP3Nb35DKaW0qamJTpo0iW7bto0uX76cFhQU0F27dtFwOEynTZtGP/jgA3rgwAE6dOhQGolEKKWUHjp0iFJK6YUXXkg/+OADSimlO3fupMOHD6eUUvrUU0/Ra6+9lv7jH/+gl156KaWU0lGjRtHt27fTyspKOmPGDFpXV0cppfTee++ld955J6WU0n79+tHKykpHv4Xj2muv1X8Lx/Lly+lpp50W9xodPHhQf3/xxRfTRYsWUUopnTp1Kn3ppZcopZQ2NjbS+vp6unjxYjp9+nRaX18f9V0RsvsOYBW14VUnlstuAMKqzCjTPjOBEDIbwO0AjqOUNrehjXEOvmSWz/vjoxQUvIqlS5di3bp1ePHFFwEA1dXV+OabbxAMBjF16lSUlZUBAMaPH48dO3Zg2rRpyMrKwhVXXIF58+bp/vSyZcuwcaPu5KKmpgZ1dXX6/xdddBHuvvtubN++Xf9sxYoV2LhxI445hg0ubGlpwfTp05P6Hc888wxWrVqF9957L6nvL1++HPfffz8aGhpQVVWFUaNGYdasWdi9ezfOPvtsAGz0J8B+6+WXX673DLp06ZLUOa1wwoQrAQwhhAwAI/ILAFwk7kAImQDgcQBzKaX7U1IyJwi3AP5M9y8coKDQybBt2zb4/X5069YNlFI8/PDDmDNnjmmfd999F5mZmfr/fr8foVAIgUAAn332Gd5++228+OKLeOSRR/DOO+8gEolgxYoVOulZEQgEcNNNN+G+++7TP6OU4qSTTsJzzz3Xpt+zbNky3H333XjvvfdMZXaKpqYm/PjHP8aqVavQp08fzJ8/Py3TNMT10CmlIQDXAVgCYBOAFyilGwghdxFCztB2+z2APAD/IYSsIYQsarcSiwi1AIHEL76CgkLyqKysxA9/+ENcd911IIRgzpw5WLBgAVpbWwEAmzdvRn19ve336+rqUF1djVNPPRV/+tOfsHbtWgDAySefjIcffljfjwdhRVx22WVYtmwZeAxu2rRp+Oijj7BlyxYAQH19PTZv3gwAyM/PR21tbdzf88UXX+Caa67BokWL0K1bcinQnLy7du2Kuro6vbeSn5+PsrIyvPLKKwCA5uZmNDQ04KSTTsJTTz2lZ+FUVVUldV4rHOWhU0oXU0qHUkoHUUrv1j77NaV0kfZ+NqW0O6V0vPZ3RuwjpgjhZhUQVVDoADQ2Nuppi7Nnz8bJJ5+MO+64AwBw5ZVXYuTIkZg4cSJGjx6Na665BqFQyPZYtbW1mDdvHsaOHYtjjz0Wf/zjHwEADz30EFatWoWxY8di5MiReOyxx6K+GwwGccMNN2D/fmYElJaWYuHChbjwwgsxduxYTJ8+HV999RUA4Oqrr8bcuXP1oOitt96KsrIyNDQ0oKysDPPnzwfAMlnq6upw/vnnY/z48TjjDIO+ZsyYgfPPPx9vv/02ysrKsGTJEulvKioqwlVXXYXRo0djzpw5mDJlir7t6aefxkMPPYSxY8fi6KOPxr59+zB37lycccYZmDx5MsaPH48HHnjA6a2ICUK1SGxHY/LkyXTVqlVtO8gr1wJb3wFu2hS9bX6h9lrdtnMoKLgAmzZtwogRI9JdDIUOhuy+E0JWU0ony/b39tD/cAsQUApdQUFBAfD69LnhZhYUVVBQUOggnH322aZMG4DllFuDwumAtwk9pBS6goJCx+Lll19OdxFs4X3LRQVFFRQUFAB0CkJXlouCgoIC4HVCDzUry0VBQUFBgzc99IqNQFaBFhQtSndpFBQUFFwBbyr0BdOBP40Cwq3KQ1dQ6ACo+dBTPx/6rFmz0OaxOBZ4U6FzhJrV0H+FIw9v3Abs+zK1x+wxBjjlXtvNaj70zjMfurvQIswR8f/t3W9oVfcdx/H3Rxub7k5SY1zRpUyzyaKCf0bYLMnQVadRwh5FSB2sghCQPcik4CoDYaCCRdJtOMYUx3wwNh2bWBVt1cYH80Gb1trUGF1TdE5JzRKaOsLmlvS7B+eXy11MrCa5OZ5zvy843PP7nQP5fW9Ovjn3d+75ngdeFPWCXc7lg9dDv9/p06fZsGFDtn3+/PnsWf2WLVuoqqpi0aJF2XIJ+ZK8M/T+nv9fn1o08n4/vgGfDU7KkJybVA84k54sFRUVDA4O0t3dzbFjxygpKaG1tZV79+5RXV3NmjVrgKjwVXt7O3PmzKG6upoLFy6wYMECjh49ytWrV5FEX18fAE1NTWzdupWamhpu3rzJ2rVr6eiIynpMmTKFbdu2sXv3bg4dOpQdR09PDzt37uTs2bNkMhn27NlDc3MzO3bsoLm5mZaWFsrKyh46roMHD7Ju3bpHfj9Wr15NY2Mj/f39ZDIZDh8+TENDAwC7du2itLSUwcFBVq1aRVtbG4sXL37kn/Ewkp3QB/41+pTLU36x1LnJ4PXQo9K+tbW1HD9+nPr6ek6ePMkrr0SPVj5y5Aj79+9nYGCArq4urly54gk9q39YufWhx9A55yaN10O/X0NDA/v27aO0tJSqqiqmT5/O9evX2bt3L62trcyYMYNNmzbltU568ubQ+8OzSNeHcpM9nfGNxbkC5PXQR7ZixQouXrzIgQMHstMtd+/eJZPJUFJSwp07dzh1asTHLU+Y5Cb0ipXR67+9PK5z+eb10B9cDx2iTyB1dXWcOnUqO420ZMkSli1bRmVlJRs3bsxODeVL8uqh/6cf/vkxlFbAX5qhsg5mfX3iB+jcY8TroRemR62Hnrw59GkZmPnVaP3bL8U7Fuece4wkL6E751yMvB66c27czAzJb5iL22TVQx/LdHjyLoo6V4CKi4vp7e0d0x+5Sx4zo7e3d9SvcI7Gz9CdS4Dy8nJu3bqV/bqeS7/i4uLsTVkPyxO6cwlQVFTEvHnz4h6Ge8z5lItzzqWEJ3TnnEsJT+jOOZcSsd0pKukfwN8+d8eRlQE9n7tXunjMhcFjLgzjifkrZjZrpA2xJfTxkPTOaLe+ppXHXBg85sKQr5h9ysU551LCE7pzzqVEUhP6/rgHEAOPuTB4zIUhLzEncg7dOefc/ZJ6hu6cc24YT+jOOZcSiUvokmolXZPUKenluMczUST9RlK3pMs5faWSzkj6MLzOCP2S9IvwHrRJ+kZ8Ix87Sc9KapF0RVK7pKbQn9q4JRVLelvS+yHmn4b+eZLeCrEdljQt9D8Z2p1h+9w4xz9WkqZKek/SidBOdbwAkm5I+kDSJUnvhL68HtuJSuiSpgK/BNYBC4EXJC2Md1QT5rdA7bC+l4FzZjYfOBfaEMU/PyyNwK8maYwTbQB4ycwWAsuBH4bfZ5rjvgc8b2ZLgKVAraTlwB7gVTP7GvAJsDnsvxn4JPS/GvZLoiagI6ed9niHfMfMluZ85zy/x7aZJWYBngNez2lvB7bHPa4JjG8ucDmnfQ2YHdZnA9fC+q+BF0baL8kLcAz4bqHEDXwBuAh8i+iuwSdCf/Y4B14HngvrT4T9FPfYHzHO8pC8ngdOAEpzvDlx3wDKhvXl9dhO1Bk68GXg7zntW6EvrZ4xs66w/jHwTFhP3fsQPlovA94i5XGH6YdLQDdwBvgI6DOzgbBLblzZmMP2T4GZkzvicfsZsA34LLRnku54hxjwhqR3JTWGvrwe214PPSHMzCSl8jumkr4I/An4kZndzX3MWhrjNrNBYKmkp4GjQGXMQ8obSXVAt5m9K2ll3OOZZDVmdlvSl4Azkq7mbszHsZ20M/TbwLM57fLQl1Z3JM0GCK/doT8174OkIqJk/jsz+3PoTn3cAGbWB7QQTTk8LWnoBCs3rmzMYXsJ0DvJQx2PauB7km4AfyCadvk56Y03y8xuh9duon/c3yTPx3bSEnorMD9cIZ8GNACvxTymfHoNeDGsv0g0xzzU/4NwZXw58GnOx7jEUHQqfhDoMLPmnE2pjVvSrHBmjqSniK4ZdBAl9vqw2/CYh96LeuBNC5OsSWBm282s3MzmEv29vmlm3yel8Q6RlJE0fWgdWANcJt/HdtwXDsZwoWE98FeiecefxD2eCYzr90AX8F+i+bPNRHOH54APgbNAadhXRN/2+Qj4AKiKe/xjjLmGaJ6xDbgUlvVpjhtYDLwXYr4M7Aj9FcDbQCfwR+DJ0F8c2p1he0XcMYwj9pXAiUKIN8T3fljah3JVvo9tv/XfOedSImlTLs4550bhCd0551LCE7pzzqWEJ3TnnEsJT+jOOZcSntCdcy4lPKE751xK/A81zV55lFNbRAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/RR_25_3_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ef7440-e8a6-4543-b6aa-1439428b76b8"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382cf4a7-7f75-4d4c-d417-176e2f432755"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "edf3ccb8-b8e2-488e-d9f0-f13e115cf269"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7e4b7b3b-6872-43d3-bdb6-793460ee9caf"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_3_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/Rotation_range_25_3_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5e25dfd0-2dea-4765-b513-494697e59927\", \"Rotation_range_25_3_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}