{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WidthShiftRange_005_1_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+lWvOSea+PaCa3rZD1Apu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/WidthShiftRange_005_1_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6ecad0-b03e-4384-ab6c-294b80e98850"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 30 21:11:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a3951a-8f78-4826-ce12-a49b15c307bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fbb3d5-5747-424a-8c19-3e6d90e61399"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35b6fbe-2162-4a1a-d756-67e2ed4987f5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.05,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbd7b3b-7d21-4e44-c06b-19a2dbb3bfad"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 52s 466ms/step - loss: 1.9298 - accuracy: 0.3264 - val_loss: 14.7973 - val_accuracy: 0.0985\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.09852, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 19s 365ms/step - loss: 1.2787 - accuracy: 0.5457 - val_loss: 12.6962 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.09852 to 0.10837, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 367ms/step - loss: 1.0141 - accuracy: 0.6608 - val_loss: 15.1800 - val_accuracy: 0.0468\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.10837\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.8125 - accuracy: 0.7308 - val_loss: 11.2396 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.10837\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 19s 370ms/step - loss: 0.7275 - accuracy: 0.7491 - val_loss: 6.1459 - val_accuracy: 0.1970\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.10837 to 0.19704, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.6221 - accuracy: 0.7899 - val_loss: 6.6860 - val_accuracy: 0.1995\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.19704 to 0.19951, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.6141 - accuracy: 0.7972 - val_loss: 4.3830 - val_accuracy: 0.3276\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.19951 to 0.32759, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 20s 373ms/step - loss: 0.5324 - accuracy: 0.8167 - val_loss: 4.1602 - val_accuracy: 0.3177\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.32759\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 20s 375ms/step - loss: 0.5147 - accuracy: 0.8240 - val_loss: 1.2524 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.32759 to 0.61576, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.4670 - accuracy: 0.8484 - val_loss: 1.3071 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.61576\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 20s 377ms/step - loss: 0.4265 - accuracy: 0.8593 - val_loss: 1.2882 - val_accuracy: 0.6256\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.61576 to 0.62562, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.4023 - accuracy: 0.8697 - val_loss: 0.8301 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.62562 to 0.72414, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.3832 - accuracy: 0.8654 - val_loss: 0.6896 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.72414 to 0.79310, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.3207 - accuracy: 0.8916 - val_loss: 0.7298 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79310\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.3500 - accuracy: 0.8819 - val_loss: 0.7345 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79310\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.3119 - accuracy: 0.8910 - val_loss: 1.0100 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.79310\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.3197 - accuracy: 0.8849 - val_loss: 0.7090 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.79310 to 0.80296, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.3103 - accuracy: 0.8952 - val_loss: 0.7548 - val_accuracy: 0.7709\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80296\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.2505 - accuracy: 0.9160 - val_loss: 1.0521 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.80296\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2595 - accuracy: 0.9099 - val_loss: 0.6175 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.80296 to 0.83990, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2643 - accuracy: 0.9093 - val_loss: 0.5539 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.83990\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.2383 - accuracy: 0.9245 - val_loss: 0.6809 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.83990\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1827 - accuracy: 0.9385 - val_loss: 0.5681 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.83990\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1926 - accuracy: 0.9294 - val_loss: 1.6999 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.83990\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1573 - accuracy: 0.9501 - val_loss: 0.6829 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.83990\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1551 - accuracy: 0.9458 - val_loss: 0.7306 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.83990\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1992 - accuracy: 0.9263 - val_loss: 1.3891 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.83990\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2362 - accuracy: 0.9166 - val_loss: 0.5784 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.83990\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1926 - accuracy: 0.9367 - val_loss: 0.4936 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.83990 to 0.85468, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1886 - accuracy: 0.9354 - val_loss: 0.9328 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85468\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1323 - accuracy: 0.9531 - val_loss: 0.5573 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85468\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1117 - accuracy: 0.9677 - val_loss: 0.5454 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85468\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0930 - accuracy: 0.9714 - val_loss: 0.4454 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.85468 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1029 - accuracy: 0.9659 - val_loss: 0.8756 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86700\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1640 - accuracy: 0.9421 - val_loss: 1.2062 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86700\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.1489 - accuracy: 0.9464 - val_loss: 1.0462 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86700\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1670 - accuracy: 0.9440 - val_loss: 0.7004 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86700\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1166 - accuracy: 0.9574 - val_loss: 0.6200 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86700\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.1135 - accuracy: 0.9610 - val_loss: 0.7903 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86700\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1512 - accuracy: 0.9452 - val_loss: 0.6130 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86700\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1216 - accuracy: 0.9598 - val_loss: 0.5017 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.86700 to 0.86946, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.1071 - accuracy: 0.9647 - val_loss: 0.5214 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86946\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1301 - accuracy: 0.9549 - val_loss: 0.6728 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86946\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0965 - accuracy: 0.9671 - val_loss: 0.5836 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.86946\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1040 - accuracy: 0.9635 - val_loss: 0.5978 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.86946\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 0.5408 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.86946\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0774 - accuracy: 0.9762 - val_loss: 0.5115 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.86946\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.1081 - accuracy: 0.9586 - val_loss: 0.8429 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.86946\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.4486 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.86946 to 0.87685, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.4102 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.87685\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.4212 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.87685 to 0.88424, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.4896 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88424\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0667 - accuracy: 0.9744 - val_loss: 0.5651 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88424\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0590 - accuracy: 0.9775 - val_loss: 0.4656 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.88424 to 0.89409, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1022 - accuracy: 0.9665 - val_loss: 0.8197 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.89409\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.7792 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.89409\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0636 - accuracy: 0.9781 - val_loss: 0.5301 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.89409\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1137 - accuracy: 0.9592 - val_loss: 0.6817 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.89409\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1228 - accuracy: 0.9622 - val_loss: 0.7908 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.89409\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1051 - accuracy: 0.9653 - val_loss: 0.9356 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.89409\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0699 - accuracy: 0.9799 - val_loss: 0.8058 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.89409\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1503 - accuracy: 0.9513 - val_loss: 0.6418 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.89409\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1205 - accuracy: 0.9598 - val_loss: 0.9844 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.89409\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0801 - accuracy: 0.9689 - val_loss: 0.4866 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.89409\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0485 - accuracy: 0.9842 - val_loss: 0.6529 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.89409\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0951 - accuracy: 0.9689 - val_loss: 0.9096 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.89409\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.5674 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.89409\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.4054 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.89409 to 0.90887, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.4702 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.90887\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.5083 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.90887\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0587 - accuracy: 0.9842 - val_loss: 0.5533 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.90887\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.5832 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.90887\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0685 - accuracy: 0.9793 - val_loss: 0.6457 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90887\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0748 - accuracy: 0.9738 - val_loss: 0.5955 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.90887\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0490 - accuracy: 0.9829 - val_loss: 0.6428 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.90887\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.6060 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.90887\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.5034 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.90887\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.4425 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.90887\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.4180 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.90887\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.5583 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.90887\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0782 - accuracy: 0.9787 - val_loss: 0.7172 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.90887\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0834 - accuracy: 0.9714 - val_loss: 0.6544 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.90887\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0458 - accuracy: 0.9817 - val_loss: 1.0045 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.90887\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0450 - accuracy: 0.9836 - val_loss: 0.9267 - val_accuracy: 0.8153\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.90887\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0695 - accuracy: 0.9744 - val_loss: 0.6510 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.90887\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.4789 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.90887\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.4574 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.90887\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.4440 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.90887\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.4313 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.90887\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.4313 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.90887\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5742 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.90887\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.4860 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90887\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.9657 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90887\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.5370 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.90887\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.6379 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.90887\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0881 - accuracy: 0.9695 - val_loss: 1.0262 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.90887\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1027 - accuracy: 0.9702 - val_loss: 1.4924 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.90887\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.6707 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.90887\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.6834 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.90887\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0379 - accuracy: 0.9890 - val_loss: 0.5865 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.90887\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0279 - accuracy: 0.9933 - val_loss: 0.6005 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.90887\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.6548 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.90887\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.4935 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.90887\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 0.5977 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.90887\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.6215 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.90887\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.6058 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.90887\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.5536 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.90887\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0286 - accuracy: 0.9890 - val_loss: 0.6255 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.90887\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1150 - accuracy: 0.9677 - val_loss: 1.6127 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.90887\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1437 - accuracy: 0.9555 - val_loss: 1.3450 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.90887\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 0.4237 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.90887\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 0.4464 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.90887\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.5826 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.90887\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0363 - accuracy: 0.9854 - val_loss: 0.5082 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.90887\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.4600 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.90887\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.3879 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.90887\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.5760 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.90887\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0141 - accuracy: 0.9933 - val_loss: 0.3838 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00118: val_accuracy improved from 0.90887 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 1.1147 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91379\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0498 - accuracy: 0.9866 - val_loss: 0.5266 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91379\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.4549 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91379\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4167 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00122: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.6659 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91872\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.6840 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91872\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 0.9867 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91872\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0717 - accuracy: 0.9762 - val_loss: 1.2970 - val_accuracy: 0.7488\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.6382 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.6511 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.5403 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4864 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91872\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4562 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91872\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4187 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91872\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.6723 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91872\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.3885 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91872\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.4452 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91872\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5036 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91872\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.5971 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91872\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.6869 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91872\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.6706 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91872\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.7335 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91872\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0435 - accuracy: 0.9829 - val_loss: 1.0827 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91872\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0402 - accuracy: 0.9884 - val_loss: 0.6230 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91872\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.6845 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91872\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.3674 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.91872 to 0.93103, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.4249 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.93103\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.7813 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.93103\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0466 - accuracy: 0.9836 - val_loss: 0.9110 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.93103\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1030 - accuracy: 0.9732 - val_loss: 0.9882 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.93103\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.7117 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.93103\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0433 - accuracy: 0.9872 - val_loss: 0.8038 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.93103\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0453 - accuracy: 0.9878 - val_loss: 0.5935 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.93103\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 0.5593 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.93103\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.4409 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.93103\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.4604 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.93103\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.4896 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.93103\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.5127 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.93103\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.5461 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.93103\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.5916 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.93103\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.6148 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.93103\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.6976 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.93103\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.5544 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.93103\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.5516 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.93103\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.4206 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.93103\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4772 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.93103\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.4166 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.93103\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.93103\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.93103\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4036 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.93103\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3726 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.93103\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.93103\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3331 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.93103\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.93103\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.93103\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.4878 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.93103\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.8397 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.93103\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 1.0740 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.93103\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1008 - accuracy: 0.9744 - val_loss: 0.9787 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.93103\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0705 - accuracy: 0.9787 - val_loss: 0.8483 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.93103\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.6410 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.93103\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.4324 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.93103\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.6098 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.93103\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.4338 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.93103\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.5491 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.93103\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.5412 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.93103\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.8689 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.93103\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0501 - accuracy: 0.9884 - val_loss: 0.9458 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.93103\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.6261 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.93103\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.7475 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.93103\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.6276 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.93103\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.4817 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.93103\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.5299 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.93103\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5044 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.93103\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5001 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.93103\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4208 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.93103\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4748 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.93103\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5514 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.93103\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5251 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.93103\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4975 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.93103\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4353 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.93103\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.8086 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.93103\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.5471 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.93103\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.4730 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.93103\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 0.8501 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.93103\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0509 - accuracy: 0.9829 - val_loss: 0.7751 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.93103\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.8068 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.93103\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5718 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.93103\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.5620 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.93103\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.5482 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.93103\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.5399 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.93103\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.4801 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.93103\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.7194 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.93103\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.9226 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.93103\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.4392 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.93103\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.5300 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.93103\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 1.3275 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.93103\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0839 - accuracy: 0.9756 - val_loss: 0.5659 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.93103\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.6257 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.93103\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.6655 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.93103\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.5047 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.93103\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.4653 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.93103\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.5705 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.93103\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4880 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.93103\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4671 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.93103\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.93103\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.93103\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4768 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.93103\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.7322 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.93103\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.7418 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.93103\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.4880 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.93103\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.6136 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.93103\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.5794 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.93103\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6416 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.93103\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.5945 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.93103\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 21s 396ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 0.4649 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.93103\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.4989 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.93103\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.7770 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.93103\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5378 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.93103\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5853 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.93103\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4591 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.93103\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.93103\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0098 - accuracy: 0.9951 - val_loss: 0.5731 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.93103\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.6080 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.93103\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.5913 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.93103\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.6937 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.93103\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.7265 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.93103\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.7324 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.93103\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.6166 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.93103\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5271 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.93103\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4451 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.93103\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4659 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.93103\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.5310 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 0.93103\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.93103\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 9.8387e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.93103\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 3.0685e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.93103\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 3.6565e-04 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.93103\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 0.5886 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.93103\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0693 - accuracy: 0.9848 - val_loss: 0.7465 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.93103\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0462 - accuracy: 0.9829 - val_loss: 1.2806 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.93103\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.7441 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.93103\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0191 - accuracy: 0.9915 - val_loss: 0.5547 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.93103\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.7987 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.93103\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.7023 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.93103\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.4759 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.93103\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.6545 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.93103\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.5296 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.93103\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4855 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.93103\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5483 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.93103\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4878 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.93103\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.6795 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.93103\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.4833 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.93103\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4936 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.93103\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.5502 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.93103\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.93103\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.93103\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 5.5872e-04 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.93103\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.93103\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4931 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.93103\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4586 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.93103\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4447 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.93103\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.6098 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.93103\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.6268 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.93103\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0403 - accuracy: 0.9933 - val_loss: 0.8544 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.93103\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0431 - accuracy: 0.9854 - val_loss: 0.8952 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.93103\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.7125 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.93103\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0471 - accuracy: 0.9866 - val_loss: 0.7220 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.93103\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.9532 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.93103\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.6173 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.93103\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.5275 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.93103\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0105 - accuracy: 0.9957 - val_loss: 0.4205 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.93103\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.93103\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.93103\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.93103\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3825 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.93103\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 388ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3956 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.93103\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.5080 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.93103\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4250 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.93103\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4786 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.93103\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.8084 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.93103\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4504 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.93103\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.6083 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.93103\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.5905 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.93103\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.5203 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.93103\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5757 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.93103\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.6097 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.93103\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.93103\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.6547 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.93103\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.6318 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.93103\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 0.6103 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.93103\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.7275 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.93103\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 1.2020 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.93103\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.6209 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.93103\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0184 - accuracy: 0.9927 - val_loss: 0.5555 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.93103\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.3766 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.93103\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.5285 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.93103\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4643 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.93103\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.6067 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.93103\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.5327 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.93103\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.6600 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.93103\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.5609 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.93103\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 6.2058e-04 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.93103\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.6352 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.93103\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0145 - accuracy: 0.9933 - val_loss: 0.4988 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.93103\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5409 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.93103\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.5767 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.93103\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.5030 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.93103\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.5442 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.93103\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5651 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.93103\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5652 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.93103\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.3947 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.93103\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.93103\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.5413 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.93103\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6777 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.93103\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.7163 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.93103\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.93103\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.4428 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.93103\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 0.6191 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.93103\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.8057 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.93103\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 0.9932 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.93103\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.6462 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.93103\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0324 - accuracy: 0.9866 - val_loss: 0.4631 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.93103\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5502 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.93103\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.5808 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.93103\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.5762 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.93103\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4497 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.93103\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.93103\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.93103\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.93103\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 6.1147e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.93103\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 5.5255e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.93103\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 5.1614e-04 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.93103\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.5083 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.93103\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.3808 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.93103\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5860 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.93103\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4593 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.93103\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.93103\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4546 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.93103\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5502 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.93103\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.5239 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.93103\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4040 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.93103\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 7.0744e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.93103\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 5.1574e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.93103\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 1.9893e-04 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.93103\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.2764e-04 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.93103\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.9658 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.93103\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0755 - accuracy: 0.9805 - val_loss: 0.8534 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.93103\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0577 - accuracy: 0.9842 - val_loss: 0.8698 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.93103\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.6284 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.93103\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.4902 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.93103\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.6358 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.93103\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0073 - accuracy: 0.9951 - val_loss: 0.6272 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.93103\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.5787 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.93103\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.4679 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.93103\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4567 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.93103\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.93103\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.6048 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.93103\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.93103\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4855 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.93103\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.5245 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.93103\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.5253 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.93103\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 6.2507e-04 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.93103\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 4.4543e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.93103\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 6.4421e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.93103\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.7847e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.93103\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.7248e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.93103\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 1.5258e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.93103\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.8643e-04 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.93103\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.7819e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.93103\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 2.7245e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.93103\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 2.5511e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.93103\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 5.6390e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.93103\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 7.1449e-04 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.93103\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 3.6482e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.93103\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 2.9637e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.93103\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 1.4413e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.93103\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 2.1526e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.93103\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 4.2612e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.93103\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 1.5677e-04 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.93103\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 2.6634e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.93103\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 3.2530e-04 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.93103\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 3.8049e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00400: val_accuracy improved from 0.93103 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 4.1632e-04 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.93350\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 3.7815e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00402: val_accuracy improved from 0.93350 to 0.94089, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 1.4057e-04 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.94089\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 1.7169e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.94089\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 9.6812e-05 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.94089\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5802 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.94089\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 1.2486 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.94089\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1096 - accuracy: 0.9702 - val_loss: 1.6508 - val_accuracy: 0.8103\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.94089\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 1.0718 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.94089\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0581 - accuracy: 0.9854 - val_loss: 0.8087 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.94089\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0260 - accuracy: 0.9896 - val_loss: 0.5478 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.94089\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.4929 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.94089\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4006 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.94089\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5180 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.94089\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.4192 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 0.94089\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 1.0811 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.94089\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.6290 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.94089\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4153 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.94089\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4208 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.94089\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0097 - accuracy: 0.9957 - val_loss: 0.5007 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.94089\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5000 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.94089\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 21s 397ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4667 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.94089\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3994 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.94089\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 7.5933e-04 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.94089\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 6.8158e-04 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.94089\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4737 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.94089\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3806 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.94089\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4379 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.94089\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5507 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.94089\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.5931 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.94089\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.5276 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.94089\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4260 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.94089\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.5001 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.94089\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.5012 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.94089\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5768 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.94089\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4566 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.94089\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4361 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.94089\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4408 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.94089\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 8.2214e-04 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.94089\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 5.5317e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.94089\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 1.6814e-04 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.94089\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 7.3389e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.94089\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 5.1564e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.94089\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 8.3987e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.94089\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.4031 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.94089\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.4660 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.94089\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5204 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.94089\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5588 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.94089\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.7634 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.94089\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 1.3441 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.94089\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.7230 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.94089\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.5064 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.94089\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5105 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.94089\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.6187 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.94089\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.7869 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.94089\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.5945 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.94089\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.6059 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.94089\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.5981 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.94089\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.7099 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.94089\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0638 - accuracy: 0.9842 - val_loss: 0.6591 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.94089\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0223 - accuracy: 0.9903 - val_loss: 0.6107 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.94089\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.5715 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.94089\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5852 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.94089\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.6169 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.94089\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5584 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.94089\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4415 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.94089\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 8.8483e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.94089\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.7651 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.94089\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0270 - accuracy: 0.9945 - val_loss: 0.8156 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.94089\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4974 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.94089\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.5038 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.94089\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4382 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.94089\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.4920 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.94089\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 6.8844e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.94089\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4244 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.94089\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 6.0173e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.94089\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.5303 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.94089\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 8.6245e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.94089\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 4.7795e-04 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.94089\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4997 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.94089\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 5.3532e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.94089\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 5.0400e-04 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.94089\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 4.7128e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.94089\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 3.8953e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.94089\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 1.5609e-04 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.94089\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.94089\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 1.8460e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.94089\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 2.2956e-04 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.94089\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 1.0379e-04 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.94089\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 3.2054e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.94089\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5070 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.94089\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 5.7913e-04 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.94089\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 3.3957e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.94089\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5375 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.94089\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.8319 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.94089\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.7025 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.94089\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 0.9924 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.94089\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.5683 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.94089\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.6650 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.94089\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.5621 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.94089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94381676d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f0c36bc2-1a9c-4d8b-b9b7-52b67a440dc5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_005_1_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd049447-c746-4623-dac3-d64e36604a06"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4b8694-1f52-4e46-ed4c-371b6831d248"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6080d06b-08dc-44aa-94b7-b05d94378e58"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2ed8cab6-174c-45c8-d9ed-e703dbe63013"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_005_1_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_005_1_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9c7c6bfc-2c63-4510-a66d-9c30436ac13e\", \"WidthShiftRange_005_1_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}