{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WidthShiftRange_015_5_DenseNet121(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOQi0kVALWPcqAaOtKylOmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/WidthShiftRange_015_5_DenseNet121(public-%2C%20private-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMLx8uC2eHeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8bb0a06-2be2-464e-ccf0-655fa175edcd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 31 13:10:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a6773e-3836-4399-a1b8-ba7ec47f2df7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "DenseNet121_model = tf.keras.applications.DenseNet121(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a697fc1c-b82c-4386-8048-b8590e53e3f6"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "DenseNet121_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.002,epsilon=None), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd2dbc0-1a35-44a4-eb70-d2c303af731e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                             rescale=1./255, \n",
        "                             validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.15,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbfd363-8d6f-43fc-900e-5ad909b0022c"
      },
      "source": [
        "DenseNet121_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 52s 458ms/step - loss: 1.8502 - accuracy: 0.3502 - val_loss: 3.7070 - val_accuracy: 0.0690\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.06897, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 19s 356ms/step - loss: 1.1437 - accuracy: 0.6200 - val_loss: 3.9564 - val_accuracy: 0.0591\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.06897\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 19s 358ms/step - loss: 0.9933 - accuracy: 0.6839 - val_loss: 6.5260 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.06897 to 0.10345, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 19s 361ms/step - loss: 0.8303 - accuracy: 0.7247 - val_loss: 5.3690 - val_accuracy: 0.1527\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.10345 to 0.15271, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 19s 363ms/step - loss: 0.7354 - accuracy: 0.7540 - val_loss: 8.4960 - val_accuracy: 0.1232\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.15271\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 19s 365ms/step - loss: 0.6966 - accuracy: 0.7741 - val_loss: 6.8794 - val_accuracy: 0.1700\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.15271 to 0.16995, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5912 - accuracy: 0.7990 - val_loss: 6.7949 - val_accuracy: 0.2340\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.16995 to 0.23399, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 19s 368ms/step - loss: 0.5647 - accuracy: 0.8149 - val_loss: 4.6197 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.23399 to 0.28325, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 19s 371ms/step - loss: 0.5162 - accuracy: 0.8252 - val_loss: 2.0302 - val_accuracy: 0.5074\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.28325 to 0.50739, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.4810 - accuracy: 0.8313 - val_loss: 1.2165 - val_accuracy: 0.7167\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.50739 to 0.71675, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.4393 - accuracy: 0.8544 - val_loss: 0.8645 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.71675 to 0.76601, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 19s 372ms/step - loss: 0.4340 - accuracy: 0.8624 - val_loss: 0.8272 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.76601\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 20s 375ms/step - loss: 0.3346 - accuracy: 0.8837 - val_loss: 0.9173 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.76601\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.3559 - accuracy: 0.8831 - val_loss: 0.7392 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.76601 to 0.79803, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.3682 - accuracy: 0.8812 - val_loss: 0.5201 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.79803 to 0.84729, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 20s 376ms/step - loss: 0.3273 - accuracy: 0.8910 - val_loss: 0.6751 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.84729\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.2834 - accuracy: 0.9050 - val_loss: 0.6687 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.84729\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.2956 - accuracy: 0.8892 - val_loss: 0.8838 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.84729\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.2750 - accuracy: 0.8989 - val_loss: 0.7624 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.84729\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.2582 - accuracy: 0.9166 - val_loss: 0.8759 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.84729\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2634 - accuracy: 0.9147 - val_loss: 1.5978 - val_accuracy: 0.6453\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.84729\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2694 - accuracy: 0.9038 - val_loss: 1.6286 - val_accuracy: 0.6601\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.84729\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.2546 - accuracy: 0.9141 - val_loss: 2.0011 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.84729\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.2804 - accuracy: 0.9099 - val_loss: 1.1264 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84729\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.2072 - accuracy: 0.9239 - val_loss: 1.1528 - val_accuracy: 0.7217\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84729\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.2166 - accuracy: 0.9269 - val_loss: 0.6188 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84729\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1686 - accuracy: 0.9421 - val_loss: 0.7878 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84729\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1816 - accuracy: 0.9385 - val_loss: 1.1566 - val_accuracy: 0.7192\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84729\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1468 - accuracy: 0.9549 - val_loss: 0.8216 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84729\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1620 - accuracy: 0.9415 - val_loss: 0.8230 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.84729\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1964 - accuracy: 0.9269 - val_loss: 0.7303 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.84729\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1254 - accuracy: 0.9592 - val_loss: 0.5003 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.84729 to 0.86207, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1162 - accuracy: 0.9555 - val_loss: 0.4635 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86207\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1163 - accuracy: 0.9610 - val_loss: 0.7681 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86207\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1546 - accuracy: 0.9458 - val_loss: 0.5472 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86207\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1898 - accuracy: 0.9330 - val_loss: 1.2379 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86207\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1829 - accuracy: 0.9324 - val_loss: 0.5101 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86207\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.1411 - accuracy: 0.9507 - val_loss: 0.6093 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86207\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1434 - accuracy: 0.9488 - val_loss: 0.8475 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86207\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.1272 - accuracy: 0.9531 - val_loss: 1.3197 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86207\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1091 - accuracy: 0.9592 - val_loss: 0.5065 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.86207 to 0.86700, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1577 - accuracy: 0.9446 - val_loss: 0.9038 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.86700\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1201 - accuracy: 0.9568 - val_loss: 0.5256 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.86700\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0916 - accuracy: 0.9708 - val_loss: 0.3802 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.86700 to 0.87192, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1278 - accuracy: 0.9604 - val_loss: 0.4251 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.87192 to 0.88670, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1012 - accuracy: 0.9659 - val_loss: 0.4794 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.88670\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1746 - accuracy: 0.9495 - val_loss: 1.3502 - val_accuracy: 0.7512\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.88670\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1216 - accuracy: 0.9562 - val_loss: 0.5894 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.88670\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1244 - accuracy: 0.9592 - val_loss: 0.5070 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.88670\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0962 - accuracy: 0.9683 - val_loss: 1.1382 - val_accuracy: 0.7611\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.88670\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0869 - accuracy: 0.9720 - val_loss: 0.4899 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.88670\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.5636 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.88670\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 0.4314 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.88670\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 0.6911 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.88670\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 0.8619 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.88670\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0659 - accuracy: 0.9775 - val_loss: 0.5801 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.88670\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.9829 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.88670\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0917 - accuracy: 0.9714 - val_loss: 0.6098 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.88670\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0999 - accuracy: 0.9683 - val_loss: 0.8091 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.88670\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0841 - accuracy: 0.9695 - val_loss: 0.5033 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.88670\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1173 - accuracy: 0.9629 - val_loss: 1.1547 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.88670\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0888 - accuracy: 0.9677 - val_loss: 0.3922 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00062: val_accuracy improved from 0.88670 to 0.91379, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.6407 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91379\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 0.5218 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91379\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0423 - accuracy: 0.9890 - val_loss: 0.5741 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91379\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.6801 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91379\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0583 - accuracy: 0.9793 - val_loss: 0.5660 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91379\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0608 - accuracy: 0.9756 - val_loss: 0.5901 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91379\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0843 - accuracy: 0.9671 - val_loss: 0.6313 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91379\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.5001 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91379\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.5114 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91379\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 0.6608 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91379\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.4265 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91379\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0557 - accuracy: 0.9787 - val_loss: 0.5744 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91379\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0605 - accuracy: 0.9805 - val_loss: 0.4718 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91379\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1189 - accuracy: 0.9629 - val_loss: 1.2258 - val_accuracy: 0.7685\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91379\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0694 - accuracy: 0.9756 - val_loss: 0.5412 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91379\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.4570 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91379\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0794 - accuracy: 0.9714 - val_loss: 0.6729 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91379\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.1041 - accuracy: 0.9671 - val_loss: 0.6490 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91379\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0630 - accuracy: 0.9781 - val_loss: 0.5773 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91379\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.4658 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91379\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.4652 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91379\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.4048 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91379\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.5061 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91379\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 0.6993 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91379\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.5423 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91379\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.5673 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91379\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.4266 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91379\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.5909 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91379\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.7259 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91379\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0737 - accuracy: 0.9799 - val_loss: 0.6198 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91379\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1024 - accuracy: 0.9683 - val_loss: 0.6714 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91379\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0907 - accuracy: 0.9683 - val_loss: 2.4480 - val_accuracy: 0.6502\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91379\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1005 - accuracy: 0.9671 - val_loss: 1.2442 - val_accuracy: 0.7635\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91379\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1540 - accuracy: 0.9488 - val_loss: 0.8443 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91379\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0639 - accuracy: 0.9775 - val_loss: 0.5165 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91379\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.5028 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91379\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.4380 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91379\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.6443 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91379\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.6025 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91379\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.5238 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91379\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0353 - accuracy: 0.9872 - val_loss: 0.4382 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91379\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0166 - accuracy: 0.9921 - val_loss: 0.5114 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91379\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.5081 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91379\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.5254 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91379\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.5457 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91379\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.7697 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91379\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1383 - accuracy: 0.9616 - val_loss: 1.0476 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91379\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1071 - accuracy: 0.9635 - val_loss: 0.6695 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91379\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0330 - accuracy: 0.9866 - val_loss: 0.4492 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91379\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0334 - accuracy: 0.9878 - val_loss: 0.4714 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91379\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.3862 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00113: val_accuracy improved from 0.91379 to 0.91872, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4210 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91872\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.5810 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91872\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0695 - accuracy: 0.9744 - val_loss: 1.3172 - val_accuracy: 0.7808\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91872\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0746 - accuracy: 0.9762 - val_loss: 0.8119 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91872\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.5793 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91872\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0928 - accuracy: 0.9677 - val_loss: 0.7696 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91872\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0386 - accuracy: 0.9842 - val_loss: 0.5573 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91872\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.5704 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91872\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.4227 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91872\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0141 - accuracy: 0.9939 - val_loss: 0.5194 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91872\n",
            "Epoch 124/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.3992 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91872\n",
            "Epoch 125/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.4469 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91872\n",
            "Epoch 126/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 1.5390 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91872\n",
            "Epoch 127/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0707 - accuracy: 0.9823 - val_loss: 1.0852 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91872\n",
            "Epoch 128/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0988 - accuracy: 0.9714 - val_loss: 0.8630 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91872\n",
            "Epoch 129/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0397 - accuracy: 0.9878 - val_loss: 0.5718 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91872\n",
            "Epoch 130/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 1.0119 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91872\n",
            "Epoch 131/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.6530 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91872\n",
            "Epoch 132/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0209 - accuracy: 0.9915 - val_loss: 0.6055 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91872\n",
            "Epoch 133/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 0.5322 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91872\n",
            "Epoch 134/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.6164 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91872\n",
            "Epoch 135/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.9025 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91872\n",
            "Epoch 136/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.5198 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91872\n",
            "Epoch 137/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.4367 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91872\n",
            "Epoch 138/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0102 - accuracy: 0.9951 - val_loss: 0.5971 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91872\n",
            "Epoch 139/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.7618 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91872\n",
            "Epoch 140/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0821 - accuracy: 0.9775 - val_loss: 0.6490 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91872\n",
            "Epoch 141/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.5604 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91872\n",
            "Epoch 142/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.6566 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91872\n",
            "Epoch 143/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.7403 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91872\n",
            "Epoch 144/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.7962 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.91872\n",
            "Epoch 145/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.6399 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.91872\n",
            "Epoch 146/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.5738 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.91872\n",
            "Epoch 147/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.6095 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.91872\n",
            "Epoch 148/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.5758 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.91872\n",
            "Epoch 149/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0496 - accuracy: 0.9799 - val_loss: 0.6733 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.91872\n",
            "Epoch 150/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0466 - accuracy: 0.9872 - val_loss: 0.8746 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.91872\n",
            "Epoch 151/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0259 - accuracy: 0.9890 - val_loss: 0.4947 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.91872\n",
            "Epoch 152/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.4678 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.91872\n",
            "Epoch 153/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.3845 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.91872\n",
            "Epoch 154/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.91872\n",
            "Epoch 155/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00155: val_accuracy improved from 0.91872 to 0.92365, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 156/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.92365\n",
            "Epoch 157/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 7.5808e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.92365\n",
            "Epoch 158/500\n",
            "52/52 [==============================] - 20s 385ms/step - loss: 0.0409 - accuracy: 0.9836 - val_loss: 0.6353 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.92365\n",
            "Epoch 159/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.8333 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.92365\n",
            "Epoch 160/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1291 - accuracy: 0.9647 - val_loss: 1.8378 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.92365\n",
            "Epoch 161/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0488 - accuracy: 0.9817 - val_loss: 0.6798 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.92365\n",
            "Epoch 162/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5230 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.92365\n",
            "Epoch 163/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.5595 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.92365\n",
            "Epoch 164/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.5288 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.92365\n",
            "Epoch 165/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0167 - accuracy: 0.9927 - val_loss: 0.4418 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.92365\n",
            "Epoch 166/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.4358 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.92365\n",
            "Epoch 167/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.4609 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.92365\n",
            "Epoch 168/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.4707 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.92365\n",
            "Epoch 169/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.92365\n",
            "Epoch 170/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.92365\n",
            "Epoch 171/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.5824 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.92365\n",
            "Epoch 172/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 1.1514 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.92365\n",
            "Epoch 173/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0518 - accuracy: 0.9860 - val_loss: 0.7905 - val_accuracy: 0.8424\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.92365\n",
            "Epoch 174/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0667 - accuracy: 0.9799 - val_loss: 0.8646 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.92365\n",
            "Epoch 175/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0280 - accuracy: 0.9884 - val_loss: 0.5380 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.92365\n",
            "Epoch 176/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.6178 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.92365\n",
            "Epoch 177/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.4799 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 0.92365\n",
            "Epoch 178/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 1.1989 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.92365\n",
            "Epoch 179/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.5442 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.92365\n",
            "Epoch 180/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.7016 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.92365\n",
            "Epoch 181/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.6810 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.92365\n",
            "Epoch 182/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.6017 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.92365\n",
            "Epoch 183/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4337 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.92365\n",
            "Epoch 184/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.3956 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.92365\n",
            "Epoch 185/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4340 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.92365\n",
            "Epoch 186/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.5120 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.92365\n",
            "Epoch 187/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5381 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.92365\n",
            "Epoch 188/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6348 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.92365\n",
            "Epoch 189/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.92365\n",
            "Epoch 190/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.6180 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.92365\n",
            "Epoch 191/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.6094 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 0.92365\n",
            "Epoch 192/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0104 - accuracy: 0.9951 - val_loss: 0.6254 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.92365\n",
            "Epoch 193/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.7143 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.92365\n",
            "Epoch 194/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.6947 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.92365\n",
            "Epoch 195/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.6150 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.92365\n",
            "Epoch 196/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0470 - accuracy: 0.9903 - val_loss: 0.6167 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.92365\n",
            "Epoch 197/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0512 - accuracy: 0.9854 - val_loss: 1.0663 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.92365\n",
            "Epoch 198/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.7174 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.92365\n",
            "Epoch 199/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.5824 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.92365\n",
            "Epoch 200/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0525 - accuracy: 0.9884 - val_loss: 1.1328 - val_accuracy: 0.8350\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 0.92365\n",
            "Epoch 201/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.7550 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.92365\n",
            "Epoch 202/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.5004 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.92365\n",
            "Epoch 203/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.7358 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.92365\n",
            "Epoch 204/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.5679 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.92365\n",
            "Epoch 205/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.1512 - accuracy: 0.9616 - val_loss: 1.5633 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.92365\n",
            "Epoch 206/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.7474 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.92365\n",
            "Epoch 207/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4821 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.92365\n",
            "Epoch 208/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.4344 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.92365\n",
            "Epoch 209/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.5153 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.92365\n",
            "Epoch 210/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.4026 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.92365\n",
            "Epoch 211/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5378 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.92365\n",
            "Epoch 212/500\n",
            "52/52 [==============================] - 20s 386ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.6117 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.92365\n",
            "Epoch 213/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.5397 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.92365\n",
            "Epoch 214/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.6670 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.92365\n",
            "Epoch 215/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.4890 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.92365\n",
            "Epoch 216/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4473 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.92365\n",
            "Epoch 217/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5920 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 0.92365\n",
            "Epoch 218/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.7596 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 0.92365\n",
            "Epoch 219/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.6993 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.92365\n",
            "Epoch 220/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0489 - accuracy: 0.9872 - val_loss: 0.7951 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.92365\n",
            "Epoch 221/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.5520 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.92365\n",
            "Epoch 222/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5639 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.92365\n",
            "Epoch 223/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4602 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.92365\n",
            "Epoch 224/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.92365\n",
            "Epoch 225/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.5410 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.92365\n",
            "Epoch 226/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.9221 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.92365\n",
            "Epoch 227/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.7826 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.92365\n",
            "Epoch 228/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.6890 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.92365\n",
            "Epoch 229/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.6810 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.92365\n",
            "Epoch 230/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.5886 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.92365\n",
            "Epoch 231/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4675 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.92365\n",
            "Epoch 232/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.4473 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.92365\n",
            "Epoch 233/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.8195 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.92365\n",
            "Epoch 234/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.5737 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.92365\n",
            "Epoch 235/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.5177 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.92365\n",
            "Epoch 236/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.5381 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.92365\n",
            "Epoch 237/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.6459 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 0.92365\n",
            "Epoch 238/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.6154 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.92365\n",
            "Epoch 239/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.4746 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.92365\n",
            "Epoch 240/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.6521 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.92365\n",
            "Epoch 241/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.6993 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.92365\n",
            "Epoch 242/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0639 - accuracy: 0.9872 - val_loss: 1.0602 - val_accuracy: 0.8005\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.92365\n",
            "Epoch 243/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.5512 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.92365\n",
            "Epoch 244/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.5198 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.92365\n",
            "Epoch 245/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.6512 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.92365\n",
            "Epoch 246/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6083 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.92365\n",
            "Epoch 247/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.4957 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.92365\n",
            "Epoch 248/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0106 - accuracy: 0.9945 - val_loss: 0.6303 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.92365\n",
            "Epoch 249/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.92365\n",
            "Epoch 250/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.92365\n",
            "Epoch 251/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.3651 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00251: val_accuracy improved from 0.92365 to 0.92857, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 252/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 8.9417e-04 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 0.92857\n",
            "Epoch 253/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 8.3350e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 0.92857\n",
            "Epoch 254/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4456 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 0.92857\n",
            "Epoch 255/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4520 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 0.92857\n",
            "Epoch 256/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.5278 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 0.92857\n",
            "Epoch 257/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 0.92857\n",
            "Epoch 258/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 0.92857\n",
            "Epoch 259/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.3954 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 0.92857\n",
            "Epoch 260/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 6.7616e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 0.92857\n",
            "Epoch 261/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 6.2008e-04 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 0.92857\n",
            "Epoch 262/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 7.2552e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 0.92857\n",
            "Epoch 263/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 4.3826e-04 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 0.92857\n",
            "Epoch 264/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5157 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 0.92857\n",
            "Epoch 265/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 0.92857\n",
            "Epoch 266/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 2.7806e-04 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 0.92857\n",
            "Epoch 267/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.5281 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 0.92857\n",
            "Epoch 268/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4521 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 0.92857\n",
            "Epoch 269/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.5588 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 0.92857\n",
            "Epoch 270/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0372 - accuracy: 0.9921 - val_loss: 1.5788 - val_accuracy: 0.7906\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 0.92857\n",
            "Epoch 271/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1551 - accuracy: 0.9555 - val_loss: 1.3389 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 0.92857\n",
            "Epoch 272/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.1006 - accuracy: 0.9671 - val_loss: 0.7637 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 0.92857\n",
            "Epoch 273/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.5554 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 0.92857\n",
            "Epoch 274/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.5175 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 0.92857\n",
            "Epoch 275/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.6694 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 0.92857\n",
            "Epoch 276/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4578 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 0.92857\n",
            "Epoch 277/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.4993 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 0.92857\n",
            "Epoch 278/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.5852 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 0.92857\n",
            "Epoch 279/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0171 - accuracy: 0.9927 - val_loss: 0.5250 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 0.92857\n",
            "Epoch 280/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 0.92857\n",
            "Epoch 281/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4451 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 0.92857\n",
            "Epoch 282/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4364 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 0.92857\n",
            "Epoch 283/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 9.8969e-04 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 0.92857\n",
            "Epoch 284/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.4340 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 0.92857\n",
            "Epoch 285/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.5762 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 0.92857\n",
            "Epoch 286/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.4772 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 0.92857\n",
            "Epoch 287/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3989 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 0.92857\n",
            "Epoch 288/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 7.2732e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 0.92857\n",
            "Epoch 289/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 7.5685e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 0.92857\n",
            "Epoch 290/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 8.6903e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 0.92857\n",
            "Epoch 291/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 4.3884e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 0.92857\n",
            "Epoch 292/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 0.92857\n",
            "Epoch 293/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 2.3735e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 0.92857\n",
            "Epoch 294/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 2.9147e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 0.92857\n",
            "Epoch 295/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 6.3829e-04 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 0.92857\n",
            "Epoch 296/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4963 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 0.92857\n",
            "Epoch 297/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.7213 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 0.92857\n",
            "Epoch 298/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.5493 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 0.92857\n",
            "Epoch 299/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.9786 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 0.92857\n",
            "Epoch 300/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.1563 - accuracy: 0.9543 - val_loss: 1.2359 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 0.92857\n",
            "Epoch 301/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1054 - accuracy: 0.9677 - val_loss: 0.8254 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 0.92857\n",
            "Epoch 302/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.6623 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 0.92857\n",
            "Epoch 303/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.7576 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 0.92857\n",
            "Epoch 304/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.7766 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 0.92857\n",
            "Epoch 305/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.7571 - val_accuracy: 0.8547\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 0.92857\n",
            "Epoch 306/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.4822 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 0.92857\n",
            "Epoch 307/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.5518 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 0.92857\n",
            "Epoch 308/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.4350 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 0.92857\n",
            "Epoch 309/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 0.92857\n",
            "Epoch 310/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.5624 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 0.92857\n",
            "Epoch 311/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.5903 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 0.92857\n",
            "Epoch 312/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.5142 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 0.92857\n",
            "Epoch 313/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 0.92857\n",
            "Epoch 314/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5458 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 0.92857\n",
            "Epoch 315/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 16.9087 - val_accuracy: 0.2414\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 0.92857\n",
            "Epoch 316/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0726 - accuracy: 0.9823 - val_loss: 0.8540 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 0.92857\n",
            "Epoch 317/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.6497 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 0.92857\n",
            "Epoch 318/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.5332 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 0.92857\n",
            "Epoch 319/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.6383 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 0.92857\n",
            "Epoch 320/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.5213 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 0.92857\n",
            "Epoch 321/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4032 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 0.92857\n",
            "Epoch 322/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 0.92857\n",
            "Epoch 323/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 0.92857\n",
            "Epoch 324/500\n",
            "52/52 [==============================] - 20s 384ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4808 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 0.92857\n",
            "Epoch 325/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4811 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 0.92857\n",
            "Epoch 326/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5685 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 0.92857\n",
            "Epoch 327/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6148 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 0.92857\n",
            "Epoch 328/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 0.92857\n",
            "Epoch 329/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6610 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 0.92857\n",
            "Epoch 330/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.6373 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 0.92857\n",
            "Epoch 331/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.6845 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 0.92857\n",
            "Epoch 332/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.9072 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 0.92857\n",
            "Epoch 333/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0361 - accuracy: 0.9927 - val_loss: 0.6842 - val_accuracy: 0.8744\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 0.92857\n",
            "Epoch 334/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.5099 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 0.92857\n",
            "Epoch 335/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0495 - accuracy: 0.9884 - val_loss: 0.9097 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 0.92857\n",
            "Epoch 336/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.6799 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 0.92857\n",
            "Epoch 337/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.4814 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 0.92857\n",
            "Epoch 338/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4799 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 0.92857\n",
            "Epoch 339/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4679 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 0.92857\n",
            "Epoch 340/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.4571 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 0.92857\n",
            "Epoch 341/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 0.92857\n",
            "Epoch 342/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4667 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 0.92857\n",
            "Epoch 343/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 0.92857\n",
            "Epoch 344/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 0.92857\n",
            "Epoch 345/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 9.0635e-04 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 0.92857\n",
            "Epoch 346/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.4604 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 0.92857\n",
            "Epoch 347/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 9.4733e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 0.92857\n",
            "Epoch 348/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.5460 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 0.92857\n",
            "Epoch 349/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.5096 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 0.92857\n",
            "Epoch 350/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4701 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 0.92857\n",
            "Epoch 351/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4867 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 0.92857\n",
            "Epoch 352/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4079 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 0.92857\n",
            "Epoch 353/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4149 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 0.92857\n",
            "Epoch 354/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 5.5462e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 0.92857\n",
            "Epoch 355/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 4.9239e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 0.92857\n",
            "Epoch 356/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0715 - accuracy: 0.9811 - val_loss: 0.7832 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 0.92857\n",
            "Epoch 357/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0722 - accuracy: 0.9799 - val_loss: 1.1154 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 0.92857\n",
            "Epoch 358/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.6232 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 0.92857\n",
            "Epoch 359/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.5808 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 0.92857\n",
            "Epoch 360/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.6366 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 0.92857\n",
            "Epoch 361/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.6230 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 0.92857\n",
            "Epoch 362/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5130 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 0.92857\n",
            "Epoch 363/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 0.92857\n",
            "Epoch 364/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.4595 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 0.92857\n",
            "Epoch 365/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 0.92857\n",
            "Epoch 366/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 5.9948e-04 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 0.92857\n",
            "Epoch 367/500\n",
            "52/52 [==============================] - 20s 387ms/step - loss: 4.3384e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 0.92857\n",
            "Epoch 368/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4963 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 0.92857\n",
            "Epoch 369/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 1.0355 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 0.92857\n",
            "Epoch 370/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0390 - accuracy: 0.9860 - val_loss: 0.7609 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 0.92857\n",
            "Epoch 371/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6279 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 0.92857\n",
            "Epoch 372/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5354 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 0.92857\n",
            "Epoch 373/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.5225 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 0.92857\n",
            "Epoch 374/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 0.92857\n",
            "Epoch 375/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 0.92857\n",
            "Epoch 376/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4716 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 0.92857\n",
            "Epoch 377/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.5054 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 0.92857\n",
            "Epoch 378/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.6073 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 0.92857\n",
            "Epoch 379/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0102 - accuracy: 0.9945 - val_loss: 0.5593 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 0.92857\n",
            "Epoch 380/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.4253 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 0.92857\n",
            "Epoch 381/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5366 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 0.92857\n",
            "Epoch 382/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 6.0766e-04 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 0.92857\n",
            "Epoch 383/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.6110 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 0.92857\n",
            "Epoch 384/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6908 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 0.92857\n",
            "Epoch 385/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0499 - accuracy: 0.9890 - val_loss: 0.7372 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 0.92857\n",
            "Epoch 386/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.7572 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 0.92857\n",
            "Epoch 387/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.4673 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 0.92857\n",
            "Epoch 388/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.5860 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 0.92857\n",
            "Epoch 389/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.4550 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 0.92857\n",
            "Epoch 390/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4770 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 0.92857\n",
            "Epoch 391/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4565 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 0.92857\n",
            "Epoch 392/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.5110 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 0.92857\n",
            "Epoch 393/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 8.0685e-04 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 0.92857\n",
            "Epoch 394/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 6.6777e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 0.92857\n",
            "Epoch 395/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 5.7834e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 0.92857\n",
            "Epoch 396/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 6.0555e-04 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 0.92857\n",
            "Epoch 397/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 4.7456e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 0.92857\n",
            "Epoch 398/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 2.9109e-04 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 0.92857\n",
            "Epoch 399/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 2.7734e-04 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 0.92857\n",
            "Epoch 400/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 1.9586e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 0.92857\n",
            "Epoch 401/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 3.5129e-04 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 0.92857\n",
            "Epoch 402/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 9.3333e-04 - accuracy: 0.9994 - val_loss: 0.4598 - val_accuracy: 0.8966\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 0.92857\n",
            "Epoch 403/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 8.5013e-04 - accuracy: 0.9994 - val_loss: 0.5060 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 0.92857\n",
            "Epoch 404/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 9.9462e-04 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 0.92857\n",
            "Epoch 405/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.4951 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 0.92857\n",
            "Epoch 406/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 0.92857\n",
            "Epoch 407/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 3.3225e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 0.92857\n",
            "Epoch 408/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 7.1336e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 0.92857\n",
            "Epoch 409/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 4.9914e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 0.92857\n",
            "Epoch 410/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 2.4638e-04 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 0.92857\n",
            "Epoch 411/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 2.7417e-04 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 0.92857\n",
            "Epoch 412/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 4.3537e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 0.92857\n",
            "Epoch 413/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 2.6688e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 0.92857\n",
            "Epoch 414/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 1.7251e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 0.92857\n",
            "Epoch 415/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 1.3953e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00415: val_accuracy improved from 0.92857 to 0.93350, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5\n",
            "Epoch 416/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 7.9489e-04 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 0.93350\n",
            "Epoch 417/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 9.5128e-04 - accuracy: 0.9994 - val_loss: 0.4900 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 0.93350\n",
            "Epoch 418/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.7573 - val_accuracy: 0.8793\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 0.93350\n",
            "Epoch 419/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 1.1350 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 0.93350\n",
            "Epoch 420/500\n",
            "52/52 [==============================] - 20s 382ms/step - loss: 0.1175 - accuracy: 0.9659 - val_loss: 2.3661 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 0.93350\n",
            "Epoch 421/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0732 - accuracy: 0.9769 - val_loss: 0.8493 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 0.93350\n",
            "Epoch 422/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0399 - accuracy: 0.9854 - val_loss: 0.7241 - val_accuracy: 0.8768\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 0.93350\n",
            "Epoch 423/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.9544 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 0.93350\n",
            "Epoch 424/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.5374 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 0.93350\n",
            "Epoch 425/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.5090 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 0.93350\n",
            "Epoch 426/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.5869 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 0.93350\n",
            "Epoch 427/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.4370 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 0.93350\n",
            "Epoch 428/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4398 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 0.93350\n",
            "Epoch 429/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 0.93350\n",
            "Epoch 430/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 0.93350\n",
            "Epoch 431/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.5095 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 0.93350\n",
            "Epoch 432/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 0.93350\n",
            "Epoch 433/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4515 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 0.93350\n",
            "Epoch 434/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 6.0997e-04 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 0.93350\n",
            "Epoch 435/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.5820 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 0.93350\n",
            "Epoch 436/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5008 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 0.93350\n",
            "Epoch 437/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5028 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 0.93350\n",
            "Epoch 438/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 6.4097e-04 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 0.93350\n",
            "Epoch 439/500\n",
            "52/52 [==============================] - 20s 378ms/step - loss: 5.4491e-04 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 0.93350\n",
            "Epoch 440/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 4.5252e-04 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 0.93350\n",
            "Epoch 441/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 4.4920e-04 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 0.93350\n",
            "Epoch 442/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 4.5156e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 0.93350\n",
            "Epoch 443/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 3.2216e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 0.93350\n",
            "Epoch 444/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 3.3492e-04 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 0.93350\n",
            "Epoch 445/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 0.93350\n",
            "Epoch 446/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 6.4450e-04 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 0.93350\n",
            "Epoch 447/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.5635 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 0.93350\n",
            "Epoch 448/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.6240 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 0.93350\n",
            "Epoch 449/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.7237 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 0.93350\n",
            "Epoch 450/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.6405 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 0.93350\n",
            "Epoch 451/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.5562 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 0.93350\n",
            "Epoch 452/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.4968 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 0.93350\n",
            "Epoch 453/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.5169 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 0.93350\n",
            "Epoch 454/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.9408 - val_accuracy: 0.8645\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 0.93350\n",
            "Epoch 455/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.9786 - val_accuracy: 0.8695\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 0.93350\n",
            "Epoch 456/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.7195 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 0.93350\n",
            "Epoch 457/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.5676 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 0.93350\n",
            "Epoch 458/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0311 - accuracy: 0.9939 - val_loss: 0.6230 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 0.93350\n",
            "Epoch 459/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.5622 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 0.93350\n",
            "Epoch 460/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.6200 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 0.93350\n",
            "Epoch 461/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.5554 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 0.93350\n",
            "Epoch 462/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5330 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 0.93350\n",
            "Epoch 463/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4757 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 0.93350\n",
            "Epoch 464/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4947 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 0.93350\n",
            "Epoch 465/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5096 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 0.93350\n",
            "Epoch 466/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5153 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 0.93350\n",
            "Epoch 467/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4983 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 0.93350\n",
            "Epoch 468/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 4.9981e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 0.93350\n",
            "Epoch 469/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 5.3872e-04 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 0.93350\n",
            "Epoch 470/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 6.8515e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 0.93350\n",
            "Epoch 471/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4677 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 0.93350\n",
            "Epoch 472/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.5237 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 0.93350\n",
            "Epoch 473/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4913 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 0.93350\n",
            "Epoch 474/500\n",
            "52/52 [==============================] - 20s 377ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.5356 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 0.93350\n",
            "Epoch 475/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.5172 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 0.93350\n",
            "Epoch 476/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.5707 - val_accuracy: 0.8719\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 0.93350\n",
            "Epoch 477/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.8857 - val_accuracy: 0.8621\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 0.93350\n",
            "Epoch 478/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0502 - accuracy: 0.9866 - val_loss: 0.7162 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 0.93350\n",
            "Epoch 479/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4683 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 0.93350\n",
            "Epoch 480/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.4684 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 0.93350\n",
            "Epoch 481/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.5589 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 0.93350\n",
            "Epoch 482/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4540 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 0.93350\n",
            "Epoch 483/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.5639 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 0.93350\n",
            "Epoch 484/500\n",
            "52/52 [==============================] - 20s 383ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.6147 - val_accuracy: 0.8990\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 0.93350\n",
            "Epoch 485/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5424 - val_accuracy: 0.9039\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 0.93350\n",
            "Epoch 486/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 0.93350\n",
            "Epoch 487/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 8.6723e-04 - accuracy: 0.9994 - val_loss: 0.5012 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 0.93350\n",
            "Epoch 488/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.5664 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 0.93350\n",
            "Epoch 489/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.6043 - val_accuracy: 0.8916\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 0.93350\n",
            "Epoch 490/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 9.2889e-04 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 0.93350\n",
            "Epoch 491/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 8.9862e-04 - accuracy: 0.9994 - val_loss: 0.5357 - val_accuracy: 0.9113\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 0.93350\n",
            "Epoch 492/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 5.6063e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 0.93350\n",
            "Epoch 493/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 7.8703e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 0.93350\n",
            "Epoch 494/500\n",
            "52/52 [==============================] - 20s 380ms/step - loss: 5.9397e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 0.93350\n",
            "Epoch 495/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 2.0832e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9089\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 0.93350\n",
            "Epoch 496/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 2.2935e-04 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 0.93350\n",
            "Epoch 497/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 1.1523e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 0.93350\n",
            "Epoch 498/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 2.6793e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9261\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 0.93350\n",
            "Epoch 499/500\n",
            "52/52 [==============================] - 20s 381ms/step - loss: 9.7990e-05 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 0.93350\n",
            "Epoch 500/500\n",
            "52/52 [==============================] - 20s 379ms/step - loss: 1.5627e-04 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 0.93350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ea7e96810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ed1e8809-dbb5-49a7-944a-25a3fa2b146e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(DenseNet121_model.history.history[\"accuracy\"], label='DenseNet121_acc')\n",
        "plt.plot(DenseNet121_model.history.history[\"val_accuracy\"], label='DenseNet121_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "DenseNet121_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/WSR_015_5_DN121.h5', compile=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fd90d8-a4a2-4af5-9816-6efa591b0f0c"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20480 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d423df49-9c86-4b05-c1a3-9f41e90349fd"
      },
      "source": [
        "DenseNet121_predict = DenseNet121_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"DenseNet121_predict\"] = DenseNet121_predict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['DenseNet121_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9c53308d-5954-4541-c201-1b3ac9401f45"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  digit\n",
              "0  10000      4\n",
              "1  10001      4\n",
              "2  10002      6\n",
              "3  10003      9\n",
              "4  10004      5"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "33b768a5-bc0f-4aa6-ef84-a9174428c4ac"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_015_5_DenseNet121_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/WidthShiftRange_015_5_DenseNet121_model.csv')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_098c9ba4-642e-4db1-8a55-7917b99a9a7e\", \"WidthShiftRange_015_5_DenseNet121_model.csv\", 155898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}