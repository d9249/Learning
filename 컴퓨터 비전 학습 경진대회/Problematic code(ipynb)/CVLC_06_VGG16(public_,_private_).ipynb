{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVLC_06_VGG16(public-, private-).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNAkkEW/tNfZEVpxAXfiuJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d9249/DACON/blob/main/CVLC_06_VGG16(public_%2C_private_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEaPJckuX-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0ea437-ea71-4c00-eaa6-aecbf83c0a84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GAtllsufPj"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qBWziyZrqBo"
      },
      "source": [
        "!mkdir images_train\n",
        "!mkdir images_train/0\n",
        "!mkdir images_train/1\n",
        "!mkdir images_train/2\n",
        "!mkdir images_train/3\n",
        "!mkdir images_train/4\n",
        "!mkdir images_train/5\n",
        "!mkdir images_train/6\n",
        "!mkdir images_train/7\n",
        "!mkdir images_train/8\n",
        "!mkdir images_train/9\n",
        "!mkdir images_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fjN8mIDrazg"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(train)) :\n",
        "    img = train.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    digit = train.loc[idx, 'digit']\n",
        "    cv2.imwrite(f'./images_train/{digit}/{train[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P9AD1gyotc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for idx in range(len(test)) :\n",
        "    img = test.loc[idx, '0':].values.reshape(28, 28).astype(int)\n",
        "    cv2.imwrite(f'./images_test/{test[\"id\"][idx]}.png', img)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUJTlJ6GxNmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "VGG16_model =  tf.keras.applications.vgg16.VGG16(weights=None, include_top=True, input_shape=(224, 224, 1), classes=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVMd30ZxUMQ"
      },
      "source": [
        "# from tensorflow.keras.optimizers import Adam\n",
        "VGG16_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1haI0Zjxa74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa066e49-78ec-41bf-ced8-8f19d1a5aedd"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1)\n",
        "\n",
        "train_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory('./images_train', target_size=(224,224), color_mode='grayscale', class_mode='categorical', subset='validation')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1642 images belonging to 10 classes.\n",
            "Found 406 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRP2R9hdxsyY"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_VGG16.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtBpC5-0dZ9q",
        "outputId": "272be9af-68f3-4cd1-8edf-b96b5334bf24"
      },
      "source": [
        "VGG16_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 1)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      640       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 134,300,362\n",
            "Trainable params: 134,300,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMJhbFnxotA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23aedead-2bba-4648-b73c-5e3e1f95e494"
      },
      "source": [
        "VGG16_model.fit_generator(train_generator, epochs=500, validation_data=val_generator, callbacks=[checkpoint])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52/52 [==============================] - 37s 325ms/step - loss: 2.3050 - accuracy: 0.1005 - val_loss: 2.3007 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11330, saving model to /content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_VGG16.h5\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 2.3017 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11330\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 13s 254ms/step - loss: 2.3017 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11330\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11330\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3018 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11330\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3013 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.11330\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.11330\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.11330\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.11330\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 2.3014 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.11330\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.11330\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.11330\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3003 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.11330\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.11330\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.11330\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.11330\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3010 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.11330\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.11330\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.11330\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.11330\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.11330\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.11330\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.11330\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.11330\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.11330\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.11330\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.11330\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.11330\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.11330\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.11330\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.11330\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3009 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.11330\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.11330\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3001 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.11330\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.11330\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.11330\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.11330\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.11330\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.11330\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.11330\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.11330\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.11330\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.11330\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.11330\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3007 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.11330\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.11330\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.11330\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.11330\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.11330\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.11330\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.11330\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.11330\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.11330\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.11330\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.11330\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.11330\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.11330\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.11330\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 13s 249ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.11330\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.11330\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.11330\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.11330\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.11330\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.11330\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.11330\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.11330\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 13s 251ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.11330\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.11330\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.11330\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.11330\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.11330\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.11330\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3006 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.11330\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.11330\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.11330\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.11330\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.11330\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.11330\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.11330\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.11330\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.11330\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 13s 248ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.2999 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.11330\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.11330\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.11330\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 13s 247ms/step - loss: 2.3005 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.11330\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 13s 246ms/step - loss: 2.3003 - accuracy: 0.1139 - val_loss: 2.3000 - val_accuracy: 0.1133\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.11330\n",
            "Epoch 87/500\n",
            "18/52 [=========>....................] - ETA: 7s - loss: 2.3012 - accuracy: 0.1137"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c7f70e009651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVGG16_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmpkzRJyCrf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(VGG16_model.history.history[\"accuracy\"], label='VGG16_acc')\n",
        "plt.plot(VGG16_model.history.history[\"val_accuracy\"], label='VGG16_val')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcElIu93yIQU"
      },
      "source": [
        "InceptionV3_model = tf.keras.models.load_model('/content/drive/MyDrive/DACON_CVLC/Checkpoint/CVLC_06_VGG16.h5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4N2pAZyiR-"
      },
      "source": [
        "!mkdir images_test/none\n",
        "!mv images_test/*.png images_test/none"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxH98QOgyu1z"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = datagen.flow_from_directory('./images_test', target_size=(224,224), color_mode='grayscale', class_mode='categorical', shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEcoCR-3DNH"
      },
      "source": [
        "VGG16_predict = VGG16_model.predict_generator(test_generator).argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhGZuzr1AjD"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/DACON_CVLC/data/submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWALVGA1shFz"
      },
      "source": [
        "import numpy as np\n",
        "mylist = []\n",
        "\n",
        "for i in range(len(submission)):\n",
        "    name =  test_generator.filenames\n",
        "    id = name[i].split('/')[1].rstrip('.').split('.')[0]\n",
        "    mylist.append(id)\n",
        "print(mylist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjLSWZJvuVK"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    submission[\"id\"][i] = mylist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNg9gk9z3Noq"
      },
      "source": [
        "submission[\"VGG16_predict\"] = VGG16_predict\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Smd-xg6deOK"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "for i in range(len(submission)) :\n",
        "    predicts = submission.loc[i, ['VGG16_predict']]\n",
        "    submission.at[i, \"digit\"] = Counter(predicts).most_common(n=1)[0][0]\n",
        "\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg9m6Zgk4foS"
      },
      "source": [
        "submission = submission[['id', 'digit']]\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flAHWrtH4flu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/DACON_CVLC/Submission/VGG16_model.csv', index=False)\n",
        "files.download('/content/drive/MyDrive/DACON_CVLC/Submission/VGG16_model.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}