{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from test_image_loader import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import sys\n",
    "import numpy\n",
    "import pytorch_colors as colors\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# G(z)\n",
    "\n",
    "########################################CGAN shadow removal##############\n",
    "batch_size = 1\n",
    "dataset = shadow_triplets_loader()\n",
    "data_loader = Data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "print(len(data_loader))\n",
    "ckpt_path = '/home/heejin/Downloads/GAN-pratice/'\n",
    "exp_name = 'loss_shadow'\n",
    "args = {\n",
    "    'snapshot' : '320'\n",
    "}\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "    \n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__() \n",
    "\n",
    "        # Initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "        \n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        \n",
    "        for _ in range(n_residual_blocks):\n",
    "            \n",
    "            model += [ResidualBlock(in_features)]\n",
    "            \n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            \n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "        \n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test start!\n",
      "Test_result(shadow) : 1.984658248336227\n",
      "original difference(shadow) : 5.656571451822916\n",
      "Test_result(non) : 3.5448972348813657\n",
      "original difference(non) : 3.4624091254340277\n",
      "Test_result : 5.529555483217592\n",
      "original difference : 9.118980577256945\n",
      "Test finish!... \n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "G = Generator(4,3).to(device)\n",
    "net = G\n",
    "net.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, args['snapshot']+',generator_param' + '.pkl'), map_location=device))\n",
    "\n",
    "def rmse(y, y_hat,mask,k):\n",
    "    \"\"\"Compute root mean squared error, shadow region and non-shadow region\"\"\"\n",
    "    #y = generated image, y_hat = Ground Truth image\n",
    "    ####shadow_region error########\n",
    "    \n",
    "    shadow_region = (y*mask)\n",
    "    shadow_region_gt = (y_hat*mask)\n",
    "    torchvision.utils.save_image(shadow_region, 'shadow/'+str(k)+'test.png')\n",
    "    ####non-shadow_region error########\n",
    "    non_shadow_region = y*(torch.ones(y.size()).cuda()-mask)\n",
    "    torchvision.utils.save_image(non_shadow_region, 'non-shadow/'+str(k)+'test.png')\n",
    "    non_shadow_region_gt = y_hat*(torch.ones(y_hat.size()).cuda()-mask)\n",
    "    \n",
    "    torchvision.utils.save_image(shadow_region+non_shadow_region, 'plus/'+str(k)+'test.png')\n",
    "    ########################################\n",
    "    error_shadow = torch.sqrt(torch.mean((shadow_region - shadow_region_gt).pow(2)))\n",
    "    error_non_shadow = torch.sqrt(torch.mean((non_shadow_region - non_shadow_region_gt).pow(2)))\n",
    "    return error_shadow,error_non_shadow\n",
    "\n",
    "# results save folder\n",
    "if not os.path.isdir('1_loss'):\n",
    "    os.mkdir('1_loss')\n",
    "if not os.path.isdir('1_loss/Fixed_results'):\n",
    "    os.mkdir('1_loss/Fixed_results')\n",
    "\n",
    "print('test start!')\n",
    "start_time = time.time()\n",
    "k=0\n",
    "d=0\n",
    "\n",
    " #1 image test \n",
    "'''\n",
    "mask = Image.open('/home/heejin/Downloads/BDRAR/SBU-shadow/SBU-Test/testB/0014.png')\n",
    "img = Image.open('/home/heejin/Downloads/BDRAR/SBU-shadow/SBU-Test/testA/0014.png')\n",
    "\n",
    "print(img.size())\n",
    "transform = transforms.ToTensor()\n",
    "img = transform(img.resize((224, 224)))\n",
    "mask = transform(mask.resize((224, 224)))\n",
    "\n",
    "fake = torch.cat((img, mask), 1)\n",
    "prediction_fake = net(fake).squeeze()\n",
    "\n",
    "torchvision.utils.save_image(prediction_fake, 'unity/'+str(gug)+'test.png')\n",
    "'''\n",
    "shadow_regions=0\n",
    "non_shadows=0\n",
    "        \n",
    "ori_shadows=0\n",
    "ori_nons=0\n",
    "\n",
    "# test image set\n",
    "with torch.no_grad():\n",
    "    for x_, y_ in enumerate(data_loader):\n",
    "        # train discriminator D\n",
    "        original_image, shadow_mask,shadow_free_image  = y_\n",
    "            \n",
    "        original_image = original_image.to(device)\n",
    "        shadow_mask = shadow_mask.to(device)\n",
    "        shadow_free_image = shadow_free_image.to(device)\n",
    "        \n",
    "        #########################################################\n",
    "        ###Generator#############################\n",
    "        \n",
    "        fake = torch.cat((original_image, shadow_mask), 1)\n",
    "        prediction_fake = net(fake).squeeze()\n",
    "        \n",
    "        torchvision.utils.save_image(prediction_fake, '1_loss/'+str(x_)+'test.png')\n",
    "        prediction_fake = colors.rgb_to_lab(prediction_fake)\n",
    "        torchvision.utils.save_image(prediction_fake, '1_loss/'+str(x_)+str(1)+'test.png')\n",
    "        shadow_free_image = colors.rgb_to_lab(shadow_free_image)\n",
    "        \n",
    "        original_image = colors.rgb_to_lab(original_image)\n",
    "        \n",
    "        shadow_region,non_shadow = rmse(prediction_fake,shadow_free_image,shadow_mask,x_)\n",
    "        \n",
    "        ori_shadow,ori_non = rmse(original_image,shadow_free_image,shadow_mask,x_)\n",
    "        \n",
    "        shadow_regions+=shadow_region\n",
    "        non_shadows+=non_shadow\n",
    "        \n",
    "        ori_shadows+=ori_shadow\n",
    "        ori_nons+=ori_non\n",
    "        \n",
    "    #epoch_end_time = time.time()\n",
    "    #per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    \n",
    "    #fixed_p = 'shadow_result/Fixed_results/shadow_cGAN_' + str(epoch + 1) + '.png'\n",
    "    #show_result((epoch+1), save=True, path=fixed_p)\n",
    "    \n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Test_result(shadow) : \"+str(shadow_regions.item()/540.0))\n",
    "print(\"original difference(shadow) : \"+str(ori_shadows.item()/540.0))\n",
    "print(\"Test_result(non) : \"+str(non_shadows.item()/540.0))\n",
    "print(\"original difference(non) : \"+str(ori_nons.item()/540.0))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Test_result : \"+str((shadow_regions.item()+non_shadows.item())/540.0))\n",
    "print(\"original difference : \"+str((ori_shadows.item()+ori_nons.item())/540.0))\n",
    "\n",
    "\n",
    "print(\"Test finish!... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3gan",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
